<!DOCTYPE html>

<html lang="ja">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>ZEROSEARCH: Incentivize the Search Capability of LLMs without Searching解説</title>
<link href="style.css" rel="stylesheet"/>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
        window.MathJax = {
          tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)'], ['\\\\(', '\\\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]'], ['\\\\[', '\\\\]']]
          }
        };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet"/>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-N7SLXFTVBP"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'G-N7SLXFTVBP');
</script>
</head>
<body>
<div class="container">
<!-- ヘッダー部分 -->
<div class="header">
<div class="title-area">
<h1 class="title">ZEROSEARCH: Incentivize the Search Capability of LLMs without Searching</h1>
<p class="subtitle">None</p>
</div>
<div class="meta-info">
<p>論文解説</p>
</div>
</div>
<div class="section-card" id="Abstract">
<h2 class="section-title"><i class="fas fa-book-open"></i> Abstract</h2>
<div class="bubble-box" style="border-color: var(--color-accent1); margin-bottom: 25px;">
<p style="font-family: 'Yomogi', cursive; font-size: 16px; color: var(--color-dark);">
<i class="fas fa-bullseye" style="color: var(--color-accent1);"></i> <strong>この論文の核心</strong><br/>
            この論文では、<strong class="keyword">ZEROSEARCH</strong> という画期的な<strong class="keyword">強化学習（RL）</strong>フレームワークを提案します。このフレームワークの主な目的は、大規模言語モデル（LLM）が情報検索を行う能力を、<strong class="highlight">実際の検索エンジンを使わずに訓練中に向上させる</strong>ことです。そのために、<strong class="highlight">シミュレートされた検索結果</strong>を活用します。これにより、従来のRLを用いた検索能力向上手法が直面していた大きな課題、すなわち「<span class="badge orange">制御不能な文書品質</span>」と「<span class="badge red">法外に高いAPIコスト</span>」を解決することを目指します。
        </p>
</div>
<h3 class="subsection-title"><i class="fas fa-search-plus"></i> LLMの能力向上と情報検索の重要性</h3>
<div class="content-box">
<p>大規模言語モデル（LLM）は、文章を理解したり生成したりする能力に優れていますが、その知識は訓練データに基づいているため、最新情報に追随できなかったり、誤った情報を生成（ハルシネーション）したりすることがあります。そのため、LLMの<strong class="keyword">推論能力</strong>や<strong class="keyword">生成能力</strong>をさらに向上させるためには、<strong class="highlight">効果的な情報検索</strong>を通じて外部の新しい情報にアクセスできるようにすることが非常に重要です。</p>
<div class="note-box" style="margin-top:15px;">
<p class="note-title"><i class="fas fa-microscope"></i> 既存の研究とそのアプローチ</p>
<p>最近の研究では、<strong class="keyword">強化学習（RL）</strong>という手法を用いて、LLMが<strong class="highlight">実世界の検索エンジン（例：Google検索）と実際にやり取り</strong>しながら、より上手に情報を検索できるようになるための訓練方法が模索されています。これらの研究は有望な結果を示しています。</p>
<div style="text-align: center; margin-top: 10px;">
<span style="font-family: 'Yomogi', cursive; font-size: 1.2em; color: var(--color-primary);">LLM</span>
<i class="fas fa-arrows-alt-h fa-lg" style="margin: 0 10px; color: var(--color-gray);"></i>
<i class="fas fa-globe fa-2x" style="color: var(--color-accent2);"></i>
<span style="font-family: 'Yomogi', cursive; font-size: 1.2em; color: var(--color-primary); margin-left: 5px;">実世界検索エンジン</span>
<i class="fas fa-arrow-right fa-lg" style="margin: 0 10px; color: var(--color-gray);"></i>
<span class="badge green">検索能力向上</span>
</div>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-exclamation-triangle"></i> 既存手法が直面する大きな壁</h3>
<p>しかし、上記のような実世界の検索エンジンを利用したRL訓練には、主に2つの大きな課題があります。</p>
<div class="info-grid" style="margin-top:15px;">
<div class="info-card glass-card">
<h4 style="font-family: 'Kaisei Decol', serif; color: var(--color-secondary); text-align:center;">
<i class="fas fa-file-excel"></i> 課題１：制御不能なドキュメント品質
            </h4>
<p>検索エンジンから返ってくるWebページなどの文書は、その品質が<strong class="highlight">予測不可能</strong>です。時には非常に役立つ情報が得られますが、時には<strong class="keyword">ノイズが多く</strong>、不正確だったり、関連性が低かったりする文書も混じってしまいます。このような品質のばらつきは、LLMの訓練プロセスに<strong class="keyword">ノイズ</strong>をもたらし、学習の<strong class="keyword">不安定化</strong>を引き起こす原因となります。</p>
<div style="text-align:center; margin-top:10px;">
<img alt="不安定な検索結果品質のイメージ図" src="https://via.placeholder.com/200x100/FFF0F5/DC143C?text=不安定な検索結果品質" style="width:70%; border-radius: 8px; border: 2px dashed var(--color-secondary); padding:5px;"/>
<p style="font-family: 'Yomogi', cursive; font-size: 0.9em; color: var(--color-secondary);">📄 文書A (高品質) vs 文書B (低品質) ❓</p>
</div>
</div>
<div class="info-card glass-card">
<h4 style="font-family: 'Kaisei Decol', serif; color: var(--color-secondary); text-align:center;">
<i class="fas fa-wallet"></i> 課題２：法外に高いAPIコスト
            </h4>
<p>強化学習の訓練では、モデルが何度も試行錯誤を繰り返す<strong class="keyword">ロールアウト</strong>というプロセスが不可欠です。これには、場合によっては<strong class="highlight">数十万回</strong>もの検索リクエストを実際の検索エンジンに送信する必要があります。商用の検索APIを利用する場合、これは<strong class="keyword">莫大なAPI利用料金</strong>につながり、研究や開発の<strong class="keyword">スケーラビリティ（拡張性）</strong>を著しく制約してしまいます。</p>
<div style="text-align:center; margin-top:10px;">
<img alt="APIコスト増大のイメージ図" src="https://via.placeholder.com/200x100/E6E6FA/FF4500?text=APIコスト増大" style="width:70%; border-radius: 8px; border: 2px dashed var(--color-secondary); padding:5px;"/>
<p style="font-family: 'Yomogi', cursive; font-size: 0.9em; color: var(--color-secondary);">💸 API呼び出し回数多すぎ！ ➡️ コスト高騰 📈</p>
</div>
</div>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-rocket"></i> 解決策：ZEROSEARCHフレームワークの提案</h3>
<div class="framework-box" style="border-color: var(--color-accent1);">
<p class="framework-title" style="color:var(--color-accent1); border-bottom-color: var(--color-accent1);"><i class="fas fa-lightbulb"></i> ZEROSEARCHの核心アイデア</p>
<p>これらの課題を克服するために、本論文では<strong class="keyword">ZEROSEARCH</strong>という新しい強化学習フレームワークを提案します。ZEROSEARCHの画期的な点は、LLMの検索能力を向上させるための訓練中に、<strong class="highlight">実際の検索エンジンとの対話を一切行わない</strong>という点です。代わりに、<strong class="highlight">シミュレートされた検索結果</strong>を用います。</p>
<div style="text-align: center; margin: 20px 0; padding: 10px; background-color: rgba(92, 184, 92, 0.1); border-radius: 8px;">
<i class="fas fa-desktop fa-2x" style="color: var(--color-accent1);"></i>
<span style="font-family: 'Yomogi', cursive; font-size: 1.3em; color: var(--color-accent1); margin: 0 10px;">ZEROSEARCH: シミュレーションで検索能力を育成！</span>
<i class="fas fa-seedling fa-2x" style="color: var(--color-accent1);"></i>
</div>
</div>
<h4 class="subsection-title" style="font-size: 18px; color: var(--color-accent2);"><i class="fas fa-cogs"></i> ZEROSEARCHのアプローチ：2つの柱</h4>
<p>ZEROSEARCHのアプローチは、主に以下の2つのステップで構成されます。</p>
<div class="two-column" style="margin-top:15px;">
<div class="column">
<div class="process-step">
<div class="step-number" style="background-color: var(--color-accent2);">1</div>
<div class="step-content">
<strong class="keyword" style="color:var(--color-accent2); border-bottom-color: var(--color-accent2);">軽量な教師ありファインチューニング (SFT)</strong>
<p>まず、LLM自身を<strong class="highlight">検索モジュール</strong>（情報を探し出す機能を持つ部品）へと変身させます。これは、比較的少量のデータセットを用いた<strong class="keyword">教師ありファインチューニング</strong>によって行われます。このファインチューニングの結果、LLMは与えられた検索クエリ（質問）に対して、<strong class="keyword">有用な文書</strong>（答えの手がかりになる良い情報）と<strong class="keyword">ノイズの多い文書</strong>（あまり役に立たない情報）の両方を意図的に生成できるようになります。</p>
<div style="text-align:center; margin-top:10px; padding: 10px; background-color: rgba(149, 117, 205, 0.1); border-radius: 8px;">
<i class="fas fa-brain fa-lg" style="color: var(--color-accent2);"></i> <span style="font-family: 'Zen Kurenaido', sans-serif;">LLM</span>
<i class="fas fa-arrow-right fa-lg" style="margin: 0 5px; color: var(--color-gray);"></i>
<i class="fas fa-tools fa-lg" style="color: var(--color-accent2);"></i> <span style="font-family: 'Zen Kurenaido', sans-serif;">SFT</span>
<i class="fas fa-arrow-right fa-lg" style="margin: 0 5px; color: var(--color-gray);"></i>
<i class="fas fa-search fa-lg" style="color: var(--color-accent2);"></i> <span style="font-family: 'Zen Kurenaido', sans-serif;">検索モジュール</span><br/>
<i class="fas fa-file-signature fa-sm" style="color: green; margin-top:5px;"></i> <span style="font-size:0.9em;">有用文書生成</span> /
                        <i class="fas fa-file-excel fa-sm" style="color: red;"></i> <span style="font-size:0.9em;">ノイズ文書生成</span>
</div>
</div>
</div>
</div>
<div class="column">
<div class="process-step">
<div class="step-number" style="background-color: var(--color-accent2);">2</div>
<div class="step-content">
<strong class="keyword" style="color:var(--color-accent2); border-bottom-color: var(--color-accent2);">カリキュラムベースのロールアウト戦略</strong>
<p>次に、強化学習の訓練段階では、<strong class="keyword">カリキュラム学習</strong>に基づいたロールアウト戦略を採用します。これは、訓練が進むにつれて、検索モジュールが生成する文書の品質を<strong class="highlight">徐々に低下させていく</strong>（つまり、ノイズの多い文書の割合を増やしていく）というものです。これにより、LLMは最初は比較的簡単な検索タスク（良質な情報が多い状況）で基本的な検索方法を学び、徐々に<strong class="keyword">より困難な検索シナリオ</strong>（情報が不確かでノイズが多い状況）に直面することで、その<strong class="keyword">推論能力</strong>を段階的に引き出し、鍛え上げていきます。</p>
<div style="text-align:center; margin-top:10px; padding: 10px; background-color: rgba(149, 117, 205, 0.1); border-radius: 8px;">
<i class="fas fa-tasks fa-lg" style="color: var(--color-accent2);"></i> <span style="font-family: 'Zen Kurenaido', sans-serif;">カリキュラム学習</span><br/>
<span style="font-size:0.9em;">易</span> <i class="fas fa-shoe-prints" style="color: green; transform: rotate(-45deg);"></i>
<i class="fas fa-shoe-prints" style="color: orange; transform: rotate(-25deg); margin-left: -5px;"></i>
<i class="fas fa-shoe-prints" style="color: red; margin-left: -5px;"></i> <span style="font-size:0.9em;">難</span><br/>
<span style="font-size:0.8em;">(文書品質: 高 <i class="fas fa-arrow-right"></i> 低)</span>
</div>
</div>
</div>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-chart-line"></i> 実験で示されたZEROSEARCHの驚くべき成果</h3>
<div class="content-box">
<p>📝 広範な実験を行った結果、ZEROSEARCHの有効性が明確に示されました。</p>
<div class="feature-card-grid" style="margin-top:15px;">
<div class="feature-item" style="border: 2px dashed var(--color-primary);">
<i class="fas fa-microchip fa-3x" style="color: var(--color-primary); margin-bottom: 10px;"></i>
<h5 style="font-family: 'Kaisei Decol', serif; color: var(--color-primary); margin-bottom: 5px;">小さなLLMでも効果を発揮</h5>
<p>わずか<strong class="highlight">30億パラメータ（3B）のLLM</strong>を検索モジュールとして使用した場合でも、ZEROSEARCHはLLMの検索能力を効果的に向上させることができました。</p>
</div>
<div class="feature-item" style="border: 2px dashed var(--color-accent1);">
<i class="fas fa-balance-scale fa-3x" style="color: var(--color-accent1); margin-bottom: 10px;"></i>
<h5 style="font-family: 'Kaisei Decol', serif; color: var(--color-accent1); margin-bottom: 5px;">実検索エンジンに匹敵・凌駕</h5>
<p>驚くべきことに、<strong class="highlight">70億パラメータ（7B）のLLM</strong>を検索モジュールとして使用すると、<strong class="keyword">実際の検索エンジンを使った場合と同等の性能</strong>を達成しました。さらに、<strong class="highlight">140億パラメータ（14B）のLLM</strong>を検索モジュールにすると、<strong class="keyword">実際の検索エンジンを超える性能</strong>を示しました！</p>
</div>
<div class="feature-item" style="border: 2px dashed var(--color-secondary);">
<i class="fas fa-universal-access fa-3x" style="color: var(--color-secondary); margin-bottom: 10px;"></i>
<h5 style="font-family: 'Kaisei Decol', serif; color: var(--color-secondary); margin-bottom: 5px;">高い汎用性</h5>
<p>ZEROSEARCHは、様々なサイズの<strong class="keyword">ベースモデル</strong>（特定のタスクに特化していない汎用的なLLM）や<strong class="keyword">インストラクションチューンドモデル</strong>（指示に従うように調整されたLLM）に対しても良好に機能し、幅広い<strong class="keyword">強化学習アルゴリズム</strong>とも互換性があることが確認されました。</p>
</div>
</div>
</div>
<div class="note-box" style="background-color: rgba(74, 111, 165, 0.1); border-left-color: var(--color-primary); margin-top:20px;">
<p class="note-title" style="color: var(--color-primary);"><i class="fas fa-key"></i> まとめ：ZEROSEARCHの意義</p>
<p>ZEROSEARCHは、LLMの検索能力を<strong class="highlight">コスト効率良く、かつ効果的に向上させる</strong>新しい道筋を提示しています。実際の検索エンジンに依存しないため、APIコストや文書品質の不安定さといった問題を回避しつつ、LLMのポテンシャルを最大限に引き出すことが期待されます。これは、特に大規模なLLMモデルの開発や研究において、非常に大きなメリットをもたらす可能性があります。</p>
<div style="text-align: center; margin-top: 15px;">
<span class="badge blue">コスト削減 <i class="fas fa-dollar-sign"></i></span>
<span class="badge green">性能向上 <i class="fas fa-chart-line"></i></span>
<span class="badge purple">高い汎用性 <i class="fas fa-project-diagram"></i></span>
</div>
</div>
</div>
<div class="section-card" id="1_Introduction">
<h2 class="section-title"><i class="fas fa-microscope"></i>1 Introduction</h2>
<div class="bubble-box" style="border-color: var(--color-accent1);">
<p style="font-family: 'Yomogi', cursive; text-align: center; font-size: 1.2em; color: var(--color-accent1);">
<i class="fas fa-bullhorn"></i> このセクションのポイント <i class="fas fa-bullhorn"></i>
</p>
<p>大規模言語モデル（LLM）は非常に高性能ですが、知識が古くなったり、誤った情報を生成する<span class="highlight">「ハルシネーション」</span>という課題があります。この信頼性の問題を解決するためには、LLMが外部の最新情報にアクセスできる能力が不可欠です。既存のアプローチではコストや品質管理の面で限界がありましたが、本論文ではこれらの課題を克服するため、<span class="keyword">実世界の検索エンジンを一切使わずにLLMに検索戦略を学習させる</span>、画期的な強化学習フレームワーク<strong style="color: var(--color-secondary); font-family: 'Kaisei Decol', serif;">「ZEROSEARCH」</strong>を提案します。ZEROSEARCHは、<span class="highlight">LLM自身が持つ知識を活用して検索環境をシミュレート</span>することで、コストを抑えつつ効果的にLLMの検索能力を向上させることを目指します。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-brain"></i>LLMの現状と課題</h3>
<p>近年、<span class="keyword">大規模言語モデル (LLM)</span> [36, 3, 46] は目覚ましい発展を遂げています。これらのモデルは、まるで人間のようにテキストを理解し、生成する能力を持っています。</p>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：大規模言語モデル (LLM)</div>
<p><strong style="color: var(--color-primary);">大規模言語モデル (Large Language Models, LLM)</strong> とは、非常に大量のテキストデータを用いて学習されたニューラルネットワークモデルのことです。Transformerアーキテクチャをベースにしていることが多く、人間が書いたような自然な文章を生成したり、質問に答えたり、文章を要約したりと、多様な言語タスクに対応できます。代表的なものにGPTシリーズなどがあります。</p>
</div>
<p>具体的には、以下のような様々な<span class="keyword">ダウンストリームタスク</span>で驚くべき性能を示しています。</p>
<div class="feature-card-grid">
<div class="feature-item">
<i class="fas fa-calculator fa-2x" style="color: var(--color-accent1);"></i>
<p><strong>数学的推論</strong><br/>[39, 40, 10, 21]</p>
<p class="reference">複雑な計算問題や論理パズルを解く能力。</p>
</div>
<div class="feature-item">
<i class="fas fa-question-circle fa-2x" style="color: var(--color-accent2);"></i>
<p><strong>質問応答 (QA)</strong><br/>[39, 40, 10, 21]</p>
<p class="reference">与えられた質問に対して的確な回答を生成する能力。</p>
</div>
<div class="feature-item">
<i class="fas fa-laptop-code fa-2x" style="color: var(--color-accent3);"></i>
<p><strong>コード生成</strong><br/>[39, 40, 10, 21]</p>
<p class="reference">プログラミング言語のコードを自動生成する能力。</p>
</div>
</div>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：ダウンストリームタスク</div>
<p><strong style="color: var(--color-primary);">ダウンストリームタスク (Downstream Tasks)</strong> とは、大規模なデータセットで事前学習されたモデル（例: LLM）を、より特定の目的や応用に合わせて利用する具体的なタスクのことです。例えば、事前学習済みLLMを質問応答システムや機械翻訳、感情分析などの特定のタスクにファインチューニングして利用する場合、これらがダウンストリームタスクにあたります。</p>
</div>
<p>しかし、これらの強力なLLMにも無視できない課題が存在します。</p>
<div class="challenge-box">
<div class="challenge-title"><i class="fas fa-exclamation-triangle"></i> LLMの抱える課題</div>
<ul class="unstyled-list">
<li><i class="fas fa-lock" style="color: var(--color-secondary);"></i> <strong class="keyword">静的な知識:</strong> LLMの知識は、事前学習時に使用されたデータに限定されます。つまり、学習データに含まれていない新しい情報や、学習後の世界の出来事については基本的に知りません。</li>
<li><i class="fas fa-ghost" style="color: var(--color-secondary);"></i> <strong class="keyword">ハルシネーション (幻覚):</strong> 事実に基づかない情報や、もっともらしい嘘を生成してしまうことがあります [12, 34, 45]。これは、モデルが内部知識だけで応答を創作しようとする場合に起こりやすいです。</li>
<li><i class="fas fa-calendar-times" style="color: var(--color-secondary);"></i> <strong class="keyword">古い情報:</strong> 知識が学習時点のものであるため、情報が時間とともに古くなってしまう可能性があります。</li>
</ul>
<p>これらの課題は、LLMを実世界のアプリケーションで利用する際の<span class="highlight">信頼性を損なう大きな要因</span>となっています。</p>
</div>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：ハルシネーション</div>
<p><strong style="color: var(--color-primary);">ハルシネーション (Hallucination)</strong> とは、AIモデル、特にLLMが、学習データに含まれていない情報や事実に反する情報を、あたかも真実であるかのように生成する現象を指します。「幻覚」とも訳されます。これは、モデルが質問に対して最もそれらしい応答を生成しようとする結果、不確かな情報を補完したり、誤った推論を行ったりするために発生します。</p>
</div>
<p><i class="fas fa-lightbulb" style="color: var(--color-accent1);"></i> そこで、LLMがより正確で信頼性の高い応答を生成するためには、<span class="highlight">外部の情報源にアクセスし、その情報を活用できるようにすること</span>が不可欠です。</p>
<div style="text-align: center; margin: 20px 0;">
<i class="fas fa-brain fa-3x" style="color: var(--color-primary);"></i>
<i class="fas fa-long-arrow-alt-right fa-2x" style="color: var(--color-gray); margin: 0 10px;"></i>
<i class="fas fa-globe fa-3x" style="color: var(--color-accent2);"></i>
<p style="font-family: 'Yomogi', cursive; margin-top: 5px;">LLMの内部知識 ＋ 外部情報アクセス ＝ より信頼性の高い応答✨</p>
</div>
<h3 class="subsection-title"><i class="fas fa-cogs"></i>既存の知識拡張アプローチ</h3>
<p>LLMの知識限界に対処するため、これまで様々なアプローチが研究されてきました。その中でも代表的なものが<span class="keyword">Retrieval-Augmented Generation (RAG)</span> です。</p>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：Retrieval-Augmented Generation (RAG)</div>
<p><strong style="color: var(--color-primary);">Retrieval-Augmented Generation (RAG)</strong> とは、「検索拡張生成」と訳され、LLMが応答を生成する際に、外部の知識ベース（例: Wikipedia、社内文書データベースなど）から関連情報を検索(Retrieve)し、その検索結果を考慮に入れて応答を生成(Generate)する技術です [29, 33, 30, 6, 2, 27]。これにより、LLMは自身の内部知識にない情報や最新情報に基づいて、より正確で信頼性の高い応答を生成できるようになります。</p>
</div>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));">
<div class="info-card">
<h4 class="subsection-title" style="font-size: 16px; color: var(--color-dark); border-left-color: var(--color-dark);"><i class="fas fa-feather-alt"></i>初期のRAG戦略：プロンプトベース</h4>
<p>初期のRAG研究では、プロンプトエンジニアリングを駆使してLLMを誘導する戦略が中心でした[44, 28, 43, 15, 33, 22]。</p>
<div class="pipeline">
<div class="pipeline-step"><i class="fas fa-search"></i> <strong>クエリ生成:</strong> ユーザーの質問から検索に適したクエリをLLMが生成。</div>
<div class="pipeline-step"><i class="fas fa-project-diagram"></i> <strong>クエリ分解:</strong> 複雑な質問を複数の単純なクエリにLLMが分解。</div>
<div class="pipeline-step"><i class="fas fa-sync-alt"></i> <strong>マルチターン情報検索:</strong> 必要に応じて複数回の検索と情報統合をLLMが実行。</div>
</div>
<div class="challenge-box" style="background-color: rgba(255, 165, 0, 0.1); border-left-color: orange; margin-top:10px;">
<div class="challenge-title" style="color: orange;"><i class="fas fa-tools"></i> 課題</div>
<ul class="unstyled-list">
<li><i class="fas fa-pencil-ruler" style="color: orange;"></i> <span class="highlight">綿密なプロンプト設計</span>が必要。</li>
<li><i class="fas fa-brain" style="color: orange;"></i> モデルの<span class="highlight">高度な推論能力</span>が要求される。</li>
</ul>
</div>
</div>
<div class="info-card">
<h4 class="subsection-title" style="font-size: 16px; color: var(--color-dark); border-left-color: var(--color-dark);"><i class="fas fa-rocket"></i>効率改善とさらなる進展</h4>
<p>プロンプトベース戦略の課題を克服し、効率を高めるために、以下のような研究が進められました。</p>
<ul class="unstyled-list" style="margin-top: 10px;">
<li style="margin-bottom:10px;">
<span class="badge blue"><i class="fas fa-microchip"></i> SFT</span>
<strong class="keyword">教師ありファインチューニング (Supervised Fine-Tuning, SFT)</strong> [1, 24, 11]: 比較的小規模なLLMの性能を、特定の検索タスクに合わせてSFTで強化するアプローチ。
                </li>
<li>
<span class="badge purple"><i class="fas fa-dice-d20"></i> MCTS</span>
<strong class="keyword">テスト時スケーリング技術 (Test-time scaling techniques)</strong> [25, 14, 47, 13]: 例えば<strong class="keyword">モンテカルロ木探索 (Monte Carlo Tree Search, MCTS)</strong> のような手法を用い、推論時に動的に検索空間を拡大するアプローチ。
                    <div class="challenge-box" style="background-color: rgba(255, 99, 71, 0.1); border-left-color: tomato; margin-top:10px;">
<div class="challenge-title" style="color: tomato;"><i class="fas fa-hourglass-half"></i> 課題</div>
<p><i class="fas fa-server" style="color: tomato;"></i> <span class="highlight">計算オーバーヘッドが大きい</span>ため、実用的な展開が難しい。</p>
</div>
</li>
</ul>
</div>
</div>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：SFT (Supervised Fine-Tuning)</div>
<p><strong style="color: var(--color-primary);">教師ありファインチューニング (SFT)</strong> とは、大規模なデータで事前学習されたモデル（例: LLM）を、特定のタスクに適応させるために、そのタスクに関連する「入力と正解出力のペア」からなる教師ありデータセットを使って追加学習させるプロセスです。これにより、モデルは汎用的な能力を維持しつつ、特定のタスクにおける性能を向上させることができます。</p>
</div>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：MCTS (Monte Carlo Tree Search)</div>
<p><strong style="color: var(--color-primary);">モンテカルロ木探索 (MCTS)</strong> は、主にゲームAIなどで用いられる探索アルゴリズムの一種です。多数のランダムなシミュレーション（プレイアウト）を行い、その結果を木構造に記録・評価することで、最も有望な手や行動を選択します。LLMの文脈では、最適な情報検索戦略や応答生成パスを見つけるために応用されることがあります。</p>
</div>
<div class="arrow-connector"></div>
<p>最近では、<span class="keyword">強化学習 (Reinforcement Learning, RL)</span> がLLMの性能をさらに向上させる有望な戦略として注目されています。RLは、LLMの<span class="highlight">推論能力や意思決定能力</span>を高めるのに役立ちます [7, 9]。</p>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：強化学習 (RL)</div>
<p><strong style="color: var(--color-primary);">強化学習 (Reinforcement Learning, RL)</strong> とは、エージェント（学習者、この場合はLLM）が、ある環境内で行動を選択し、その行動の結果として得られる報酬（または罰）に基づいて、将来の行動戦略を改善していく機械学習の手法です。試行錯誤を通じて、最大の累積報酬を得るための方策（ポリシー）を学習します。</p>
<div style="text-align: center; margin-top: 10px;">
<i class="fas fa-robot fa-2x" style="color: var(--color-accent1);"></i> (エージェント)
            <i class="fas fa-exchange-alt fa-2x" style="color: var(--color-gray); margin: 0 5px;"></i>
<i class="fas fa-globe-americas fa-2x" style="color: var(--color-accent2);"></i> (環境)
            <i class="fas fa-arrow-right fa-2x" style="color: var(--color-gray); margin: 0 5px;"></i>
<i class="fas fa-trophy fa-2x" style="color: var(--color-accent3);"></i> (報酬)
        </div>
</div>
<p>特に、OpenAI-o1やDeepSeek-R1といったRLベースのモデルは、明示的なステップバイステップの指示なしに、<span class="highlight">報酬主導の学習のみ</span>で論理的推論や反復的推論において大幅な進歩を示しています [19]。</p>
<p>この流れの中で、RLを用いて<span class="keyword">ポリシーモデル</span>を訓練し、より効果的に関連情報を検索できるようにする研究も進んでいます。</p>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：ポリシーモデル (Policy Model)</div>
<p><strong style="color: var(--color-primary);">ポリシーモデル (Policy Model)</strong> とは、強化学習において、エージェントが特定の状態（状況）でどのような行動を取るべきかという「方策（ポリシー）」を学習・表現するモデルのことです。LLMをポリシーモデルとして使う場合、LLMは現在の文脈やクエリに基づいて、次にどのような検索クエリを発行するか、あるいはどのような応答を生成するかといった行動を決定します。</p>
</div>
<div class="info-grid">
<div class="info-card glass-card">
<h4 class="subsection-title" style="font-size: 16px; color: var(--color-dark); border-left-color: var(--color-dark);"><i class="fas fa-search-dollar"></i>RLを用いた情報検索モデルの例</h4>
<ul class="unstyled-list">
<li><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i> <strong>Search-R1</strong> [16]</li>
<li><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i> <strong>R1-Searcher</strong> [35]</li>
<li><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i> <strong>ReSearch</strong> [18]</li>
</ul>
</div>
<div class="info-card glass-card">
<h4 class="subsection-title" style="font-size: 16px; color: var(--color-dark); border-left-color: var(--color-dark);"><i class="fab fa-google"></i>実世界検索エンジンとの連携</h4>
<p><strong>DeepResearcher</strong> [48] や <strong>WebThinker</strong> [23] のような研究では、Googleなどの商用検索エンジンと<span class="highlight">ライブで対話</span>することで、モデルを実世界のウェブ検索に近い環境で訓練しています。</p>
</div>
</div>
<p>これらの進歩にもかかわらず、RLと実世界の検索シナリオを統合するには、いくつかの大きな課題があります。</p>
<div class="two-column">
<div class="column">
<div class="challenge-box">
<div class="challenge-title"><i class="fas fa-file-excel"></i> (1) 制御不能な文書品質</div>
<p>ライブ検索エンジンから取得される文書の品質は予測不可能であることが多く、訓練プロセスに<span class="highlight">ノイズや不安定性</span>をもたらします。例えば、検索結果に不適切な情報や関連性の低い情報が含まれていると、モデルの学習が妨げられる可能性があります。</p>
<div style="text-align: center; margin-top: 10px;">
<i class="fas fa-file-alt fa-2x" style="color: green;"></i> <span style="font-family: 'Yomogi';">高品質文書</span> vs <i class="fas fa-file-excel fa-2x" style="color: red;"></i> <span style="font-family: 'Yomogi';">低品質文書</span>
</div>
</div>
</div>
<div class="column">
<div class="challenge-box">
<div class="challenge-title"><i class="fas fa-wallet"></i> (2) 法外に高いAPIコスト</div>
<p>RLの訓練では、<span class="keyword">ロールアウト</span>と呼ばれるシミュレーションを頻繁に（場合によっては数十万回も）行う必要があります。実世界の検索エンジンAPIを利用する場合、これが<span class="highlight">莫大な費用</span>につながり、スケーラビリティを著しく制限します。</p>
<div style="text-align: center; margin-top: 10px;">
<i class="fas fa-coins fa-2x" style="color: gold;"></i> <i class="fas fa-arrow-up fa-2x" style="color: red;"></i> <span style="font-family: 'Yomogi';">APIコスト増大</span>
</div>
</div>
</div>
</div>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：ロールアウト (Rollout)</div>
<p><strong style="color: var(--color-primary);">ロールアウト (Rollout)</strong> とは、強化学習において、現在のポリシーモデル（方策）に従ってエージェントが一連の行動を実際に行い、その結果として得られる経験（状態、行動、報酬の系列）を収集するプロセスのことです。この収集された経験データは、ポリシーモデルをさらに改善するための学習に使われます。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-paper-plane"></i>本論文の提案：ZEROSEARCH</h3>
<p>これらの課題に対処するため、本論文では<strong style="color: var(--color-secondary); font-family: 'Kaisei Decol', serif;">ZEROSEARCH</strong>という新しい強化学習フレームワークを提案します。ZEROSEARCHの核心は、<span class="highlight">実世界の検索エンジンと対話することなく、LLMに検索戦略を学習させる</span>点にあります。</p>
<div class="framework-box">
<div class="framework-title"><i class="fas fa-lightbulb"></i> ZEROSEARCHの重要な洞察</div>
<p>大規模な事前学習を通じて、LLMは広範な世界知識を獲得しており、検索クエリが与えられれば<span class="highlight">関連文書を生成する能力</span>を既に持っているという点です [44]。</p>
<p>実際の検索エンジンとシミュレーションLLMの主な違いは、返されるコンテンツの<span class="keyword">テキストスタイル</span>にあります。しかし、<strong class="keyword">軽量な教師ありファインチューニング (lightweight supervised fine-tuning)</strong> を施すことで、比較的小さなLLMでも実際の検索エンジンの振る舞いを効果的にシミュレートできます。</p>
</div>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));">
<div class="info-card">
<h4 class="subsection-title" style="font-size: 16px; color: var(--color-dark); border-left-color: var(--color-dark);"><i class="fas fa-dollar-sign"></i>APIコストの排除</h4>
<p>LLMをシミュレータとして使用することで、高価な検索エンジンAPIの利用コストを完全に排除できます。</p>
<div style="text-align: center; margin-top:15px;">
<i class="fas fa-search-dollar fa-3x" style="color: var(--color-accent1);"></i>
<p style="font-family: 'Yomogi';">APIコスト <strong style="color: red;">ゼロ</strong></p>
</div>
</div>
<div class="info-card">
<h4 class="subsection-title" style="font-size: 16px; color: var(--color-dark); border-left-color: var(--color-dark);"><i class="fas fa-sliders-h"></i>文書品質の制御</h4>
<p>LLMによる文書生成の大きな利点は、<span class="highlight">文書品質を制御できる</span>ことです。SFT中に、正しい答えに繋がる文書と誤った答えに繋がる文書をプロンプト設計によって区別します。これにより、シミュレーションLLMはプロンプト内の数語を調整するだけで、<span class="keyword">有用な文書</span>または<span class="keyword">ノイズの多い文書</span>を生成するように学習できます。</p>
<div class="two-column" style="margin-top:10px;">
<div class="column" style="text-align: center;">
<i class="fas fa-file-signature fa-2x" style="color: var(--color-accent2);"></i>
<p><span class="badge purple">プロンプトA</span> <i class="fas fa-arrow-right"></i> <span style="font-family: 'Yomogi';">有用な文書</span></p>
</div>
<div class="column" style="text-align: center;">
<i class="fas fa-file-signature fa-2x" style="color: var(--color-secondary);"></i>
<p><span class="badge orange">プロンプトB</span> <i class="fas fa-arrow-right"></i> <span style="font-family: 'Yomogi';">ノイズ文書</span></p>
</div>
</div>
</div>
</div>
<div class="note-box">
<div class="note-title"><i class="fas fa-graduation-cap"></i> カリキュラムロールアウトメカニズムの導入</div>
<p>この文書品質制御能力を基盤として、訓練中に<strong class="keyword">カリキュラムロールアウト (curriculum rollout)</strong> メカニズムを導入します。これは、生成される文書の品質を時間とともに徐々に低下させ、ますます困難な検索シナリオをシミュレートする手法です。</p>
<div class="pipeline" style="margin-top:15px;">
<div class="pipeline-step" style="background-color: #e6ffe6;"><strong>初期段階:</strong> 高品質な文書を提供 <i class="fas fa-smile-beam" style="color: green;"></i><br/>→ ポリシーモデルは基本的な出力形式とタスク要件を学習。</div>
<div class="pipeline-step" style="background-color: #fff0e6;"><strong>進行段階:</strong> 徐々にノイズの多い文書を導入 <i class="fas fa-meh" style="color: orange;"></i><br/>→ ポリシーモデルはより困難でノイズの多い検索シナリオに適応。</div>
</div>
<p>これにより、ポリシーモデルはまず基本的な事項を習得し、その後、徐々により挑戦的でノイズの多い検索状況に適応していくことができます。</p>
</div>
<div class="glass-card">
<h4 class="subsection-title" style="font-size: 16px; color: var(--color-dark); border-left-color: var(--color-dark);"><i class="fas fa-expand-arrows-alt"></i> ZEROSEARCHの強力なスケーラビリティ</h4>
<p>ZEROSEARCHは非常に高いスケーラビリティを示します。GPUの数を増やすことで、シミュレーションLLMの<span class="highlight">生成スループットが大幅に向上</span>し、効率的な大規模ロールアウトが可能になります。</p>
<div style="text-align:center; margin: 15px 0;">
<i class="fas fa-server fa-2x" style="color: var(--color-primary);"></i> <span style="font-family: 'Yomogi';">GPU数 <i class="fas fa-arrow-up" style="color: var(--color-accent1);"></i></span>
<i class="fas fa-long-arrow-alt-right fa-2x" style="color: var(--color-gray); margin: 0 10px;"></i>
<i class="fas fa-tachometer-alt fa-2x" style="color: var(--color-primary);"></i> <span style="font-family: 'Yomogi';">生成速度 <i class="fas fa-arrow-up" style="color: var(--color-accent1);"></i></span>
</div>
<p>実験結果によれば、</p>
<ul class="unstyled-list">
<li><i class="fas fa-check" style="color: var(--color-accent1);"></i> <span class="badge blue">3Bパラメータ</span>のLLMをシミュレート検索エンジンとして使用するだけで、ポリシーモデルの実検索エンジン利用能力を効果的に向上させることができました。</li>
<li><i class="fas fa-check" style="color: var(--color-accent1);"></i> <span class="badge purple">7Bパラメータ</span>のLLMをシミュレータとして使用すると、実検索エンジンで訓練した場合と同等の性能を達成しました。</li>
<li><i class="fas fa-check" style="color: var(--color-accent1);"></i> <span class="badge orange">14Bパラメータ</span>のシミュレータでは、実検索エンジンを超える性能さえ示しました。</li>
</ul>
</div>
<div class="feature-card-grid">
<div class="feature-item">
<i class="fas fa-universal-access fa-2x" style="color: var(--color-accent2);"></i>
<p><strong>汎用性</strong></p>
<p class="reference">ZEROSEARCHは、様々なパラメータサイズの<span class="keyword">ベースモデル</span>および<span class="keyword">instruction-tunedモデル</span>の両方に対応しており、個別の教師ありウォームアップ段階は不要です。</p>
</div>
<div class="feature-item">
<i class="fas fa-puzzle-piece fa-2x" style="color: var(--color-accent3);"></i>
<p><strong>互換性</strong></p>
<p class="reference"><span class="keyword">REINFORCE</span> [38]、<span class="keyword">Proximal Policy Optimization (PPO)</span> [31]、<span class="keyword">Group Relative Policy Optimization (GRPO)</span> [32, 7] といった広く使用されているRLアルゴリズムとシームレスに統合できます。</p>
</div>
</div>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：ベースモデル vs Instruction-tunedモデル</div>
<p><strong style="color: var(--color-primary);">ベースモデル (Base Model)</strong> は、大規模なテキストコーパスで事前学習された直後のLLMを指します。広範な知識を持っていますが、特定の指示に従う能力や対話能力は限定的です。<br/>
<strong style="color: var(--color-secondary);">Instruction-tunedモデル</strong> は、ベースモデルをさらに「指示（instruction）」と「その指示に対する望ましい応答」のペアデータセットでファインチューニングしたものです。これにより、ユーザーの指示をよりよく理解し、それに従った応答を生成する能力が向上します。</p>
</div>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i>用語解説：RLアルゴリズム</div>
<p><strong style="color: var(--color-primary);">REINFORCE</strong>: 方策勾配法の一種で、単純ながらも基本的なRLアルゴリズムです。<br/>
<strong style="color: var(--color-secondary);">PPO (Proximal Policy Optimization)</strong>: 方策の更新ステップを制限することで学習を安定させる、より高度な方策勾配アルゴリズムです。多くのRLタスクで高い性能を示します。<br/>
<strong style="color: var(--color-accent1);">GRPO (Group Relative Policy Optimization)</strong>: PPOをベースに、複数の方策候補グループの中から相対的に良い方策を選択するように学習するアルゴリズムで、特定のタスクでPPOを上回ることがあります。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-medal"></i>本研究の貢献</h3>
<p>本研究の貢献は以下のようにまとめられます。</p>
<div class="info-grid">
<div class="info-card" style="border-left: 5px solid var(--color-accent1);">
<p><span class="badge green" style="background-color: var(--color-accent1);"><i class="fas fa-lightbulb"></i> 提案</span><br/>訓練中に実世界の検索エンジンと対話することなく、LLMが実検索エンジンを使用する能力を向上させる新しい強化学習フレームワーク<strong style="color: var(--color-secondary); font-family: 'Kaisei Decol', serif;">ZEROSEARCH</strong>を提案します。</p>
</div>
<div class="info-card" style="border-left: 5px solid var(--color-accent2);">
<p><span class="badge purple" style="background-color: var(--color-accent2);"><i class="fas fa-cogs"></i> 手法</span><br/>教師ありファインチューニングを通じてLLMを、クエリに応じて有用な文書とノイズの多い文書の両方を生成できる検索モジュールに変換します。さらに、カリキュラムロールアウトメカニズムを導入し、ますます困難な検索シナリオにモデルを段階的にさらすことで、モデルの推論能力を引き出します。</p>
</div>
<div class="info-card" style="border-left: 5px solid var(--color-accent3);">
<p><span class="badge yellow" style="background-color: var(--color-accent3); color: var(--color-dark);"><i class="fas fa-chart-line"></i> 実証</span><br/>ドメイン内およびドメイン外のデータセットで広範な実験を実施。結果は、ZEROSEARCHがAPIコストをゼロに抑えながら、実検索エンジンベースのモデルを上回る性能を示すことを明らかにしました。さらに、様々なパラメータサイズのベースモデルおよびinstruction-tuned LLMにわたって優れた汎化性能を示し、さまざまな強化学習アルゴリズムをサポートします。</p>
</div>
</div>
</div>
<div class="section-card" id="2_Related_Work">
<h2 class="section-title"><i class="fas fa-book-open"></i> 2 Related Work</h2>
<p style="margin-bottom: 20px;">このセクションでは、本論文で提案する<span class="keyword">ZEROSEARCH</span>が、既存の研究の中でどのように位置づけられるかを解説します。特に重要な関連分野として、<span class="highlight">「検索拡張生成（RAG）」</span>と<span class="highlight">「強化学習による探索学習」</span>の2つの柱に焦点を当てます。これらの分野におけるこれまでの進展と、依然として残されている課題を明らかにすることで、ZEROSEARCHの新規性と貢献を明確にしていきます。✏️</p>
<h3 class="section-title"><i class="fas fa-microscope"></i> 2.1 Retrieval-Augmented Generation</h3>
<div class="definition-box" style="margin-bottom: 20px;">
<div class="definition-title"><i class="fas fa-lightbulb"></i> 検索拡張生成 (RAG) とは？</div>
<p><span class="keyword">検索拡張生成 (Retrieval-Augmented Generation, RAG)</span> は、大規模言語モデル (LLM) が情報を生成する際に、外部の知識源から関連情報を検索し、その情報を活用することで、生成される内容の<span class="highlight">正確性や信頼性を向上させる</span>ための技術です。これにより、LLMがより事実に基づいた、最新の情報を含む回答を生成できるようになることを目指しています。</p>
</div>
<div class="framework-box">
<div class="framework-title"><i class="fas fa-pencil-ruler"></i> 初期のRAGアプローチ：プロンプトベースの手法</div>
<p>初期の研究では、主に<span class="keyword">プロンプトベース</span>のアプローチが採用されました。これは、LLMに対する指示（プロンプト）を工夫することで、以下のような処理を誘導するものです：</p>
<ul class="unstyled-list" style="padding-left: 20px; margin-top: 10px;">
<li><i class="fas fa-search" style="color: var(--color-primary);"></i> 検索クエリの生成 <sup>[44, 28]</sup></li>
<li><i class="fas fa-project-diagram" style="color: var(--color-primary);"></i> クエリの分解（複雑な質問を簡単な質問に分ける）<sup>[43]</sup></li>
<li><i class="fas fa-sync-alt" style="color: var(--color-primary);"></i> 複数ターンにわたる情報検索 <sup>[15, 33, 22]</sup></li>
</ul>
<div class="challenge-box" style="margin-top: 15px;">
<div class="challenge-title"><i class="fas fa-exclamation-triangle"></i> プロンプトベースの課題</div>
<p>これらの手法は一定の有効性を示しましたが、しばしば<span class="highlight">非常に複雑なプロンプトエンジニアリング</span>（職人技的なプロンプト調整）を必要とし、また、モデルの<span class="highlight">高度な推論能力に大きく依存する</span>という課題がありました。</p>
</div>
</div>
<div class="arrow-connector"></div>
<div class="framework-box">
<div class="framework-title"><i class="fas fa-cogs"></i> 次のステップ：教師ありファインチューニング (SFT)</div>
<p>プロンプトベース手法の課題を受け、効率を改善し、特に強力な（しかし運用コストが高い、あるいは内部が公開されていない）<span class="keyword">ブラックボックスLLM</span>への依存を減らすために、より小規模なLLMを<span class="keyword">教師ありファインチューニング (Supervised Fine-Tuning, SFT)</span> によって強化する戦略が提案されました。代表的な手法として以下のようなものがあります：</p>
<div class="info-grid" style="margin-top: 15px;">
<div class="info-card">
<p><span class="badge blue">Self-RAG</span> <sup>[1]</sup><br/>
<i class="fas fa-comments" style="color: var(--color-accent1);"></i> <span class="keyword">自己反射メカニズム</span>を採用し、モデルが生成した出力の質を自ら評価・批判し、予測された「反射トークン」に基づいて反復的に出力を洗練させます。</p>
</div>
<div class="info-card">
<p><span class="badge green">RetroLLM</span> <sup>[24]</sup><br/>
<i class="fas fa-file-alt" style="color: var(--color-accent1);"></i> <span class="keyword">制約付きデコーディング</span>という技術を利用して、LLMが知識コーパスから直接、きめ細かい証拠（エビデンス）を生成できるようにし、検索と生成のプロセスを統合します。</p>
</div>
</div>
</div>
<div class="arrow-connector"></div>
<div class="framework-box">
<div class="framework-title"><i class="fas fa-chart-line"></i> 最近の進展：テスト時スケーリング技術</div>
<p>さらに最近では、推論時（テスト時）に探索空間を動的に拡大する<span class="keyword">テスト時スケーリング技術</span> <sup>[25, 14, 47, 13]</sup>も開発されています。特に注目されているのが<span class="keyword">モンテカルロ木探索 (Monte Carlo Tree Search, MCTS)</span>の活用です。</p>
<div class="info-grid" style="margin-top: 15px;">
<div class="info-card">
<p><span class="badge purple">RAG-star</span> <sup>[13]</sup><br/>
<i class="fas fa-sitemap" style="color: var(--color-accent2);"></i> 検索によって得られた情報を<span class="highlight">ツリーベースの推論プロセス</span>に統合し、より深い思考や計画を可能にします。</p>
</div>
<div class="info-card">
<p><span class="badge orange">AirRAG</span> <sup>[5]</sup><br/>
<i class="fas fa-feather-alt" style="color: var(--color-accent2);"></i> MCTSを利用してLLMが本来持っている<span class="highlight">内的な推論能力を活性化</span>し、解答空間を拡大します。</p>
</div>
</div>
</div>
<div class="challenge-box" style="margin-top: 20px;">
<div class="challenge-title"><i class="fas fa-battery-half"></i> RAG全体の共通課題</div>
<p>これらのRAG関連アプローチは有望な結果を示してはいるものの、多くの場合、<span class="highlight">計算オーバーヘッドが大きい</span>という問題があり、その実用性が限定されてしまうという課題を抱えています。</p>
</div>
<h3 class="section-title" style="margin-top: 30px;"><i class="fas fa-robot"></i> 2.2 Learning to Search through Reinforcement Learning</h3>
<div class="note-box" style="margin-bottom: 20px;">
<div class="note-title"><i class="fas fa-brain"></i> 強化学習 (RL) の可能性</div>
<p><span class="keyword">強化学習 (Reinforcement Learning, RL)</span> は、エージェントが環境との相互作用を通じて試行錯誤し、報酬を最大化するような行動戦略を学習する機械学習の一分野です。近年、LLMの<span class="highlight">推論能力や意思決定能力を強化する</span>ための有望なパラダイムとして浮上しています<sup>[7, 9]</sup>。</p>
</div>
<p><i class="fas fa-trophy" style="color: var(--color-accent3);"></i> <span class="highlight">OpenAI-o1</span> や <span class="highlight">DeepSeek-R1</span> <sup>[19]</sup> といったRLベースのモデルは、人間が作成した詳細なステップごとの教師データなしに、<span class="keyword">報酬信号のみを頼り</span>にして、論理的推論や反復的推論において顕著な能力向上を示しています。</p>
<div class="framework-box" style="margin-top: 20px;">
<div class="framework-title"><i class="fas fa-search-location"></i> RL技術による情報検索の最適化</div>
<p>LLMが効果的に情報を検索できるように訓練するために、RL技術を活用する研究もいくつか行われています。以下はその代表例です：</p>
<div class="info-grid" style="margin-top: 15px;">
<div class="info-card">
<p><span class="badge blue">Search-R1</span> <sup>[16]</sup><br/>
<i class="fas fa-tasks" style="color: var(--color-primary);"></i> 強化学習を利用して、段階的な推論プロセスの途中で<span class="highlight">複数の検索クエリを自律的に生成する</span>ことを学習します。</p>
</div>
<div class="info-card">
<p><span class="badge green">R1-Searcher</span> <sup>[35]</sup><br/>
<i class="fas fa-route" style="color: var(--color-primary);"></i> 検索能力を向上させることを目的とした、<span class="highlight">2段階からなる結果ベースのRL手法</span>を提案しています。</p>
</div>
<div class="info-card">
<p><span class="badge purple">ReSearch</span> <sup>[18]</sup><br/>
<i class="fas fa-history" style="color: var(--color-primary);"></i> 中間的な推論ステップに関する教師データを一切使用せず、<span class="highlight">検索を通じて推論する</span>ことをモデルに学習させます。</p>
</div>
</div>
</div>
<div class="challenge-box" style="margin-top: 20px;">
<div class="challenge-title"><i class="fas fa-map-marked-alt"></i> 既存RL検索手法の限界</div>
<p>しかし、これらの手法の多くは、Wikipediaのような<span class="keyword">静的でローカルなテキストコーパス</span>（事前に用意された固定的なデータセット）を利用しており、<span class="highlight">実世界のインタラクションの複雑さ</span>（情報の動的な変化や多様性など）を十分に捉えられていないという限界がありました。</p>
</div>
<div class="arrow-connector"></div>
<p style="text-align: center; font-family: 'Yomogi', cursive; color: var(--color-secondary);"><i class="fas fa-globe-americas"></i> 実世界への橋渡し：商用検索エンジンとの連携</p>
<div class="framework-box" style="margin-top: 10px;">
<div class="framework-title"><i class="fas fa-link"></i> ギャップを埋める試み</div>
<p>このギャップを埋めるために、<span class="keyword">DeepResearcher</span> <sup>[48]</sup> や <span class="keyword">WebThinker</span> <sup>[23]</sup> のような研究では、Googleなどの<span class="highlight">実際の商用検索エンジンと直接対話する</span>アプローチを導入しました。これにより、訓練環境を現実世界の検索シナリオに近づけることが可能になりました。</p>
</div>
<div class="challenge-box" style="margin-top: 20px;">
<div class="challenge-title"><i class="fas fa-exclamation-circle"></i> リアルタイム検索手法の新たな課題</div>
<p>これらのリアルタイム検索を利用する手法は優れた性能を達成しつつありますが、以下のような重大な課題に直面しています：</p>
<ul class="unstyled-list" style="padding-left: 20px; margin-top: 10px;">
<li><span class="badge orange" style="margin-right: 5px;">課題 1</span> <i class="fas fa-file-excel" style="color: var(--color-secondary);"></i> <span class="keyword">予測不可能な文書品質</span>: 検索エンジンから返される文書の品質はしばしば予測不可能であり、訓練プロセスにノイズや不安定性をもたらす可能性があります。</li>
<li><span class="badge orange" style="margin-right: 5px;">課題 2</span> <i class="fas fa-wallet" style="color: var(--color-secondary);"></i> <span class="keyword">法外に高いAPIコスト</span>: 強化学習の訓練には頻繁なロールアウト（試行）が必要であり、場合によっては数十万回もの検索リクエストが発生します。これにより、API利用料が莫大になり、システムの<span class="highlight">スケーラビリティが著しく制限</span>されます。</li>
</ul>
</div>
<div class="glass-card" style="margin-top: 25px;">
<p style="text-align: center; font-family: 'Yomogi', cursive; font-size: 1.2em; color: var(--color-primary);"><i class="fas fa-lightbulb"></i> <strong>そこでZEROSEARCHの提案！</strong> <i class="fas fa-lightbulb"></i></p>
<p>これらの限界に対処するため、本論文では<span class="keyword">ZEROSEARCH</span>を提案します。ZEROSEARCHは、LLMを利用して<span class="highlight">リアルタイム検索をシミュレートする</span>ことで、高価でレート制限のある実際の検索APIへの依存を効果的に排除します。</p>
<div class="feature-card-grid" style="margin-top: 15px;">
<div class="feature-item">
<i class="fas fa-magic" style="color: var(--color-accent1); font-size: 2em;"></i>
<p><strong>軽量な教師ありファインチューニング</strong>により、文書品質を明示的に制御可能にします。</p>
</div>
<div class="feature-item">
<i class="fas fa-graduation-cap" style="color: var(--color-accent1); font-size: 2em;"></i>
<p><strong>カリキュラムロールアウトメカニズム</strong>を実装し、訓練の安定性と頑健性を向上させます。</p>
</div>
</div>
<p style="margin-top: 15px;">これにより、ZEROSEARCHはAPIコストをゼロにしつつ、実世界の検索エンジンを利用した学習と同等、あるいはそれ以上の性能を目指します。🎉</p>
</div>
</div>
<div class="section-card" id="3_ZEROSEARCH">
<h2 class="section-title"><i class="fas fa-search-dollar"></i>3 ZEROSEARCH</h2>
<p>このセクションでは、<strong><span class="keyword">ZEROSEARCH</span></strong> という新しいフレームワークの設計について詳しく解説します。ZEROSEARCHの核心は、<span class="highlight">実際の検索エンジンを使わずに、大規模言語モデル（LLM）の検索能力を強化学習（RL）によって向上させる</span>点にあります。</p>
<p>具体的には、以下の要素について掘り下げていきます：</p>
<div class="info-grid">
<div class="info-card">
<div class="icon-item"><i class="fas fa-chalkboard-teacher"></i></div>
<p><strong>訓練テンプレート</strong>：モデルがどのように思考し、検索し、回答するかを導く指示形式。</p>
</div>
<div class="info-card">
<div class="icon-item"><i class="fas fa-cogs"></i></div>
<p><strong>検索シミュレーションのチューニング</strong>：LLMが本物の検索エンジンのように振る舞うための調整方法。</p>
</div>
<div class="info-card">
<div class="icon-item"><i class="fas fa-graduation-cap"></i></div>
<p><strong>カリキュラムベースのロールアウト戦略</strong>：簡単な課題から徐々に難しい課題へと移行する訓練手法。</p>
</div>
<div class="info-card">
<div class="icon-item"><i class="fas fa-medal"></i></div>
<p><strong>報酬設計</strong>：モデルの良い行動を促すための「ご褒美」の与え方。</p>
</div>
<div class="info-card">
<div class="icon-item"><i class="fas fa-brain"></i></div>
<p><strong>訓練アルゴリズム</strong>：学習を効率的に進めるための具体的な計算手順。</p>
</div>
</div>
<p>これらの要素を組み合わせることで、API費用を気にすることなく、LLMの検索・推論能力を効果的に引き出すことを目指します。それでは、詳細を見ていきましょう！✏️</p>
<h3 class="section-title"><i class="fas fa-robot"></i>3.1 検索エンジンなしの強化学習</h3>
<p>ZEROSEARCHでは、<span class="highlight">実際の検索エンジンを必要としない強化学習の枠組み</span>を提案します。その代わりに、<span class="keyword">LLM自身に検索エンジンをシミュレート</span>させるのです。これにより、APIコストや外部環境の不安定さといった問題を回避できます。</p>
<p>このフレームワークにおける最適化目標は、以下の数式で表されます：</p>
<div class="formula">
        $$
        \displaystyle { \operatorname* { m a x } _ { \pi _ { \theta } } \mathbb { E } _ { x \sim \mathcal { D } , y \sim \pi _ { \theta } ( \cdot | x ; \pi _ { \psi } ) } \left[ r _ { \phi } ( x , y ) \right] \ - \ \beta \operatorname { D } _ { \mathrm { K L } } \left[ \pi _ { \theta } ( y \mid x ; \pi _ { \psi } ) \right. \Big \vert \pi _ { \mathrm { r e f } } ( y \mid x ; \pi _ { \psi } ) \Big ] }
        $$
    </div>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-calculator"></i> 数式の解説</p>
<ul>
<li><span class="keyword">$\pi_{\theta}$ (ポリシーモデル)</span>: 私たちが訓練して賢くしたいモデルです。このモデルが最善の行動（思考、検索、回答）シーケンス $y$ を出力するように最適化します。</li>
<li><span class="keyword">$\pi_{\mathrm{ref}}$ (参照モデル)</span>: 元となる事前学習済みLLMなど、$\pi_{\theta}$ が学習の初期段階で大きく逸脱しないようにするための基準となるモデルです。</li>
<li><span class="keyword">$r_{\phi}(x, y)$ (報酬関数)</span>: ポリシーモデル $\pi_{\theta}$ が入力 $x$ (質問など) に対して出力 $y$ を生成した際に得られる「ご褒美」です。例えば、正しい答えを出せたら高い報酬が得られます。</li>
<li><span class="keyword">$\pi_{\psi}$ (シミュレーションLLM)</span>: 検索エンジンの代わりをするLLMです。ポリシーモデルが検索クエリを投げると、このシミュレーションLLMが検索結果（ドキュメント）を生成します。重要なのは、この$\pi_{\psi}$のパラメータは訓練中に<span class="highlight">固定</span>される点です。</li>
<li>$x \sim \mathcal{D}$: 入力データ（例：質問）で、データセット $\mathcal{D}$ からランダムに選ばれます。</li>
<li>$y \sim \pi_{\theta}(\cdot | x; \pi_{\psi})$: ポリシーモデル $\pi_{\theta}$ が、入力 $x$ とシミュレーションLLM $\pi_{\psi}$ から得られる情報を使って生成する出力（一連の思考や行動）です。</li>
<li>$\mathbb{E}[\cdot]$: 期待値を表します。様々な入力 $x$ とそれに対するモデルの出力 $y$ を考慮して、平均的にどれくらいの報酬が得られるかを示します。</li>
<li>$\operatorname{D}_{\mathrm{KL}}[\cdot || \cdot]$ (<span class="keyword">KLダイバージェンス</span>): 2つの確率分布の「近さ」を測る指標です。ここでは、訓練中のポリシーモデル $\pi_{\theta}$ が参照モデル $\pi_{\mathrm{ref}}$ からあまりにもかけ離れた振る舞いをしないようにするためのペナルティ項として機能します。これにより、学習が安定しやすくなります。</li>
<li>$\beta$: KLダイバージェンス項の重要度を調整する係数です。この値が大きいほど、ポリシーモデルは参照モデルに近い振る舞いを維持しようとします。</li>
</ul>
<div class="bubble-box">
<p>🤔 <strong>この数式は何を目指しているの？</strong></p>
<p>この数式の目標は、<span class="highlight">「ポリシーモデル $\pi_{\theta}$ ができるだけ高い報酬 $r_{\phi}$ を得られるようにしつつも、元のモデル $\pi_{\mathrm{ref}}$ の知識や振る舞いから大きく逸脱しすぎないようにする」</span>ということです。KLダイバージェンスの項は、モデルが学習中に「暴走」してしまわないように、ある種の「おもり」の役割を果たします。</p>
</div>
</div>
<img alt="Figure 1: PPO and GRPO training without search engine" class="figure-image" src="ppo_grpo_training_no_search_engine.jpg"/>
<div class="note-box">
<p class="note-title"><i class="fas fa-image"></i> 図1の解説: PPOとGRPOの検索エンジンなし訓練</p>
<p>この図は、検索エンジンを使わない強化学習フレームワークで、代表的なアルゴリズムであるPPO (Proximal Policy Optimization) とGRPO (Group Relative Policy Optimization) がどのように動作するかを示しています。</p>
<div class="two-column">
<div class="column">
<p><strong>共通の要素:</strong></p>
<ul>
<li><span class="badge blue">q (query)</span>: 入力される質問。</li>
<li><span class="badge purple">Rollout Module</span>: ポリシーモデルとシミュレーションLLMが相互作用して、一連の行動（思考、検索クエリ、シミュレーションLLMからの情報）を生成する部分。
                        <ul>
<li><span class="badge yellow">Policy Model ($\pi_{\theta}$)</span>: 訓練対象のモデル（黄色）。質問に対して思考し、必要なら検索クエリを生成します。</li>
<li><span class="badge blue">Simulation LLM ($\pi_{\psi}$)</span>: 検索エンジン役のLLM（青色）。検索クエリに応じた情報を生成します。</li>
</ul>
</li>
<li><span class="badge green">o (observation)</span>: ロールアウトの結果得られる一連の観測（思考、検索結果、最終回答など）。</li>
<li><span class="badge green">Reward Model ($r_{\phi}$)</span>: 観測 $o$ を評価し、報酬 $r$ を計算します（緑色）。</li>
<li><span class="badge green">Reference Model ($\pi_{\mathrm{ref}}$)</span>: ポリシーモデルの逸脱を防ぐための基準モデル（緑色）。</li>
</ul>
</div>
<div class="column">
<p><strong>PPO (上段):</strong></p>
<ul>
<li>単一の観測 $o$ から価値 $v$ (Value Model経由) と報酬 $r$ を計算します。</li>
<li><span class="keyword">GAE (Generalized Advantage Estimation)</span>: 報酬 $r$ と価値 $v$ を使って、各行動の「良さ」を示すアドバンテージ $A$ を計算します。</li>
<li>このアドバンテージ $A$ を使ってポリシーモデル $\pi_{\theta}$ を更新します。</li>
</ul>
<p><strong>GRPO (下段):</strong></p>
<ul>
<li>複数の観測 $o_1, o_2, ..., o_G$ を生成し、それぞれに対して報酬 $r_1, r_2, ..., r_G$ を計算します。</li>
<li><span class="keyword">Group Computation</span>: これらの複数の報酬をグループとして扱い、アドバンテージ $A_1, A_2, ..., A_G$ を計算します。GRPOは、このグループ内での相対的な報酬の違いを利用して学習します。</li>
<li>これらのアドバンテージを使ってポリシーモデル $\pi_{\theta}$ を更新します。</li>
</ul>
</div>
</div>
<p>図中の凡例：<span class="badge yellow">Trained Model</span>は学習されるモデル、<span class="badge green">Frozen Model</span>は学習中にパラメータが固定されるモデル、<span class="badge blue">Simulation LLM</span>は検索をシミュレートするLLMを指します。</p>
</div>
<h3 class="section-title"><i class="fas fa-file-alt"></i>3.2 訓練テンプレート</h3>
<p>ZEROSEARCHでは、モデルがタスクを実行する際の「台本」とも言える<span class="keyword">訓練テンプレート</span>を使用します。これは、教師ありファインチューニング（SFT）に頼るのではなく、[16]の研究に従い、<span class="highlight">複数ターンの対話形式テンプレート</span>を適用しています。このテンプレートは、ポリシーモデルを反復的な推論と情報検索のプロセスを通じて導き、最終的な回答に到達させます。</p>
<div class="glass-card">
<h4>📝 Table 1: 訓練テンプレートの構造</h4>
<p>以下は、訓練および推論時に質問が末尾に付加されるテンプレートの例です。</p>
<div class="bubble-box">
<pre style="white-space: pre-wrap; word-wrap: break-word; background-color: #f8f9fa; border: 1px solid #dee2e6; padding: 10px; border-radius: 5px; font-family: 'Yomogi', cursive;">
与えられた質問に答えてください。新しい情報を得るたびに、まず<think>と</think>の中で推論を行わなければなりません。推論の後、知識が不足していると判断した場合は、<search>クエリ</search>と記述することで検索エンジンを呼び出すことができます。検索エンジンは<information>と</information>の間に上位の検索結果を返します。検索は何回でも行うことができます。これ以上外部の知識が必要ないと判断した場合は、詳細な説明なしに<answer>と</answer>の中に直接回答を提供できます。例：<answer>北京</answer>。質問：
        </pre>
</div>
<p>このテンプレートは、対話のプロセスを3つの明確な段階に分けています：</p>
<ol class="process-step-list unstyled-list">
<li class="process-step">
<div class="step-number">1</div>
<div class="step-content">
<strong><i class="fas fa-brain"></i> 思考 (Reasoning)</strong>: モデルは、まず <code>&lt;think&gt;...&lt;/think&gt;</code> タグの中で自身の内部的な推論を記述します。
                    <p class="example-text">例：<code class="highlight">&lt;think&gt;この質問は〇〇に関するものだ。まずは△△について調べる必要があるかもしれない。&lt;/think&gt;</code></p>
</div>
</li>
<li class="process-step">
<div class="step-number">2</div>
<div class="step-content">
<strong><i class="fas fa-search"></i> 検索 (Searching)</strong>: 追加の情報が必要だと判断した場合、モデルは <code>&lt;search&gt;...&lt;/search&gt;</code> タグ内に検索クエリを発行します。
                    <p class="example-text">例：<code class="highlight">&lt;search&gt;△△とは何か&lt;/search&gt;</code></p>
<p>（この後、シミュレーションLLMが <code>&lt;information&gt;...&lt;/information&gt;</code> タグで検索結果を返します）</p>
</div>
</li>
<li class="process-step">
<div class="step-number">3</div>
<div class="step-content">
<strong><i class="fas fa-lightbulb"></i> 回答 (Answering)</strong>: 十分な情報が収集されたと判断したら、モデルは <code>&lt;answer&gt;...&lt;/answer&gt;</code> タグ内に最終的な回答を提供します。
                    <p class="example-text">例：<code class="highlight">&lt;answer&gt;最終的な答えは□□です。&lt;/answer&gt;</code></p>
</div>
</li>
</ol>
<p>このように<span class="highlight">推論、検索、回答のプロセスを明示的に分離する</span>ことで、構造化された意思決定プロセスをモデルに強制し、その<span class="keyword">透明性</span>と<span class="keyword">信頼性</span>を高めることを目指しています。</p>
</div>
<h3 class="section-title"><i class="fas fa-wrench"></i>3.3 検索シミュレーションのチューニング</h3>
<p>ロールアウト（モデルに実際にタスクを実行させること）の際、ZEROSEARCHではLLMを使って<span class="highlight">実際の検索エンジンをシミュレート</span>し、クエリに応じてドキュメントを生成します。単純にLLMにドキュメント生成を指示するだけでは、実際の検索エンジンの出力との間に<span class="keyword">文体のギャップ</span>が生じがちです。</p>
<p>このギャップを埋めるために、<span class="keyword">軽量な教師ありファインチューニング（SFT）</span>を行います。手順は以下の通りです：</p>
<div class="pipeline">
<div class="pipeline-step">
<p><strong><span class="badge blue">ステップ1</span> 相互作用軌跡の収集</strong> 💬</p>
<p>LLMに実際の検索エンジン（例：Google）と複数回やり取りさせ、最終的な回答に至るまでの一連の対話データ（軌跡）を集めます。</p>
</div>
<div class="pipeline-step">
<p><strong><span class="badge blue">ステップ2</span> クエリ-ドキュメントペアの抽出</strong> 🔗</p>
<p>収集した軌跡から、「検索クエリ」とそれに対して得られた「ドキュメント」のペアを抽出します。</p>
</div>
<div class="pipeline-step">
<p><strong><span class="badge blue">ステップ3</span> ドキュメントのラベリング</strong> <span class="badge yellow">有用</span> / <span class="badge orange">ノイズ</span></p>
<p>LLMを「審査員」として使い、各ドキュメントが対応するクエリに答えるために十分な情報を含んでいるかを評価させます。</p>
<ul>
<li><span class="highlight">十分な情報を含む場合 <i class="fas fa-check-circle" style="color: var(--color-accent1);"></i></span>: 「有用な出力 (useful output)」としてラベル付け。</li>
<li><span class="highlight">含まない場合 <i class="fas fa-times-circle" style="color: var(--color-secondary);"></i></span>: 「ノイズの多い出力 (noisy output)」としてラベル付け。</li>
</ul>
</div>
<div class="pipeline-step">
<p><strong><span class="badge blue">ステップ4</span> 軽量SFTの実施</strong> ⚙️</p>
<p>LLMがクエリに対して「有用な出力」と「ノイズの多い出力」の両方を生成できるように、SFTで追加学習させます。</p>
</div>
</div>
<div class="note-box">
<p class="note-title"><i class="fas fa-info-circle"></i> SFTのポイント</p>
<ul>
<li><strong>プロンプトによる制御</strong>: 論文のTable 2で示されるように、プロンプト内の数語を調整するだけで、「有用な出力」と「ノイズの多い出力」の生成を効果的に制御できます。</li>
<li><strong>知識範囲の拡大</strong>: 入力された質問とその正解（グラウンドトゥルース）もプロンプトに含めることで、シミュレーションLLMの知識範囲を広げます。</li>
</ul>
</div>
<p>このファインチューニングにより、シミュレーションLLMは<span class="highlight">有用なドキュメントとノイズの多いドキュメントの両方を生成する能力</span>を獲得し、ロールアウト中にドキュメントの品質を動的に制御できるようになります。これは次のカリキュラム学習で重要になります。</p>
<h3 class="section-title"><i class="fas fa-chart-line"></i>3.4 カリキュラム検索シミュレーションによるロールアウト</h3>
<p>ロールアウト中、ポリシーモデルは対話的に推論を行い、検索クエリを生成します。これらのクエリはシミュレーションLLMに送られ、対応するドキュメントが生成されます。</p>
<p>訓練の難易度を徐々に上げていくために、ZEROSEARCHでは<span class="keyword">カリキュラム学習ベースのロールアウトメカニズム</span>を導入しています。これは、生成されるドキュメントの品質を時間の経過とともに段階的に低下させる（つまり、ノイズを増やしていく）というものです。</p>
<p>この品質制御は、ステップ $i$ でノイズの多いドキュメントを生成する確率 $p_i$ によって行われます。その確率は以下の数式で定義されます：</p>
<div class="formula">
        $$
        p _ { i } ~ = ~ p _ { s } ~ + ~ { \frac { b ^ { ~ i / m } - 1 } { b - 1 } } \left( p _ { e } - p _ { s } \right)
        $$
    </div>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-calculator"></i> 確率関数 $p_i$ の解説</p>
<ul>
<li>$p_s$: <span class="keyword">初期ノイズ確率</span> (Initial noise probability)。訓練開始時のノイズの多いドキュメントを生成する確率。最初は低く設定されることが多いです（例：0）。</li>
<li>$p_e$: <span class="keyword">最終ノイズ確率</span> (Final noise probability)。訓練終了時のノイズの多いドキュメントを生成する確率。訓練が進むにつれてこの値に近づいていきます（例：0.75）。</li>
<li>$i$: <span class="keyword">現在の訓練ステップ数</span> (Current training step)。</li>
<li>$m$: <span class="keyword">総訓練ステップ数</span> (Total number of training steps)。</li>
<li>$b$: <span class="keyword">指数基底</span> (Exponential base)。デフォルト値は4。この値が確率の上昇カーブの形状を決定します。</li>
</ul>
<div class="bubble-box">
<p>📈 <strong>$p_i$ はどう変化するの？</strong></p>
<p>訓練が進むにつれて、$i/m$ の比率（訓練の進捗度）が増加します。これにより、$b^{i/m}$ の値が大きくなり、結果として $p_i$ の値も上昇します。つまり、<span class="highlight">訓練が進むほど、ノイズの多いドキュメントが生成される可能性が高く</span>なります。</p>
<p>例えば、$p_s=0, p_e=0.5, b=4$ の場合：</p>
<ul>
<li>訓練初期 ($i/m \approx 0$): $p_i \approx p_s = 0$ （ほとんどノイズなし）</li>
<li>訓練中期 ($i/m = 0.5$): $p_i \approx 0 + \frac{4^{0.5}-1}{4-1}(0.5-0) = \frac{2-1}{3} \times 0.5 \approx 0.167$</li>
<li>訓練終期 ($i/m \approx 1$): $p_i \approx p_e = 0.5$ （目標とするノイズレベル）</li>
</ul>
</div>
</div>
<p>このカリキュラム学習戦略により、ポリシーモデルはまず<span class="highlight">基本的な出力構造やタスク要件を学習</span>し、その後、徐々により<span class="highlight">挑戦的でノイズの多い検索シナリオに適応</span>していくことができます。</p>
<img alt="Table 2: Template for Search Simulation" class="figure-image" src="table1.png"/>
<div class="note-box">
<p class="note-title"><i class="fas fa-table"></i> 表2の解説: 検索シミュレーションのテンプレート</p>
<p>この表（論文中のTable 2、ここではtable1.pngとして表示）は、シミュレーションLLMが検索結果を生成する際に使用するテンプレートの例を示しています。重要な点は以下の通りです。</p>
<ul>
<li><span class="keyword">キーワードによる品質制御</span>: 「useful」や「noisy」といったキーワードをプロンプトに含めることで、生成されるドキュメントの品質を制御します。これにより、シミュレーションLLMは意図的に有用な情報やノイズを含んだ情報を生成できるようになります。</li>
<li><span class="keyword">知識範囲の拡張</span>: 入力された質問とその正解（ground-truth answer）もプロンプトに含めることで、シミュレーションLLMがカバーできる知識の範囲を広げる助けとなります。</li>
</ul>
<p>このテンプレートは、前述のSFTプロセス（3.3節）でシミュレーションLLMを訓練する際に使用され、カリキュラム学習におけるドキュメント品質の制御を可能にします。</p>
</div>
<h3 class="section-title"><i class="fas fa-award"></i>3.5 報酬設計</h3>
<p>報酬信号は、強化学習プロセスにおける<span class="keyword">主要な教師信号</span>となります。つまり、モデルが「何をすれば良いか」を学ぶための手がかりです。</p>
<p>この研究では、<span class="highlight">回答の正確さのみに焦点を当てたルールベースの報酬関数</span>を採用しています。</p>
<div class="challenge-box">
<p class="challenge-title"><i class="fas fa-exclamation-triangle"></i> 予備実験での課題：報酬ハッキング</p>
<p>初期の実験では、報酬指標として<span class="keyword">完全一致（Exact Match, EM）</span>を使用していましたが、問題が発生しました。ポリシーモデルが、正解を含む可能性を高めるために<span class="highlight">不必要に長い回答を生成する傾向</span>が見られたのです。これは「報酬ハッキング」と呼ばれる現象で、モデルが報酬を最大化しようとするあまり、本質的ではない行動をとってしまうことです。</p>
</div>
<p>この問題を軽減するため、<span class="keyword">F1スコアベースの報酬</span>を採用しました。F1スコアは<span class="highlight">適合率（Precision）と再現率（Recall）のバランスを取る</span>指標であり、より頑健な評価が可能です。</p>
<p>F1スコアは以下のように計算されます：</p>
<div class="formula">
        $$
        r _ { \phi } ( x , y ) = \frac { 2 \times IN } { P N + R N }
        $$
    </div>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-calculator"></i> F1スコア報酬の構成要素</p>
<ul>
<li>$IN$: モデルの予測 (prediction) と正解 (ground truth) の間で<span class="keyword">重複する単語の数</span> (Number of overlapping words)。</li>
<li>$PN$: モデルの<span class="keyword">予測に含まれる単語の数</span> (Number of words in the prediction)。</li>
<li>$RN$: <span class="keyword">正解に含まれる単語の数</span> (Number of words in the ground truth)。</li>
</ul>
<div class="bubble-box">
<p>💡 <strong>具体例で見てみよう！</strong></p>
<p>質問: 「日本の首都は？」</p>
<p>正解 (Ground Truth): 「東京」 (RN = 1)</p>
<ul>
<li><strong>良い予測:</strong> 「東京」
                <ul>
<li>IN = 1 (「東京」が一致)</li>
<li>PN = 1</li>
<li>報酬 = (2 * 1) / (1 + 1) = 1.0 (満点！)</li>
</ul>
</li>
<li><strong>長すぎる予測 (報酬ハッキングの例):</strong> 「日本の首都は美しい都市である東京です」
                <ul>
<li>IN = 1 (「東京」が一致)</li>
<li>PN = 7</li>
<li>報酬 = (2 * 1) / (7 + 1) = 2 / 8 = 0.25 (低い！)</li>
</ul>
</li>
<li><strong>不完全な予測:</strong> 「京」
                <ul>
<li>IN = 0 (「東京」とは一致しない)</li>
<li>PN = 1</li>
<li>報酬 = (2 * 0) / (1 + 1) = 0</li>
</ul>
</li>
</ul>
<p>このようにF1スコアは、単に正解の単語を含んでいるだけでなく、余計な単語が少なく、かつ必要な単語を網羅しているかを評価します。</p>
</div>
</div>
<p>興味深いことに、<span class="highlight">出力フォーマットに対する追加の報酬は組み込んでいません</span>。明示的な教師なしでも、モデルは一貫して適切にフォーマットされた応答（例：<code>&lt;think&gt;</code>, <code>&lt;search&gt;</code>, <code>&lt;answer&gt;</code>タグの使用）を生成することが観測されたためです。</p>
<h3 class="section-title"><i class="fas fa-cogs"></i>3.6 訓練アルゴリズム</h3>
<p>ZEROSEARCHのアプローチは、さまざまな強化学習アルゴリズムと互換性があります。論文では以下のアルゴリズムが挙げられています：</p>
<div class="feature-card-grid">
<div class="feature-item">
<div class="icon-item"><i class="fas fa-brain"></i></div>
<h4>REINFORCE [38]</h4>
<p>最も基本的な方策勾配アルゴリズムの一つ。比較的シンプルですが、分散が大きい場合があります。</p>
</div>
<div class="feature-item">
<div class="icon-item"><i class="fas fa-balance-scale"></i></div>
<h4>Proximal Policy Optimization (PPO) [31]</h4>
<p>方策の更新ステップを制限することで学習を安定させる人気のアルゴリズム。性能と実装の容易さのバランスが良いです。</p>
</div>
<div class="feature-item">
<div class="icon-item"><i class="fas fa-users-cog"></i></div>
<h4>Group Relative Policy Optimization (GRPO) [32, 7]</h4>
<p>複数のロールアウト結果を比較し、相対的な性能に基づいて方策を更新するアルゴリズム。特に複雑なタスクで有効な場合があります。</p>
</div>
</div>
<p>これらのアルゴリズムはそれぞれ、検索拡張推論を最適化する上で異なる利点を提供します。</p>
<div class="challenge-box">
<p class="challenge-title"><i class="fas fa-exclamation-triangle"></i> 訓練の不安定性への対策：損失マスキング</p>
<p>ZEROSEARCHにおけるロールアウトシーケンス（モデルの一連の行動）には、以下の2種類のトークンが含まれます：</p>
<ol>
<li>ポリシーモデル自身が生成したトークン（思考内容、検索クエリ、最終回答など）</li>
<li>シミュレーションLLMから返されたドキュメントのトークン</li>
</ol>
<p>これら両方のタイプのトークンに同じ最適化手順を均一に適用すると、<span class="highlight">訓練が不安定になる可能性</span>があります。なぜなら、ドキュメントトークンは外部（シミュレーションLLM）から生成されたものであり、ポリシーモデルが直接制御しているわけではないからです。</p>
</div>
<p>この問題に対処するため、<span class="keyword">ドキュメントトークンに対する損失マスキングメカニズム</span>を導入します。これは、<span class="highlight">勾配計算をモデル自身の出力（ポリシーモデルが生成したトークン）に関してのみ行う</span>ようにするものです。つまり、シミュレーションLLMが生成したドキュメント部分については、損失を計算せず、パラメータ更新の対象外とします。</p>
<p>この戦略により、RL訓練プロセスを<span class="keyword">安定化</span>させるとともに、検索拡張生成の有効性を維持することができます。</p>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-shield-alt"></i> 損失マスキングのイメージ</p>
<p>例：モデルの出力シーケンスが以下の場合</p>
<p><code>&lt;think&gt; 質問はAについてだ &lt;/think&gt; &lt;search&gt; Aとは &lt;/search&gt; &lt;information&gt; ドキュメント内容... &lt;/information&gt; &lt;answer&gt; 答えはB &lt;/answer&gt;</code></p>
<p>損失マスキングを適用すると、</p>
<ul>
<li><span style="background-color: #c8e6c9;"><code>&lt;think&gt; 質問はAについてだ &lt;/think&gt;</code></span> <i class="fas fa-check" style="color: green;"></i> 損失計算対象</li>
<li><span style="background-color: #c8e6c9;"><code>&lt;search&gt; Aとは &lt;/search&gt;</code></span> <i class="fas fa-check" style="color: green;"></i> 損失計算対象</li>
<li><span style="background-color: #ffcdd2;"><code>&lt;information&gt; ドキュメント内容... &lt;/information&gt;</code></span> <i class="fas fa-times" style="color: red;"></i> 損失計算対象外 (マスク)</li>
<li><span style="background-color: #c8e6c9;"><code>&lt;answer&gt; 答えはB &lt;/answer&gt;</code></span> <i class="fas fa-check" style="color: green;"></i> 損失計算対象</li>
</ul>
<p>これにより、ポリシーモデルは自身が制御可能な部分の生成品質向上に集中できます。</p>
</div>
</div>
<div class="section-card" id="4_Main_Results">
<h2 class="section-title"><i class="fas fa-chart-bar"></i>4 Main Results</h2>
<p style="font-family: 'Yomogi', cursive; font-size: 16px; line-height: 1.6;">
        このセクションでは、提案手法である <span class="keyword">ZEROSEARCH</span> の有効性を検証するために実施した様々な実験とその結果について詳しく報告します。具体的には、どのようなデータセットと評価指標を用いたのか、比較対象としてどのような既存手法（ベースライン）を選んだのか、実験はどのような設定で行ったのか、そして最終的にどのようなパフォーマンスが得られたのかを順番に解説していきます。このセクションを読むことで、ZEROSEARCHが既存の手法と比較してどの程度優れているのか、そしてどのような状況でその強みが発揮されるのかが明確になるでしょう。
    </p>
<h3 class="subsection-title"><i class="fas fa-database"></i>4.1 Datasets and Evaluation Metrics</h3>
<div class="content-box">
<p>ZEROSEARCHの性能を評価するために、多様な質問応答ベンチマークを使用しました。これらのデータセットは、質問の複雑さや必要な推論のステップ数によって分類されます。</p>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));">
<div class="info-card">
<p class="note-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-lightbulb"></i>Single-Hop Question Answering</p>
<p>これは、答えを見つけるために1つの情報源や知識断片を参照すればよい、比較的単純な質問応答タスクです。例えるなら、「日本の首都はどこですか？」という質問に「東京」と答えるようなものです。</p>
<ul class="unstyled-list">
<li>✏️ <span class="keyword">NQ (Natural Questions) [20]</span>: Google検索の実際のクエリに基づいて作成されたデータセット。</li>
<li>✏️ <span class="keyword">TriviaQA [17]</span>: トリビア好きの人々が作成した質問と、ウェブ上の証拠文書から構成されるデータセット。</li>
<li>✏️ <span class="keyword">PopQA [26]</span>: ポップカルチャーに関する質問を集めたデータセット。</li>
</ul>
</div>
<div class="info-card">
<p class="note-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-cogs"></i>Multi-Hop Question Answering</p>
<p>こちらは、答えにたどり着くために複数の情報源を跨いで情報を収集し、それらを組み合わせて推論する必要がある、より複雑なタスクです。例えば、「映画『君の名は。』の監督が監督した別のアニメ映画の興行収入は？」といった質問です。この場合、「『君の名は。』の監督は誰か」→「その監督が他にどんなアニメ映画を監督したか」→「それらの映画の興行収入はいくらか」というように、複数のステップ（ホップ）で情報を探す必要があります。</p>
<ul class="unstyled-list">
<li>🧩 <span class="keyword">HotpotQA [42]</span>: Wikipediaの記事を基に、複数の文書にまたがる推論が必要な質問で構成。</li>
<li>🧩 <span class="keyword">2WikiMultiHopQA [8]</span>: こちらもWikipediaベースで、2つの情報源を結びつける必要がある質問。</li>
<li>🧩 <span class="keyword">Musique [37]</span>: 複数のシングルホップ質問を組み合わせて作られたマルチホップ質問データセット。</li>
<li>🧩 <span class="keyword">Bamboogle [28]</span>: Google検索で答えが見つからないように設計された、推論が必要な質問。</li>
</ul>
</div>
</div>
<div class="arrow-connector"></div>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-check-circle"></i>評価指標: Exact Match (EM)</p>
<p>評価指標としては、先行研究 [16] に倣い <span class="keyword">Exact Match (EM)</span> を採用しました。</p>
<p>EMとは、モデルの予測した答えが、正解の答え（複数ある場合はそのいずれか）と、<span class="highlight">正規化された形式で完全に一致するかどうか</span>で評価する指標です。</p>
<div class="glass-card" style="margin-top: 10px;">
<p><strong>正規化とは？</strong> 🤔</p>
<p>テキストデータを比較しやすくするために、表記の揺れを統一する処理のことです。例えば、</p>
<ul>
<li>大文字・小文字を統一する（例: "Apple" と "apple" を同じとみなす）</li>
<li>句読点や記号を除去する（例: "東京タワー。" と "東京タワー" を同じとみなす）</li>
<li>冠詞（a, an, theなど）を無視する</li>
</ul>
<p>などがあります。これにより、本質的に同じ内容の答えであれば、些細な表記の違いで不正解とならないようにします。</p>
<p><strong>EMの具体例:</strong></p>
<p>質問: 「日本の首都は？」</p>
<ul>
<li>正解 (Ground Truth): ["東京", "東京都"]</li>
<li>モデルの予測: "東京" → <span style="color: var(--color-accent1); font-weight: bold;">正解 (EM成立)</span> ✨</li>
<li>モデルの予測: "東京都。" (正規化後 "東京都") → <span style="color: var(--color-accent1); font-weight: bold;">正解 (EM成立)</span> ✨</li>
<li>モデルの予測: "大阪" → <span style="color: var(--color-secondary); font-weight: bold;">不正解 (EM不成立)</span> 💔</li>
</ul>
</div>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-balance-scale"></i>4.2 Baselines</h3>
<div class="content-box">
<p>ZEROSEARCHの有効性を評価するために、以下のベースライン手法と比較しました。これらのベースラインは、アプローチの異なるいくつかのカテゴリに分類されます。</p>
<div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));">
<div class="feature-item" style="background-color: rgba(74, 111, 165, 0.05); border: 1px dashed var(--color-primary);">
<p class="note-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-pencil-alt"></i>1. Vanilla Prompting Methods</p>
<p>(基本的なプロンプティング手法)</p>
<p class="reference" style="text-align: left;">LLMに直接指示（プロンプト）を与えてタスクを解かせるシンプルな方法群です。</p>
<ul class="unstyled-list" style="text-align: left; padding-left: 10px;">
<li><span class="badge blue">Direct Prompting</span>: 単純な質問応答プロンプト。</li>
<li><span class="badge blue">Chain-of-Thought (CoT)</span>: 思考の連鎖を促すプロンプトで、推論過程を生成させる手法。</li>
<li><span class="badge blue">Standard RAG</span>: 標準的な検索拡張生成。外部知識を検索してプロンプトに含める手法。</li>
</ul>
</div>
<div class="feature-item" style="background-color: rgba(255, 126, 95, 0.05); border: 1px dashed var(--color-secondary);">
<p class="note-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-search-plus"></i>2. Advanced RAG Methods</p>
<p>(高度なRAG手法)</p>
<p class="reference" style="text-align: left;">標準的なRAGをさらに発展させ、より高度な検索や情報統合を行う手法群です。</p>
<ul class="unstyled-list" style="text-align: left; padding-left: 10px;">
<li><span class="badge orange">RAgent [22]</span></li>
<li><span class="badge orange">Search-o1 [22]</span></li>
</ul>
<p class="reference" style="text-align: left;">これらは関連情報を反復的に検索する特徴があります。</p>
</div>
<div class="feature-item" style="background-color: rgba(92, 184, 92, 0.05); border: 1px dashed var(--color-accent1);">
<p class="note-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-robot"></i>3. RL Tuning Methods</p>
<p>(強化学習によるチューニング手法)</p>
<p class="reference" style="text-align: left;">強化学習を用いてLLMの検索や推論能力を向上させる手法群です。</p>
<ul class="unstyled-list" style="text-align: left; padding-left: 10px;">
<li><span class="badge green">R1 [16]</span>: ポリシーモデルが内部知識のみに基づいて詳細な推論を行うよう訓練。</li>
<li><span class="badge green">Search-R1 [16]</span>: ポリシーモデルが推論中に<span class="highlight">実際の検索エンジン</span>と複数回対話可能。</li>
</ul>
</div>
</div>
<div class="note-box" style="margin-top: 20px;">
<p class="note-title"><i class="fas fa-info-circle"></i>公平な比較のための工夫</p>
<p>すべての強化学習(RL)ベースの手法で、報酬の指標として <span class="keyword">F1スコア</span> を採用しました。これは、予測の精度（Precision）と再現率（Recall）のバランスを取る指標で、より公平な性能比較を可能にします。(F1スコアについては、セクション3.5で詳しく説明されています)</p>
<p>特に重要な点として、RLベースの検索機能を持つベースラインの中では、<span class="keyword">Search-R1</span> のみと比較しています。その理由は、Search-R1が複雑な報酬設計、特定のデータ選択、あるいは手の込んだ訓練パイプラインを必要としないためです。この設定により、<span class="highlight">実際の検索エンジン（Search-R1が使用）と、私たちのZEROSEARCHが用いるシミュレートされた検索エンジンとの間で、直接的かつ公平な比較を行うことができます</span>。</p>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-tools"></i>4.3 Experimental Setup</h3>
<div class="content-box">
<p>ZEROSEARCHの性能を検証するための実験設定について説明します。</p>
<div class="info-grid">
<div class="info-card">
<p class="note-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-brain"></i>使用モデル</p>
<p>実験には、以下の3つのモデルファミリーを使用しました。それぞれに、事前学習済みで特定の指示に特化していない「Base」モデルと、指示に従うようにファインチューニングされた「Instruct」モデルがあります。</p>
<ul class="unstyled-list">
<li><span class="tag">Qwen-2.5-7B (Base/Instruct) [41]</span></li>
<li><span class="tag">Qwen-2.5-3B (Base/Instruct) [41]</span></li>
<li><span class="tag">LLaMA-3.2-3B (Base/Instruct) [4]</span></li>
</ul>
</div>
<div class="info-card">
<p class="note-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-search-location"></i>検索エンジン設定</p>
<p>実世界の検索シナリオを模倣するため、外部検索エンジンとして <span class="keyword">Google Web Search</span> を <span class="highlight">SerpAPI</span><a href="#footnote1" id="ref1"><sup>2</sup></a> を介して利用しました。</p>
<p><strong>評価時</strong>: 全ての比較手法で公平を期すため、検索エンジンとして <span class="keyword">SerpAPI</span> を使用しました。</p>
<p><strong>取得ドキュメント数</strong>: これも公平な比較のため、全ての手法で検索結果として取得するドキュメント数を <span class="highlight">5つに固定</span> しました。</p>
<p class="reference" id="footnote1">2: SerpAPIは、Googleなどの検索エンジンの結果をプログラムで取得できるようにするサービスです。</p>
</div>
</div>
<div class="pipeline">
<div class="pipeline-step">
<span class="step-number">1</span>
<div class="step-content">
<strong>データセットの準備</strong>: 先行研究 [16] の設定を踏襲し、<span class="keyword">NQ</span> と <span class="keyword">HotpotQA</span> の訓練セットを統合。これにより、ファインチューニングを行う全ての手法に対して統一された訓練データセットを作成しました。
                </div>
</div>
<div class="pipeline-step">
<span class="step-number">2</span>
<div class="step-content">
<strong>評価範囲</strong>: 作成したモデルの性能を、<span class="keyword">ドメイン内</span> (訓練データに含まれる種類のタスクやトピック) および <span class="keyword">ドメイン外</span> (訓練データには含まれない新しい種類のタスクやトピック) の両方で評価するため、合計7つのデータセットを使用しました。
                </div>
</div>
<div class="pipeline-step" style="margin-bottom: 0;">
<span class="step-number">3</span>
<div class="step-content">
<strong>モデルタイプの選択</strong>:
                    <ul>
<li><span class="badge yellow">プロンプトベースのベースライン</span>: <span class="keyword">Instructモデル</span> を使用。Baseモデルは一般的にタスク指示の理解が苦手なためです。</li>
<li><span class="badge purple">RLベースの手法 (ZEROSEARCH含む)</span>: <span class="keyword">Baseモデル</span> と <span class="keyword">Instructモデル</span> の両方で評価。これにより、異なるタイプのモデルに対する手法の汎用性を確認します。</li>
</ul>
</div>
</div>
</div>
<div class="framework-box" style="margin-top: 20px;">
<p class="framework-title"><i class="fas fa-server"></i>実験環境と訓練詳細</p>
<ul>
<li><strong>GPU構成</strong>: シミュレーションサーバー（ZEROSEARCHで検索エンジンを模倣するLLMが動くサーバー）は <span class="highlight">4基のH20 GPU</span> に、強化学習の訓練自体は別の <span class="highlight">4基のH20 GPU</span> に展開しました。</li>
<li><strong>ZEROSEARCHの訓練アルゴリズム</strong>: 3つの異なる強化学習アルゴリズム (<span class="keyword">REINFORCE</span>, <span class="keyword">GRPO</span>, <span class="keyword">PPO</span>) で実験を行いました。
                    <ul><li>特に指定がない場合、全てのRLベースの手法では <span class="keyword">REINFORCE</span> をデフォルトの訓練アルゴリズムとして使用しました。</li></ul>
</li>
<li><strong>デフォルトのシミュレート検索エンジン</strong>: 全ての実験を通じて、ファインチューニングされた <span class="keyword">Qwen-2.5-14B-Instruct</span> モデルをデフォルトのシミュレートされた検索エンジンとして使用しました。</li>
<li><strong>推論時の公平性</strong>: <span class="highlight">推論（最終的な性能評価）時</span>には、ZEROSEARCHを含む全てのモデルが、実際のWeb環境である <span class="keyword">Google Web Search</span> (SerpAPI経由) と対話するようにし、比較の公平性を担保しました。</li>
</ul>
<p class="reference"><i class="fas fa-book-open"></i>ハイパーパラメータなどの詳細な実装情報については、論文の付録Fを参照してください。</p>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-trophy"></i>4.4 Performance</h3>
<div class="content-box">
<p>このセクションでは、ZEROSEARCHと複数のベースライン手法のパフォーマンスを7つのデータセットで比較した結果を示します。論文中のTable 3にその結果がまとめられています。</p>
<div class="glass-card" style="padding: 15px; margin-bottom: 20px;">
<p class="note-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-table"></i>Table 3: 主要結果の概要</p>
<p>この表は、異なるLLM（Qwen-2.5-3B/7B Base/Instruct, LLaMA-3.2-3B Base/Instruct）をバックボーン（処理の核となるモデル）として使用した際の、ZEROSEARCHと各種ベースライン手法のExact Match (EM) スコアを示しています。太字は各データセットで最も高いスコアを示します。</p>
<p>データセットは、NQ, TriviaQA, PopQA (Single-Hop QA), HotpotQA, 2Wiki, Musique, Bamboogle (Multi-Hop QA) です。</p>
<p>ベースラインには、Direct Prompting, CoT, Standard RAG (Vanilla Prompting)、RAgent, Search-o1 (Advanced RAG)、R1, Search-R1 (RL Tuning) が含まれます。</p>
</div>
<img alt="Table 3: Main results using different LLMs as the backbone. The best performance is set in bold." class="section-image" src="table2.png"/>
<p class="reference" style="text-align: center; margin-bottom: 25px;">Table 3: 異なるLLMをバックボーンとして使用した場合の主な結果。最高のパフォーマンスは太字で示されています。</p>
<p>これらの結果から、いくつかの重要な所見が得られました。</p>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));">
<div class="info-card bubble-box">
<p class="note-title" style="font-family: 'Yomogi', cursive; color: var(--color-primary);"><i class="fas fa-star"></i>所見1: 一貫した優位性</p>
<p><span class="keyword">ZEROSEARCH</span> は、<span class="highlight">全てのベースライン手法を一貫して上回る</span>パフォーマンスを示しました。</p>
<p>この性能の優位性は、訓練データと似た特性を持つ <span class="badge blue">ドメイン内データセット</span>（例: NQ, HotpotQA）だけでなく、訓練データとは異なる特性を持つ <span class="badge purple">ドメイン外データセット</span>（例: TriviaQA, PopQA, 2WikiMultiHopQA, Musique, Bamboogle）においても確認されました。これは、ZEROSEARCHが特定のデータセットに過度に適合することなく、<span class="highlight">多様な状況で安定して高い性能を発揮できる堅牢性 (robustness) を持っている</span>ことを示しています。</p>
<div style="text-align: center; margin-top:10px;">
<i class="fas fa-shield-alt fa-2x" style="color: var(--color-accent1);"></i>
<i class="fas fa-arrow-up fa-2x" style="color: var(--color-accent1); margin-left: 5px;"></i>
</div>
</div>
<div class="info-card bubble-box">
<p class="note-title" style="font-family: 'Yomogi', cursive; color: var(--color-secondary);"><i class="fas fa-rocket"></i>所見2: 実検索エンジン依存手法超え</p>
<p><span class="keyword">ZEROSEARCH</span> は、<span class="highlight">実際の検索エンジンに依存する手法をも上回りました</span>。</p>
<p>具体的には、推論中に実際の検索エンジン（Google Search）を利用する <span class="keyword">Search-R1</span> と比較しても、ZEROSEARCHの方が優れたパフォーマンスを達成しました。これは、ZEROSEARCHが実際の検索エンジンを使わずに訓練されても、実際の検索エンジンを使う手法と同等かそれ以上の能力を獲得できることを意味し、<span class="highlight">大規模な強化学習において、高コストな実際の検索APIの利用を代替できる効果的な選択肢</span>としての可能性を示唆しています。</p>
<div style="text-align: center; margin-top:10px;">
<span style="font-family: 'Yomogi', cursive; font-size: 1.2em; color: var(--color-primary);">ZEROSEARCH</span>
<i class="fas fa-greater-than fa-1x" style="color: var(--color-dark); margin: 0 10px;"></i>
<span style="font-family: 'Yomogi', cursive; font-size: 1.2em; color: var(--color-secondary);">Search-R1 (実検索)</span>
</div>
</div>
<div class="info-card bubble-box">
<p class="note-title" style="font-family: 'Yomogi', cursive; color: var(--color-accent2);"><i class="fas fa-universal-access"></i>所見3: 高い汎化能力とスケーラビリティ</p>
<p><span class="keyword">ZEROSEARCH</span> は、<span class="highlight">強力な汎化能力 (generalizability)</span> を示しました。</p>
<p>これは、異なるモデルファミリー（例: Qwen, LLaMA）、パラメータサイズ（例: 3B, 7B）、モデルタイプ（<span class="badge yellow">Base</span> または <span class="badge purple">Instruction-tuned</span>）といった様々な条件のLLMに適用した場合でも、一貫してベースライン手法を上回る結果が得られたことから明らかです。</p>
<p>さらに、<span class="highlight">より大きなモデルを使用すると、ZEROSEARCHのパフォーマンスはさらに向上</span>しました。これは、ZEROSEARCHがモデルの規模拡大に伴って性能を向上させることができる、<span class="keyword">スケーラビリティ (scalability)</span> を有していることを示しています。</p>
<div style="text-align: center; margin-top:10px;">
<i class="fas fa-cogs fa-2x" style="color: var(--color-accent2);"></i> <span style="font-size: 1.5em; vertical-align: middle;">→</span> <i class="fas fa-chart-line fa-2x" style="color: var(--color-accent2);"></i>
</div>
</div>
</div>
</div>
</div>
<div class="section-card" id="5_Further_Analysis">
<h2 class="section-title"><i class="fas fa-microscope"></i>5 Further Analysis</h2>
<div class="content-box">
<p>このセクションでは、本論文で提案された <span class="keyword">ZEROSEARCH</span> フレームワークの様々な側面について、より詳細な分析を行います。 <i class="fas fa-lightbulb" style="color: var(--color-accent3);"></i></p>
<p>具体的には、以下の点を深掘りしていきます：</p>
<ul class="unstyled-list">
<li><i class="fas fa-balance-scale" style="color: var(--color-primary);"></i> 実際の検索エンジンとの性能比較</li>
<li><i class="fas fa-cogs" style="color: var(--color-secondary);"></i> シミュレーションに使用する大規模言語モデル（LLM）の選択の影響</li>
<li><i class="fas fa-comments" style="color: var(--color-accent1);"></i> 訓練中の対話ターンの変化</li>
<li><i class="fas fa-brain" style="color: var(--color-accent2);"></i> 異なる強化学習（RL）アルゴリズムの適用可能性</li>
<li><i class="fas fa-graduation-cap" style="color: var(--color-accent3);"></i> カリキュラムロールアウト戦略の有効性</li>
</ul>
<p>これらの分析を通じて、<span class="keyword">ZEROSEARCH</span> の<span class="highlight">堅牢性</span>、<span class="highlight">汎用性</span>、そして<span class="highlight">実用性</span>を明らかにすることを目的としています。✏️📌</p>
</div>
<h3 class="section-title"><i class="fas fa-chart-line"></i>5.1 Compare ZEROSEARCH with Real Search Engine</h3>
<div class="content-box">
<p>このサブセクションでは、<span class="keyword">ZEROSEARCH</span>（シミュレーション検索を利用）と <span class="keyword">Search-R1</span>（実際の検索エンジンを利用）の報酬曲線を比較します。実験には <span class="highlight">Qwen-2.5-3B</span> モデルが使用されました。結果は図2(a)および(b)に示されています。</p>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i> 用語解説</div>
<p><span class="keyword">ポリシーモデル (Policy Model)</span>: 強化学習において、特定の状態（例：ユーザーからの質問）に対してどのような行動（例：検索クエリの生成、回答の生成）を取るかの方針（ポリシー）を学習するモデルです。</p>
<p><span class="keyword">報酬曲線 (Reward Curve)</span>: 強化学習の訓練が進むにつれて、ポリシーモデルが得る報酬がどのように変化するかを示すグラフです。通常、学習が進むと報酬は上昇傾向を示します。</p>
</div>
<img alt="Figure 2 (a-b): Reward curve comparison between ZEROSEARCH and Search-R1" src="reward_curve_zerosearch_searchr1_comparison.jpg"/>
<p class="reference">Figure 2: (a-b): Reward curve comparison between ZEROSEARCH and Search-R1 using Qwen-2.5-3B. (c): The reward curve and interaction turns during training of LLaMA-3.2-3B-Base. (注: 提供された画像は論文中のFigure 3に該当しますが、ここではFigure 2(a)(b)の傾向を説明するために参考にしています。横軸が学習ステップ、縦軸が報酬を示します。)</p>
<div class="note-box">
<div class="note-title"><i class="fas fa-info-circle"></i> 主要な観察結果 <i class="fas fa-search"></i></div>
<ul class="unstyled-list">
<li>
<div class="process-step">
<div class="step-number">1</div>
<div class="step-content">
<strong><i class="fas fa-sync-alt"></i> 全体的な報酬トレンドの類似性</strong>:
                            <p>訓練が進むにつれて、<span class="keyword">ZEROSEARCH</span> と <span class="keyword">Search-R1</span> の両方で報酬スコアが一貫して上昇しました。これは、どちらの設定でもポリシーモデルが効果的に検索エンジンと対話し、正しい答えを生成することを学習していることを示しています。</p>
</div>
</div>
</li>
<li>
<div class="process-step">
<div class="step-number">2</div>
<div class="step-content">
<strong><i class="fas fa-arrow-up"></i> ZEROSEARCHによる顕著な報酬改善</strong>:
                            <p>図2(b)（Instruction-tunedモデルの場合）を見ると、<span class="keyword">ZEROSEARCH</span> は初期段階では <span class="keyword">Search-R1</span> に比べて報酬が低いものの、最終的にはより少ない変動で <span class="keyword">Search-R1</span> を上回る性能を達成しました。これは、<span class="highlight">カリキュラムロールアウト機構</span>がモデルが徐々に検索ツールの使用方法を習得するのを助けるためと考えられます。</p>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i> カリキュラムロールアウト (Curriculum Rollout)</div>
<p>学習の初期には易しいタスク（例：質の高い検索結果）から始め、徐々に難しいタスク（例：ノイズの多い検索結果）へと移行させる強化学習の戦略です。これにより、モデルは段階的に複雑な能力を習得できます。</p>
</div>
</div>
</div>
</li>
<li>
<div class="process-step">
<div class="step-number">3</div>
<div class="step-content">
<strong><i class="fas fa-universal-access"></i> ベースモデルとInstruction-tunedモデル双方での汎用性</strong>:
                            <p><span class="keyword">ZEROSEARCH</span> は、元のままの<span class="keyword">ベースモデル</span>と、指示に従うように調整された<span class="keyword">Instruction-tunedモデル</span>の両方で、安定して報酬性能を向上させました。これは、<span class="keyword">ZEROSEARCH</span> が異なるタイプのモデルに対しても有効であることを示しています。</p>
</div>
</div>
</li>
</ul>
</div>
</div>
<h3 class="section-title"><i class="fas fa-cogs"></i>5.2 Choice of Simulation LLMs</h3>
<div class="content-box">
<p>このセクションでは、シミュレーション検索エンジン（シミュレーションLLM）の様々な設定がポリシーモデルの性能にどのような影響を与えるかを調査します。具体的には、プロンプトベースのLLMとファインチューニングされたLLM（パラメータ数3Bから14B）を比較検討します。ポリシーモデルには <span class="highlight">Qwen-2.5-3B-Base</span> が使用されました。結果は表4にまとめられています。</p>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i> 用語解説</div>
<p><span class="keyword">シミュレーションLLM (Simulation LLM)</span>: 実際の検索エンジンの代わりに、検索クエリに対して検索結果風の文書を生成するように訓練または設計された大規模言語モデル。</p>
<p><span class="keyword">SFT (Supervised Fine-Tuning)</span>: 事前学習済みのLLMを、特定のタスク（この場合は検索結果のシミュレーション）に適応させるために、教師ありデータ（例：クエリと対応する「有用な文書」または「ノイズの多い文書」のペア）で追加学習すること。</p>
<p><span class="keyword">プロンプトベース (Prompt-based)</span>: LLMに特定の指示（プロンプト）を与えることで、所望の出力（この場合は検索結果風の文書）を生成させる手法。SFTほど特化していない。</p>
</div>
<img alt="Table 4: Performance of different simulated search engines" src="table3.png"/>
<p class="reference">Table 4: Performance of different simulated search engines with Qwen-2.5-3B-Base as the policy model. The Base Model refers to performance without any RL training.</p>
<p>表4から、以下の重要な点が観察されます <i class="fas fa-binoculars" style="color: var(--color-accent2);"></i>：</p>
<div class="info-grid">
<div class="info-card glass-card">
<h4><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i> SFT済みLLMの有効性</h4>
<p>ファインチューニングされた70億パラメータのシミュレーションエンジン（<span class="keyword">SFT-7B</span>）は、<span class="highlight">Google検索と同等の性能</span>を達成しました。さらに、140億パラメータのバージョン（<span class="keyword">SFT-14B</span>）はGoogle検索を<span class="highlight">上回る性能</span>を示しました。これは、適切に訓練されたLLMが強化学習の設定において実際の検索エンジンの代替として機能しうることを実証しています。</p>
</div>
<div class="info-card glass-card">
<h4><i class="fas fa-exchange-alt" style="color: var(--color-primary);"></i> SFT vs. プロンプトベース</h4>
<p>ファインチューニングされたシミュレーションエンジンは、プロンプトベースのシミュレーションエンジンよりも<span class="highlight">大幅に優れた性能</span>を示しました。プロンプトベースの手法は、実際の検索エンジンの応答スタイルを模倣するように明示的に指示されていますが、実際の検索結果との間には依然として大きな<span class="keyword">分布ギャップ</span>（応答の質や形式の違い）が存在し、これが性能低下につながっていると考えられます。</p>
</div>
<div class="info-card glass-card">
<h4><i class="fas fa-layer-group" style="color: var(--color-secondary);"></i> モデルサイズと性能</h4>
<p>シミュレーションLLMの<span class="highlight">モデルサイズが大きくなるほど、一貫して性能が向上</span>しました。大規模なシミュレーションLLMは、より強力なシミュレーション能力を持つだけでなく、<span class="keyword">有用な文書とノイズの多い文書をより正確に区別</span>することができます。これにより、訓練中のカリキュラムロールアウトがより効果的に機能するようになります。</p>
</div>
</div>
</div>
<h3 class="section-title"><i class="fas fa-history"></i>5.3 Interaction Turns Study</h3>
<div class="content-box">
<p>このセクションでは、<span class="keyword">ZEROSEARCH</span> の訓練ダイナミクスを分析します。具体的には、<span class="highlight">LLaMA-3.2-3B-Base</span> をポリシーモデルとして使用し、訓練中の報酬曲線と対話ターン数の両方を調べます。結果は図2(c)に示されています。</p>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i> 対話ターン数 (Interaction Turns)</div>
<p>ポリシーモデルが最終的な回答を生成するまでに、検索エンジン（シミュレーションLLMを含む）と何回やり取り（検索クエリの発行と結果の受信）を行ったかを示す数です。</p>
</div>
<img alt="Figure 2 (c): Interaction Turns Study" src="reward_curve_zerosearch_searchr1_comparison.jpg"/>
<p class="reference">Figure 2: (c): The reward curve and interaction turns during training of LLaMA-3.2-3B-Base. (注: 図2(c)は、横軸が学習ステップ、左の縦軸が報酬、右の縦軸が対話ターン数を示します。)</p>
<p>図2(c)から、訓練プロセスにおける以下の2つの主要なフェーズが観察できます 📈📉:</p>
<div class="two-column">
<div class="column">
<div class="bubble-box">
<h4><i class="fas fa-hourglass-start"></i> 訓練初期フェーズ</h4>
<p><span class="highlight">対話ターン数は急激に減少し、報酬はゆっくりと増加</span>します。</p>
<p><strong>理由</strong>: 最初は、ポリシーモデルが検索エンジンを適切に呼び出す方法を知らないため、<span class="keyword">冗長な対話</span>が発生します。しかし、モデルはすぐに正しいフォーマットを学習し、効果的に不要なステップを排除し始めます。📝➡️🗑️</p>
</div>
</div>
<div class="column">
<div class="bubble-box">
<h4><i class="fas fa-hourglass-end"></i> 訓練進行フェーズ</h4>
<p><span class="highlight">対話ターン数と報酬曲線の両方が急激に増加し、その後安定</span>します。</p>
<p><strong>理由</strong>: ポリシーモデルが関連文書を効果的に検索し、最終的に正しい答えを達成できるようになるため、より高い報酬が得られます。注目すべきは、訓練の後半段階で報酬が安定しているように見えても、<span class="keyword">カリキュラムロールアウト機構</span>により、根本的なタスクの難易度は上昇し続けている点です。したがって、ポリシーは高い報酬スコアを維持するために、戦略を継続的に洗練させ、推論能力を向上させる必要があります。🧠💡</p>
</div>
</div>
</div>
</div>
<h3 class="section-title"><i class="fas fa-balance-scale-right"></i>5.4 Different RL algorithms: REINFORCE vs. GRPO vs. PPO</h3>
<div class="content-box">
<p>このセクションでは、<span class="keyword">ZEROSEARCH</span> フレームワーク内で、広く使用されている3つの強化学習（RL）アルゴリズム（<span class="keyword">REINFORCE</span>, <span class="keyword">GRPO</span>, <span class="keyword">PPO</span>）の性能を評価します。ポリシーモデルには <span class="highlight">Qwen-2.5-3B-Base</span> が使用されました。比較結果は表5に示されています。</p>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i> RLアルゴリズム紹介</div>
<ul class="unstyled-list">
<li><span class="keyword">REINFORCE</span>: 最も基本的な方策勾配アルゴリズムの一つ。モンテカルロ法を用いて方策の勾配を推定します。</li>
<li><span class="keyword">GRPO (Group Relative Policy Optimization)</span>: グループ化された相対的な方策最適化。詳細はこの論文の文脈では省略されていますが、一般的には方策最適化の一手法です。</li>
<li><span class="keyword">PPO (Proximal Policy Optimization)</span>: 方策の更新ステップを制限することで学習の安定性を高めるアルゴリズム。</li>
</ul>
</div>
<img alt="Table 5: Performance of ZEROSEARCH under different RL algorithms" src="table4.png"/>
<p class="reference">Table 5: Performance of ZEROSEARCH under different RL algorithms. We compare REINFORCE, GRPO and PPO using Qwen-2.5-3B-Base as the policy model.</p>
<div class="note-box">
<div class="note-title"><i class="fas fa-poll"></i> 結果の分析 <i class="fas fa-chart-bar"></i></div>
<p>表5から以下の点が明らかになります:</p>
<ul class="unstyled-list">
<li><i class="fas fa-check-double" style="color: var(--color-accent1);"></i> <strong>全アルゴリズムの有効性</strong>: 3つのアルゴリズムすべてが、我々のフレームワーク内でモデルの検索実行能力を効果的に向上させました。これは、<span class="keyword">ZEROSEARCH</span> の<span class="highlight">強力な汎用性</span>を示しています。</li>
<li><i class="fas fa-trophy" style="color: var(--color-accent3);"></i> <strong>REINFORCEの優位性</strong>: これらのうち、<span class="keyword">REINFORCE</span> が最高の性能を達成しました。これは、<span class="keyword">Search-R1 [16]</span> での観察結果と一致しており、訓練の安定性における利点をさらに強調しています。</li>
<li><i class="fas fa-dollar-sign" style="color: var(--color-secondary);"></i> <strong>コスト効率の示唆</strong>: <span class="keyword">REINFORCE</span> と <span class="keyword">GRPO</span> はどちらも<span class="highlight">繰り返しロールアウト</span>を伴います。これは、実際の検索エンジンと対話する場合、より高いAPIコストが発生することを意味します。この事実は、我々の<span class="highlight">シミュレートされた検索設定の実用性</span>をさらに強調するものです。💰➡️📉</li>
</ul>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i> 繰り返しロールアウト (Repeated Rollouts)</div>
<p>強化学習において、同じ初期状態やプロンプトから複数回エピソード（一連の行動と状態遷移）を生成し、それらの結果を学習に利用する手法。より安定した勾配推定や探索の促進に役立つことがありますが、計算コストが増加します。</p>
</div>
</div>
</div>
<h3 class="section-title"><i class="fas fa-tasks"></i>5.5 Curriculum Rollout Study</h3>
<div class="content-box">
<p>このセクションでは、提案手法である<span class="keyword">カリキュラムロールアウト戦略</span>の有効性を調査します。具体的には、訓練全体を通してノイズの多い文書を生成する確率を0.5に固定したベースラインの<span class="keyword">ランダムロールアウト設定</span>と比較します。ポリシーモデルには <span class="highlight">Qwen-2.5-3B-Base</span> と <span class="highlight">LLaMA-3.2-3B-Base</span> が使用されました。比較結果は表6にまとめられています。</p>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i> カリキュラムロールアウト vs. ランダムロールアウト</div>
<p><span class="keyword">カリキュラムロールアウト</span>: 本論文で提案されている、学習初期は質の高い（ノイズの少ない）検索結果を提供し、徐々に質の低い（ノイズの多い）検索結果の割合を増やしていく戦略。</p>
<p><span class="keyword">ランダムロールアウト (Random Rollout)</span>: 比較対象のベースライン戦略。学習期間中、一定の確率（ここでは0.5）でノイズの多い文書を生成する。</p>
</div>
<img alt="Table 6: Curriculum Rollout Study" src="table5.png"/>
<p class="reference">Table 6: Curriculum Rollout Study. We compare the performance of standard and random rollout settings using the Qwen-2.5-3B-Base and LLaMA-3.2-3B-Base as the policy models.</p>
<div class="framework-box">
<div class="framework-title"><i class="fas fa-clipboard-check"></i> 結果の明確な示唆</div>
<p>表6の結果は明確に、<span class="highlight">標準的な「易から難へ」のカリキュラム</span>が、両方のモデルにおいてランダムロールアウト方式よりも<span class="highlight">一貫して優れた性能</span>を示すことを示しています。これは、我々のフレームワークにおけるカリキュラムロールアウトの有効性を検証するものです。</p>
<div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));">
<div class="feature-item glass-card">
<i class="fas fa-chalkboard-teacher fa-2x" style="color: var(--color-primary);"></i>
<p><strong>初期学習の促進</strong></p>
<p>より良い検索結果から始めることで、ポリシーモデルはまず検索エンジンの呼び出し方法と基本的な出力形式を学習できます。</p>
</div>
<div class="feature-item glass-card">
<i class="fas fa-level-up-alt fa-2x" style="color: var(--color-secondary);"></i>
<p><strong>段階的な難易度上昇</strong></p>
<p>訓練が進むにつれて、モデルはますます困難なシナリオにさらされ、より強力な推論能力を育成します。</p>
</div>
</div>
<p style="text-align: center; margin-top: 15px;">
<i class="fas fa-arrow-down" style="color: var(--color-accent1); font-size: 20px;"></i>
</p>
<p style="text-align: center; font-weight: bold; color: var(--color-accent1);">カリキュラム学習による効果的な能力獲得！🎓✨</p>
</div>
</div>
</div>
<div class="section-card" id="6_Conclusion_and_Limitation_Discussion">
<h2 class="section-title"><i class="fas fa-flag-checkered"></i> 6 Conclusion and Limitation Discussion</h2>
<div class="bubble-box">
<p style="font-family: 'Yomogi', cursive; text-align: center; font-size: 18px; color: var(--color-primary);">🎉 論文のまとめと、ちょっぴり反省点コーナー！ 🎉</p>
<p>このセクションでは、本論文で提案された革新的なフレームワーク <span class="keyword">ZEROSEARCH</span> の主な成果を総括し、その有効性を改めて強調します。どのような点が優れているのか、そしてどのような可能性を秘めているのかを見ていきましょう。
        <br/>さらに、どんな素晴らしい研究にも限界はあるものです。ここでは、<span class="keyword">ZEROSEARCH</span> が抱えるいくつかの課題や制約についても正直に議論し、将来の改善に向けたヒントを探ります。
        <br/>一言でまとめると、<span class="highlight">「ZEROSEARCHは、検索エンジンを使わずにLLMの検索スキルを鍛える画期的な方法だけど、実行するにはちょっぴりパワフルなコンピュータ（GPUサーバー）が必要だよ！」</span>というお話です。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-trophy"></i> 結論 (Conclusion)</h3>
<div class="info-grid" style="grid-template-columns: 1fr;">
<div class="info-card" style="border-left: 5px solid var(--color-accent1);">
<p><i class="fas fa-lightbulb" style="color: var(--color-accent1);"></i> 本論文では、<span class="keyword">ZEROSEARCH</span> と名付けられた、全く新しい<span class="highlight">強化学習（Reinforcement Learning: RL）フレームワーク</span>を提案しました。</p>
<div class="framework-box" style="margin-top: 15px;">
<p class="framework-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-cogs"></i> ZEROSEARCHの核心アイデア <i class="fas fa-brain"></i></p>
<ul class="unstyled-list">
<li><i class="fas fa-search-dollar" style="color: var(--color-secondary);"></i> <strong>画期的な目標:</strong> 従来のRL手法では、LLMに検索能力を学習させるために実際のウェブ検索エンジン（Googleなど）と何度もやり取りさせる必要がありました。これは時間もコストもかかります。<span class="keyword">ZEROSEARCH</span>は、この<span class="highlight">「実際の検索エンジンとのインタラクション」を一切行わずに</span>、LLMの検索能力を効果的に向上させることを目指します。</li>
<li><i class="fas fa-user-astronaut" style="color: var(--color-accent2);"></i> <strong>賢いアプローチ:</strong> LLM自体が持つ広範な知識と生成能力を利用し、<span class="highlight">LLMに検索エンジンの役割をシミュレート</span>させます。つまり、別のLLMが「仮想の検索エンジン」として機能するのです。</li>
</ul>
<div style="text-align:center; margin-top:10px; padding:10px; background-color:rgba(230,240,255,0.5); border-radius:8px;">
<span style="font-family: 'Kaisei Decol', serif; font-size:16px;">従来の検索 <i class="fas fa-wifi" style="color:var(--color-primary);"></i> 実際の検索エンジン</span>
<br/><i class="fas fa-times-circle" style="color:red; font-size:20px; margin: 5px 0;"></i><br/>
<span style="font-family: 'Kaisei Decol', serif; font-size:16px;">ZEROSEARCH <i class="fas fa-recycle" style="color:var(--color-accent1);"></i> LLMによるシミュレーション検索</span>
</div>
</div>
</div>
</div>
<div class="arrow-connector" style="margin: 25px 0;">
<i class="fas fa-chevron-down fa-2x" style="color: var(--color-primary);"></i>
</div>
<h4 class="subsection-title" style="font-size: 18px; color: var(--color-accent1); font-family: 'Yomogi', cursive;"><i class="fas fa-tools"></i> ZEROSEARCHを支える2本の柱：主要技術 <i class="fas fa-cogs"></i></h4>
<div class="info-grid">
<div class="info-card glass-card">
<h5 style="font-family: 'Kaisei Decol', serif; color: var(--color-primary);"><i class="fas fa-graduation-cap"></i> 1. 教師ありファインチューニング (Supervised Fine-Tuning: SFT)</h5>
<p>まず、<span class="keyword">SFT</span> という手法を用いて、LLMを特別な<span class="highlight">「検索モジュール」</span>へと変身させます。このSFTのプロセスは、LLMに特定のタスク（この場合は検索結果のシミュレーション）を上手にこなせるように追加学習させるようなものです。</p>
<p>この検索モジュールは、ユーザーからの質問（クエリ）に対して、意図的に2種類の異なる性質を持つ文書を生成できるようになります。</p>
<ul class="unstyled-list" style="margin-top: 10px;">
<li><i class="fas fa-file-alt" style="color: var(--color-accent1);"></i> <strong class="keyword">有用な文書 (Useful documents):</strong> 質問に答えるために本当に役立つ情報、正しい手がかり、あるいは直接的な答えを含む文書。これらは、モデルが良い判断を下すための「良いエサ」となります。</li>
<li><i class="fas fa-file-excel" style="color: var(--color-secondary);"></i> <strong class="keyword">ノイズの多い文書 (Noisy documents):</strong> 質問とは無関係な情報、不正確な内容、あるいはモデルを混乱させるような誤解を招く情報を含む文書。これらは、モデルが情報の真偽を見抜く能力を鍛えるための「訓練用の障害物」です。</li>
</ul>
<div style="text-align: center; margin-top: 15px; padding: 10px; border: 2px dashed var(--color-primary); border-radius: 8px;">
<span style="font-size: 28px; font-family: 'Yomogi', cursive;">🤖</span> (普通のLLM)
                <i class="fas fa-arrow-right fa-2x" style="color: var(--color-primary); margin: 0 10px; vertical-align: middle;"></i>
<span style="font-size: 24px; font-family: 'Kaisei Decol', serif;">🎓SFT</span>
<i class="fas fa-arrow-right fa-2x" style="color: var(--color-primary); margin: 0 10px; vertical-align: middle;"></i>
<span style="font-size: 28px; font-family: 'Yomogi', cursive;">🔍</span> (検索モジュールLLM)
                <div style="margin-top:10px;">
<span style="font-size: 12px; display:inline-block; padding:5px; background-color:rgba(92,184,92,0.2); border-radius:4px;">👍 役立つ文書</span>
<span style="font-size: 12px; display:inline-block; padding:5px; background-color:rgba(255,126,95,0.2); border-radius:4px; margin-left:5px;">👎 ノイズ文書</span>
</div>
</div>
<p style="font-size:12px; color: var(--color-gray); margin-top:10px;">このSFTにより、検索モジュールLLMはクエリに応じて「良い情報」と「悪い情報」を意図的に出し分ける能力を獲得します。これが後のカリキュラム学習の鍵となります。</p>
</div>
<div class="info-card glass-card">
<h5 style="font-family: 'Kaisei Decol', serif; color: var(--color-primary);"><i class="fas fa-layer-group"></i> 2. カリキュラムロールアウトメカニズム (Curriculum Rollout Mechanism)</h5>
<p>次に、<span class="keyword">カリキュラム学習</span>の考え方に基づいた特別な<span class="highlight">「ロールアウト戦略」</span>（強化学習の訓練データ収集プロセス）を採用します。これは、赤ちゃんにいきなり難しい問題を解かせるのではなく、簡単な問題から始めて徐々に難易度を上げていく教育方法に似ています。</p>
<p>具体的には、訓練の進行度合いに応じて、検索モジュールLLMが生成する文書の質を以下のように変化させます:</p>
<ul class="unstyled-list" style="margin-top: 10px;">
<li><i class="fas fa-dice-one" style="color: var(--color-accent2);"></i> <strong>訓練初期:</strong> 主に<span class="highlight">有用な文書</span>を多く提供し、基本的な検索タスクの進め方や正しい応答形式を学習させます。</li>
<li><i class="fas fa-dice-three" style="color: var(--color-accent2);"></i> <strong>訓練中期:</strong> 徐々に<span class="highlight">ノイズの多い文書</span>の割合を増やし、情報を選別する能力を養います。</li>
<li><i class="fas fa-dice-six" style="color: var(--color-accent2);"></i> <strong>訓練後期:</strong> かなり多くのノイズが含まれる、<span class="highlight">挑戦的な検索シナリオ</span>を提供し、高度な推論能力と頑健性を鍛え上げます。</li>
</ul>
<div style="text-align: center; margin-top: 15px; padding: 10px; border: 2px dashed var(--color-accent2); border-radius: 8px;">
<span style="font-family: 'Yomogi', cursive;">ステップ <i class="fas fa-shoe-prints"></i></span><br/>
<i class="fas fa-mountain" style="font-size: 20px; color: var(--color-accent1);"></i> (簡単な課題)
                <i class="fas fa-arrow-right" style="color: var(--color-accent2); margin: 0 5px;"></i>
<i class="fas fa-hiking" style="font-size: 24px; color: var(--color-primary);"></i> (中程度の課題)
                <i class="fas fa-arrow-right" style="color: var(--color-accent2); margin: 0 5px;"></i>
<i class="fas fa-rocket" style="font-size: 28px; color: var(--color-secondary);"></i> (難しい課題)
                <p style="font-size:12px; color: var(--color-gray); margin-top:5px;">推論能力 <i class="fas fa-level-up-alt" style="color:var(--color-accent1);"></i></p>
</div>
<p class="reference" style="margin-top:10px;">この段階的な難易度調整により、モデルは無理なくステップアップし、最終的には非常にノイズの多い状況でも的確な推論を行えるようになります。</p>
</div>
</div>
<div class="arrow-connector" style="margin: 25px 0;">
<i class="fas fa-chevron-down fa-2x" style="color: var(--color-primary);"></i>
</div>
<h4 class="subsection-title" style="font-size: 18px; color: var(--color-accent1); font-family: 'Yomogi', cursive;"><i class="fas fa-chart-line"></i> 実験結果のハイライト：ZEROSEARCHは本当にすごいの？ <i class="fas fa-award"></i></h4>
<div class="glass-card" style="background: linear-gradient(135deg, rgba(255,255,255,0.7), rgba(230,240,255,0.8));">
<p>広範な実験の結果、<span class="keyword">ZEROSEARCH</span> はその有効性を力強く証明しました。主な成果は以下の通りです。</p>
<div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));">
<div class="feature-item" style="border-top: 3px solid var(--color-accent3);">
<i class="fas fa-medal fa-2x" style="color: var(--color-accent3); margin-bottom:10px;"></i>
<h5 style="font-family: 'Kaisei Decol', serif;">1. 既存手法を凌駕する性能</h5>
<p><span class="highlight">実際の検索エンジンを利用する従来の手法（例: Search-R1）よりも優れたパフォーマンス</span>を達成しました。これは、シミュレーションによる検索でも実環境以上の効果が得られる可能性を示唆しています。</p>
</div>
<div class="feature-item" style="border-top: 3px solid var(--color-accent1);">
<i class="fas fa-universal-access fa-2x" style="color: var(--color-accent1); margin-bottom:10px;"></i>
<h5 style="font-family: 'Kaisei Decol', serif;">2. 驚くべき汎化能力</h5>
<p>ZEROSEARCHは特定のLLMや設定に限定されません。</p>
<ul class="unstyled-list" style="text-align:left; font-size:13px; margin-top:5px;">
<li><i class="fas fa-robot" style="color:var(--color-primary);"></i> <span class="keyword">ベースモデル</span>（事前学習されたままのLLM）と<span class="keyword">指示チューニングモデル</span>（特定タスク向けに調整されたLLM）の両方で効果を発揮。</li>
<li><i class="fas fa-expand-arrows-alt" style="color:var(--color-primary);"></i> 3B（30億パラメータ）から14B（140億パラメータ）といった<span class="highlight">様々なサイズのLLM</span>で一貫して良好な結果を示しました。</li>
</ul>
</div>
<div class="feature-item" style="border-top: 3px solid var(--color-accent2);">
<i class="fas fa-puzzle-piece fa-2x" style="color: var(--color-accent2); margin-bottom:10px;"></i>
<h5 style="font-family: 'Kaisei Decol', serif;">3. 幅広いRLアルゴリズムへの対応</h5>
<p><span class="highlight">REINFORCE、PPO、GRPO</span>など、主要な強化学習アルゴリズムとスムーズに連携し、それぞれのアルゴリズムで性能向上を確認できました。これにより、研究者は好みのRLアルゴリズムを選択してZEROSEARCHを適用できます。</p>
</div>
</div>
<div style="text-align: center; margin-top: 20px;">
<span class="badge yellow" style="font-size:14px; padding: 8px 12px;"><i class="fas fa-star"></i> 高性能</span>
<span class="badge blue" style="font-size:14px; padding: 8px 12px; margin-left:10px;"><i class="fas fa-globe-americas"></i> 高汎用性</span>
<span class="badge purple" style="font-size:14px; padding: 8px 12px; margin-left:10px;"><i class="fas fa-cogs"></i> 高互換性</span>
</div>
<p style="font-family: 'Yomogi', cursive; text-align:center; margin-top:15px; font-size:16px;">これらの結果は、ZEROSEARCHがLLMの検索能力を向上させるための実用的かつ強力なアプローチであることを示しています。</p>
</div>
<h3 class="subsection-title" style="margin-top: 30px;"><i class="fas fa-exclamation-triangle" style="color: var(--color-secondary);"></i> 限界の議論 (Limitation Discussion) <i class="fas fa-search-minus"></i></h3>
<div class="challenge-box">
<p class="challenge-title" style="font-family: 'Yomogi', cursive; font-size:18px;"><i class="fas fa-server"></i> インフラストラクチャに関する考慮事項</p>
<p>素晴らしい成果を上げたZEROSEARCHですが、実用化に向けてはいくつかの限界点も認識しておく必要があります。主なものは以下の通りです。</p>
<div class="definition-box" style="margin-top:15px; background-color: rgba(255,245,230,0.7);">
<p class="definition-title" style="color: var(--color-secondary); border-bottom-color: var(--color-secondary);"><i class="fas fa-microchip"></i> 課題点：GPUサーバーへのアクセスが必須</p>
<p>ZEROSEARCHの心臓部である<span class="keyword">「シミュレートされた検索LLM」</span>（検索タスクを代行するLLM）を展開し、効率的に動作させるためには、<span class="highlight">強力な計算能力を持つGPUサーバーへのアクセスが不可欠</span>です。これは、研究室や個人が手軽に試すには、ややハードルが高いかもしれません。</p>
<div style="display: flex; align-items: center; justify-content: space-around; margin-top: 15px; padding: 10px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
<div>
<i class="fas fa-cloud-upload-alt fa-3x" style="color: var(--color-primary);"></i>
<p style="font-family: 'Kaisei Decol', serif; font-size: 14px; margin-top:5px;">シミュレーションLLM</p>
</div>
<i class="fas fa-arrow-right fa-2x" style="color: var(--color-gray); margin: 0 20px;"></i>
<div>
<i class="fas fa-server fa-3x" style="color: var(--color-secondary);"></i>
<p style="font-family: 'Kaisei Decol', serif; font-size: 14px; margin-top:5px;">GPUサーバーが必要</p>
</div>
</div>
</div>
<div class="note-box" style="margin-top:20px; border-left-color: var(--color-accent1); background-color: rgba(92,184,92,0.1);">
<p class="note-title" style="color: var(--color-accent1); font-family: 'Yomogi', cursive;"><i class="fas fa-coins"></i> コスト面での比較</p>
<ul class="unstyled-list">
<li><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i> <strong>利点:</strong> Google Search APIのような<span class="highlight">商用検索APIの利用料金と比較すれば、長期的にはGPUサーバー運用の方がコスト効率は良い</span>です。特に大規模な実験や多数のモデルを訓練する場合、API料金は莫大になる可能性がありますが、ZEROSEARCHはその心配がありません。</li>
<li><i class="fas fa-exclamation-circle" style="color: var(--color-secondary);"></i> <strong>課題:</strong> しかし、GPUサーバーの導入や維持には、<span class="highlight">初期投資や電気代、専門知識を持つ人材などの追加のインフラコストが発生</span>します。これらのコストは、特にリソースが限られている小規模な研究グループやスタートアップにとっては無視できない要因となり得ます。</li>
</ul>
<p style="font-size: 12px; color: var(--color-gray); margin-top:10px;">論文の付録D (Appendix D) で、これらのコストに関するより詳細な比較・分析が提供されているとのことなので、興味のある方はそちらも参照してください。</p>
<div style="text-align: center; margin-top: 15px;">
<span style="font-family: 'Yomogi', cursive; display: block; margin-bottom: 5px;">コスト比較イメージ <i class="fas fa-balance-scale"></i></span>
<div style="display:flex; justify-content:space-around; align-items:flex-start;">
<div style="text-align:center; padding:10px; border:1px solid var(--color-secondary); border-radius:5px; width:45%;">
<strong style="color:var(--color-secondary);">商用API</strong><br/>
<i class="fas fa-dollar-sign" style="color:var(--color-secondary);"></i> 初期費用: 低<br/>
<i class="fas fa-chart-line" style="color:var(--color-secondary);"></i> 利用量比例: 高
                    </div>
<div style="text-align:center; padding:10px; border:1px solid var(--color-accent1); border-radius:5px; width:45%;">
<strong style="color:var(--color-accent1);">ZEROSEARCH (GPU)</strong><br/>
<i class="fas fa-server" style="color:var(--color-accent1);"></i> 初期費用: 高<br/>
<i class="fas fa-recycle" style="color:var(--color-accent1);"></i> 利用量比例: 低
                    </div>
</div>
</div>
</div>
<p style="font-family: 'Yomogi', cursive; text-align:center; margin-top:20px; font-size:16px;">🔍 この限界点は、ZEROSEARCHの適用範囲や導入の容易さに影響を与える可能性がありますが、コスト効率やスケーラビリティの観点からは依然として魅力的な選択肢と言えるでしょう。</p>
</div>
<div class="note-box" style="background-color: rgba(74, 111, 165, 0.1); border-left-color: var(--color-primary); margin-top: 25px;">
<p class="note-title" style="color: var(--color-primary); font-family: 'Yomogi', cursive; font-size:18px;"><i class="fas fa-lightbulb"></i> まとめると…</p>
<p><span class="keyword">ZEROSEARCH</span>は、<span class="highlight">実際の検索エンジンを使わずにLLMの検索・推論能力を向上させる</span>という点で非常に画期的な手法です。様々な条件下で高い性能を示し、多くのRLアルゴリズムと互換性があるなど、多くの利点を持っています。しかし、その強力なシミュレーション機能を実現するためにはGPUサーバーという<span class="highlight">計算リソースが必要</span>になる点が、現時点での主な制約と言えるでしょう。今後の技術発展やコスト低減により、この制約が緩和されることが期待されます。</p>
</div>
</div>
<div class="section-card" id="A_Compare_ZEROSEARCH_with_Real_Search_Engine">
<h2 class="section-title"><i class="fas fa-chart-bar"></i> A Compare ZEROSEARCH with Real Search Engine</h2>
<div class="content-box">
<p>このセクションでは、<span class="keyword">ZEROSEARCH</span>と実際の検索エンジンを使った場合とを、特に<span class="badge yellow">LLaMA-3.2-3B</span>モデルおよび<span class="badge yellow">Qwen-2.5-7B</span>モデルシリーズを用いて比較した追加の結果について解説します。</p>
<div class="bubble-box">
<p><i class="fas fa-bullseye"></i> <strong>このセクションの主な論点</strong></p>
<p>論文の主張の核心は、<span class="keyword">ZEROSEARCH</span>が、実際の検索エンジンと比較して、より<span class="highlight">滑らかな報酬曲線</span>を描きながらモデルを訓練できる点にあります。この優位性は、主にZEROSEARCHが訓練プロセス中に検索ドキュメントの<span class="keyword">品質（難易度）を動的に制御できる</span>能力に起因します。</p>
</div>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fas fa-image"></i> 📊 Figure 3: 報酬曲線の比較</h3>
<p>まず、論文で提示されているFigure 3を見てみましょう。この図は、<span class="keyword">ZEROSEARCH</span>と実検索エンジンを利用する<span class="keyword">Search-R1</span>というベースライン手法の<span class="keyword">報酬曲線</span>を比較しています。</p>
<img alt="Figure 3: Reward curve comparison between ZEROSEARCH and Search-R1" src="reward_curve_zerosearch_searchr1_comparison.jpg"/>
<div class="note-box">
<p class="note-title"><i class="fas fa-chart-line"></i> 図3の読み解き方</p>
<ul>
<li><span class="badge blue">横軸</span>: 訓練のステップ数（学習の進行度）</li>
<li><span class="badge blue">縦軸</span>: 報酬スコア（モデルの性能の高さ）</li>
<li><span class="badge purple">各グラフ</span>:
                    <ul>
<li>(a) LLaMA-3.2-3B-Base モデル</li>
<li>(b) LLaMA-3.2-3B-Instruct モデル</li>
<li>(c) Qwen-2.5-7B-Base モデル</li>
<li>(d) Qwen-2.5-7B-Instruct モデル</li>
</ul>
</li>
<li><span class="badge orange">線の種類</span>: ZEROSEARCH（図中の凡例で確認）とSearch-R1（実検索エンジン使用、図中の凡例で確認）の性能推移を示しています。</li>
</ul>
<p><i class="fas fa-lightbulb"></i> <strong>注目ポイント</strong>: 全体的に、<span class="keyword">ZEROSEARCH</span>に対応する線（例えば、青や緑の線）が、Search-R1に対応する線（例えば、赤やオレンジの線）と比較して、<span class="highlight">より滑らかに上昇し、振動が少ない傾向</span>が見られます。これが「滑らかな報酬曲線」の意味するところです。</p>
</div>
</div>
<div class="arrow-connector"></div>
<div class="content-box">
<h3 class="subsection-title"><i class="fas fa-balance-scale"></i> ZEROSEARCH vs. 実検索エンジン：なぜ差が出るのか？</h3>
<p>論文では、モデルのサイズ（3Bや7B）に関わらず、<span class="keyword">ZEROSEARCH</span>が一貫して実検索エンジンよりも滑らかな報酬曲線を達成すると述べています。この違いが生じる主な理由を掘り下げてみましょう。</p>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-book-open"></i> ちょっと用語解説</p>
<p><span class="keyword">Rollout (ロールアウト)</span>: 強化学習において、現在の<span class="keyword">policy model</span> (方策モデル) を使って、環境（この場合は検索シミュレータや実検索エンジン）と一連の相互作用を行い、学習データを収集するプロセスのことです。</p>
<p><span class="keyword">Policy Model (方策モデル)</span>: LLMが次にどのような行動（思考、検索クエリ生成、回答など）をとるかを決定するモデルです。この研究ではLLM自体が方策モデルの役割を担います。</p>
</div>
<div class="two-column">
<div class="column">
<div class="challenge-box">
<p class="challenge-title"><i class="fas fa-search-minus"></i> <i class="fas fa-exclamation-triangle"></i> 実検索エンジンの課題：ドキュメント品質の制御不能性</p>
<p>実世界の検索エンジンから返されるドキュメントの品質は、<span class="keyword">rollout</span>中に制御することが困難です。これが訓練プロセスに以下のような影響を与えます。</p>
<ul class="unstyled-list">
<li>
<div class="process-step">
<div class="step-number" style="background-color: var(--color-secondary);">①</div>
<div class="step-content">
<strong><i class="fas fa-seedling"></i> 訓練初期段階</strong><br/>
                                    返されるドキュメントの品質が低い（ノイズが多い、情報が不十分など）場合、方策モデルがタスクの正しい理解を深めるのを妨げる可能性があります。
                                    <div style="text-align: center; margin-top:10px;">
<i class="fas fa-book" style="font-size: 20px; color: var(--color-gray);"></i> <i class="fas fa-times" style="color:red; margin: 0 5px;"></i> <i class="fas fa-brain" style="font-size: 20px; color: var(--color-gray);"></i>
</div>
<span class="highlight" style="background-color: rgba(255, 126, 95, 0.2);">まるで、初心者が質の悪い参考書で混乱してしまうような状況です。</span>
</div>
</div>
</li>
<li>
<div class="process-step">
<div class="step-number" style="background-color: var(--color-secondary);">②</div>
<div class="step-content">
<strong><i class="fas fa-graduation-cap"></i> 訓練後期段階</strong><br/>
                                    逆に、ドキュメントの品質が高すぎる（常に完璧な情報が与えられる）場合、方策モデルは十分に挑戦されず、推論能力を継続的に向上させるインセンティブが低下する可能性があります。
                                    <div style="text-align: center; margin-top:10px;">
<i class="fas fa-trophy" style="font-size: 20px; color: var(--color-accent3);"></i> <i class="fas fa-arrow-down" style="color:var(--color-secondary); margin: 0 5px;"></i> <i class="fas fa-user-astronaut" style="font-size: 20px; color: var(--color-gray);"></i> (<small>挑戦機会の減少</small>)
                                    </div>
<span class="highlight" style="background-color: rgba(255, 126, 95, 0.2);">簡単すぎる問題ばかりでは、応用力は鍛えられません。</span>
</div>
</div>
</li>
</ul>
</div>
</div>
<div class="column">
<div class="note-box" style="border-left-color: var(--color-accent1); background-color: rgba(92, 184, 92, 0.1);">
<p class="note-title" style="color: var(--color-accent1);"><i class="fas fa-cogs"></i> <i class="fas fa-check-circle"></i> ZEROSEARCHの強み：ドキュメント難易度の動的制御</p>
<p><span class="keyword">ZEROSEARCH</span>は、これとは対照的に、訓練全体を通してシミュレートされた検索エンジンが生成する<span class="highlight">ドキュメントの難易度を動的に制御</span>できます（これは以前のセクションで説明された「カリキュラム学習ベースのロールアウト」戦略によるものです）。</p>
<p>この制御可能性が、以下のような効果的な学習プロセスを可能にします。</p>
<ul class="unstyled-list">
<li>
<div class="process-step">
<div class="step-number" style="background-color: var(--color-accent1);">❶</div>
<div class="step-content">
<strong><i class="fas fa-chalkboard-teacher"></i> 基礎理解の構築 (初期)</strong><br/>
                                    方策モデルは、まずタスクの基本的な理解（例：正しい出力形式、簡単な情報検索）を構築します。
                                    <div style="text-align: center; margin-top:10px;">
<i class="fas fa-book-reader" style="font-size: 20px; color: var(--color-accent1);"></i> <i class="fas fa-arrow-right" style="color:var(--color-accent1); margin: 0 5px;"></i> <i class="fas fa-lightbulb" style="font-size: 20px; color: var(--color-accent3);"></i>
</div>
<span class="highlight" style="background-color: rgba(92, 184, 92, 0.2);">易しい問題から始めて、基本をしっかり固めるイメージです。</span>
</div>
</div>
</li>
<li>
<div class="process-step">
<div class="step-number" style="background-color: var(--color-accent1);">❷</div>
<div class="step-content">
<strong><i class="fas fa-mountain"></i> 複雑なシナリオへの適応 (進行)</strong><br/>
                                    学習が進むにつれて、徐々により複雑でノイズの多い、挑戦的な検索シナリオに直面するようになります。
                                    <div style="text-align: center; margin-top:10px;">
<i class="fas fa-puzzle-piece" style="font-size: 20px; color: var(--color-primary);"></i> <i class="fas fa-arrow-right" style="color:var(--color-accent1); margin: 0 5px;"></i> <i class="fas fa-brain" style="font-size: 20px; color: var(--color-accent1);"></i> (<small>高度な推論力UP</small>)
                                    </div>
<span class="highlight" style="background-color: rgba(92, 184, 92, 0.2);">段階的に難易度を上げることで、モデルはより頑健な推論能力を獲得します。</span>
</div>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="glass-card" style="margin-top: 25px;">
<p style="text-align: center; font-family: 'Yomogi', cursive; font-size: 18px;">
<i class="fas fa-rocket" style="color: var(--color-secondary);"></i> <strong>結論として</strong> <i class="fas fa-rocket" style="color: var(--color-secondary); transform: scaleX(-1);"></i>
</p>
<p>ZEROSEARCHの<span class="keyword">カリキュラム学習</span>と<span class="keyword">ドキュメント品質の制御</span>は、方策モデルが安定して段階的に学習を進めることを可能にし、結果として実検索エンジンを用いた場合よりも滑らかで効果的な性能向上（報酬曲線の改善）に繋がるのです。</p>
<p style="text-align:center; margin-top:15px;">
<span class="badge purple">安定学習</span> <i class="fas fa-long-arrow-alt-right"></i> <span class="badge green">着実な性能向上</span> <i class="fas fa-long-arrow-alt-right"></i> <span class="badge blue">高い最終性能</span>
</p>
</div>
</div>
<div class="section-card" id="B_Compare_Base_and_Instruct_LLMs">
<h2 class="section-title"><i class="fas fa-chart-line"></i> B Compare Base and Instruct LLMs</h2>
<div class="content-box">
<p>このセクションでは、<span class="keyword">ベースモデル</span>と<span class="keyword">インストラクションチューニング済みモデル</span>という2種類のLLMが、ZEROSEARCHフレームワークでどのように学習を進めるかを比較しています。特に、訓練中の<span class="keyword">報酬（ごほうび）</span>の推移に着目し、それぞれのモデルが検索能力をどの程度効率よく獲得できるかを分析します。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-bullseye"></i> このセクションの目的と主な論点</p>
<ul class="unstyled-list">
<li><i class="fas fa-dna"></i> <strong>ベースモデル (Base Model)</strong>: 大規模なデータセットで<mark>事前学習されただけの「素の」状態のLLM</mark>です。特定の指示への応答やタスク実行能力はまだ磨かれていません。</li>
<li><i class="fas fa-graduation-cap"></i> <strong>インストラクションチューニング済みモデル (Instruction-tuned Model)</strong>: ベースモデルに<mark>「指示に従う」訓練を施したLLM</mark>です。例えば「〇〇を要約して」といった指示に対して、より適切に応答できるようになっています。</li>
<li><i class="fas fa-search-plus"></i> ZEROSEARCHが、これら2種類のモデルでうまく機能するかを検証します。</li>
<li><i class="fas fa-running"></i> 特に、ベースモデルが追加の準備運動（<span class="keyword">教師ありファインチューニング(SFT)</span>によるウォームアップ）なしに、強化学習だけで検索スキルを身につけられるかどうかが重要な焦点です。</li>
</ul>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-image"></i> 図4a, 4b: 報酬曲線の比較</h3>
<img alt="図4: ベースモデルとインストラクションチューニング済みモデルの報酬曲線比較" src="reward_curve_zerosearch_searchr1_comparison.jpg"/>
<div class="content-box" style="text-align: center; margin-bottom: 20px;">
<p class="reference">図4: (a) Qwen-2.5-3Bモデル、(b) Qwen-2.5-7Bモデル を用いたベースモデル（緑）とインストラクションチューニング済みモデル（青）の訓練報酬曲線。<br/>(c)のグラフはドキュメントトークンの損失マスキング効果に関するもので、このセクションの主題とは異なります。</p>
</div>
<div class="glass-card">
<p><i class="fas fa-chart-pie"></i> <strong>グラフの見方</strong> 📊</p>
<ul class="unstyled-list">
<li><i class="fas fa-arrows-alt-h"></i> <strong>横軸 (Step)</strong>: 訓練のステップ数（訓練の進み具合）を表します。右に進むほど、訓練が多く行われたことを意味します。</li>
<li><i class="fas fa-arrows-alt-v"></i> <strong>縦軸 (Train Reward)</strong>: モデルが訓練中に獲得した<span class="keyword">報酬</span>の平均値です。この報酬が高いほど、モデルがタスク（この論文では検索を伴う質問応答）を上手にこなせていることを示します。</li>
<li><span style="color: green; font-weight: bold; font-family: 'Yomogi', cursive;">──</span> <strong>緑色の線 (Base)</strong>: <span class="keyword">ベースモデル</span>の報酬の推移を示します。</li>
<li><span style="color: blue; font-weight: bold; font-family: 'Yomogi', cursive;">──</span> <strong>青色の線 (Instruct)</strong>: <span class="keyword">インストラクションチューニング済みモデル</span>の報酬の推移を示します。</li>
</ul>
<div class="note-box" style="background-color: rgba(255, 248, 225, 0.5); border-left-color: var(--color-accent3);">
<p class="note-title" style="color: var(--color-accent3);"><i class="fas fa-lightbulb"></i> 実験に使われたモデル</p>
<p>この比較実験では、<span class="badge blue">Qwen-2.5-3B</span> (30億パラメータを持つモデル) と <span class="badge purple">Qwen-2.5-7B</span> (70億パラメータを持つモデル) という、2つの異なるサイズのQwenシリーズのLLMが使用されています。</p>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-magnifying-glass-chart"></i> 分析結果の詳細 🔍</h3>
<div class="info-grid">
<div class="info-card">
<p class="note-title" style="font-size: 1.1em; color: var(--color-secondary);"><i class="fas fa-rocket"></i> 序盤戦: インストラクションモデルがリード！</p>
<p>グラフを見ると、訓練の初期段階（横軸の左側）では、<span style="color: blue; font-weight: bold;">青色の線 (Instruct)</span> が <span style="color: green; font-weight: bold;">緑色の線 (Base)</span> よりも高い位置からスタートしています。これは、インストラクションチューニング済みモデルの方が、訓練初期からより高い報酬を獲得していることを意味します。</p>
<div class="bubble-box" style="border-color: var(--color-secondary);">
<p style="font-family: 'Yomogi', cursive;"><i class="fas fa-question-circle"></i> なぜインストラクションモデルが初期に有利なの？</p>
<p>これは、インストラクションチューニング済みモデルが元々持っている<span class="highlight">「指示に従う能力 (instruction-following capabilities)」</span>が高いためです。ZEROSEARCHでは、モデルが検索エンジンを利用する際にも特定の形式で指示（クエリを生成するなど）を出す必要があります。インストラクションチューニング済みモデルは、このような指示を初期からうまく理解し、効果的に検索エンジンを呼び出すことができるのです。</p>
<div style="text-align: center; margin-top:10px;">
<span class="badge orange">高い指示理解力</span> <i class="fas fa-brain"></i> <i class="fas fa-arrow-right"></i> <span class="badge green">検索を上手に使える</span>
</div>
</div>
</div>
<div class="info-card">
<p class="note-title" style="font-size: 1.1em; color: var(--color-accent1);"><i class="fas fas fa-chart-line"></i> 訓練の進展: 両モデルとも着実に成長！</p>
<p>訓練が進むにつれて（グラフの横軸が右に進むほど）、<span style="color: green; font-weight: bold;">緑色の線 (Base)</span> と <span style="color: blue; font-weight: bold;">青色の線 (Instruct)</span> の両方が、全体として右肩上がりに上昇していることが確認できます。これは、ベースモデルもインストラクションチューニング済みモデルも、ZEROSEARCHによる強化学習を通じて着実に報酬を改善し、検索能力を含むタスク遂行能力を高めていることを示しています。</p>
<div style="text-align: center; margin-top:20px;">
<i class="fas fa-seedling" style="color: var(--color-accent1); font-size: 2em; margin-right: 10px;"></i>
<i class="fas fa-long-arrow-alt-right" style="font-size: 1.5em; color: var(--color-dark); margin-right: 10px;"></i>
<i class="fas fa-tree" style="color: var(--color-accent1); font-size: 3em;"></i>
<p style="font-family: 'Yomogi', cursive; margin-top: 5px;">どちらのモデルも訓練でどんどん賢くなる！</p>
</div>
</div>
</div>
<div class="content-box" style="margin-top: 20px;">
<div style="border: 3px dashed var(--color-accent2); padding: 20px; border-radius: 12px; background: linear-gradient(135deg, rgba(230, 230, 250, 0.8), rgba(200, 200, 240, 0.7)); backdrop-filter: blur(5px);">
<p class="note-title" style="font-size: 1.3em; color: var(--color-accent2); text-align:center;"><i class="fas fa-star"></i> 🌟 特筆すべき発見: ベースモデルの目覚ましい成長！ 🌟</p>
<p>この実験で特に注目すべきは、<span class="keyword">ベースモデル</span>（緑色の線）が見せる<span class="highlight">報酬改善の幅が大きい</span>点です。訓練初期はインストラクションチューニング済みモデルに比べて低い報酬でしたが、訓練が進むにつれて急速に性能を向上させ、最終的にはインストラクションチューニング済みモデルと<span class="keyword">同等の性能レベル</span>に到達しています。</p>
<div style="display: flex; flex-wrap: wrap; align-items: center; justify-content: space-around; margin-top: 20px; padding: 10px 0; border-top: 1px solid var(--color-accent2); border-bottom: 1px solid var(--color-accent2);">
<div style="text-align: center; margin:10px;">
<p style="font-weight: bold; font-family: 'Kaisei Decol', serif;">ベースモデルの軌跡 <i class="fas fa-hiking" style="color: green;"></i></p>
<div style="position: relative; width: 120px; height: 70px; margin: 0 auto;">
<svg height="70" viewbox="0 0 120 70" width="120" xmlns="http://www.w3.org/2000/svg">
<path d="M10 60 Q 40 50, 60 30 T 110 10" fill="none" stroke="rgba(0,128,0,0.3)" stroke-dasharray="4,4" stroke-width="3"></path>
<path d="M10 60 Q 40 20, 70 35 T 110 10" fill="none" stroke="green" stroke-width="4"></path>
<circle cx="10" cy="60" fill="green" r="4"></circle>
<text fill="green" font-size="10" x="5" y="55">🔰</text>
<circle cx="110" cy="10" fill="green" r="4"></circle>
<text fill="green" font-size="10" x="105" y="10">🏆</text>
</svg>
<span style="position: absolute; left: 0px; top: 60px; font-size: 0.8em; color: green;">低いスタート</span>
<span style="position: absolute; right: -15px; top: -5px; font-size: 0.8em; color: green;">急成長！</span>
</div>
</div>
<i class="fas fa-equals" style="font-size: 2.5em; color: var(--color-primary); margin:10px;"></i>
<div style="text-align: center; margin:10px;">
<p style="font-weight: bold; font-family: 'Kaisei Decol', serif;">インストラクションモデル <i class="fas fa-running" style="color: blue;"></i></p>
<div style="position: relative; width: 120px; height: 70px; margin: 0 auto;">
<svg height="70" viewbox="0 0 120 70" width="120" xmlns="http://www.w3.org/2000/svg">
<path d="M10 30 Q 60 20, 110 10" fill="none" stroke="blue" stroke-width="4"></path>
<circle cx="10" cy="30" fill="blue" r="4"></circle>
<text fill="blue" font-size="10" x="5" y="25">🚀</text>
<circle cx="110" cy="10" fill="blue" r="4"></circle>
<text fill="blue" font-size="10" x="105" y="10">🏆</text>
</svg>
<span style="position: absolute; left: 0px; top: 30px; font-size: 0.8em; color: blue;">高いスタート</span>
<span style="position: absolute; right: -15px; top: -5px; font-size: 0.8em; color: blue;">安定成長</span>
</div>
</div>
</div>
<p style="margin-top:15px;">この結果は非常に重要で、以下の2つの大きな結論を示唆しています：</p>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-puzzle-piece"></i> 結論と示唆</h3>
<div class="info-grid">
<div class="info-card" style="background-color: rgba(92, 184, 92, 0.1);">
<p class="note-title" style="color: var(--color-accent1);"><i class="fas fa-check-circle"></i> 1. ZEROSEARCHの汎用性</p>
<p>ZEROSEARCHは、<span class="keyword">ベースモデル</span>と<span class="keyword">インストラクションチューニング済みモデル</span>の<span class="highlight">両方に対して互換性がある</span>ことが示されました。モデルの種類を選ばずに、検索能力を向上させるための有効なフレームワークであると言えます。</p>
<div style="text-align: center; margin-top:15px;">
<i class="fas fa-microchip" style="font-size: 2em; color: var(--color-accent1);"></i>
<span style="font-size: 1.5em; margin: 0 10px;">🤝</span>
<i class="fas fa-robot" style="font-size: 2em; color: var(--color-accent1);"></i>
<p style="font-family: 'Yomogi', cursive; margin-top: 5px;">どんなタイプのLLMでもOK！</p>
</div>
</div>
<div class="info-card" style="background-color: rgba(255, 126, 95, 0.1);">
<p class="note-title" style="color: var(--color-secondary);"><i class="fas fa-bolt"></i> 2. ベースモデルの潜在能力の開花</p>
<p>より重要なのは、<span class="keyword">ベースモデル</span>が、事前に<span class="keyword">教師ありファインチューニング (Supervised Fine-Tuning, SFT)</span>による「ウォームアップ」を行わなくても、強化学習を通じて効果的に<span class="highlight">検索能力を獲得できる</span>ことが実証された点です。</p>
<div class="definition-box" style="margin-top:10px; background-color: rgba(255,255,255,0.7);">
<p class="definition-title"><i class="fas fa-book-open"></i> 用語解説: 教師ありファインチューニング (SFT)</p>
<p>SFTとは、特定のタスク（例：質問応答、要約）について、事前に用意された「質問と正しい答えのペア」のデータセットを使ってLLMを追加学習させる手法です。これにより、モデルはそのタスクをこなすための特定の能力を身につけます。この論文の文脈では、SFTを「ウォームアップ」と表現し、強化学習に入る前の準備段階として使われることがあります。</p>
</div>
<p style="margin-top:10px;">この発見は、LLMの訓練プロセスを簡略化し、コストを削減できる可能性を示唆しています。つまり、ベースモデルに直接ZEROSEARCHを適用するだけで、十分な検索能力を引き出せるということです。</p>
<div style="text-align: center; margin-top:15px;">
<i class="fas fa-dumbbell" style="font-size: 2em; color: var(--color-secondary); text-decoration: line-through;"></i>
<span style="font-size: 1em; margin: 0 10px; font-family: 'Yomogi', cursive;">SFTウォームアップ不要！</span>
<i class="fas fa-arrow-right" style="font-size: 1.5em; color: var(--color-dark); margin: 0 10px;"></i>
<i class="fas fa-brain" style="font-size: 2em; color: var(--color-secondary);"></i>
<span style="font-size: 1em; margin: 0 10px; font-family: 'Yomogi', cursive;">強化学習だけでOK！</span>
</div>
</div>
</div>
<div class="framework-box" style="margin-top: 25px; border-style: solid; border-color: var(--color-primary);">
<p class="framework-title" style="font-size: 1.2em;"><i class="fas fa-clipboard-check"></i> まとめ</p>
<p>このセクションの実験結果は、ZEROSEARCHフレームワークの有効性と柔軟性を強調しています。</p>
<ul class="unstyled-list">
<li><i class="fas fa-cogs" style="color: var(--color-primary);"></i> インストラクションチューニング済みモデルは初期から検索エンジンをうまく使えますが、ベースモデルも訓練によって同等のレベルまで成長します。</li>
<li><i class="fas fa-leaf" style="color: var(--color-accent1);"></i> 特に、ベースモデルがSFTによる事前準備なしに、強化学習のみで効率的に検索能力を学習できることは、ZEROSEARCHの大きな利点と言えるでしょう。</li>
</ul>
</div>
</div>
<div class="section-card" id="C_Effect_of_Document_Token_Loss_Masking">
<h2 class="section-title"><i class="fas fa-puzzle-piece"></i>C Effect of Document Token Loss Masking</h2>
<div class="bubble-box" style="margin-bottom: 25px;">
<p style="font-family: 'Yomogi', cursive; font-size: 16px;">
<i class="fas fa-bullhorn"></i> このセクションの目的とポイント！
        </p>
<p>このセクションでは、ZEROSEARCHの学習プロセスにおいて、<strong class="keyword">「ドキュメントトークンに対する損失マスキング」</strong>というテクニックがなぜ重要で、モデルの性能にどんな影響を与えるのかを解き明かしていきます。主な結論は、<span class="highlight">ドキュメントトークンを損失計算に含めてしまうと、学習が不安定になり、結果としてモデルの性能が下がってしまう</span>ため、これらをマスキング（無視）することが非常に効果的である、ということです。一緒に詳しく見ていきましょう！ ✏️🔍</p>
</div>
<div class="content-box">
<p>ZEROSEARCHの学習中、私たちは<strong class="keyword">ドキュメントトークン</strong>に対して<strong class="keyword">損失マスキング (loss masking)</strong> を適用しています。これはなぜかというと、ドキュメントトークンはポリシーモデル（つまり、我々が学習させたい主体）自身が生み出したものではなく、外部のシミュレーションLLMから提供される情報です。そのため、これらを直接損失計算に含めると、ポリシーモデルの学習にとって<span class="highlight">ノイズとなる可能性</span>があるからです。</p>
</div>
<div class="definition-box">
<div class="definition-title"><i class="fas fa-book-open"></i> 用語解説：ドキュメントトークンと損失マスキング</div>
<ul class="unstyled-list">
<li><i class="fas fa-file-alt" style="color: var(--color-primary);"></i> <strong class="keyword">ドキュメントトークン (Document Tokens)</strong>: 
                ポリシーモデルが検索クエリを発行した後、シミュレーションLLM（または実際の検索エンジン）から返される検索結果（ドキュメント）を構成するトークン（単語やサブワードなどのテキスト単位）のことです。これらはポリシーモデルが直接生成したものではありません。
                <div style="text-align: center; margin: 10px 0;">
<span style="font-family: 'Yomogi', cursive; background-color: #e7f3fe; padding: 5px 10px; border-radius: 8px; border: 1px dashed var(--color-primary);">
                        ポリシーモデル <i class="fas fa-long-arrow-alt-right" style="color: var(--color-gray);"></i> <span class="badge blue">検索クエリ</span> <i class="fas fa-long-arrow-alt-right" style="color: var(--color-gray);"></i> シミュレーションLLM <i class="fas fa-long-arrow-alt-right" style="color: var(--color-gray);"></i> <span class="badge orange">ドキュメントトークン</span>
</span>
</div>
</li>
<li style="margin-top: 10px;"><i class="fas fa-shield-alt" style="color: var(--color-accent1);"></i> <strong class="keyword">損失マスキング (Loss Masking)</strong>: 
                ニューラルネットワークの学習中に、特定のトークンに関する損失を計算から除外する手法です。ZEROSEARCHの場合、ドキュメントトークン由来の損失を無視することで、ポリシーモデルが自身の生成したトークン（思考や最終回答など）に集中して学習できるようにします。これにより、学習の安定化と効率向上が期待されます。
                <div style="text-align: center; margin: 10px 0;">
<span style="font-family: 'Yomogi', cursive; background-color: #e8f5e9; padding: 5px 10px; border-radius: 8px; border: 1px dashed var(--color-accent1);">
                        損失計算時：<span class="highlight">ドキュメントトークン由来の損失をゼロにする <i class="fas fa-times-circle" style="color: var(--color-secondary);"></i></span>
</span>
</div>
</li>
</ul>
</div>
<h3 class="subsection-title"><i class="fas fa-flask"></i> アブレーション実験による効果検証</h3>
<div class="content-box">
<p>この損失マスキングが実際にどれほど重要なのかを評価するために、私たちは<strong class="keyword">アブレーション実験 (ablation experiments)</strong>を行いました。具体的には、LLaMA-3.2-3Bというモデルを使って、「損失マスキングを適用した場合」と「適用しない場合」で性能を比較しました。</p>
</div>
<div class="note-box">
<div class="note-title"><i class="fas fa-lightbulb"></i> アブレーション実験とは？</div>
<p>アブレーション実験とは、機械学習モデルやシステムの構成要素の一部を取り除いたり、変更したりして、その要素が全体の性能にどのような影響を与えるかを調べる実験手法です。「この部品がなかったらどうなる？」を検証するイメージですね。今回の場合は、「ドキュメントトークンの損失マスキング」という部品の重要性を調べています。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-chart-line"></i> 実験結果：報酬曲線 (図4c)</h3>
<img alt="Figure 4c: Effect of document token loss masking" class="section-image" src="reward_curve_zerosearch_searchr1_comparison.jpg"/>
<div class="glass-card" style="margin-top: 15px;">
<p style="font-family: 'Yomogi', cursive; font-size: 16px; text-align: center;">
<i class="fas fa-chart-bar"></i> 図4cの読み解きポイント <i class="fas fa-glasses"></i>
</p>
<p>上のグラフセットの右端、<strong class="keyword">(c) Effect of document masking</strong> と題されたグラフが、ここでの主役です。これはLLaMA-3.2-3B-baseモデルを用いた際の結果を示しています。</p>
<ul>
<li><strong class="keyword">横軸 (Step)</strong>: 学習の進行度（ステップ数）を表します。右に行くほど学習が進んでいる状態です。</li>
<li><strong class="keyword">縦軸 (Train Reward)</strong>: 学習中の報酬スコアです。高いほど、モデルが良い回答を生成できていることを意味します。</li>
<li><strong style="color: #28a745;">緑色の線 (w Mask <i class="fas fa-check-circle"></i>)</strong>: ドキュメントトークンに<span class="highlight">損失マスキングを適用した場合</span>の報酬の推移です。</li>
<li><strong style="color: #007bff;">青色の線 (w/o Mask <i class="fas fa-times-circle"></i>)</strong>: ドキュメントトークンに<span class="highlight">損失マスキングを適用しなかった場合</span>の報酬の推移です。</li>
</ul>
<div class="bubble-box" style="border-color: var(--color-secondary); margin-top:15px;">
<p><i class="fas fa-exclamation-triangle" style="color: var(--color-secondary);"></i> <strong>重要な観察結果</strong>：</p>
<p>グラフから明らかなように、<strong style="color: #007bff;">青色の線（マスキングなし）</strong>は、<strong style="color: #28a745;">緑色の線（マスキングあり）</strong>と比較して、報酬が<span class="highlight">大幅に低いレベルで推移</span>しています。特に学習が進んでも報酬がなかなか上昇せず、不安定な様子が見て取れます。</p>
<p>これは、ドキュメントトークンの損失マスキングを除去すると、<strong class="keyword">報酬が大幅に低下する</strong>ことを示しています。つまり、ドキュメントトークンを損失計算に含めてしまうと、学習がうまくいかず、モデルの性能が上がりにくくなるのです。</p>
</div>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-table"></i> 実験結果：パフォーマンス比較 (表7)</h3>
<img alt="Table 7: Effect of Document Token Loss Masking" class="section-image" src="table7.png"/>
<div class="glass-card" style="margin-top: 15px;">
<p style="font-family: 'Yomogi', cursive; font-size: 16px; text-align: center;">
<i class="fas fa-clipboard-list"></i> 表7の読み解きポイント <i class="fas fa-search"></i>
</p>
<p>この表は、LLaMA-3.2-3B-Baseモデルを使い、様々な質問応答データセット（NQ, TriviaQA, HotpotQAなど）において、ドキュメントトークンの損失マスキングの有無が最終的なモデルの正解率（EM: Exact Match）にどのような影響を与えたかを示しています。</p>
<ul class="unstyled-list">
<li><strong class="keyword">Mask</strong>: ドキュメントトークンに損失マスキングを<span class="badge green" style="background-color: var(--color-accent1);">適用した (✓)</span> 場合と、<span class="badge red" style="background-color: var(--color-secondary);">適用しなかった (✗)</span> 場合の結果を示します。</li>
<li><strong class="keyword">各データセット名 (NQ, TriviaQA, etc.)</strong>: それぞれ異なる質問応答のベンチマークデータセットです。数値は正解率（EMスコア）を表し、高いほど性能が良いことを意味します。</li>
<li><strong class="keyword">Avg.</strong>: 全データセットの平均スコアです。</li>
</ul>
<div class="bubble-box" style="border-color: var(--color-primary); margin-top:15px;">
<p><i class="fas fa-thumbs-up" style="color: var(--color-primary);"></i> <strong>ここでも明確な差が！</strong>：</p>
<p>表7の結果を見ると、全てのデータセットにおいて、損失マスキングを<span class="badge green" style="background-color: var(--color-accent1);">適用した (✓)</span> 場合の方が、<span class="badge red" style="background-color: var(--color-secondary);">適用しなかった (✗)</span> 場合よりも<span class="highlight">EMスコアが一貫して高い</span>ことが分かります。特に平均スコア (Avg.) を比較すると、マスキングあり (28.6) に対して、マスキングなし (20.1) と、<strong class="keyword">大幅な性能低下</strong>が見られます。</p>
</div>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-lightbulb"></i> 結論と考察</h3>
<div class="note-box" style="background-color: rgba(255, 213, 79, 0.2); border-left-color: var(--color-accent3);">
<div class="note-title" style="color: var(--color-accent3);"><i class="fas fa-check-circle"></i> まとめ：損失マスキングは超重要！</div>
<p>図4cの報酬曲線と表7のパフォーマンス比較から、以下の結論が導き出されます：</p>
<ul class="process-step">
<li class="step-number">1</li>
<li class="step-content">ドキュメントトークンの損失マスキングを除去し、これらのトークンを損失計算に含めると、<strong class="keyword">学習の不安定性</strong>を引き起こします。</li>
</ul>
<ul class="process-step">
<li class="step-number">2</li>
<li class="step-content">その結果、モデルの<strong class="keyword">学習効果が低下</strong>し、最終的なタスクパフォーマンス（質問応答の正解率など）も<span class="highlight">著しく悪化</span>します。</li>
</ul>
<p style="text-align:center; font-family: 'Yomogi', cursive; font-size: 18px; margin-top:15px;">
<i class="fas fa-shield-alt" style="color:var(--color-accent1);"></i> したがって、ドキュメントトークンへの損失マスキングは、ZEROSEARCHフレームワークにおいて、安定した学習と高い性能を達成するために<strong class="keyword">不可欠な要素</strong>であると言えます！ <i class="fas fa-award" style="color:var(--color-accent3);"></i>
</p>
</div>
</div>
<div class="section-card" id="D_Cost_Analysis">
<h2 class="section-title"><i class="fas fa-coins"></i>D Cost Analysis</h2>
<div class="content-box">
<p>このセクションでは、私たちの提案手法である<span class="keyword">ZEROSEARCH</span>にかかるコストを分析し、従来の<span class="highlight">商用検索APIを利用するアプローチ</span>と比較します。ZEROSEARCHは、学習中に実際の検索エンジンを使わないため、商用APIの利用料金は発生しません。しかし、その代わりに<span class="keyword">シミュレート検索LLM</span>（検索エンジンを模倣する大規模言語モデル）をGPUサーバー上で動かす必要があります。このGPUサーバーの運用コストが、ZEROSEARCHの主な費用となります。</p>
<p>📌 この分析の目的は、ZEROSEARCHが経済的な観点からも実用的な選択肢となり得るか、特に大規模な強化学習の文脈で評価することです。</p>
</div>
<div class="info-grid">
<div class="info-card">
<h3 class="subsection-title"><i class="fas fa-search-dollar"></i> APIコストの見積もり基準</h3>
<p>商用検索APIを利用する場合のコストは、<span class="keyword">SerpAPI</span>の料金に基づいて計算しています。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-info-circle"></i> SerpAPIとは？</p>
<p>SerpAPIは、Googleなどの検索エンジンの検索結果を、プログラムを通じて簡単に取得できるようにするサービスです。研究や開発で検索機能を利用する際に使われますが、利用回数に応じて料金が発生します。</p>
</div>
</div>
<div class="info-card">
<h3 class="subsection-title"><i class="fas fa-server"></i> GPUデプロイコストの見積もり基準</h3>
<p>シミュレート検索LLMを動かすためのGPUサーバーのコストは、<span class="keyword">Amazon Web Services (AWS)</span>の料金に基づいて計算しています。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-info-circle"></i> AWSとは？</p>
<p>Amazon Web Servicesは、Amazonが提供するクラウドコンピューティングプラットフォームです。必要な計算資源（GPUサーバーなど）を、使った分だけ料金を支払う形で利用できます。</p>
</div>
</div>
</div>
<div class="framework-box">
<h3 class="subsection-title"><i class="fas fa-cogs"></i> 本論文での強化学習(RL)トレーニング設定</h3>
<p>この論文で行った強化学習の具体的な設定は以下の通りです。これらの数値がコスト評価の前提となります。</p>
<ul class="unstyled-list">
<li>✏️ <span class="keyword">バッチサイズ</span>: 64</li>
<li>🔄 <span class="keyword">ロールアウト反復 (Rollout repetition)</span>: 5回
                <div class="bubble-box" style="margin-top: 5px; margin-bottom:10px; border-color: var(--color-secondary); padding:10px;">
<span style="font-family: 'Yomogi', cursive; color: var(--color-secondary);"><i class="fas fa-comment-dots"></i> 用語解説: ロールアウト反復</span>
<p style="font-size: 13px; margin-top:5px;">強化学習では、モデル（エージェント）が実際に行動してみて経験データ（ロールアウト）を集めます。ロールアウト反復とは、1回の学習サイクル（バッチ処理）の中で、このデータ収集を何回繰り返すか、という意味です。ここでは5回繰り返しています。</p>
</div>
</li>
<li>📊 <span class="keyword">総トレーニングステップ</span>: 200ステップ</li>
</ul>
<p>この設定で、基盤となるLLM（<span class="keyword">バックボーン (Backbone)</span>）として<span class="highlight">Qwen-2.5-7B</span>を使用した場合：</p>
<ul class="unstyled-list">
<li>⏰ <span class="keyword">総トレーニング時間</span>: 約<strong>12時間</strong></li>
<li>❓ <span class="keyword">生成された検索リクエスト総数</span>: 約<strong>64,000件</strong></li>
</ul>
<div class="bubble-box" style="margin-top: 10px; border-color: var(--color-accent1); padding:10px;">
<span style="font-family: 'Yomogi', cursive; color: var(--color-accent1);"><i class="fas fa-comment-dots"></i> 用語解説: バックボーン</span>
<p style="font-size: 13px; margin-top:5px;">「バックボーン」とは、システムやモデルの根幹を成す主要なコンポーネントを指します。ここでは、ZEROSEARCHの検索能力を学習するLLMの基礎となる大規模言語モデル（Qwen-2.5-7B）のことです。</p>
</div>
</div>
<div class="arrow-connector"></div>
<div class="bubble-box">
<h3 class="subsection-title"><i class="fas fa-table"></i> Table 8 からわかるコスト比較のポイント 📝</h3>
<p>(論文中のTable 8で示されているように、コストには大きな違いがあります)</p>
<ul>
<li>📉 <span class="keyword">Google Search (商用API) のコスト</span>: 私たちのZEROSEARCHアプローチと比較して、<span class="highlight" style="background-color: rgba(255, 126, 95, 0.3);"><strong>著しく高額</strong></span>です。</li>
<li>📈 <span class="keyword">APIコストの増大問題</span>: バッチサイズを大きくしたり、トレーニングステップ数を増やしたりすると、APIコストは<span class="highlight" style="background-color: rgba(255, 126, 95, 0.3);"><strong>急激に増加</strong></span>します。これにより、大規模な学習が<span class="highlight" style="background-color: rgba(255, 126, 95, 0.3);"><strong>法外な費用</strong></span>のために困難になり、スケーラビリティが著しく制限されます。</li>
<li>✅ <span class="keyword">ZEROSEARCHの利点</span>: 対照的に、ZEROSEARCHは<span class="highlight" style="background-color: rgba(92, 184, 92, 0.3);"><strong>よりコスト効率の高い代替手段</strong></span>を提供します。初期投資としてGPUサーバーが必要ですが、検索リクエスト数が増えてもAPI料金のように直接的にはコストが増えません。</li>
</ul>
</div>
<div class="challenge-box">
<h3 class="subsection-title"><i class="fas fa-exclamation-triangle"></i> GPU利用率に関する注意点と課題</h3>
<p>ZEROSEARCHで使う<span class="keyword">シミュレーションサーバー</span>のGPU利用率には、以下のような特徴があります。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-info-circle"></i> 用語解説: シミュレーションサーバー</p>
<p>ZEROSEARCHにおいて、実際の検索エンジンの代わりをするLLM（シミュレート検索LLM）が稼働しているGPUサーバーのことです。このサーバーが、学習中のモデルからの検索クエリに対して、擬似的な検索結果を生成します。</p>
</div>
<ul>
<li><span class="badge blue">ロールアウト中</span>: GPU利用率は<span class="highlight">高い</span> (多くの検索結果を生成するため)</li>
<li><span class="badge orange">ポリシー更新中</span>: GPU利用率は<span class="highlight">低い</span> (方策モデルの学習が主で、検索シミュレーションは少ないため)</li>
</ul>
<p>このようにGPU利用率が一定でないため、GPUが十分に活用されない期間が生じ、<span class="keyword">リソースの無駄</span>が発生する可能性があります。</p>
<div style="text-align: center; margin: 15px 0;">
<svg height="120" style="font-family: 'Yomogi', cursive;" viewbox="0 0 250 120" width="250" xmlns="http://www.w3.org/2000/svg">
<line stroke="#6c757d" stroke-width="2" x1="20" x2="230" y1="100" y2="100"></line>
<line stroke="#6c757d" stroke-width="2" x1="20" x2="20" y1="20" y2="100"></line>
<text fill="#6c757d" font-size="10" x="0" y="15">高</text>
<text fill="#6c757d" font-size="10" x="0" y="100">低</text>
<polyline fill="none" points="30,80 50,30 70,30 90,80 110,80 130,30 150,30 170,80 190,80 210,30" stroke="var(--color-primary)" stroke-dasharray="4 2" stroke-width="3"></polyline>
<text fill="#2c3e50" font-size="10" x="60" y="115">ロールアウト</text>
<text fill="#2c3e50" font-size="10" x="145" y="115">ポリシー更新</text>
<path d="M 50 30 Q 60 20 70 30" fill="none" stroke="var(--color-primary)" stroke-width="1.5"></path>
<path d="M 130 30 Q 140 20 150 30" fill="none" stroke="var(--color-primary)" stroke-width="1.5"></path>
<path d="M 210 30 Q 220 20 230 30" fill="none" stroke="var(--color-primary)" stroke-width="1.5" transform="translate(-10,0)"></path> <!-- 最後の要素がはみ出ないように調整 -->
<circle cx="50" cy="30" fill="var(--color-accent1)" r="3"></circle>
<circle cx="70" cy="30" fill="var(--color-accent1)" r="3"></circle>
<circle cx="130" cy="30" fill="var(--color-accent1)" r="3"></circle>
<circle cx="150" cy="30" fill="var(--color-accent1)" r="3"></circle>
<circle cx="210" cy="30" fill="var(--color-accent1)" r="3"></circle>
<circle cx="30" cy="80" fill="var(--color-secondary)" r="3"></circle>
<circle cx="90" cy="80" fill="var(--color-secondary)" r="3"></circle>
<circle cx="110" cy="80" fill="var(--color-secondary)" r="3"></circle>
<circle cx="170" cy="80" fill="var(--color-secondary)" r="3"></circle>
<circle cx="190" cy="80" fill="var(--color-secondary)" r="3"></circle>
<text fill="#6c757d" font-size="12" font-weight="bold" x="80" y="10">GPU利用率の波</text>
</svg>
<p style="font-size:12px; color: var(--color-gray); margin-top: -5px;">(簡易的なGPU利用率のイメージ図)</p>
</div>
</div>
<div class="note-box" style="border-left-color: var(--color-accent1);">
<h3 class="subsection-title" style="color:var(--color-accent1); border-left-color: var(--color-accent1);"><i class="fas fa-lightbulb"></i> GPU利用率問題の賢い解決策 💡</h3>
<p>このGPU利用率の非効率性を緩和するための実用的な戦略として、<span class="keyword">単一のシミュレーションサーバーを複数の強化学習タスクで共有する</span>ことが考えられます。</p>
<div style="display: flex; align-items: center; justify-content: space-around; margin: 15px 0;">
<div style="text-align: center;">
<i class="fas fa-tasks fa-2x" style="color: var(--color-primary);"></i>
<p style="font-size: 12px;">RLタスク A</p>
</div>
<i class="fas fa-arrow-right fa-lg" style="color: var(--color-gray);"></i>
<div style="text-align: center;">
<i class="fas fa-server fa-3x" style="color: var(--color-accent1);"></i>
<p style="font-size: 12px;">共有シミュレーションサーバー</p>
</div>
<i class="fas fa-arrow-left fa-lg" style="color: var(--color-gray);"></i>
<div style="text-align: center;">
<i class="fas fa-tasks fa-2x" style="color: var(--color-secondary);"></i>
<p style="font-size: 12px;">RLタスク B</p>
</div>
</div>
<p>これにより、各タスクのポリシー更新中に空いているGPUリソースを他のタスクのロールアウトに活用でき、全体としてGPUの稼働率を高め、<span class="highlight" style="background-color: rgba(92, 184, 92, 0.3);"><strong>デプロイコストをさらに削減</strong></span>できます。</p>
</div>
<div class="glass-card" style="margin-top: 25px;">
<h3 class="subsection-title"><i class="fas fa-balance-scale"></i> さらなる柔軟性: パフォーマンスとリソースのバランス ⚖️</h3>
<p>ZEROSEARCHでは、コストと性能のバランスをユーザーが調整できるように、<span class="keyword">様々なパラメータサイズのシミュレーションLLM</span>を提供しています。</p>
<div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));">
<div class="feature-item">
<i class="fas fa-feather-alt fa-2x" style="color: var(--color-accent2);"></i>
<p style="font-size: 13px;">軽量モデル (例: 3B)</p>
<p style="font-size: 12px;">低リソース・低コスト</p>
</div>
<div class="feature-item">
<i class="fas fa-brain fa-2x" style="color: var(--color-primary);"></i>
<p style="font-size: 13px;">中規模モデル (例: 7B)</p>
<p style="font-size: 12px;">バランス型</p>
</div>
<div class="feature-item">
<i class="fas fa-rocket fa-2x" style="color: var(--color-secondary);"></i>
<p style="font-size: 13px;">大規模モデル (例: 14B)</p>
<p style="font-size: 12px;">高性能・高リソース</p>
</div>
</div>
<p>これにより、ユーザーは自身の特定のニーズ（予算、要求される性能レベルなど）に応じて、最適なシミュレーションLLMを選択できる<span class="highlight">柔軟なオプション</span>を持つことができます。</p>
</div>
<div class="content-box" style="margin-top:25px; border-top: 2px dashed var(--color-primary); padding-top:15px;">
<p><strong>まとめると</strong> 🎯: ZEROSEARCHは、商用APIを利用する手法に比べて<span class="keyword">大幅なコスト削減</span>を実現しつつ、GPUサーバーの共有やモデルサイズの選択といった工夫により、<span class="keyword">運用コストの最適化</span>も可能です。これにより、特に大規模な強化学習タスクにおいて、ZEROSEARCHは<span class="highlight">経済的にも魅力的な選択肢</span>となります。</p>
</div>
</div>
<div class="section-card" id="E_Case_Study">
<h2 class="section-title"><i class="fas fa-microscope"></i> E Case Study</h2>
<p style="margin-bottom: 20px;">このセクションでは、提案手法である<span class="keyword">ZEROSEARCH</span>の有効性をさらに具体的に示すために、実際の<span class="keyword">インタラクション軌跡</span>（モデルがどのように思考し検索したかの記録）と、<span class="keyword">シミュレートされた文書</span>（学習中にモデルに提示される検索結果の例）のケーススタディを詳しく見ていきます。これらの具体例を通して、ZEROSEARCHがどのように機能し、なぜ効果的なのかを深掘りしていきましょう！ ✏️🔍</p>
<h3 class="subsection-title"><i class="fas fa-project-diagram"></i> インタラクション軌跡の研究 (Interaction Trajectory Study)</h3>
<div class="content-box">
<p>まず、ポリシーモデル（ZEROSEARCHによって訓練されたLLM）が、どのように複数回の検索（<span class="keyword">multi-turn search</span>）を行い、段階的に情報を集めて最終的な回答にたどり着くのか、その具体的な<span class="keyword">インタラクション軌跡</span>を見ていきましょう。論文のTable 9で示されている事例を通じて、以下の重要な観察結果が得られました。</p>
<div class="glass-card" style="margin-top: 20px; margin-bottom: 20px;">
<p class="note-title" style="color: var(--color-dark); border-bottom: 1px dashed var(--color-dark); padding-bottom: 5px;"><i class="fas fa-clipboard-list"></i> Table 9 事例からの主な観察ポイント</p>
<div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));">
<div class="feature-item" style="background-color: rgba(74, 111, 165, 0.1);">
<div class="icon-item"><i class="fas fa-file-alt" style="color: var(--color-primary);"></i></div>
<p style="font-weight: bold; color: var(--color-primary);">フォーマットの遵守</p>
<p>ポリシーモデルは、<span class="highlight">期待される出力フォーマット</span>（例：<code>&lt;think&gt;...&lt;/think&gt;</code>, <code>&lt;search&gt;...&lt;/search&gt;</code>, <code>&lt;answer&gt;...&lt;/answer&gt;</code>）に一貫して従っていました。これは驚くべきことで、フォーマット要件は入力テンプレートで指定されているだけで、報酬設計（モデルの学習目標）では明示的に強化されていなかったのです。</p>
</div>
<div class="feature-item" style="background-color: rgba(255, 126, 95, 0.1);">
<div class="icon-item"><i class="fas fa-cogs" style="color: var(--color-secondary);"></i></div>
<p style="font-weight: bold; color: var(--color-secondary);">複数ターン検索行動</p>
<p>モデルは、最終的な答えに到達するために、<span class="highlight">複数回の検索を行う能力</span>を示しました。これは非常に重要な発見であり、提案手法がモデルの検索能力を効果的に引き出していることを裏付けています。</p>
</div>
</div>
</div>
<div class="bubble-box" style="margin-top: 30px;">
<p><strong><i class="fas fa-lightbulb"></i> 具体例で考えてみよう！</strong></p>
<p>例えば、「クララ・ノヴェッロの父親の出生地はどこですか？」という質問があったとします。（Table 9の最初の例）</p>
<div class="pipeline">
<div class="pipeline-step">
<strong>ステップ1: 初期思考と検索 💡➡️🔍</strong><br/>
                    モデルはまず、<code>&lt;think&gt;</code> タグ内で「クララ・ノヴェッロの父親の出生地についての質問だ」と考えます。そして、<code>&lt;search&gt;クララ・ノヴェッロの父親の出生地&lt;/search&gt;</code> と検索します。
                </div>
<div class="pipeline-step">
<strong>ステップ2: 情報評価と追加検索 🤔➡️🔍</strong><br/>
                    最初の検索結果 (<code>&lt;information&gt;...&lt;/information&gt;</code>) を見て、直接的な答えがないこと、しかしクララ・ノヴェッロの父親がヴィンセント・ノヴェッロという音楽家である可能性を推測します。そこで、<code>&lt;think&gt;</code> タグ内で「ヴィンセント・ノヴェッロの出生地を検索する必要がある」と考え、次に <code>&lt;search&gt;ヴィンセント・ノヴェッロの出生地&lt;/search&gt;</code> と検索します。
                </div>
<div class="pipeline-step">
<strong>ステップ3: 回答生成 ✅➡️🗣️</strong><br/>
                    2回目の検索結果から、ヴィンセント・ノヴェッロの出生地が「ロンドン、イングランド」であることを見つけます。<code>&lt;think&gt;</code> タグ内で最終確認し、<code>&lt;answer&gt;ロンドン、イングランド&lt;/answer&gt;</code> と回答します。
                </div>
</div>
<p>このように、モデルは必要な情報を得るために、思考と検索を繰り返すことができています。これが<span class="keyword">複数ターン検索行動</span>です。そして、その過程全体が指定されたフォーマットに従っている点も注目に値します。</p>
</div>
</div>
<img alt="Table 9: Interaction Trajectories" src="table9.png" style="width: 100%; max-width: 800px; margin-top: 20px; margin-bottom: 20px; border: 1px solid #ccc; border-radius: 8px;"/>
<p class="reference" style="text-align: center; margin-bottom: 30px;">表9: インタラクション軌跡の例。モデルが複数回の思考と検索を経て回答に至る様子が示されています。</p>
<h3 class="subsection-title"><i class="fas fa-file-signature"></i> シミュレートされた文書の研究 (Simulated Document Study)</h3>
<div class="content-box">
<p>次に、シミュレーションLLM（検索エンジン役のLLM）によって生成された<span class="keyword">シミュレートされた文書</span>の例をTable 10で見てみましょう。ここでは、「有用な出力」と「ノイズの多い出力」を比較することで、その品質の違いが明確に分かります。</p>
<div class="note-box" style="margin-top:20px; margin-bottom: 20px;">
<p class="note-title"><i class="fas fa-check-circle"></i> 重要なポイント</p>
<ul>
<li><span class="highlight">有用な出力 (Useful Output)</span>: 正しい答えを一貫して含んでいます。</li>
<li><span class="highlight">ノイズの多い出力 (Noisy Output)</span>: 正しい答えを含んでいません。</li>
</ul>
<p>このように文書の品質を精密に制御できることは、以下の点で非常に重要です。</p>
<ol>
<li><span class="keyword">カリキュラムベースのロールアウトメカニズム</span>の実現: 学習の初期段階では質の高い（有用な）情報を与え、徐々に難しい（ノイズの多い）情報に挑戦させることで、モデルの学習を段階的に進めることができます。</li>
<li>強化学習の<span class="keyword">訓練プロセスの安定化</span>: 予測不可能な品質の文書を使う代わりに、制御された品質の文書を使うことで、学習が不安定になるのを防ぎます。</li>
</ol>
</div>
<img alt="Table 10: Examples of Simulated Documents" src="table10.png" style="width: 100%; max-width: 800px; margin-top: 20px; margin-bottom: 20px; border: 1px solid #ccc; border-radius: 8px;"/>
<p class="reference" style="text-align: center; margin-bottom:10px;">表10: シミュレートされた文書の例。上段が有用な出力、下段がノイズの多い出力です。</p>
<div class="two-column" style="margin-top: 20px;">
<div class="column">
<div class="info-card">
<p style="font-weight: bold; color: var(--color-accent1); display: flex; align-items: center;"><i class="fas fa-thumbs-up" style="margin-right: 8px;"></i>有用な出力の例 (Useful Output)</p>
<p>質問: 「2018年のツール・ド・フランスで2位だったのは誰？」</p>
<p>クエリ: Tour de France 2018 second place</p>
<hr/>
<p><strong>Doc 2 (抜粋):</strong> <code>2nd – Tom Dumoulin (NED / Team Sunweb)</code></p>
<p style="font-size: 0.9em;"><em>➡️ この文書には明確に「トム・デュムラン」という正解が含まれています。</em></p>
</div>
</div>
<div class="column">
<div class="info-card">
<p style="font-weight: bold; color: var(--color-secondary); display: flex; align-items: center;"><i class="fas fa-times-circle" style="margin-right: 8px;"></i>ノイズの多い出力の例 (Noisy Output)</p>
<p>質問: 「2018年のツール・ド・フランスで2位だったのは誰？」</p>
<p>クエリ: Tour de France 2018 second place</p>
<hr/>
<p><strong>Doc 1 (抜粋):</strong> <code>second place is 5000 euros, with 3000 euros for the third-placed rider.</code></p>
<p style="font-size: 0.9em;"><em>➡️ この文書は2位の賞金について述べていますが、選手名は含んでいません。</em></p>
</div>
</div>
</div>
<div class="framework-box" style="margin-top:30px;">
<p class="framework-title"><i class="fas fa-graduation-cap"></i> カリキュラム学習との関連</p>
<p>この「有用な出力」と「ノイズの多い出力」を制御できる能力が、<span class="keyword">カリキュラム学習</span>（簡単な問題から難しい問題へと段階的に学習を進める手法）を実現する上で鍵となります。</p>
<ul class="unstyled-list">
<li style="margin-bottom: 10px;"><span class="badge blue">初期段階</span>: モデルには主に「有用な出力」が提供されます。これにより、基本的な検索スキルやタスクの理解を促します。</li>
<li style="margin-bottom: 10px;"><span class="badge orange">進行段階</span>: 徐々に「ノイズの多い出力」の割合を増やしていきます。これにより、モデルはより複雑な情報の中から必要な情報を見つけ出す能力、つまり<span class="highlight">高度な推論能力</span>を養うことができます。</li>
</ul>
<p>この段階的な難易度調整が、ZEROSEARCHの強化学習プロセスを安定させ、より効果的な学習を可能にしているのです。</p>
</div>
</div>
<div class="note-box" style="margin-top: 30px; background-color: rgba(92, 184, 92, 0.1); border-left-color: var(--color-accent1);">
<p class="note-title" style="color: var(--color-accent1);"><i class="fas fa-chart-line"></i> ケーススタディのまとめ</p>
<p>これらのケーススタディは、ZEROSEARCHが以下の点で優れていることを示しています：</p>
<ul>
<li>📝 <strong>フォーマット遵守</strong>: LLMは、明示的な報酬なしに、期待される思考・検索・回答のフォーマットに従うことができます。</li>
<li>🔄 <strong>複数ターン検索</strong>: LLMは、複数回の検索を通じて情報を収集し、複雑な質問にも対応できる能力を獲得します。</li>
<li>🎯 <strong>文書品質の制御</strong>: シミュレーションLLMは、有用な文書とノイズの多い文書を意図通りに生成でき、これがカリキュラム学習と訓練の安定化に貢献します。</li>
</ul>
<p>これらの要素が組み合わさることで、ZEROSEARCHは、実際の検索エンジンを使わずにLLMの検索能力を効果的に向上させることができるのです。</p>
</div>
</div>
<div class="section-card" id="F_Implementation_Details">
<h2 class="section-title"><i class="fas fa-cogs"></i> F Implementation Details</h2>
<p style="margin-bottom: 20px;">
        このセクションでは、論文で提案されている<span class="keyword">ZEROSEARCH</span>フレームワークの実験が、具体的にどのような設定で行われたのか、その詳細を丁寧に解説します。実験のセットアップを理解することは、結果の解釈や研究の再現性を担保する上で非常に重要です。ここでは、使用された計算資源、各モデルの学習方法、ハイパーパラメータの設定値など、実験を正確に再現するために必要な情報を網羅的に見ていきましょう。
    </p>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-server"></i> 実験の舞台裏：計算環境</p>
<p>実験は、大きく分けて「シミュレーションLLMを動かすサーバー」と「強化学習（RL）を行うサーバー」の2つの役割を持つ計算機群で実施されました。それぞれのGPU構成は以下の通りです。</p>
<div class="info-grid">
<div class="info-card">
<div class="icon-item"><i class="fas fa-brain" style="color:var(--color-accent1);"></i></div>
<h4><span class="badge green">シミュレーションサーバー</span></h4>
<p>検索エンジンを模倣する役割を持つ<span class="keyword">シミュレーションLLM</span>は、<strong style="color:var(--color-primary);">4基のH20 GPU</strong>上で展開・運用されました。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-info-circle"></i> H20 GPUとは？</p>
<p>NVIDIA社が開発したデータセンター向けの高性能GPUです。大規模なAIモデルの学習や推論処理を効率的に実行するために設計されています。</p>
</div>
</div>
<div class="info-card">
<div class="icon-item"><i class="fas fa-dumbbell" style="color:var(--color-accent2);"></i></div>
<h4><span class="badge purple">RLトレーニングサーバー</span></h4>
<p>ZEROSEARCHの頭脳となる<span class="keyword">ポリシーLLM</span>（検索戦略を学習するモデル）の強化学習は、<strong style="color:var(--color-secondary);">別の4基のH20 GPU</strong>上で行われました。</p>
<p style="margin-top:10px;">✏️ <small>このように計算資源を役割分担することで、複雑なシミュレーション環境とRLエージェントの学習を効率的に並行して進めることが可能になります。</small></p>
</div>
</div>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-chalkboard-teacher"></i> 1. シミュレーションLLMの学習：検索エンジンの「ものまね役者」を育てる</h3>
<div class="content-box">
<p>まず、検索エンジンのように振る舞う「シミュレーションLLM」を準備します。このモデルは、クエリに対して関連文書を生成する役割を担います。</p>
<div class="pipeline">
<div class="pipeline-step">
<p><span class="badge blue">バックボーンモデル</span> 📚</p>
<p>以下の事前学習済み大規模言語モデルが、シミュレーションLLMの素体（バックボーン）として使用されました。これらは「Instruct」バージョンであり、指示追従能力が高いモデルです。</p>
<ul class="unstyled-list" style="margin-left: 20px; margin-top:10px;">
<li><i class="fas fa-feather-alt" style="color:var(--color-primary);"></i> <span class="highlight">Qwen2.5-3B-Instruct</span> (30億パラメータ)</li>
<li><i class="fas fa-feather-alt" style="color:var(--color-primary);"></i> <span class="highlight">Qwen-2.5-7B-Instruct</span> (70億パラメータ)</li>
<li><i class="fas fa-feather-alt" style="color:var(--color-primary);"></i> <span class="highlight">Qwen-2.5-14B-Instruct</span> (140億パラメータ)</li>
</ul>
</div>
<div class="pipeline-step">
<p><span class="badge orange">学習手法</span> 💡</p>
<p><span class="keyword">軽量SFT (Supervised Fine-Tuning)</span> が実施されました。</p>
<div class="definition-box" style="margin-top:10px;">
<p class="definition-title"><i class="fas fa-book-open"></i> SFTとは？</p>
<p>Supervised Fine-Tuning（教師ありファインチューニング）の略で、大規模な事前学習済みモデルを特定のタスクに適応させるために、そのタスクに関連する教師ありデータ（入力と期待される出力のペア）を使って追加学習を行うことです。ここで「軽量」とは、比較的少ないデータや計算資源で短時間に行うことを指します。</p>
</div>
</div>
<div class="pipeline-step">
<p><span class="badge yellow">学習率</span> ⚙️</p>
<p>学習率は <span class="highlight">1e-6</span> ( \(1 \times 10^{-6}\) ) に設定されました。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-search-dollar"></i> 学習率とは？</p>
<p>モデルが学習データからどれだけ「一気に」学ぶかを調整するパラメータです。値が大きすぎると学習が不安定になり、小さすぎると学習に時間がかかりすぎる可能性があります。1e-6は比較的小さな学習率で、慎重な学習を促します。</p>
</div>
</div>
</div>
<p style="margin-top: 20px;">📌 <strong>ポイント:</strong> ここでのSFTの目的は、これらのLLMが、与えられた検索クエリに対して、<span class="keyword">「役立つ文書」</span>と<span class="keyword">「ノイズの多い文書」</span>の両方を生成できるようにすることです。これにより、後述するカリキュラム学習で、検索の難易度を徐々に上げていくことが可能になります。</p>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-brain"></i> 2. ZEROSEARCHのポリシーLLM学習：検索戦略を学ぶエージェント</h3>
<p>次に、ZEROSEARCHフレームワークの中核であるポリシーLLM（実際に検索を行うかどうか、どのようなクエリで検索するかを決定するLLM）を強化学習で訓練します。</p>
<div class="feature-card-grid">
<div class="feature-item glass-card">
<div class="icon-item"><i class="fas fa-robot" style="color:var(--color-primary);"></i></div>
<h4><span class="badge purple">採用された強化学習アルゴリズム</span></h4>
<p>ZEROSEARCHの汎用性を示すため、以下の3つの代表的な強化学習アルゴリズムが試されました。</p>
<ul class="unstyled-list" style="margin-top:10px; text-align: left; padding-left:20px;">
<li><i class="fas fa-cogs" style="color:var(--color-accent1);"></i> <strong>REINFORCE:</strong> 最も基本的な方策勾配法の一つ。</li>
<li><i class="fas fa-cogs" style="color:var(--color-accent2);"></i> <strong>GRPO (Group Relative Policy Optimization):</strong> 複数のLLM出力を比較・ランク付けすることで学習を安定させる手法。</li>
<li><i class="fas fa-cogs" style="color:var(--color-secondary);"></i> <strong>PPO (Proximal Policy Optimization):</strong> 方策の更新幅を制限することで学習の安定性と効率を高める手法。</li>
</ul>
</div>
</div>
<div class="info-grid">
<div class="info-card">
<h4 class="subsection-title" style="margin-top:0; color:var(--color-primary); border-left-color: var(--color-primary);"><i class="fas fa-graduation-cap"></i> REINFORCE と GRPO の設定</h4>
<ul class="unstyled-list" style="padding-left:15px; margin-bottom:15px;">
<li><i class="fas fa-coins" style="color:var(--color-accent3);"></i> <strong>ポリシーLLMの学習率:</strong> <span class="highlight">1e-6</span></li>
<li><i class="fas fa-stream" style="color:var(--color-accent3);"></i> <strong>サンプリング応答数:</strong> 1つのプロンプト（質問）に対して <span class="highlight">5つ</span> の応答をサンプリング。</li>
</ul>
<div class="note-box">
<p class="note-title"><i class="fas fa-lightbulb"></i> サンプリング応答数とは？</p>
<p>強化学習では、エージェント（ポリシーLLM）が様々な行動（応答）を試すことで学習が進みます。1つの状況（プロンプト）に対して複数の応答を生成し、それらの良し悪しを評価することで、より良い行動戦略を見つけやすくなります。</p>
</div>
</div>
<div class="info-card">
<h4 class="subsection-title" style="margin-top:0; color:var(--color-primary); border-left-color: var(--color-primary);"><i class="fas fa-network-wired"></i> PPO の設定</h4>
<ul class="unstyled-list" style="padding-left:15px; margin-bottom:15px;">
<li><i class="fas fa-coins" style="color:var(--color-accent3);"></i> <strong>ポリシーLLMの学習率:</strong> <span class="highlight">1e-6</span></li>
<li><i class="fas fa-tachometer-alt" style="color:var(--color-accent3);"></i> <strong>価値モデル (Value Model) の学習率:</strong> <span class="highlight">1e-5</span> （ポリシーLLMとは異なる学習率）</li>
</ul>
<div class="definition-box" style="margin-top:10px;">
<p class="definition-title"><i class="fas fa-calculator"></i> 価値モデルとは？</p>
<p>PPOなどのActor-Critic系の強化学習アルゴリズムで使われるコンポーネントです。Actor（ポリシーLLM）が行動を選択し、Critic（価値モデル）がその行動がどれくらい良いかを評価します。価値モデルは、現在の状態や状態と行動のペアの「価値」を予測するように学習されます。</p>
</div>
</div>
</div>
<div class="bubble-box" style="margin-top:25px;">
<p><i class="fas fa-puzzle-piece"></i> <strong>Generalized Advantage Estimation (GAE) の適用</strong></p>
<p>PPOでは、報酬の評価をより安定させるためにGAEという手法が用いられました。GAEは、将来の報酬の割引和（Advantage）を推定するテクニックです。</p>
<p>設定されたハイパーパラメータは以下の通りです:</p>
<ul class="unstyled-list" style="padding-left:15px; margin-top:10px;">
<li><i class="fas fa-lambda" style="color:var(--color-primary);"></i> <strong class="keyword">\(\lambda\) (ラムダ):</strong> <span class="highlight">1</span>
<div class="formula" style="font-size:12px; padding:5px 8px;">
                    \( \text{GAE}(\lambda) \) のパラメータ。 \(\lambda=1\) の場合、モンテカルロ法に近い推定になり、バイアスは小さいがバリアンスが大きくなる傾向があります。
                </div>
</li>
<li><i class="fas fa-gamma" style="color:var(--color-secondary);"></i> <strong class="keyword">\(\gamma\) (ガンマ):</strong> <span class="highlight">1</span>
<div class="formula" style="font-size:12px; padding:5px 8px;">
                    割引率。将来の報酬をどれだけ重視するかを示します。 \(\gamma=1\) の場合、割引を行わず、すべての将来報酬を等しく評価します。これは、エピソードが有限の長さで終わるタスクに適しています。
                </div>
</li>
</ul>
<div class="note-box" style="margin-top:15px;">
<p class="note-title"><i class="fas fa-chart-line"></i> GAEの役割</p>
<p>GAEは、報酬信号の分散を抑えつつ、バイアスを適切に制御することで、学習の安定性と効率を向上させる効果があります。特にPPOのようなアルゴリズムでは重要な要素となります。</p>
</div>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-sliders-h"></i> 3. カリキュラム学習のためのノイズ確率設定</h3>
<p>ZEROSEARCHの重要な特徴の一つである<span class="keyword">カリキュラム学習</span>では、学習が進むにつれてシミュレーションLLMが生成する文書の質を徐々に低下させます（ノイズの多い文書を生成する確率を上げる）。これにより、ポリシーLLMは簡単な状況から徐々に難しい状況に適応していくことができます。</p>
<p>このノイズ生成確率は、初期ノイズ確率 <span class="keyword">\(p_s\)</span> と最終ノイズ確率 <span class="keyword">\(p_e\)</span> によって制御されます。モデルの種類とサイズによって、これらの値は以下のように設定されました。</p>
<div class="table-wrapper glass-card" style="padding: 15px;">
<p style="text-align:center; font-family: 'Yomogi', cursive; font-size:16px; color:var(--color-dark); margin-bottom:10px;">📊 ノイズ確率設定一覧</p>
<table>
<thead>
<tr>
<th><i class="fas fa-robot"></i> モデル</th>
<th><i class="fas fa-thermometer-empty"></i> 初期ノイズ確率 <span class="keyword">\(p_s\)</span></th>
<th><i class="fas fa-thermometer-full"></i> 最終ノイズ確率 <span class="keyword">\(p_e\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>Qwen-2.5-7B (Base/Instruct)</td>
<td><span class="highlight">0</span></td>
<td><span class="highlight">0.75</span></td>
</tr>
<tr>
<td>Qwen-2.5-3B (Base/Instruct)</td>
<td><span class="highlight">0</span></td>
<td><span class="highlight">0.25</span></td>
</tr>
<tr>
<td>LLaMA-3.2-3B (Base/Instruct)</td>
<td><span class="highlight">0.25</span></td>
<td><span class="highlight">0.5</span></td>
</tr>
</tbody>
</table>
</div>
<div class="challenge-box" style="margin-top:20px;">
<p class="challenge-title"><i class="fas fa-question-circle"></i> なぜモデルによって \(p_s, p_e\) の値が異なるの？</p>
<p>モデルのサイズや能力によって、ノイズに対する耐性や学習の進み方が異なります。例えば、より大きなモデル（Qwen-2.5-7B）は、より高い最終ノイズ確率（0.75）まで対応できるポテンシャルがあると考えられます。一方、比較的小さなモデル（Qwen-2.5-3B）では、最終ノイズ確率を低め（0.25）に設定することで、学習が破綻するのを防いでいる可能性があります。LLaMA-3.2-3Bは、初期からある程度のノイズ（0.25）を与え、最終的にも中程度のノイズ（0.5）で学習させています。これらの値は、実験的な試行錯誤を通じて、各モデルにとって最適な学習曲線を描けるように調整されたものと考えられます。</p>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-cog"></i> 4. デフォルト設定と推論時の設定</h3>
<div class="info-grid">
<div class="info-card glass-card">
<h4 class="subsection-title" style="margin-top:0; color:var(--color-accent1); border-left-color: var(--color-accent1);"><i class="fas fa-flag-checkered"></i> デフォルトの強化学習アルゴリズム</h4>
<p>特に指定がない限り、強化学習ベースの手法では<strong style="color:var(--color-accent1);">REINFORCE</strong>がデフォルトの学習アルゴリズムとして使用されました。</p>
<p style="margin-top:10px;">📝 <small>REINFORCEは実装が比較的単純でありながら、この種のタスクで良好な性能を示すことが他の研究でも報告されているため、基準として採用されたと考えられます。</small></p>
</div>
<div class="info-card glass-card">
<h4 class="subsection-title" style="margin-top:0; color:var(--color-accent2); border-left-color: var(--color-accent2);"><i class="fas fa-server"></i> デフォルトのシミュレーションLLM</h4>
<p>全ての実験を通じて、デフォルトの<span class="keyword">シミュレーション検索エンジン</span>としては、ファインチューニングされた<strong style="color:var(--color-accent2);">Qwen-2.5-14B-Instructモデル</strong>が使用されました。</p>
<p style="margin-top:10px;">📈 <small>最も大きなシミュレーションLLMを使用することで、できるだけ現実の検索エンジンに近い、質の高いシミュレーション環境を提供することを目指したと考えられます。</small></p>
</div>
<div class="info-card glass-card">
<h4 class="subsection-title" style="margin-top:0; color:var(--color-secondary); border-left-color: var(--color-secondary);"><i class="fas fa-globe"></i> 推論時の検索エンジン</h4>
<p>学習（訓練）時とは異なり、<strong style="color:var(--color-secondary);">推論（評価）時</strong>には、全ての比較手法で公平性を期すために、<strong style="color:var(--color-secondary);">Google Web Search</strong> が統一して検索エンジンとして使用されました。</p>
<p style="margin-top:10px;">⚖️ <small>これは、ZEROSEARCHで学習したモデルが、シミュレートされた環境だけでなく、実際の検索エンジンを使っても効果的に機能するかどうかを評価するために重要です。</small></p>
</div>
</div>
<div class="note-box" style="margin-top:25px; background-color: rgba(92, 184, 92, 0.1); border-left-color: var(--color-accent1);">
<p class="note-title" style="color: var(--color-accent1);"><i class="fas fa-check-circle"></i> まとめ：再現性のための詳細情報</p>
<p>このセクションで提供された実装の詳細は、ZEROSEARCHフレームワークの実験結果を理解し、必要であれば他の研究者が追試を行うための基盤となります。特に、学習率、バッチサイズ、各種モデルの選択、ハイパーパラメータの値などは、実験の再現性において非常に重要な情報です。</p>
<p>これらの詳細な設定情報を把握することで、論文の主張するZEROSEARCHの有効性や汎用性について、より深く考察することができますね！ 👨‍🔬👩‍🔬</p>
</div>
</div>
<div class="section-card" id="G_Broad_Impact">
<h2 class="section-title"><i class="fas fa-broadcast-tower"></i> G Broad Impact</h2>
<p>このセクションでは、本研究で提案された<span class="keyword">ZEROSEARCH</span>フレームワークが持つ広範な影響（Broad Impact）について考察します。ZEROSEARCHは、大規模言語モデル（LLM）が<span class="highlight">実際の検索エンジンと直接やり取りすることなく</span>、その検索能力を向上させるための新しい<span class="keyword">強化学習（RL）トレーニングフレームワーク</span>です。このアプローチが、研究開発のあり方や社会にどのような影響を与える可能性があるのかを見ていきましょう。</p>
<div class="bubble-box">
<p class="note-title" style="font-family: 'Yomogi', cursive; font-size: 1.2em; color: var(--color-accent2);"><i class="fas fa-bullhorn"></i> この研究の核心！</p>
<p style="font-family: 'Zen Kurenaido', sans-serif;">本研究は、LLMの<span class="keyword">検索能力</span>を、実際の検索エンジンを使わずに<span class="highlight">シミュレーション環境下で訓練</span>するという画期的なRLフレームワークを提案しています。これにより、多くのメリットが期待できるんです！</p>
</div>
<h3 class="subsection-title"><i class="fas fa-plus-circle"></i> 期待されるポジティブな影響</h3>
<p>ZEROSEARCHは、いくつかの重要な点でポジティブな影響をもたらすと考えられます。</p>
<div class="info-grid">
<div class="info-card">
<h4 style="font-family: 'Kaisei Decol', serif; color: var(--color-primary);"><i class="fas fa-dollar-sign"></i> RLトレーニングコストの大幅削減 <span class="badge orange">コストダウン！</span></h4>
<p>従来のRLベースの検索能力向上手法では、LLMが実際の検索エンジン（例：Google API）と頻繁にやり取り（数万～数十万回の検索リクエスト！）を行う必要がありました。これには<span class="highlight">高額なAPI利用料</span>が伴い、特に大規模な実験や研究のスケールアップを難しくしていました。</p>
<p><span class="keyword">ZEROSEARCH</span>は、LLM自体を検索シミュレータとして利用するため、これらのAPIコストを<span class="highlight">実質ゼロ</span>に抑えることができます。 <i class="fas fa-piggy-bank" style="color: var(--color-accent1);"></i> これにより、より多くの研究者や開発者が、予算を気にせずにLLMの検索能力向上のための研究に取り組めるようになります。</p>
</div>
<div class="info-card">
<h4 style="font-family: 'Kaisei Decol', serif; color: var(--color-primary);"><i class="fas fa-flask"></i> LLMを実世界のシミュレータとして活用する研究の促進 <span class="badge purple">未来の研究！</span></h4>
<p>ZEROSEARCHの核心的なアイデアの一つは、<span class="keyword">LLMを実世界のシミュレータとして活用する</span>点にあります。この研究は、LLMが持つ広範な知識を利用して、検索エンジンのような複雑な外部環境を模擬できる可能性を示唆しています。</p>
<p>このアプローチが成功すれば、検索に限らず、さまざまな実世界のインタラクションをLLMでシミュレートする研究が加速するかもしれません <i class="fas fa-rocket" style="color: var(--color-secondary);"></i>。これにより、より安全かつ効率的に、多様なシナリオでのLLMの挙動を検証・改善できるようになります。</p>
</div>
</div>
<div class="note-box">
<p class="note-title"><i class="fas fa-globe"></i> ポジティブな社会的インパクトの可能性</p>
<p>上記のコスト削減や研究の促進は、最終的に<span class="keyword">社会全体にポジティブな影響</span>をもたらす可能性があります。例えば、より高度で信頼性の高い情報アクセス技術の開発、教育分野での活用、あるいは専門知識を必要とする分野での意思決定支援など、LLMの応用範囲が大きく広がるかもしれません。 <i class="fas fa-users" style="color: var(--color-primary);"></i></p>
</div>
<h3 class="subsection-title"><i class="fas fa-shield-alt"></i> ネガティブな社会的影響について</h3>
<div class="content-box">
<p>本研究チームは、このZEROSEARCHフレームワークから直接的に生じる<span class="keyword">ネガティブな社会的影響は予見されない</span>（We do not foresee any negative societal impacts arising from this work.）と考えています。</p>
<ul style="list-style-type: '✏️ ';">
<li>提案手法は、既存のLLMの能力をより効率的に引き出すことを目的としています。</li>
<li>それ自体が悪意のある目的に特化して利用されやすい技術とは考えにくいです。</li>
</ul>
<p class="reference">もちろん、LLM技術全般に関わる倫理的な課題（例：バイアス、誤情報生成のリスクなど）は、ZEROSEARCHを利用する場合でも別途慎重に考慮されるべきです。しかし、ZEROSEARCHフレームワーク特有の大きな社会的リスクは現時点ではないと評価されています。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-cogs"></i> ZEROSEARCHの動作具体例</h3>
<p>論文のこのセクションでは、ZEROSEARCHが実際にどのように質問応答タスクを実行するかを示す具体例がいくつか提示されています。これらの例を通じて、モデルが内部でどのように<span class="highlight">思考</span>し、情報を<span class="highlight">検索</span>し、最終的な<span class="highlight">回答</span>に至るかのプロセスを見てみましょう。論文に記載されている形式（<code>&lt;think&gt;</code>, <code>&lt;search&gt;</code>, <code>&lt;information&gt;</code>, <code>&lt;answer&gt;</code>タグ）に注目してください。</p>
<div class="glass-card">
<p class="note-title" style="font-family: 'Yomogi', cursive; font-size: 1.1em; color: var(--color-dark);"><i class="fas fa-question-circle"></i> 例1: Clara Novelloの父親の出生地</p>
<p><strong>質問:</strong> What is the place of birth of Clara Novello’s father? (クララ・ノヴェッロの父親の出生地はどこですか？)</p>
<p><strong>正解:</strong> London, England (ロンドン、イングランド)</p>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-brain"></i> ZEROSEARCHの思考プロセス:</p>
<div class="pipeline">
<div class="pipeline-step">
<p><code>&lt;think&gt;</code> 質問はクララ・ノヴェッロの父親の出生地についてです。 <code>&lt;/think&gt;</code></p>
<p class="reference">📝 まず質問内容を理解します。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;search&gt;</code> place of birth of Clara Novello’s father (クララ・ノヴェッロの父親の出生地) <code>&lt;/search&gt;</code></p>
<p class="reference">🔍 最初の検索クエリを生成します。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;information&gt;</code></p>
<ul class="unstyled-list">
<li>Doc 1: 68 Clara Novello’s Reminiscences In this interesting small place I knew the daughter-in-law of Goethe, who showed us his house, his bedroom, the gold laurel</li>
<li>Doc 2: So, we may happily add James Clerk Maxwell to our list as this year is the 175th since his birth in Edinburgh on November 13th, 1831.</li>
<li>Doc 3: When I was intro- duced to him as Vincent Novello’s eldest daughter, Coleridge was struck by my father’s name, knowing it to be that of a musician, and</li>
<li>Doc 4: ABSTRACT. This publication presents biographical profiles of people of interest to young readers. The concept is unique in that.</li>
<li>Doc 5: Reuse: Copies of full items can be used for personal research or study, educational, or not-for-profit purposes without prior permission or charge.</li>
</ul>
<p><code>&lt;/information&gt;</code></p>
<p class="reference">📄 シミュレートされた検索結果（ドキュメント）が返されます。この段階では、父親の名前が「Vincent Novello」であること、彼が音楽家であることが示唆されますが、出生地は不明です。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;think&gt;</code> 検索結果に基づくと、クララ・ノヴェッロの父親の出生地は直接言及されていません。しかし、クララ・ノヴェッロの父親はヴィンセント・ノヴェッロであり、彼は音楽家であると推測できます。検索結果ではヴィンセント・ノヴェッロの出生地が提供されていないため、彼の出生地を検索する必要があります。 <code>&lt;/think&gt;</code></p>
<p class="reference">🤔 最初の検索結果を分析し、次のステップを考えます。父親の名前を特定し、その人物の出生地を検索する必要があると判断します。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;search&gt;</code> place of birth of Vincent Novello (ヴィンセント・ノヴェッロの出生地) <code>&lt;/search&gt;</code></p>
<p class="reference">🔍 2回目の検索クエリを生成します。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;information&gt;</code></p>
<ul class="unstyled-list">
<li>Doc 1: Born: September 6, 1781, <span class="highlight">London, England</span>. Died: August 9, 1861, Nice, France. Buried: Cimetiére du Château, Nice, France. portrait. Biography.</li>
<li>Doc 2: NOVELLO, VINCENT (1781–1861), organist, musical composer, editor, and arranger, was born at 240 Oxford Road (now Oxford Street), <span class="highlight">London</span>,</li>
<li>Doc 3: Vincent Novello Leigh Hunt was born about 1823 in Genoa, Italy, where his parents, writer Leigh Hunt and his wife Marianne Kent, had been living</li>
<li>Doc 4: NOVELLO, Vincent, son of an Italian father and English mother, was born at 240, Oxford Street, Sept. 6, 1781.</li>
<li>Doc 5: Vincent Novello (6 September 1781 – 9 August 1861), was an English musician and music publisher born in <span class="highlight">London</span>.</li>
</ul>
<p><code>&lt;/information&gt;</code></p>
<p class="reference">📄 2回目の検索結果。複数のドキュメントで「London, England」または「London」が出生地として示されています。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;think&gt;</code> 検索結果に基づくと、クララ・ノヴェッロの父親であるヴィンセント・ノヴェッロの出生地は<span class="keyword">ロンドン、イングランド</span>です。 <code>&lt;/think&gt;</code></p>
<p class="reference">💡 必要な情報が得られたと判断します。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;answer&gt;</code> <span class="highlight">London, England</span> <code>&lt;/answer&gt;</code></p>
<p class="reference">✅ 最終的な回答を生成します。</p>
</div>
</div>
</div>
</div>
<div class="glass-card">
<p class="note-title" style="font-family: 'Yomogi', cursive; font-size: 1.1em; color: var(--color-dark);"><i class="fas fa-question-circle"></i> 例2: 映画「ワンス・アンド・フォーエバー」の曹長役の俳優の配偶者</p>
<p><strong>質問:</strong> (The question is about the spouse of the person who played the sergeant major in the movie "We Were Soldiers") (映画「ワンス・アンド・フォーエバー」で曹長を演じた人物の配偶者は誰ですか？)</p>
<p><strong>正解:</strong> Katharine Ross (キャサリン・ロス)</p>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-brain"></i> ZEROSEARCHの思考プロセス:</p>
<div class="pipeline">
<div class="pipeline-step">
<p><code>&lt;think&gt;</code> 質問は、映画「ワンス・アンド・フォーエバー」で曹長を演じた人物の配偶者についてです。 <code>&lt;/think&gt;</code></p>
<p class="reference">📝 まず質問内容を分解します。曹長役の俳優を特定し、その俳優の配偶者を調べるという2段階のタスクです。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;search&gt;</code> who played the sergeant major in We Were Soldiers (ワンス・アンド・フォーエバーで曹長を演じたのは誰か) <code>&lt;/search&gt;</code></p>
<p class="reference">🔍 まず曹長役の俳優を特定するための検索クエリ。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;information&gt;</code></p>
<ul class="unstyled-list">
<li>Doc 1: Maj. Basil L. Plumley. <span class="highlight">Sam Elliott</span> was the only actor who Randall Wallace could envision as the battalion’s hard-as-nails sergeant major.</li>
<li>Doc 2: But apparently, Plumley had no issues with Elliott’s portrayal. The actor "under played" the sergeant major, said Galloway, who introduced the</li>
<li>Doc 3: The U.S. Army is investigating allegations that the late Command Sgt. Major Basil Plumley wore unauthorized combat and valor awards.</li>
<li>Doc 4: Plumley was played by actor <span class="highlight">Sam Elliott</span> in the movie We Were Soldiers (2002) about the Battle of Ia Drang. Command Sergeant Major Basil L.</li>
<li>Doc 5: I’ll start by saying Plumley was a badass (edit: apparently not, TIL), and that Sam Elliott’s portrayal was equally brilliant.</li>
</ul>
<p><code>&lt;/information&gt;</code></p>
<p class="reference">📄 検索結果から、曹長役は「Sam Elliott」であることがわかります。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;think&gt;</code> 検索結果に基づくと、「ワンス・アンド・フォーエバー」で曹長を演じたのは<span class="keyword">サム・エリオット</span>です。次に、彼の配偶者が誰であるかを調べる必要があります。 <code>&lt;/think&gt;</code></p>
<p class="reference">🤔 次のステップはサム・エリオットの配偶者を検索することだと判断します。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;search&gt;</code> spouse of Sam Elliott (サム・エリオットの配偶者) <code>&lt;/search&gt;</code></p>
<p class="reference">🔍 サム・エリオットの配偶者を検索するクエリ。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;information&gt;</code></p>
<ul class="unstyled-list">
<li>Doc 1: Sam Elliott has been married to <span class="highlight">Katharine Ross</span> since 1984, indicating a long-term heterosexual relationship. There is no credible evidence to</li>
<li>Doc 2: Actor Sam Elliott, star of the film "The Hero," talks Hollywood, his 30-year marriage to actress <span class="highlight">Katherine Ross</span> and his famous mustache.</li>
<li>Doc 3: Sam Elliott and <span class="highlight">Katharine Ross</span> met in 1978 and were married in 1984. They met while filming the horror movie, The Legacy. It was Ross’s</li>
<li>Doc 4: After more than 35 years of marriage, it’s clear that Sam Elliott and his wife, <span class="highlight">Katharine Ross</span>, are one of Hollywood’s most successful love</li>
<li>Doc 5: Sam Elliott and his wife <span class="highlight">Katharine Ross</span> have been married for nearly four decades. Their love story dates back to the late 1960s.</li>
</ul>
<p><code>&lt;/information&gt;</code></p>
<p class="reference">📄 検索結果から、サム・エリオットの配偶者は「Katharine Ross」であることがわかります。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;think&gt;</code> 検索結果に基づくと、「ワンス・アンド・フォーエバー」で曹長を演じたサム・エリオットの配偶者は<span class="keyword">キャサリン・ロス</span>です。 <code>&lt;/think&gt;</code></p>
<p class="reference">💡 必要な情報が得られたと判断します。</p>
</div>
<div class="pipeline-step">
<p><code>&lt;answer&gt;</code> <span class="highlight">Katharine Ross</span> <code>&lt;/answer&gt;</code></p>
<p class="reference">✅ 最終的な回答を生成します。</p>
</div>
</div>
</div>
</div>
<div class="glass-card">
<p class="note-title" style="font-family: 'Yomogi', cursive; font-size: 1.1em; color: var(--color-dark);"><i class="fas fa-question-circle"></i> 例3: ツール・ド・フランス2018の2位</p>
<p><strong>質問:</strong> who came second in tour de france 2018? (ツール・ド・フランス2018で2位だったのは誰ですか？)</p>
<p><strong>正解:</strong> Tom Dumoulin (トム・デュムラン)</p>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-search"></i> ZEROSEARCH (この例では思考プロセスは省略され、クエリのみが示されています):</p>
<p><code>Query:</code> Tour de France 2018 second place (ツール・ド・フランス 2018 2位)</p>
<p class="reference">🎯 この例では、モデルが生成したであろう検索クエリが示されています。これは、モデルが質問を理解し、適切な検索クエリを生成できる能力を持っていることを示唆しています。</p>
</div>
</div>
<div class="note-box">
<p class="note-title"><i class="fas fa-lightbulb"></i> 具体例からの洞察</p>
<p>これらの例は、<span class="keyword">ZEROSEARCH</span>が単にキーワードを検索するだけでなく、複数回の検索を組み合わせたり、得られた情報から推論を行ったりする<span class="highlight">多段階の思考プロセス</span>を実行できることを示しています。これは、実際の検索エンジンを使わずにシミュレーションだけで、高度な検索・推論能力を学習できるという本研究の主張を裏付けるものです。</p>
</div>
</div>
<div class="section-card" id="Useful_Output:">
<h2 class="section-title"><i class="fas fa-lightbulb"></i> Useful Output:</h2>
<p>このセクションでは、ZEROSEARCHフレームワークの中核機能の一つである、<span class="keyword">シミュレーションLLMによる検索結果生成</span>に焦点を当てます。特に、このシミュレーションLLMが、与えられたクエリに対してどのように<span class="highlight">「有益な（Useful）」ドキュメント</span>を生成できるのかを、具体的な例を通して詳しく見ていきましょう。ここでのポイントは、実際の検索エンジンAPIを叩くことなく、LLM自身が持つ知識や生成能力を活用して、あたかも検索エンジンが返してきたかのような、そして実際に<span class="keyword">問題解決に役立つ情報</span>を生成することです。これにより、APIコストを削減しつつ、制御された環境で強化学習を進めることが可能になります。✏️</p>
<div class="glass-card" style="margin-top: 20px; margin-bottom: 25px;">
<h3 class="subsection-title" style="border-left: none; padding-left:0; margin-top:0;"><i class="fas fa-vial" style="color: var(--color-accent2);"></i> 具体例：ツール・ド・フランス2018に関する質問</h3>
<p style="margin-left: 25px;">例として、以下の質問、正解、そして対応する検索クエリを見てみましょう。シミュレーションLLMは、このクエリに基づいて「Useful Output」を生成します。</p>
<div class="bubble-box" style="margin-top: 15px; margin-bottom: 15px; margin-left: 25px; margin-right: 25px; border-color: var(--color-secondary);">
<p style="margin-bottom: 8px;"><strong><i class="fas fa-question-circle" style="color: var(--color-secondary);"></i> 質問 (Question):</strong> <span class="highlight" style="background-color: rgba(255, 126, 95, 0.2);">who came second in tour de france 2018?</span></p>
<p style="margin-bottom: 8px;"><strong><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i> 正解 (Answer):</strong> <span class="highlight" style="background-color: rgba(92, 184, 92, 0.2);">Tom Dumoulin</span></p>
<p><strong><i class="fas fa-search" style="color: var(--color-primary);"></i> クエリ (Query):</strong> <span class="highlight" style="background-color: rgba(74, 111, 165, 0.2);">Tour de France 2018 second place</span></p>
</div>
<p style="margin-left: 25px;">このクエリに対して、シミュレーションLLMが生成した<span class="keyword">「Useful Output」</span>（有益な出力ドキュメント群）が以下になります。これらのドキュメントがどのように質問の解決に貢献するかを分析します。📊</p>
</div>
<h3 class="subsection-title" style="margin-top: 30px;"><i class="fas fa-file-signature"></i> シミュレーションLLMによって生成されたUseful Output</h3>
<p>以下は、上記のクエリ「Tour de France 2018 second place」に対して、シミュレーションLLMが生成した5つの「Useful Output」ドキュメントです。それぞれの内容と、なぜそれが有益と判断されるのかを見ていきましょう。</p>
<div class="info-grid" style="margin-top: 15px;">
<!-- Doc 1 -->
<div class="info-card">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span class="badge blue" style="margin-right: 8px; font-size:14px; padding: 5px 10px;">Doc 1</span>
<h4 style="margin:0; font-family: 'Yomogi', cursive; color: var(--color-primary); font-size: 16px;">背景情報</h4>
</div>
<div class="content-box">
<p class="document-content" style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; background-color: #f0f4f8; border-left: 4px solid var(--color-accent2); padding: 12px; border-radius: 4px; line-height: 1.5;">"The 2018 Tour de France was the 105th edition of the race, and the first under the leadership of new event president Étienne Thobois."</p>
</div>
<div class="note-box" style="margin-top: 10px; padding: 12px; font-size: 13px;">
<p class="note-title" style="font-size: 14px; color: var(--color-accent2);"><i class="fas fa-chalkboard-teacher"></i> このドキュメントの役割</p>
                このドキュメントは、2018年のツール・ド・フランスが<span class="highlight">第105回大会</span>であることや、新しい大会会長（Étienne Thobois氏）のもとで初めて開催されたという<span class="keyword">基本的な背景情報</span>を提供しています。直接的に2位の選手を特定する情報はありませんが、コンテキストを理解する上で役立ちます。📌
            </div>
</div>
<!-- Doc 2 -->
<div class="info-card">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span class="badge blue" style="margin-right: 8px; font-size:14px; padding: 5px 10px;">Doc 2</span>
<h4 style="margin:0; font-family: 'Yomogi', cursive; color: var(--color-primary); font-size: 16px;">核心情報！🎯</h4>
</div>
<div class="content-box">
<p class="document-content" style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; background-color: #f0f4f8; border-left: 4px solid var(--color-accent1); padding: 12px; border-radius: 4px; line-height: 1.5;">"2nd – <span style="background-color: #FFF3CD; color: #856404; padding: 2px 4px; border-radius: 3px; font-weight: bold;">Tom Dumoulin</span> (NED / Team Sunweb) 3rd – Geraint Thomas (GBR / Team Sky) 4th – Jakob Fuglsang (DEN / Astana) 5th – Romain Bardet (FRA / AG2R"
                </p>
</div>
<div class="note-box" style="margin-top: 10px; padding: 12px; font-size: 13px;">
<p class="note-title" style="font-size: 14px; color: var(--color-accent1);"><i class="fas fa-search-plus"></i> このドキュメントの役割</p>
<span style="font-weight:bold; color: var(--color-accent1);">これぞまさしく質問の核心に迫る情報です！</span>明確に「<span class="highlight" style="background-color: rgba(255, 213, 79, 0.4);">2nd – Tom Dumoulin</span>」と記載されており、国籍（NED:オランダ）と所属チーム（Team Sunweb）も併記されています。この情報だけで質問に直接回答できます。📝 他の順位の選手（3位 Geraint Thomas、4位 Jakob Fuglsang、5位 Romain Bardet）もリストアップされており、情報の信頼性を高めています。
            </div>
</div>
</div>
<div class="info-grid" style="margin-top: 15px;">
<!-- Doc 3 -->
<div class="info-card">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span class="badge blue" style="margin-right: 8px; font-size:14px; padding: 5px 10px;">Doc 3</span>
<h4 style="margin:0; font-family: 'Yomogi', cursive; color: var(--color-primary); font-size: 16px;">特定ステージの情報</h4>
</div>
<div class="content-box">
<p class="document-content" style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; background-color: #f0f4f8; border-left: 4px solid var(--color-accent2); padding: 12px; border-radius: 4px; line-height: 1.5;">"2018 Tour de France – Stage 20. 15:20 | 51:58. Stage 20 is the final time trial of this year’s Tour de France. The 28.6km parcours will start and finish"</p>
</div>
<div class="note-box" style="margin-top: 10px; padding: 12px; font-size: 13px;">
<p class="note-title" style="font-size: 14px; color: var(--color-accent2);"><i class="fas fa-road"></i> このドキュメントの役割</p>
                このドキュメントは、2018年ツール・ド・フランスの<span class="keyword">ステージ20（最終タイムトライアル）</span>に関する詳細情報を提供しています。距離（28.6km）や、スタートとフィニッシュ地点についての言及があります。総合順位（2位の選手）を直接示すものではありませんが、大会の特定の側面に関する情報です。
            </div>
</div>
<!-- Doc 4 -->
<div class="info-card">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span class="badge blue" style="margin-right: 8px; font-size:14px; padding: 5px 10px;">Doc 4</span>
<h4 style="margin:0; font-family: 'Yomogi', cursive; color: var(--color-primary); font-size: 16px;">報道・メディア情報</h4>
</div>
<div class="content-box">
<p class="document-content" style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; background-color: #f0f4f8; border-left: 4px solid var(--color-accent2); padding: 12px; border-radius: 4px; line-height: 1.5;">"Tour de France 2018: Live coverage of final stage | Cycling News $\cdot \cdot$ Stage 21 live commentary. 1.1M views · 1 year ago #cyclingnews $\cdot ^ { \cdot }$ Tour de France 2018: Stage 21 -"</p>
</div>
<div class="note-box" style="margin-top: 10px; padding: 12px; font-size: 13px;">
<p class="note-title" style="font-size: 14px; color: var(--color-accent2);"><i class="fas fa-tv"></i> このドキュメントの役割</p>
                これは、Cycling Newsによる2018年ツール・ド・フランスの<span class="keyword">最終ステージ（ステージ21）のライブカバレッジ</span>に関する情報です。視聴回数（1.1M views）やハッシュタグ（#cyclingnews）など、メディアコンテンツに関連するメタデータが含まれています。これも総合2位の選手を直接示すものではありませんが、大会に関する報道状況を示唆しています。
            </div>
</div>
</div>
<div class="info-grid" style="grid-template-columns: 1fr; margin-top: 15px;"> <!-- 1カラムに変更 -->
<!-- Doc 5 -->
<div class="info-card">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span class="badge blue" style="margin-right: 8px; font-size:14px; padding: 5px 10px;">Doc 5</span>
<h4 style="margin:0; font-family: 'Yomogi', cursive; color: var(--color-primary); font-size: 16px;">選手リスト (一部)</h4>
</div>
<div class="content-box">
<p class="document-content" style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; background-color: #f0f4f8; border-left: 4px solid var(--color-accent1); padding: 12px; border-radius: 4px; line-height: 1.5;">"2018 TDF. Egan Bernal. 29. Chris Froome. 30. <span style="background-color: #FFF3CD; color: #856404; padding: 2px 4px; border-radius: 3px; font-weight: bold;">Tom Dumoulin</span>. 31. Geraint Thomas. 32. Romain Bardet. 33. Simon Yates. 34. Thibaut Pinot. 35."</p>
</div>
<div class="note-box" style="margin-top: 10px; padding: 12px; font-size: 13px;">
<p class="note-title" style="font-size: 14px; color: var(--color-accent1);"><i class="fas fa-users"></i> このドキュメントの役割</p>
                このドキュメントは、2018年ツール・ド・フランス（TDF）に参加した<span class="keyword">選手名とゼッケン番号（または順位の一部）らしき数字のリスト</span>を提示しています。リストの中に「<span class="highlight" style="background-color: rgba(255, 213, 79, 0.4);">Tom Dumoulin</span>」の名前が含まれており、その隣には「30」という数字があります（これがゼッケン番号か一時的な順位かは不明）。Doc 2の情報と組み合わせることで、Tom Dumoulinが重要な選手であることを補強します。Egan Bernal、Chris Froome、Geraint Thomasなど、他の著名な選手の名前も挙げられています。
            </div>
</div>
</div>
<div class="arrow-connector"></div>
<div class="framework-box" style="margin-top: 25px;">
<h3 class="framework-title" style="font-size: 20px;"><i class="fas fa-puzzle-piece"></i> 総合的な評価：なぜこれが「Useful Output」なのか？</h3>
<p>これらのドキュメント群が「Useful Output」と見なされる主な理由は以下の通りです：</p>
<ul class="unstyled-list" style="margin-left: 15px; margin-top: 10px;">
<li class="process-step">
<div class="step-number" style="background-color: var(--color-accent1);">1</div>
<div class="step-content">
<strong><i class="fas fa-bullseye" style="color: var(--color-accent1);"></i> 直接的な回答の存在：</strong> <span class="keyword">Doc 2</span> は、質問「who came second in tour de france 2018?」に対して、「Tom Dumoulin」という直接的かつ明確な回答を含んでいます。これは最も重要な点です。
                </div>
</li>
<li class="process-step">
<div class="step-number" style="background-color: var(--color-accent1);">2</div>
<div class="step-content">
<strong><i class="fas fa-link" style="color: var(--color-accent1);"></i> 関連性の高い情報：</strong> 他のドキュメント（Doc 1, 3, 4, 5）も、2018年のツール・ド・フランスに関連する情報を提供しており、主題から逸脱していません。Doc 5は、Doc 2の情報を補強する可能性もあります。
                </div>
</li>
<li class="process-step">
<div class="step-number" style="background-color: var(--color-accent1);">3</div>
<div class="step-content">
<strong><i class="fas fa-check-double" style="color: var(--color-accent1);"></i> 情報の具体性：</strong> 選手名、チーム名、国籍、ステージ情報、メディア情報など、具体的な詳細が含まれています。
                </div>
</li>
<li class="process-step">
<div class="step-number" style="background-color: var(--color-accent1);">4</div>
<div class="step-content">
<strong><i class="fas fa-cogs" style="color: var(--color-accent1);"></i> シミュレーションの質：</strong> これらのドキュメントは、実際の検索エンジンが返しそうなスニペット（短い要約文）のスタイルを模倣しており、シミュレーションLLMがSFT（教師ありファインチューニング）によって、検索結果らしいテキストを生成する能力を学習したことを示唆しています。
                </div>
</li>
</ul>
<p style="margin-top: 15px;">このように、シミュレーションLLMは、<span class="highlight">クエリに対して的確で、かつ関連性の高い情報を複数提示</span>することで、後続のポリシーモデルが正解を導き出すための十分な「材料」を提供します。これがZEROSEARCHフレームワークにおける「Useful Output」の役割であり、強化学習の効率と効果を高める鍵となります。特に、<span class="keyword">APIコストをかけずに</span>このような質の高いシミュレーションができる点が、この論文の重要な貢献の一つです。🚀</p>
</div>
<div class="note-box" style="margin-top: 30px; background-color: rgba(255, 126, 95, 0.1); border-left-color: var(--color-secondary);">
<p class="note-title" style="color: var(--color-secondary);"><i class="fas fa-exclamation-triangle"></i> 「Noisy Output」との比較</p>
<p>論文中では、この「Useful Output」の例の直後に「Noisy Output」（ノイズの多い出力）の例も示されています（この解説では省略）。Noisy Outputは、クエリには関連しているように見えても、直接的な答えを含まなかったり、誤解を招く情報だったりするものを指します。ZEROSEARCHでは、学習の初期段階ではUseful Outputを多く生成し、徐々にNoisy Outputの割合を増やす<span class="keyword">カリキュラム学習</span>を行うことで、モデルの頑健性を高めます。この「Useful Output」の具体例は、そのカリキュラム学習の初期段階でモデルが目指すべき理想的な情報提供の形を示していると言えるでしょう。💡</p>
</div>
</div>
<div class="section-card" id="Noisy_Output:">
<h2 class="section-title"><i class="fas fa-comment-slash"></i>Noisy Output:</h2>
<p style="margin-bottom: 20px;">
        このセクションでは、論文で提案されている<span class="keyword">ZEROSEARCH</span>フレームワークにおいて、シミュレーションLLM（検索エンジン役のLLM）が意図的に<strong style="color: var(--color-secondary);">「ノイズの多い出力 (Noisy Output)」</strong>を生成する具体例を示します。これは、モデルが現実世界の検索エンジンのように、必ずしも完璧ではない検索結果に直面する状況をシミュレートし、そのような状況でも適切に情報を処理し推論する能力を養うための重要なステップです。
    </p>
<p style="margin-bottom: 20px;">
        論文のセクション3.3「Search Simulation Tuning」で説明されているように、シミュレーションLLMはファインチューニングによって、有用な情報を含むドキュメントだけでなく、あえて<strong style="color: var(--color-secondary);">関連性の低い、あるいは誤解を招く可能性のあるノイズドキュメント</strong>を生成する能力を獲得します。そして、セクション3.4「Rollout with Curriculum Search Simulation」で述べているカリキュラム学習を通じて、これらのノイズドキュメントの生成確率を徐々に上げていくことで、ポリシーモデル（実際に回答を生成するLLM）を段階的に困難な検索シナリオに慣らしていきます。
    </p>
<div class="glass-card" style="margin-bottom: 25px; padding: 20px;">
<h3 class="subsection-title" style="margin-top:0; color: var(--color-primary); border-bottom: 1px dashed var(--color-primary); padding-bottom: 5px;"><i class="fas fa-question-circle"></i> 提示された質問と検索クエリ</h3>
<p><span class="badge blue">質問</span> <i class="fas fa-long-arrow-alt-right"></i> What is the name of the sequel to the novel "The Alienist" by author Caleb Carr?</p>
<p style="font-family: 'Yomogi', cursive;">（著者カレブ・カーの小説「エイリアニスト」の続編の名前は何ですか？）</p>
<hr style="border: 0; border-top: 1px dashed var(--color-gray); margin: 10px 0;"/>
<p><span class="badge purple">正解</span> <i class="fas fa-long-arrow-alt-right"></i> The Angel of Darkness</p>
<p style="font-family: 'Yomogi', cursive;">（エンジェル・オブ・ダークネス）</p>
<hr style="border: 0; border-top: 1px dashed var(--color-gray); margin: 10px 0;"/>
<p><span class="badge orange">検索クエリ</span> <i class="fas fa-long-arrow-alt-right"></i> sequel to The Alienist Caleb Carr</p>
<p style="font-family: 'Yomogi', cursive;">（エイリアニスト カレブ・カー 続編）</p>
</div>
<div class="bubble-box" style="margin-bottom: 25px;">
<p>
<i class="fas fa-info-circle" style="color: var(--color-primary);"></i> 以下に示すのは、上記の検索クエリに対してシミュレーションLLMが生成した<strong style="color: var(--color-secondary);">「ノイズの多い出力」</strong>の例です。これらのドキュメントは、質問に対する直接的な答えや、答えを見つける上で<span class="highlight">有用な情報を含んでいません</span>。
        </p>
</div>
<h3 class="subsection-title"><i class="fas fa-stream"></i> 📄 具体例：ノイズのある出力 (Noisy Output)</h3>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));">
<div class="info-card">
<h4 class="subsection-title" style="margin-top:0; font-size: 16px; color: var(--color-dark); border-left: 3px solid var(--color-dark);"><i class="far fa-file-alt"></i> Doc 1:</h4>
<p style="font-family: 'Zen Kurenaido', sans-serif;">second place is 5000 euros, with 3000 euros for the third-placed rider. Riders in the top three of each stage receive a cash bonus as well.</p>
<div class="note-box" style="background-color: rgba(255, 126, 95, 0.1); border-left-color: var(--color-secondary);">
<p class="note-title" style="color: var(--color-secondary);"><i class="fas fa-times-circle"></i> なぜこれがノイズか？</p>
<p>これは自転車レースの賞金に関する情報であり、小説「エイリアニスト」の続編とは全く関連がありません。</p>
</div>
</div>
<div class="info-card">
<h4 class="subsection-title" style="margin-top:0; font-size: 16px; color: var(--color-dark); border-left: 3px solid var(--color-dark);"><i class="far fa-file-alt"></i> Doc 2:</h4>
<p style="font-family: 'Zen Kurenaido', sans-serif;">second place was 1 minute and 47 seconds. This time gap is the biggest ever in the history of Tour de France. The previous record is 1 minute</p>
<div class="note-box" style="background-color: rgba(255, 126, 95, 0.1); border-left-color: var(--color-secondary);">
<p class="note-title" style="color: var(--color-secondary);"><i class="fas fa-times-circle"></i> なぜこれがノイズか？</p>
<p>ツール・ド・フランス（自転車レース）のタイム差に関する記述で、質問の小説とは無関係です。</p>
</div>
</div>
<div class="info-card">
<h4 class="subsection-title" style="margin-top:0; font-size: 16px; color: var(--color-dark); border-left: 3px solid var(--color-dark);"><i class="far fa-file-alt"></i> Doc 3:</h4>
<p style="font-family: 'Zen Kurenaido', sans-serif;">1978. Second place, Joop Zoetemelk. 1980. Not Having Enough Time. An hour before Wouter Weylandt won stage nine, a picture of the Tour 2020 got painted.</p>
<div class="note-box" style="background-color: rgba(255, 126, 95, 0.1); border-left-color: var(--color-secondary);">
<p class="note-title" style="color: var(--color-secondary);"><i class="fas fa-times-circle"></i> なぜこれがノイズか？</p>
<p>過去のツール・ド・フランスの出来事や選手に関する情報で、小説の続編とは関連がありません。</p>
</div>
</div>
<div class="info-card">
<h4 class="subsection-title" style="margin-top:0; font-size: 16px; color: var(--color-dark); border-left: 3px solid var(--color-dark);"><i class="far fa-file-alt"></i> Doc 4:</h4>
<p style="font-family: 'Zen Kurenaido', sans-serif;">second place in January 2017. Over the following two years, the Swiss rider won the Giro d’Italia and Tour de France, adding the Vuelta to Spain in</p>
<div class="note-box" style="background-color: rgba(255, 126, 95, 0.1); border-left-color: var(--color-secondary);">
<p class="note-title" style="color: var(--color-secondary);"><i class="fas fa-times-circle"></i> なぜこれがノイズか？</p>
<p>あるスイスの自転車選手のキャリアに関する情報であり、質問の小説とは無関係です。</p>
</div>
</div>
<div class="info-card">
<h4 class="subsection-title" style="margin-top:0; font-size: 16px; color: var(--color-dark); border-left: 3px solid var(--color-dark);"><i class="far fa-file-alt"></i> Doc 5:</h4>
<p style="font-family: 'Zen Kurenaido', sans-serif;">The awards for best riders in their respective categories were presented at the end of each stage and the overall rankings are published every evening.</p>
<div class="note-box" style="background-color: rgba(255, 126, 95, 0.1); border-left-color: var(--color-secondary);">
<p class="note-title" style="color: var(--color-secondary);"><i class="fas fa-times-circle"></i> なぜこれがノイズか？</p>
<p>自転車レースの表彰やランキング発表に関する一般的な情報で、小説の続編とは関連がありません。</p>
</div>
</div>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-lightbulb"></i> 「ノイズのある出力」の役割と重要性</h3>
<div class="framework-box" style="padding: 20px;">
<p class="framework-title" style="font-family: 'Yomogi', cursive; font-size: 18px;">💡 なぜ「ノイズ」をわざわざ学習するの？</p>
<p>これらの<strong style="color: var(--color-secondary);">「ノイズの多い出力」</strong>は、一見すると役に立たないように思えますが、<span class="keyword">ZEROSEARCH</span>フレームワークにおいて非常に重要な役割を担っています。</p>
<ul style="list-style-type: none; padding-left: 0;">
<li style="margin-bottom: 10px;">
<span class="badge yellow"><i class="fas fa-graduation-cap"></i> カリキュラム学習</span>: ポリシーモデルは、最初から難しい問題に直面するのではなく、徐々に難易度が上がるように訓練されます。初期段階では質の高い（ノイズの少ない）検索結果に触れ、学習が進むにつれて、このような<span class="highlight">ノイズの多い検索結果の中から正しい情報を見つけ出す能力</span>を養います。
                <div style="text-align: center; margin-top:10px;">
<span style="font-family: 'Yomogi', cursive; font-size: 16px; border: 1px dashed var(--color-accent1); padding: 5px 10px; border-radius: 5px; background-color: rgba(92,184,92,0.1);">簡単な検索 <i class="fas fa-arrow-right" style="color: var(--color-accent1);"></i></span>
<span style="font-family: 'Yomogi', cursive; font-size: 16px; border: 1px dashed var(--color-accent1); padding: 5px 10px; border-radius: 5px; background-color: rgba(92,184,92,0.1);">少しノイズ <i class="fas fa-arrow-right" style="color: var(--color-accent1);"></i></span>
<span style="font-family: 'Yomogi', cursive; font-size: 16px; border: 1px dashed var(--color-accent1); padding: 5px 10px; border-radius: 5px; background-color: rgba(92,184,92,0.1);">ノイズが多い (この例のような状況)</span>
</div>
</li>
<li style="margin-bottom: 10px;">
<span class="badge purple"><i class="fas fa-shield-alt"></i> ロバスト性の向上</span>: 現実世界の検索エンジンは、常に完璧な情報を提供してくれるわけではありません。関連性の低い情報や、時には誤った情報が返ってくることもあります。<span class="highlight">ノイズの多い出力に慣れることで、モデルはより頑健（ロバスト）になり</span>、実環境での性能向上が期待できます。
            </li>
<li style="margin-bottom: 10px;">
<span class="badge blue"><i class="fas fa-cogs"></i> 制御可能性</span>: シミュレーションLLMが意図的にノイズを生成できることで、開発者は訓練環境の難易度を<span class="highlight">細かく制御</span>できます。これにより、特定の能力を重点的に鍛えるなど、より効率的な学習戦略を立てることが可能になります。
            </li>
</ul>
<div class="note-box" style="margin-top: 15px;">
<p class="note-title"><i class="fas fa-pencil-alt"></i> 📝 <strong>補足</strong></p>
<p>
                論文では、シミュレーションLLMをファインチューニングする際、プロンプトに特定のキーワード（例：<code style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px; color: var(--color-secondary);">"noisy"</code> や <code style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px; color: var(--color-accent1);">"useful"</code>）を含めることで、生成されるドキュメントの質を制御できると述べています（Table 2参照）。この「Noisy Output:」の例は、その <code style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px; color: var(--color-secondary);">"noisy"</code> 指示によって生成された結果と解釈できます。
            </p>
</div>
</div>
<p style="margin-top: 25px; font-style: italic; color: var(--color-gray); text-align: center;">
        ✏️ このように、<span class="keyword">ZEROSEARCH</span>はシミュレートされた環境下で、コストを抑えつつ、LLMの検索・推論能力を効果的に向上させることを目指しています。
    </p>
</div>
<div class="section-card" id="Useful_Output:">
<h2 class="section-title"><i class="fas fa-lightbulb"></i>Useful Output: 「有用な出力」とは？</h2>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 16px; line-height: 1.6;">
        このセクションでは、論文で提案されている<span class="keyword">ZEROSEARCH</span>フレームワークにおいて、シミュレーションLLM（大規模言語モデル）が検索クエリに対してどのように<strong style="color: var(--color-accent1);">「有用なドキュメント」</strong>を生成するのか、その具体例を通じて見ていきましょう。ここでの「有用なドキュメント」とは、ユーザーが投げかけた質問に答えるために必要な、<span class="highlight">鍵となる情報</span>を含んだ文書のことを指します。論文では、この「有用な出力」の例と、後に示される「ノイズの多い出力 (Noisy Output)」の例を比較することで、シミュレーションLLMが質の高い文書を生成できる能力と、それを用いた強化学習プロセスの有効性を示唆しています。
    </p>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 16px; line-height: 1.6;">
        それでは、具体的な例を見ていきましょう。✏️
    </p>
<div class="glass-card" style="margin-top: 30px;">
<h3 class="subsection-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-question-circle"></i>提示された質問</h3>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 16px;">
            who came second in tour de france 2018?
        </p>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; color: var(--color-gray);">
            (日本語訳: 2018年のツール・ド・フランスで2位だったのは誰ですか？)
        </p>
</div>
<div class="two-column" style="margin-top: 15px; margin-bottom:15px; align-items: stretch;">
<div class="column">
<div class="glass-card" style="height: 100%;">
<h3 class="subsection-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-search"></i>対応するクエリ</h3>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 16px;">
                    Tour de France 2018 second place
                </p>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; color: var(--color-gray);">
                    (日本語訳: ツール・ド・フランス 2018 2位)
                </p>
</div>
</div>
<div class="column">
<div class="glass-card" style="height: 100%; background-color: rgba(92, 184, 92, 0.1);">
<h3 class="subsection-title" style="font-family: 'Yomogi', cursive; color: var(--color-accent1); border-left-color: var(--color-accent1);"><i class="fas fa-check-circle"></i>正解</h3>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 16px; color: var(--color-accent1); font-weight: bold;">
                    Tom Dumoulin
                </p>
</div>
</div>
</div>
<div class="arrow-connector" style="margin-top: 10px; margin-bottom:10px;">
<span style="font-size: 30px; color: var(--color-primary);">⬇️</span>
</div>
<div class="framework-box" style="border-style: solid; border-color: var(--color-primary);">
<h3 class="subsection-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-file-alt"></i>シミュレーションLLMによって生成された「有用な出力」ドキュメント群</h3>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 15px; line-height: 1.6; margin-bottom: 20px;">
            上記のクエリに対して、シミュレーションLLMは以下のような5つのドキュメントを「有用な出力」として生成しました。これらのドキュメントが、どのように質問の答えである「Tom Dumoulin」にたどり着くのに役立つかを見ていきましょう。
        </p>
<div class="info-grid">
<div class="info-card">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span class="badge blue">Doc 1</span>
<h4 style="font-family: 'Kaisei Decol', serif; margin: 0 0 0 10px; font-size:16px; color: var(--color-primary);">コンテキスト情報</h4>
</div>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; border-left: 3px solid var(--color-primary); padding-left: 10px;">
<em>The 2018 Tour de France was the 105th edition of the race, and the first under the leadership of new event president Étienne Thobois.</em>
</p>
<div class="note-box" style="background-color: rgba(74, 111, 165, 0.05); margin-top:10px;">
<p class="note-title" style="font-family: 'Yomogi', cursive; color: var(--color-primary);"><i class="fas fa-info-circle"></i>解説</p>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px;">
                        このドキュメントは、質問の主題である「<span class="keyword">2018年のツール・ド・フランス</span>」に関する基本的な背景情報を提供しています。具体的には、これが第105回目の大会であることや、新しい大会会長のもとで行われた最初のレースであることを示しています。
                        <br/>直接的に2位の選手名を述べてはいませんが、質問のコンテキスト（どの年のどのレースか）を明確にする上で<span class="highlight">有用な情報</span>です。
                    </p>
</div>
</div>
<div class="info-card" style="border: 2px solid var(--color-accent1); box-shadow: 0 4px 15px rgba(92, 184, 92, 0.3);">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span class="badge" style="background-color: var(--color-accent1);">Doc 2</span>
<h4 style="font-family: 'Kaisei Decol', serif; margin: 0 0 0 10px; font-size:16px; color: var(--color-accent1);">📌最重要ドキュメント！</h4>
</div>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; border-left: 3px solid var(--color-accent1); padding-left: 10px;">
<em><strong style="background-color: yellow;">2nd – Tom Dumoulin (NED / Team Sunweb)</strong> 3rd – Geraint Thomas (GBR / Team Sky) 4th – Jakob Fuglsang (DEN / Astana) 5th – Romain Bardet (FRA / AG2R</em>
</p>
<div class="note-box" style="background-color: rgba(92, 184, 92, 0.05); margin-top:10px;">
<p class="note-title" style="font-family: 'Yomogi', cursive; color: var(--color-accent1);"><i class="fas fa-star"></i>解説</p>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px;">
                        🌟 <strong>これぞ核心情報！</strong> このドキュメントには、質問に対する<span class="keyword">直接的な答え</span>が含まれています。「<strong style="color: var(--color-accent1);">2nd – Tom Dumoulin</strong>」と明記されており、2018年ツール・ド・フランスの2位がトム・デュムラン選手（オランダ/チームサンウェブ所属）であることが明確に分かります。
                        <br/>この情報があれば、質問に正しく回答できます。まさに「有用な出力」の典型例です。
                    </p>
</div>
</div>
<div class="info-card">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span class="badge blue">Doc 3</span>
<h4 style="font-family: 'Kaisei Decol', serif; margin: 0 0 0 10px; font-size:16px; color: var(--color-primary);">関連情報</h4>
</div>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; border-left: 3px solid var(--color-primary); padding-left: 10px;">
<em>2018 Tour de France – Stage 20. 15:20 | 51:58. Stage 20 is the final time trial of this year’s Tour de France. The 28.6km parcours will start and finish</em>
</p>
<div class="note-box" style="background-color: rgba(74, 111, 165, 0.05); margin-top:10px;">
<p class="note-title" style="font-family: 'Yomogi', cursive; color: var(--color-primary);"><i class="fas fa-info-circle"></i>解説</p>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px;">
                        このドキュメントは、2018年ツール・ド・フランスの<span class="keyword">第20ステージ</span>に関する詳細情報を提供しています。最終タイムトライアルのステージであること、距離などが記載されています。
                        <br/>順位に関する直接的な情報はありませんが、大会の特定のステージに関する<span class="highlight">文脈情報</span>として役立つ可能性があります。例えば、最終ステージの結果が総合順位に影響するような場合などです。
                    </p>
</div>
</div>
<div class="info-card">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span class="badge blue">Doc 4</span>
<h4 style="font-family: 'Kaisei Decol', serif; margin: 0 0 0 10px; font-size:16px; color: var(--color-primary);">関連報道</h4>
</div>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; border-left: 3px solid var(--color-primary); padding-left: 10px;">
<em>Tour de France 2018: Live coverage of final stage | Cycling News $\cdot \cdot$ Stage 21 live commentary. 1.1M views · 1 year ago #cyclingnews $\cdot ^ { \cdot }$ Tour de France 2018: Stage 21 -</em>
</p>
<div class="note-box" style="background-color: rgba(74, 111, 165, 0.05); margin-top:10px;">
<p class="note-title" style="font-family: 'Yomogi', cursive; color: var(--color-primary);"><i class="fas fa-info-circle"></i>解説</p>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px;">
                        このドキュメントは、<span class="keyword">Cycling News</span>というメディアによる2018年ツール・ド・フランス最終ステージのライブカバレッジ（実況中継）に関する情報です。視聴回数や投稿時期なども含まれています。
                        <br/>Doc 3と同様に、直接的な順位情報はありませんが、大会に関する<span class="highlight">メディア報道</span>の一例として、関連情報を提供しています。
                    </p>
</div>
</div>
<div class="info-card">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span class="badge blue">Doc 5</span>
<h4 style="font-family: 'Kaisei Decol', serif; margin: 0 0 0 10px; font-size:16px; color: var(--color-primary);">選手リスト（一部）</h4>
</div>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; border-left: 3px solid var(--color-primary); padding-left: 10px;">
<em>2018 TDF. Egan Bernal. 29. Chris Froome. 30. <strong style="background-color: yellow;">Tom Dumoulin</strong>. 31. Geraint Thomas. 32. Romain Bardet. 33. Simon Yates. 34. Thibaut Pinot. 35.</em>
</p>
<div class="note-box" style="background-color: rgba(74, 111, 165, 0.05); margin-top:10px;">
<p class="note-title" style="font-family: 'Yomogi', cursive; color: var(--color-primary);"><i class="fas fa-info-circle"></i>解説</p>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px;">
                        このドキュメントは、2018年のツール・ド・フランス（TDF）に出場した選手リストの一部を、ゼッケン番号（？）と思われる数字と共に示しています。リストの中に「<strong style="color: var(--color-accent1);">Tom Dumoulin</strong>」の名前が含まれています。
                        <br/>Doc 2ほど直接的ではありませんが、<span class="highlight">トム・デュムラン選手が2018年の大会に出場していた</span>ことを確認できる点で有用です。Doc 2の情報と組み合わせることで、確信度を高めることができます。
                    </p>
</div>
</div>
</div>
</div>
<div class="bubble-box" style="margin-top: 30px; border-color: var(--color-accent1);">
<h3 class="subsection-title" style="font-family: 'Yomogi', cursive; color: var(--color-accent1); border-left: 3px solid var(--color-accent1);">
<i class="fas fa-microscope" style="color: var(--color-accent1);"></i>考察：なぜこれらが「有用な出力」なのか？
        </h3>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 15px; line-height: 1.6;">
            これらのドキュメント群が「有用」とされる理由は、<strong style="color: var(--color-accent1);">質問に答えるための直接的な手がかりや、それを補強する情報を含んでいる</strong>からです。
        </p>
<ul style="font-family: 'Zen Kurenaido', sans-serif; font-size: 14px; line-height: 1.6; list-style-type: '✅ '; padding-left: 20px;">
<li><span class="keyword">Doc 2</span> は、質問に対する<strong style="color: var(--color-accent1);">決定的な答え</strong>を提示しています。</li>
<li><span class="keyword">Doc 1, Doc 3, Doc 4</span> は、質問の背景となる<strong style="color: var(--color-primary);">コンテキスト情報</strong>や関連情報を提供し、理解を深めるのに役立ちます。</li>
<li><span class="keyword">Doc 5</span> は、答えとなる人物が確かにそのイベントに参加していたことを<strong style="color: var(--color-secondary);">裏付ける情報</strong>を提供しています。</li>
</ul>
<p style="font-family: 'Zen Kurenaido', sans-serif; font-size: 15px; line-height: 1.6;">
            このように、ZEROSEARCHフレームワークにおけるシミュレーションLLMは、単にキーワードに合致する文書を返すだけでなく、質問応答タスクを遂行する上で<span class="highlight">意味のある情報</span>、<span class="highlight">文脈的に関連性の高い情報</span>、そして<span class="highlight">核心をつく情報</span>を生成することを目指しています。これが、後の強化学習ステップでエージェント（ポリシーモデル）が効果的に学習するための基盤となります。
        </p>
<div class="tag-list" style="margin-top: 15px;">
<span class="tag" style="background-color: var(--color-accent1); color: white;">#直接的な証拠</span>
<span class="tag" style="background-color: var(--color-primary); color: white;">#コンテキスト提供</span>
<span class="tag" style="background-color: var(--color-secondary); color: white;">#補強情報</span>
<span class="tag" style="background-color: var(--color-accent3); color: var(--color-dark);">#情報品質</span>
</div>
</div>
</div>
<div class="section-card" id="Noisy_Output:">
<h2 class="section-title"><i class="fas fa-filter"></i> Noisy Output:</h2>
<div class="glass-card" style="margin-bottom: 25px;">
<p style="font-family: 'Yomogi', cursive; font-size: 16px; text-align:center;">
<span class="badge yellow">📝イントロダクション</span><br/>
            このセクションでは、ZEROSEARCHフレームワークにおいて非常に重要な概念である「<span class="keyword">Noisy Output（ノイズの多い出力）</span>」について、具体的な事例を通して詳しく見ていきましょう。
        </p>
<div class="note-box">
<p class="note-title"><i class="fas fa-lightbulb"></i>「Noisy Output」とは？</p>
<p>これは、ユーザー（またはAIエージェント）が検索クエリを入力した際に、シミュレーションLLMが生成するドキュメントの一種です。これらのドキュメントは、意図的に<span class="highlight">直接的な答えを含まなかったり</span>、<span class="highlight">関連性が低かったり</span>、時には<span class="highlight">誤解を招くような情報</span>を含んでいたりします。</p>
</div>
<div style="text-align: center; margin: 25px 0;">
<i class="fas fa-question-circle fa-2x" style="color: var(--color-secondary);"></i>
<p style="font-family: 'Yomogi', cursive; font-size: 18px; color: var(--color-secondary); margin-top: 5px;">なぜ、わざわざノイズの多い出力を作るの？</p>
</div>
<p>その答えは、強化学習で訓練される<span class="keyword">ポリシーモデル</span>をより賢く、より頑健にするためです。現実の世界で情報を探すとき、常に完璧で役立つ情報だけが見つかるわけではありませんよね？ 🧐</p>
<p>ZEROSEARCHでは、<span class="keyword">カリキュラム学習</span>というアプローチを採用しています。これは、最初は簡単な問題から始め、徐々に難しい問題に挑戦していく学習方法です。ノイズの多い出力は、この「難しい問題」に相当します。</p>
<div class="framework-box" style="margin-top:20px;">
<p class="framework-title"><i class="fas fa-graduation-cap"></i> カリキュラム学習のイメージ</p>
<div class="pipeline" style="align-items: center;">
<div class="pipeline-step" style="width: 70%; text-align:center;">
<span class="step-number" style="float:left;">1</span>
<strong>初期段階:</strong> <i class="fas fa-seedling" style="color: var(--color-accent1);"></i> ポリシーモデルは、主に役立つ情報（Useful Output）に触れて基本的な検索方法やタスクの理解を深めます。
                </div>
<div class="pipeline-step" style="width: 70%; text-align:center;">
<span class="step-number" style="float:left;">2</span>
<strong>進行段階:</strong> <i class="fas fa-chart-line" style="color: var(--color-accent2);"></i> 徐々にノイズの多い情報（Noisy Output）の割合が増え、モデルはより複雑な状況での情報処理能力を試されます。
                </div>
<div class="pipeline-step" style="width: 70%; text-align:center;">
<span class="step-number" style="float:left;">3</span>
<strong>最終段階:</strong> <i class="fas fa-mountain" style="color: var(--color-secondary);"></i> モデルは、ノイズが多い中でも正確な情報を引き出し、推論する高度な能力を獲得します。
                </div>
</div>
<p style="text-align:center; font-size:12px; color:var(--color-gray); margin-top:15px;">このように段階的に難易度を上げることで、モデルはロバストな検索・推論能力を身につけます。</p>
</div>
<p style="margin-top:15px;">これから紹介する例は、論文のAppendix E Case Studyにある「Simulated Document Study」から取られたもので、シミュレーションLLMが特定の質問と検索クエリに対して、どのような「Noisy Output」を生成するのかを示しています。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-bicycle"></i> 具体例1: ツール・ド・フランス 2018</h3>
<div class="framework-box">
<p class="framework-title">🔍 Context: この例の背景情報</p>
<ul class="unstyled-list">
<li><i class="fas fa-question" style="color:var(--color-primary); margin-right:5px;"></i><strong>質問 (Question):</strong> who came second in tour de france 2018? <br/>(2018年のツール・ド・フランスで2位だったのは誰ですか？)</li>
<li><i class="fas fa-check" style="color:var(--color-accent1); margin-right:5px;"></i><strong>正解 (Answer):</strong> Tom Dumoulin (トム・デュムラン)</li>
<li><i class="fas fa-search" style="color:var(--color-secondary); margin-right:5px;"></i><strong>検索クエリ (Query):</strong> Tour de France 2018 second place</li>
</ul>
</div>
<p>上記の質問とクエリに対し、シミュレーションLLMが生成した「<span class="keyword">Noisy Output</span>」の具体例を見てみましょう。これらのドキュメントは、質問の核心である「2018年の2位の選手名」という情報を<span class="highlight">含んでいません</span>。</p>
<div class="info-grid" style="margin-top:20px;">
<div class="info-card">
<p><span class="badge orange">Doc 1</span></p>
<p>"second place is 5000 euros, with 3000 euros for the third-placed rider. Riders in the top three of each stage receive a cash bonus as well."</p>
<div class="bubble-box">
<p>💬 <strong>解説:</strong> このドキュメントは、ツール・ド・フランスの<span class="highlight">順位に応じた賞金額</span>について述べています。しかし、<span class="keyword">「誰が」</span>2位だったのかという肝心な情報は含まれていません。お金の話は興味深いですが、質問の答えにはなっていませんね。</p>
</div>
</div>
<div class="info-card">
<p><span class="badge orange">Doc 2</span></p>
<p>"second place was 1 minute and 47 seconds. This time gap is the biggest ever in the history of Tour de France. The previous record is 1 minute"</p>
<div class="bubble-box">
<p>💬 <strong>解説:</strong> ここでは、2位の選手と優勝者との<span class="highlight">タイム差</span>に焦点が当てられています。「ツール・ド・フランス史上最大のタイム差」という事実は注目に値しますが、その2位の選手の名前は依然として謎のままです。</p>
</div>
</div>
<div class="info-card">
<p><span class="badge orange">Doc 3</span></p>
<p>"1978. Second place, Joop Zoetemelk. 1980. Not Having Enough Time. An hour before Wouter Weylandt won stage nine, a picture of the Tour 2020 got painted."</p>
<div class="bubble-box">
<p>💬 <strong>解説:</strong> この情報は、<span class="highlight">1978年</span>や<span class="highlight">1980年</span>といった過去の大会の結果や、<span class="highlight">2020年</span>の大会に関するエピソードに触れています。質問は<span class="keyword">2018年</span>について尋ねているため、これは<span class="highlight">時代違いの情報</span>でありノイズとなります。</p>
</div>
</div>
<div class="info-card">
<p><span class="badge orange">Doc 4</span></p>
<p>"second place in January 2017. Over the following two years, the Swiss rider won the Giro d’Italia and Tour de France, adding the Vuelta to Spain in"</p>
<div class="bubble-box">
<p>💬 <strong>解説:</strong> <span class="highlight">2017年1月</span>の別のレースでの2位の話や、あるスイス人選手の過去の業績について述べています。これも、質問が求める<span class="keyword">2018年ツール・ド・フランスの2位選手</span>の情報とは直接関係ありません。</p>
</div>
</div>
<div class="info-card">
<p><span class="badge orange">Doc 5</span></p>
<p>"The awards for best riders in their respective categories were presented at the end of each stage and the overall rankings are published every evening."</p>
<div class="bubble-box">
<p>💬 <strong>解説:</strong> ツール・ド・フランスの<span class="highlight">一般的な運営方法</span>（各ステージ後の表彰やランキング発表）について説明しています。これも大会に関する情報ではありますが、特定の年の特定の順位の選手名という具体的な答えには結びつきません。</p>
</div>
</div>
</div>
<div class="note-box" style="margin-top:20px;">
<p class="note-title"><i class="fas fa-bullseye"></i> この例から分かること</p>
<p>これらのノイズの多い出力は、一見するとツール・ド・フランスに関連する情報を含んでいますが、質問の核心（「2018年大会の2位の選手は誰か？」）には答えていません。「second place」というキーワードは含まれているものの、文脈が異なるため、ポリシーモデルはこれらの情報から正しい答えを導き出すために、さらなる推論や検索を行う必要があります。</p>
<p>このようなノイズの多い文書群を学習データに含めることで、ポリシーモデルは、<span class="highlight">関連キーワードが含まれていても必ずしもそれが答えではない</span>ということを学び、より深い文脈理解と情報フィルタリング能力を養うことができます。</p>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-book-open"></i> 具体例2: 小説「エイリアニスト」の続編</h3>
<div class="framework-box">
<p class="framework-title">🔍 Context: この例の背景情報</p>
<ul class="unstyled-list">
<li><i class="fas fa-question" style="color:var(--color-primary); margin-right:5px;"></i><strong>質問 (Question):</strong> What is the name of the sequel to the novel "The Alienist" by author Caleb Carr? <br/>(ケイレブ・カー作の小説「エイリアニスト」の続編の名前は何ですか？)</li>
<li><i class="fas fa-check" style="color:var(--color-accent1); margin-right:5px;"></i><strong>正解 (Answer):</strong> The Angel of Darkness (エンジェル・オブ・ダークネス)</li>
<li><i class="fas fa-search" style="color:var(--color-secondary); margin-right:5px;"></i><strong>検索クエリ (Query):</strong> sequel to The Alienist Caleb Carr</li>
</ul>
</div>
<p>次に、小説に関する質問に対する「<span class="keyword">Noisy Output</span>」の例を見てみましょう。この場合も、生成されたドキュメントは、質問の直接的な答えである「続編のタイトル」を<span class="highlight">含んでいません</span>。</p>
<div class="info-grid" style="margin-top:20px;">
<div class="info-card">
<p><span class="badge orange">Doc 1</span></p>
<p>"The Alienist has been adapted for the screen, the eight-part miniseries coming to production this summer and airing in January 2018 on TNT."</p>
<div class="bubble-box">
<p>💬 <strong>解説:</strong> このドキュメントは、「エイリアニスト」が<span class="highlight">映像化（ミニシリーズ化）</span>されたことについて述べています。これは原作小説に関する情報ですが、<span class="keyword">続編のタイトル</span>という質問の核心には触れていません。</p>
</div>
</div>
<div class="info-card">
<p><span class="badge orange">Doc 2</span></p>
<p>"The Alienist is a 1994 American suspense novel by Caleb Carr. Set in New York City during the winter of 1896, it follows the investigation of a"</p>
<div class="bubble-box">
<p>💬 <strong>解説:</strong> これは「エイリアニスト」自体の<span class="highlight">基本的な情報</span>（出版年、作者、ジャンル、舞台設定など）を説明しています。小説の概要を知る上では役立ちますが、続編については何も語られていません。</p>
</div>
</div>
<div class="info-card">
<p><span class="badge orange">Doc 3</span></p>
<p>"Imagine an alienist, an alienist is a psychiatrist in the 19th century. Okay, so who’s the alienist? John Corrigan. John Corrigan played by Daniel"</p>
<div class="bubble-box">
<p>💬 <strong>解説:</strong> 「エイリアニスト」という言葉の<span class="highlight">意味（19世紀の精神科医）</span>や、おそらくドラマ版の登場人物や俳優について触れています。これは小説の背景知識にはなりますが、続編のタイトルとは関係ありません。</p>
</div>
</div>
<div class="info-card">
<p><span class="badge orange">Doc 4</span></p>
<p>"Revisit Caleb Carr’s The Alienist by watching the classic crime drama, now streaming on HBO Max."</p>
<div class="bubble-box">
<p>💬 <strong>解説:</strong> 再び「エイリアニスト」の<span class="highlight">ドラマ版</span>に言及し、視聴を勧める内容です。原作小説の宣伝や関連情報ではありますが、続編のタイトルという具体的な答えは提供していません。</p>
</div>
</div>
<div class="info-card">
<p><span class="badge orange">Doc 5</span></p>
<p>"Join us this week as we explore Caleb Carr’s fictional world of monsters and monsters hunters in our conversation with Caleb about his most"</p>
<div class="bubble-box">
<p>💬 <strong>解説:</strong> 作者ケイレブ・カーの<span class="highlight">作品世界に関する議論やインタビュー</span>を示唆する内容です。作者や作品のテーマには関連していますが、特定の続編のタイトルという情報は見当たりません。</p>
</div>
</div>
</div>
<div class="note-box" style="margin-top:20px;">
<p class="note-title"><i class="fas fa-bullseye"></i> この例から分かること</p>
<p>ここでも、ノイズの多い出力は質問に関連するキーワード（「The Alienist」、「Caleb Carr」）を含んでいますが、求められている「続編のタイトル」という核心情報を提供していません。例えば、ドラマ化の情報、原作の概要、用語解説、作者インタビューへの誘導など、どれも直接的な答えではありません。</p>
<p>これらのノイズ情報を経験することで、ポリシーモデルは、<span class="highlight">単にキーワードが一致するだけでは不十分</span>であり、質問の意図を正確に把握し、必要な情報をピンポイントで見つけ出す能力を鍛えられます。これがZEROSEARCHの目指す、より実践的で賢い検索能力の育成に繋がります。</p>
</div>
<div class="glass-card" style="margin-top: 30px;">
<p style="font-family: 'Yomogi', cursive; font-size: 16px; text-align:center;">
<span class="badge purple">🚀 まとめ: Noisy Outputの役割</span><br/>
            「Noisy Output」は、ZEROSEARCHフレームワークにおいて、シミュレーションLLMが意図的に生成する、<span class="keyword">直接的な答えを含まない</span>、あるいは<span class="keyword">関連性の低い情報</span>です。<br/>
            これらは、強化学習で訓練されるポリシーモデルに対して、以下のような効果をもたらします：
        </p>
<div class="feature-card-grid">
<div class="feature-item">
<i class="fas fa-brain fa-2x" style="color:var(--color-primary);"></i>
<p><strong>推論能力の向上:</strong><br/>曖昧な情報や不完全な情報から正しい答えを推測する能力を鍛えます。</p>
</div>
<div class="feature-item">
<i class="fas fa-shield-alt fa-2x" style="color:var(--color-accent1);"></i>
<p><strong>頑健性の強化:</strong><br/>現実世界の不確実な情報環境に対応できる、よりロバストなモデルを育成します。</p>
</div>
<div class="feature-item">
<i class="fas fa-filter fa-2x" style="color:var(--color-secondary);"></i>
<p><strong>情報選別能力の学習:</strong><br/>大量の情報の中から、本当に必要な情報を見分けるスキルを養います。</p>
</div>
</div>
<p style="text-align:center; margin-top:20px;">
<span class="highlight">カリキュラム学習</span>の一環として、これらのノイズの多い出力を段階的に導入することで、ポリシーモデルはより高度な検索・推論戦略を習得し、最終的には実際の検索エンジンを使った場合と同等、あるいはそれ以上の性能を発揮することが期待されます。これが、APIコストをかけずに検索能力を向上させるZEROSEARCHの核心的なアイデアの一つです。
        </p>
</div>
</div>
</div>
</body>
</html>
