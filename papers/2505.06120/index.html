<!DOCTYPE html>

<html lang="ja">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Philippe Laban∗♢解説</title>
<link href="style.css" rel="stylesheet"/>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
        window.MathJax = {
          tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)'], ['\\\\(', '\\\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]'], ['\\\\[', '\\\\]']]
          }
        };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet"/>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-N7SLXFTVBP"></script>
</script>

<!-- Enhanced Analytics with Paper Title Tracking -->
<script src="/js/analytics-enhanced.js"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'G-N7SLXFTVBP');
</script>

<!-- Enhanced Analytics with Paper Title Tracking -->
<script src="/js/analytics-enhanced.js"></script>
</script>
</head>
<body>
<div class="container">
<!-- ヘッダー部分 -->
<div class="header">
<div class="title-area">
<h1 class="title">Philippe Laban∗♢</h1>
<p class="subtitle">None</p>
</div>
<div class="meta-info">
<p>論文解説</p>
</div>
</div>
<div class="section-card" id="ABSTRACT">
<h2 class="section-title"><i class="fas fa-book-open"></i> ABSTRACT</h2>
<p style="margin-bottom: 20px;">
        このセクションでは、大規模言語モデル（LLM）が会話型インターフェースとして持つ潜在能力と、特に複数ターンにわたる会話での課題について論じます。ユーザーがタスクを完全に明確化できない場合でも、LLMは会話を通じて要求の定義、探求、洗練を手助けできる可能性があります。しかし、現状のLLM評価は、情報が一度に全て提供される<span class="keyword">シングルターン</span>で、かつ<span class="keyword">完全に指定された指示</span>の状況に偏っているという問題意識から本研究は出発しています。
    </p>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-info-circle"></i> 初めて登場する用語解説</p>
<ul>
<li><span class="keyword">大規模言語モデル (Large Language Models, LLMs)</span>: ChatGPTやGeminiのように、大量のテキストデータで学習し、人間と自然な会話をしたり、文章を生成したりできるAIのことです。まるで博識なアシスタントのような存在です。✏️</li>
<li><span class="keyword">会話型インターフェース (Conversational Interfaces)</span>: 人間とAIがチャットのように対話形式で情報をやり取りする仕組みのことです。</li>
<li><span class="keyword">複数ターンの会話的やり取り (Multi-turn conversational exchange)</span>: ユーザーとLLMが一往復だけでなく、複数回にわたって対話を重ねることです。ラリーが続くテニスのようなイメージです。🗣️</li>
<li><span class="keyword">不完全指定 (Underspecification)</span>: ユーザーの指示や質問が曖昧だったり、必要な情報が不足していたりする状態のことです。「美味しいものが食べたい」だけでは、和食か洋食か、予算はいくらかなどが不明瞭な状態を指します。❓</li>
<li><span class="keyword">シングルターン、完全指定の指示設定 (Single-turn, fully-specified instruction setting)</span>: ユーザーが1回の発話で、必要な情報を全て明確にLLMに伝える状況です。「東京駅周辺で、予算5000円以内の美味しいイタリアンレストランを教えて」のように具体的です。✔️</li>
</ul>
</div>
<h3 class="subsection-title"><i class="fas fa-cogs"></i> 本研究の核心：マルチターンの謎に迫る</h3>
<div class="glass-card" style="margin-bottom: 20px;">
<p>ユーザーの指示における<span class="highlight">不完全指定</span>は実際の利用シーンでは頻繁に発生していることがLLMの会話ログ分析から確認されています。それにもかかわらず、LLMの評価の多くは、この現実を反映していません。</p>
<p>そこで本研究では、<i class="fas fa-flask"></i> 大規模なシミュレーション実験を通じて、LLMが<span class="keyword">シングルターン</span>の状況と、より現実に近い<span class="keyword">複数ターン</span>の会話状況で、どのようにパフォーマンスが異なるのかを比較・分析しました。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-chart-line"></i> 衝撃的な実験結果：LLMは会話が長引くと迷子になる？</h3>
<div class="challenge-box" style="margin-bottom: 20px;">
<p class="challenge-title"><i class="fas fa-exclamation-triangle"></i> マルチターンでの大幅な性能低下</p>
<p>実験の結果、驚くべきことに、テストした主要な<span class="keyword">オープンウェイトLLM</span>（モデル構造や重みが公開されているもの）および<span class="keyword">クローズドウェイトLLM</span>（非公開のもの）の全てが、複数ターンにわたる会話では、シングルターンと比較して性能が著しく低下することが明らかになりました。</p>
<p>具体的には、6つの異なる<span class="keyword">生成タスク</span>（例：文章作成、プログラミングなど）において、平均して<span class="highlight keyword" style="font-size: 1.5em; font-family: 'Yomogi', cursive; color: var(--color-secondary);">39%</span>もの性能低下が見られました。</p>
<div class="definition-box" style="margin-top:10px;">
<p class="definition-title"><i class="fas fa-tags"></i> 関連用語</p>
<ul>
<li><span class="keyword">オープンウェイトLLM (Open-weight LLMs)</span> / <span class="keyword">クローズドウェイトLLM (Closed-weight LLMs)</span>: モデルの内部情報（重みパラメータ）が公開されているか否かによる分類です。</li>
<li><span class="keyword">生成タスク (Generation tasks)</span>: LLMが新しいテキスト、コード、アイデアなどを自ら作り出す種類のタスクです。</li>
</ul>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-search-plus"></i> なぜ性能が下がるのか？要因を徹底分析</h3>
<p>この性能低下の原因を探るため、<span class="highlight keyword" style="font-family: 'Yomogi', cursive;">20万回以上</span>のシミュレーション会話を分析しました。その結果、性能低下は主に2つの要素に分解できることがわかりました。</p>
<div class="info-grid">
<div class="info-card">
<h4 class="subsection-title" style="font-size: 16px; color: var(--color-accent1); border-color: var(--color-accent1);"><i class="fas fa-brain"></i> 適性 (Aptitude) のわずかな低下</h4>
<p>LLMがタスクをこなす基本的な能力自体は、マルチターンになってもそれほど大きくは損なわれませんでした。これは、モデルがタスクの本質を理解する力は比較的保たれていることを示唆します。</p>
<div style="text-align: center; margin-top: 10px;">
<i class="fas fa-arrow-down" style="font-size: 20px; color: var(--color-accent1);"></i>
<span class="badge" style="background-color: var(--color-accent1); font-size: 14px;">微減</span>
</div>
</div>
<div class="info-card">
<h4 class="subsection-title" style="font-size: 16px; color: var(--color-secondary); border-color: var(--color-secondary);"><i class="fas fa-unlink"></i> 信頼性 (Unreliability) の著しい増加</h4>
<p>一方で、<span class="keyword">信頼性</span>（一貫して正しい答えを出す能力）は劇的に悪化しました。つまり、マルチターンになると、LLMは時々正しい答えを出せても、安定して良い結果を出すことが非常に難しくなるのです。</p>
<div style="text-align: center; margin-top: 10px;">
<i class="fas fa-arrow-up" style="font-size: 20px; color: var(--color-secondary);"></i>
<span class="badge" style="background-color: var(--color-secondary); font-size: 14px;">激増</span>
</div>
</div>
</div>
<img alt="論文中の図" class="section-image" src="Microsoft/lost_in_conversation datasets/Microsoft/lost_in_conversation FuSlilny-gSlep-eTcuirfined LLMs get Lost in Conversation UnMdeurltsi-pTeucrifined 100 Single-turn 0 I'm trying to implement X. High Aptitude 尚 Low Unreliability Clarification Do you mean X' ? 90 O   
    8 No I want [Requirement 1].   
    User nPleeads[eRgeeqnuierreatmeeXn.t  I1], [Requirement 23],. also 80 Gemini 2.5 Pro GPT-4.1 o3 😄• Claude 3.7 sonnet PreAmnastwurer Attempt dSeurf tfhuincg!tion(x): 尚 Deepseek-R1 Attnesmwpert dSeurf tshoilnug!tion(x, y): LLM A 70 8 [WRelql,uI raelsmoenete3d]. that Oh, in that case: 局 60 AssIuncmoprrtieocnt d[e.f. f]unction(x, y): 50 Lower Aptitude Multi-turn $( - 1 5 \% )$ 0 One more thing, can you include [Requirement 2]? Very High Unreliability $( + 7 7 2 \% )$ 10 20 30 40 50 Absolutely, here it is: Unreliability BAlnosatwedr d[e.f. f]unction(y, x): ×" style="width: 80%; margin: 20px auto; border: 1px solid var(--color-gray); border-radius: 8px;"/>
<div class="note-box" style="margin-top: 20px;">
<p class="note-title"><i class="fas fa-lightbulb"></i> 図の解説：LLMが会話で迷子になる様子</p>
<p>上の図は、本研究の核心的な発見を視覚的に表現したものです。縦軸はLLMの性能（Aptitude: 適性、Unreliability: 不信頼性）、横軸は様々なLLMモデルを示しています。</p>
<ul>
<li><span class="badge blue">Single-turn (青いバー)</span>: 情報が一度に全て与えられる場合。LLMは高い適性（グラフ上部）と低い不信頼性（バーの長さが短い）を示します。つまり、安定して良い性能を発揮します。
                <ul class="unstyled-list" style="margin-left: 20px;">
<li>例：ユーザー「Xを実装してください。[要件1],[要件2],[要件3]もお願いします。」→ LLM「はい、どうぞ！ `def thing(x,y): ...`」 (正解に近い)</li>
</ul>
</li>
<li><span class="badge orange">Multi-turn (オレンジのバー)</span>: 情報が少しずつ与えられる場合。適性はやや低下（-15%程度）しますが、不信頼性が著しく増加（+772%！）します（バーが非常に長い）。これは、良い時と悪い時の性能の差が非常に大きいことを意味します。
                <ul class="unstyled-list" style="margin-left: 20px;">
<li>ユーザー「Xを実装しようとしています。」</li>
<li>LLM「X'ということですか？」（明確化の試み）</li>
<li>ユーザー「いいえ、[要件1]が欲しいです。」</li>
<li>LLM「承知しました！ `def thing(x): ...`」（<span style="color:red; font-weight:bold;">時期尚早な試み、仮定に基づく</span>）</li>
<li>ユーザー「[要件3]も必要です。」</li>
<li>LLM「ああ、その場合はこうです: `def function(x,y): ...`」（<span style="color:red; font-weight:bold;">誤った仮定</span>）</li>
<li>ユーザー「もう一つ、[要件2]も入れてもらえますか？」</li>
<li>LLM「もちろんです、どうぞ: `def function(y,x): ...`」（<span style="color:red; font-weight:bold;">混乱し、回復できない</span>）</li>
</ul>
</li>
</ul>
<p>この図が示すのは、LLMが複数ターンの会話で<span class="keyword">間違った方向に進んでしまうと、道に迷ってしまい、そこから回復できない</span>という「会話で迷子になる (Lost in Conversation)」現象です。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-user-secret"></i> LLMの困った癖：早合点と固執</h3>
<p>さらに詳細な分析から、LLMがマルチターン会話で陥りやすい具体的な行動パターンが明らかになりました。</p>
<div class="feature-card-grid">
<div class="feature-item">
<div class="icon-item"><i class="fas fa-fast-forward fa-2x" style="color: var(--color-accent2);"></i></div>
<h4>早すぎる最終解答の提示</h4>
<p>LLMは、会話の初期段階で情報が不完全なうちから<span class="highlight">仮定</span>を立て、<span class="keyword">時期尚早に最終的な解決策を生成しようとする</span>傾向があります。</p>
<p style="font-family: 'Yomogi', cursive;">ユーザー「このデータでグラフを作りたいな…」<br/>LLM「はい、棒グラフです！📈 (まだ種類も指定されてないのに！)」</p>
</div>
<div class="feature-item">
<div class="icon-item"><i class="fas fa-hand-paper fa-2x" style="color: var(--color-accent3);"></i></div>
<h4>間違った解答への過度な依存</h4>
<p>一度間違った解答や仮定をしてしまうと、その後の会話で新しい情報が提示されても、<span class="highlight">初期の間違いに固執し、修正できない</span>ことが多いです。</p>
<p style="font-family: 'Yomogi', cursive;">ユーザー「やっぱり折れ線グラフがいいな」<br/>LLM「棒グラフに折れ線を追加しました！📊📉 (根本的な変更ができない…)」</p>
</div>
</div>
<div class="bubble-box" style="margin-top: 30px;">
<p style="font-family: 'Kaisei Decol', serif; font-size: 1.1em; text-align: center;">
<i class="fas fa-map-signs"></i> 要するに、<span class="keyword" style="font-size: 1.2em; background: linear-gradient(transparent 60%, var(--color-accent3) 60%);">LLMは会話の途中で一度間違った角を曲がってしまうと、迷子になり、元の正しい道に戻ってこられない</span>のです。
        </p>
</div>
<hr style="border: 1px dashed var(--color-primary); margin: 30px 0;"/>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-bullseye"></i> このアブストラクトの主要な目的と論旨</p>
<p><strong><i class="fas fa-question-circle"></i> 問題提起:</strong></p>
<ul>
<li>LLMは会話型AIとして大きな可能性を秘めているが、その評価は現実の使われ方（情報が不完全な状態からの複数ターン対話）と乖離している。</li>
<li>実際の利用ではユーザーの指示が不完全なことが多いにも関わらず、既存評価はシングルターン・完全指定指示に偏っている。</li>
</ul>
<p><strong><i class="fas fa-tools"></i> アプローチ:</strong></p>
<ul>
<li>大規模シミュレーション実験により、LLMのシングルターンとマルチターンでの性能を比較。</li>
</ul>
<p><strong><i class="fas fa-lightbulb"></i> 主要な発見:</strong></p>
<ul>
<li>全ての主要LLMは、マルチターン会話でシングルターン時より性能が著しく低下する（平均39%減）。</li>
<li>この性能低下は、「適性の微減」と「信頼性の大幅な増加」に起因する。</li>
<li>LLMは初期のターンで仮定を立てて早計な解を生成し、それに固執する傾向がある。</li>
<li>結論として、<span class="highlight">「LLMは会話で一度道に迷うと回復できない (Lost in Conversation)」</span>。</li>
</ul>
</div>
</div>
<div class="section-card" id="1_Introduction">
<h2 class="section-title"><i class="fas fa-lightbulb"></i>1 Introduction</h2>
<div class="content-box">
<p>このセクションでは、大規模言語モデル（LLM）が実世界の対話シナリオ、特にユーザーの指示が最初から完全には明確でない「未指定の指示」が複数ターンにわたって与えられる状況で、どのように振る舞うのかという問題に焦点を当てています。現在のLLM評価の主流である「シングルターンで完全に指定された指示」による評価と、実際の使われ方との間にあるギャップを指摘し、このギャップを埋めるための新しい評価アプローチと、それによって明らかになったLLMの課題について概説します。</p>
<p><span class="keyword">主な目的</span>は、LLMがマルチターンの未指定な会話で示す性能低下を定量的に評価し、その根本原因を分析することです。そして、<span class="keyword">主な論旨</span>として、現行の高性能LLMであっても、複数ターンにわたる未指定の指示の下では著しく性能が低下し、いわば「会話の途中で迷子になってしまう」現象が発生することを明らかにします。</p>
</div>
<div class="info-grid">
<div class="info-card">
<h3 class="subsection-title"><i class="fas fa-comments"></i>LLMの現状と対話インターフェースとしての可能性</h3>
<p>現代の<span class="keyword">大規模言語モデル (LLMs)</span><i class="fas fa-brain" style="color:var(--color-accent1); margin-left:5px;"></i> は、ChatGPT、Gemini、Claudeに代表されるように、強力な<span class="keyword">対話型インターフェース</span><i class="fas fa-comments" style="color:var(--color-accent1); margin-left:5px;"></i>として機能します。これにより、ユーザーはLLMと複数回のやり取り（<span class="keyword">マルチターン会話</span>）を通じて対話できます。</p>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-book-open"></i>用語解説</p>
<p><strong class="keyword">大規模言語モデル (LLM: Large Language Models)</strong>: 大量のテキストデータで訓練され、人間が生成するような自然なテキストを理解したり生成したりする能力を持つAIモデル。例: ChatGPT、Gemini、Claude。</p>
<p><strong class="keyword">対話型インターフェース (Conversational Interfaces)</strong>: ユーザーと自然言語（話し言葉や書き言葉）で対話できるシステムやソフトウェアの総称。</p>
<p><strong class="keyword">マルチターン会話 (Multiple conversation turns)</strong>: ユーザーとシステム（LLMなど）が、複数回にわたって発言を交わしながら進行する会話。</p>
</div>
<p>このような対話形式は、ユーザーが何を必要としているかを明確に知っている場合（つまり、指示で要求を完全に指定できる場合）だけでなく、そうでない場合にも役立つと期待されています。</p>
<div class="two-column">
<div class="column">
<div class="feature-item" style="background-color: #e6f7ff; border: 1px dashed var(--color-primary);">
<i class="fas fa-check-circle fa-2x" style="color: var(--color-accent1);"></i>
<h4>明確な要求</h4>
<p>ユーザーが要求を完全に指定できるケース。</p>
</div>
</div>
<div class="column">
<div class="feature-item" style="background-color: #fff0e6; border: 1px dashed var(--color-secondary);">
<i class="fas fa-question-circle fa-2x" style="color: var(--color-secondary);"></i>
<h4>不明確な要求</h4>
<p>ユーザーが要求を明確に指定できないケース。対話を通じて要求を明確化する。</p>
</div>
</div>
</div>
<p>後者のケースでは、ユーザーは<span class="keyword">未指定の指示 (underspecified instruction)</span><i class="fas fa-map-signs" style="color:var(--color-accent2); margin-left:5px;"></i>から始め、対話を通じて徐々にニーズを明確化していくことができます。実際に、LLMの会話ログを分析した研究[27]では、ユーザーの指示における<span class="keyword">未指定性 (underspecification)</span>は頻繁に見られることが確認されています。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-exclamation-triangle"></i>現状の評価の課題</p>
<p>しかし、LLMシステムの評価は、主に<span class="keyword">シングルターン (single-turn)</span><i class="fas fa-arrow-right" style="color:var(--color-gray); margin-left:5px;"></i>で、かつ<span class="keyword">完全に指定された (fully-specified)</span><i class="fas fa-file-alt" style="color:var(--color-gray); margin-left:5px;"></i>設定で行われています。これは実際の使われ方と乖離がある可能性があります。</p>
</div>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-book-open"></i>用語解説</p>
<p><strong class="keyword">未指定の指示 (Underspecified instruction)</strong>: ユーザーの要求が曖昧だったり、情報が不足していたりして、完全には明確でない指示のこと。</p>
<p><strong class="keyword">未指定性 (Underspecification)</strong>: 指示や情報が完全には特定されておらず、曖昧さや不足がある状態。</p>
<p><strong class="keyword">シングルターン (Single-turn)</strong>: ユーザーからの1回の指示（発話）と、それに対するシステムからの1回の応答で完結するやり取り。</p>
<p><strong class="keyword">完全に指定された (Fully-specified)</strong>: 指示に必要な情報が全て明確かつ具体的に含まれている状態。</p>
</div>
</div>
<div class="info-card">
<h3 class="subsection-title"><i class="fas fa-sitemap"></i>既存研究の問題点：エピソード的タスク</h3>
<p>LLMをマルチターンで評価しようとする研究は増えつつありますが（詳細はセクション2で後述）、多くの先行研究では会話を<span class="keyword">エピソード的 (episodic)</span><i class="fas fa-puzzle-piece" style="color:var(--color-accent1); margin-left:5px;"></i>に扱っていると、本論文では指摘しています。</p>
<div class="bubble-box" style="border-color: var(--color-secondary);">
<p><strong>エピソード的タスクとは？</strong> <i class="fas fa-layer-group" style="color:var(--color-secondary);"></i></p>
<p>会話の各ターンは互いに関連しているかもしれませんが、会話全体としては、それぞれ独立して評価可能な<span class="highlight">サブタスクの連続</span>として分解できてしまうようなタスクを指します。個々のサブタスクは前のターンの情報を参照するかもしれませんが、タスクの本質はターンごとに区切られています。</p>
</div>
<div class="challenge-box">
<p class="challenge-title"><i class="fas fa-bullseye"></i>本論文の主張</p>
<p>このようなエピソード的なタスクは、人間同士の自然な会話で頻繁に見られる<span class="keyword">未指定性</span> [91, 27]という重要な側面から離れてしまっている、と論じています。現実の会話では、情報は徐々に明らかになり、全体として1つの目標に向かうことが多いのです。</p>
</div>
</div>
</div>
<div class="arrow-connector"></div>
<div class="info-grid">
<div class="info-card">
<h3 class="subsection-title"><i class="fas fa-tools"></i>本研究の貢献：シャーデッド・シミュレーション</h3>
<p>このギャップを埋めるため、本研究ではマルチターンの未指定な会話をシミュレートするための新しい環境、<span class="keyword">シャーデッド・シミュレーション (sharded simulation)</span><i class="fas fa-flask" style="color:var(--color-primary); margin-left:5px;"></i>を開発しました。この環境は、既存の高品質なシングルターンベンチマークの指示を利用します。</p>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-project-diagram"></i>シャーデッド・シミュレーションの仕組み</p>
<div class="process-step">
<div class="step-number">1</div>
<div class="step-content">
<strong>シャーディングプロセス (Sharding Process)</strong> <i class="fas fa-cut" style="color:var(--color-secondary);"></i>:
                        <p>既存のシングルターンの完全な指示を、<span class="keyword">シャーデッド指示 (sharded instructions)</span>に変換します。</p>
</div>
</div>
<div class="process-step">
<div class="step-number">2</div>
<div class="step-content">
<strong>シャーデッド指示 (Sharded Instructions)</strong> <i class="fas fa-th-list" style="color:var(--color-accent2);"></i>:
                        <p>これは、元の指示と同じ情報を共同で提供する、より小さな指示（<span class="highlight">情報のかけら＝シャード</span>）のセットです。元の長い指示を、いくつかの短い部品に分割するイメージです。</p>
</div>
</div>
<div class="process-step">
<div class="step-number">3</div>
<div class="step-content">
<strong>シャーデッド・シミュレーションの実行</strong> <i class="fas fa-tasks" style="color:var(--color-accent1);"></i>:
                        <p>会話の各ターンで、最大でも<span class="highlight">1つのシャード（情報のかけら）だけ</span>をLLMに明らかにします。これにより、指示全体が会話を通じて徐々に提示される状況を強制的に作り出します。</p>
<p style="text-align: center; margin-top:10px;">
<span class="badge blue">指示1</span> <i class="fas fa-arrow-right"></i> <span class="badge blue">指示2</span> <i class="fas fa-arrow-right"></i> <span class="badge blue">指示3</span> ... (徐々に情報開示)
                        </p>
</div>
</div>
</div>
</div>
<div class="info-card">
<h3 class="subsection-title"><i class="fas fa-chart-line"></i>実験結果の概要：性能低下の発見</h3>
<p>このシャーデッド・シミュレーションを用いて実験を行った結果、驚くべき事実が明らかになりました。</p>
<div class="glass-card">
<p style="text-align:center; font-size: 1.2em; font-weight: bold;">マルチターン未指定会話での性能</p>
<div style="display: flex; justify-content: space-around; align-items: center; margin-top: 15px;">
<div>
<p><i class="fas fa-tasks" style="color:var(--color-primary);"></i> シングルターン性能 (全情報初期提示):</p>
<p style="font-size: 2em; color: var(--color-accent1); text-align:center;"><strong>90%</strong></p>
</div>
<div>
<i class="fas fa-arrow-down fa-2x" style="color:var(--color-secondary);"></i>
<p style="text-align:center; color:var(--color-secondary);">-25 ポイント</p>
</div>
<div>
<p><i class="fas fa-comments" style="color:var(--color-primary);"></i> マルチターン性能 (情報逐次提示):</p>
<p style="font-size: 2em; color: var(--color-secondary); text-align:center;"><strong>65%</strong></p>
</div>
</div>
<p style="font-size: 0.9em; color: var(--color-gray); margin-top:15px; text-align:center;">(平均値)</p>
</div>
<p>この性能低下は、会話がわずか<span class="highlight">2ターン</span>の場合でも確認され、テストした全てのLLM（小規模なオープンウェイトモデルである<span class="keyword">Llama3.1-8B-Instruct</span>から、最先端モデルの<span class="keyword">Gemini 2.5 Pro</span>まで）で共通して見られました。</p>
</div>
</div>
<div class="arrow-connector"></div>
<div class="info-grid">
<div class="info-card">
<h3 class="subsection-title"><i class="fas fa-search-minus"></i>性能低下の要因分析</h3>
<p>さらに、この性能低下を2つの主要な構成要素に分解して分析しました。</p>
<div class="two-column" style="margin-top: 15px; margin-bottom:15px;">
<div class="column" style="text-align:center; padding: 10px; background-color: #f0f8ff; border-radius: 8px;">
<i class="fas fa-brain fa-2x" style="color: var(--color-primary); margin-bottom: 5px;"></i>
<h4>(1) 適性 (Aptitude) の低下 <i class="fas fa-arrow-down" style="color: var(--color-secondary);"></i></h4>
<p>タスクを解くための基本的な能力そのものの低下。</p>
</div>
<div class="column" style="text-align:center; padding: 10px; background-color: #fff5e6; border-radius: 8px;">
<i class="fas fa-unlink fa-2x" style="color: var(--color-secondary); margin-bottom: 5px;"></i>
<h4>(2) 信頼性の欠如 (Unreliability) の増加 <i class="fas fa-arrow-up" style="color: var(--color-secondary);"></i></h4>
<p>同じ指示でも結果が安定せず、悪い結果が出やすくなること。</p>
</div>
</div>
<p>分析の結果、興味深い傾向が明らかになりました：</p>
<ul>
<li><span class="badge green">シングルターン設定</span>: <span class="keyword">適性 (Aptitude)</span> が高いモデル（例: GPT-4.1, Gemini 2.5 Pro）は、<span class="keyword">信頼性 (Reliability)</span> も高い傾向にあります。つまり、元々賢いモデルは安定もしているということです。</li>
<li><span class="badge orange">マルチターン設定</span>: <span class="keyword">適性 (Aptitude)</span> に関係なく、全てのLLMが非常に高い<span class="keyword">信頼性の欠如 (Unreliability)</span> を示しました。賢いモデルでも、マルチターンの未指定会話では不安定になるのです。</li>
</ul>
<div class="definition-box" style="margin-top:20px;">
<p class="definition-title"><i class="fas fa-map-signs"></i> Lost in Conversation Phenomenon (会話での迷子現象)</p>
<p>この現象を、本論文では「<span class="keyword">会話での迷子現象 (lost in conversation phenomenon)</span>」と名付けています。これは、LLMがマルチターンの会話で一度間違った解釈や方向に進んでしまうと、そこから<span class="highlight">抜け出せずに迷子になり、回復できない</span>状況を指します。</p>
</div>
</div>
<div class="info-card">
<h3 class="subsection-title"><i class="fas fa-microscope"></i>迷子現象の原因調査</h3>
<p>なぜLLMは「会話で迷子」になってしまうのでしょうか？本研究では、いくつかの原因を調査し、以下の傾向があることを突き止めました。</p>
<div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));">
<div class="feature-item" style="border: 1px solid var(--color-accent1);">
<i class="fas fa-comment-dots fa-2x" style="color: var(--color-accent1); margin-bottom: 8px;"></i>
<p><strong>冗長な応答</strong><br/>LLMは過度に長い応答を生成しがちです。</p>
</div>
<div class="feature-item" style="border: 1px solid var(--color-accent2);">
<i class="fas fa-rocket fa-2x" style="color: var(--color-accent2); margin-bottom: 8px;"></i>
<p><strong>早すぎる最終解答</strong><br/>その結果、会話の早い段階で最終的な解決策を提案してしまう傾向があります。</p>
</div>
<div class="feature-item" style="border: 1px solid var(--color-secondary);">
<i class="fas fa-random fa-2x" style="color: var(--color-secondary); margin-bottom: 8px;"></i>
<p><strong>誤った仮定</strong><br/>未指定の詳細について誤った仮定を立ててしまいます。</p>
</div>
<div class="feature-item" style="border: 1px solid var(--color-accent3);">
<i class="fas fa-history fa-2x" style="color: var(--color-accent3); margin-bottom: 8px;"></i>
<p><strong>過去の誤りに固執</strong><br/>以前の（誤った）解答の試みに過度に依存してしまいます。</p>
</div>
</div>
</div>
</div>
<div class="arrow-connector"></div>
<div class="info-grid">
<div class="info-card">
<h3 class="subsection-title"><i class="fas fa-balance-scale"></i>実用と評価のギャップ</h3>
<p>本研究の発見は、LLMが<span class="keyword">実際にどのように使われているか</span>（マルチターン、未指定の指示が多い）と、<span class="keyword">どのように評価されているか</span>（シングルターン、完全に指定された指示が主流）の間に大きなギャップがあることを強調しています。</p>
<div class="challenge-box" style="background-color: rgba(255, 160, 122, 0.1); border-left-color: #ff7e5f;">
<p class="challenge-title" style="color: #ff7e5f;"><i class="fas fa-users-cog"></i> AIシステム導入の障壁？</p>
<p>マルチターンの対話における広範な性能低下は、AIシステムの導入が進まない一因である可能性があります [73, 4, 28]。特に、会話の最初から完全で詳細な指示を与えることに慣れていない<span class="keyword">初心者ユーザー (novice users)</span> [87, 35]にとっては、この問題はより深刻かもしれません。</p>
</div>
</div>
<div class="info-card">
<h3 class="subsection-title"><i class="fas fa-stream"></i>論文の構成</h3>
<p>本論文の残りの部分は以下のように構成されています。</p>
<ul class="unstyled-list">
<li><i class="fas fa-book" style="color:var(--color-primary); margin-right:5px;"></i><strong>セクション2:</strong> マルチターン評価に関する先行研究との関連で本研究を位置づけます。</li>
<li><i class="fas fa-cogs" style="color:var(--color-primary); margin-right:5px;"></i><strong>セクション3:</strong> 多様な生成タスクにおけるシングルターンおよびマルチターン会話のために構築したシミュレーション環境について説明します。</li>
<li><i class="fas fa-tasks" style="color:var(--color-primary); margin-right:5px;"></i><strong>セクション4.1:</strong> モデルの適性と信頼性を評価するために使用する6つのタスクと指標を紹介します。</li>
<li><i class="fas fa-vials" style="color:var(--color-primary); margin-right:5px;"></i><strong>セクション5-6:</strong> 15のLLMを用いた主要な実験を定義し、主な結果を分析します。</li>
<li><i class="fas fa-bullhorn" style="color:var(--color-primary); margin-right:5px;"></i><strong>セクション7 (Implications):</strong> LLMベースの対話製品を開発する組織から、LLMベースシステムのエンドユーザーまで、本研究の意義について議論します。小規模な実験に基づいた実用的な推奨事項を提供し、LLM開発者に対して、将来のモデル改良において適性と共にマルチターンの信頼性を優先するよう具体的な行動を促します。</li>
</ul>
</div>
</div>
</div>
<div class="section-card" id="2_Background_and_Related_Work">
<h2 class="section-title"><i class="fas fa-book-open"></i>2 Background and Related Work</h2>
<!-- イントロダクション：このセクションの目的と概要 -->
<div class="content-box">
<p>このセクションでは、大規模言語モデル（LLM）の評価がこれまでどのように行われてきたか、特にマルチターン会話の評価における課題と既存研究の位置づけを概観します。そして、本研究がどのような問題意識を持ち、従来の研究とどう異なるのかを明確にしていきます。特に<span class="keyword">「情報不足の指示 (underspecified user instructions)」</span>と<span class="keyword">「エピソード的会話 (episodic conversations)」</span>というキーワードが、このセクションを理解する上で非常に重要になります。</p>
<div style="text-align: center; margin: 15px 0;">
<span class="badge yellow">主要テーマ</span> <i class="fas fa-arrow-right" style="color: var(--color-primary); margin: 0 5px;"></i> LLM評価の歴史 <i class="fas fa-arrow-right" style="color: var(--color-primary); margin: 0 5px;"></i> マルチターン会話の課題 <i class="fas fa-arrow-right" style="color: var(--color-primary); margin: 0 5px;"></i> 本研究の位置づけ
        </div>
</div>
<!-- 従来モデルの限界と会話AIの評価 -->
<div class="content-box glass-card">
<h3 class="subsection-title"><i class="fas fa-history"></i>従来モデルと会話AI評価の変遷</h3>
<p>まず、ChatGPTのような現代的なLLMが登場する以前の言語モデルについて見ていきましょう。</p>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));">
<div class="info-card">
<div class="icon-item" style="text-align: center;">
<i class="fas fa-cogs fa-2x" style="color: var(--color-accent2);"></i>
<p style="font-family: 'Yomogi', cursive; font-size: 16px; color: var(--color-accent2);">旧世代言語モデルの特徴</p>
</div>
<p>例えば、<span class="highlight">BART</span> [45]、<span class="highlight">GPT-2</span> [65]、<span class="highlight">T5</span> [66] といったモデルは、現代のLLMほど高度な<span class="keyword">マルチターン会話能力</span>（複数回のやり取りを続ける能力）を備えていませんでした。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-lightbulb"></i>補足：マルチターン会話とは？</p>
<p>ユーザーとAIが複数回にわたって対話し、文脈を維持しながら情報をやり取りすることです。例えば、「今日の天気は？」「東京の天気は晴れだよ。」「ありがとう。じゃあ明日は？」といった一連の会話がマルチターン会話にあたります。</p>
</div>
<p>そのため、これらのモデルの評価は、主に<span class="keyword">シングルターンタスク</span>（一問一答形式のタスク）に焦点が当てられていました [79]。</p>
</div>
<div class="info-card">
<div class="icon-item" style="text-align: center;">
<i class="fas fa-robot fa-2x" style="color: var(--color-accent1);"></i>
<p style="font-family: 'Yomogi', cursive; font-size: 16px; color: var(--color-accent1);">当時の会話AIシステム</p>
</div>
<p>当時の会話AIは、これらの言語モデルを部品として活用する<span class="keyword">特化型システム</span>として実装されるのが一般的でした [36]。</p>
<p>これらのシステムの評価は、</p>
<ul class="unstyled-list">
<li>🧑‍🔬 <span class="highlight">人手による評価プロトコル</span> [17, 42, 21, 54]</li>
<li>🏆 <span class="highlight">AmazonのAlexa Prizeのようなコンペティション</span> [67]</li>
</ul>
<p>を通じて行われていました。</p>
<div style="text-align: center; margin-top: 15px;">
<i class="fas fa-comments fa-3x" style="color: var(--color-primary);"></i>
<p style="font-size: 12px; color: var(--color-gray);">旧世代の会話AI評価方法</p>
</div>
</div>
</div>
</div>
<div class="arrow-connector"></div>
<!-- ChatGPT登場後のマルチターン評価 -->
<div class="content-box glass-card">
<h3 class="subsection-title"><i class="fas fa-rocket"></i>ChatGPT登場とマルチターン評価への関心の高まり</h3>
<p>ChatGPTの急速な普及により、<span class="keyword">マルチターン評価</span>への関心が一気に高まりました。初期の代表的な取り組みとして、<span class="highlight">MT-bench</span> [89] があります。</p>
<div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));">
<div class="feature-item">
<div class="icon-item"><i class="fas fa-users" style="color: var(--color-secondary);"></i></div>
<p><span class="keyword">MT-bench [89]</span></p>
<p style="font-size: 12px;">クラウドソーシングによるアノテーションを活用し、<span class="keyword">LLM-as-a-judge</span>（LLMを評価者として使う）能力を評価しました。</p>
</div>
</div>
<p>MT-benchに続く研究では、さらに評価の側面が拡張されました。</p>
<div class="info-grid">
<div class="info-card">
<p class="badge orange">MT-benchの拡張</p>
<ul class="unstyled-list">
<li>📏 <span class="highlight">より長い会話</span>の評価 [37, 18]</li>
<li>🔬 <span class="highlight">評価粒度の細分化</span> [2]</li>
<li>💬 <span class="highlight">自然さ</span> [72] や <span class="highlight">ツール使用</span> [85, 80] といった異なる側面の評価</li>
</ul>
</div>
</div>
</div>
<div class="arrow-connector"></div>
<!-- エピソード的会話の問題点 -->
<div class="content-box glass-card">
<h3 class="subsection-title"><i class="fas fa-puzzle-piece"></i>エピソード的会話と本研究の問題意識</h3>
<p>ここが本論文の核心的な主張につながる重要なポイントです。これらの既存研究は、多くの場合<span class="keyword">「エピソード的会話 (episodic conversations)」</span>をシミュレートしています。</p>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-book-reader"></i>用語解説：エピソード的会話</p>
<p>会話の各ターンが前のターンと関連しつつも、<span class="highlight">個別のサブタスクとして独立して評価できる</span>ような会話形式を指します。つまり、会話全体が一つの大きな流れというよりは、関連する小さなタスクの連続として扱われるイメージです。</p>
<div style="display: flex; align-items: center; justify-content: space-around; margin-top: 10px; flex-wrap: wrap;">
<div style="text-align: center; margin: 5px;">
<i class="fas fa-list-ol fa-2x" style="color: var(--color-primary);"></i>
<p style="font-size: 12px;">ターン1: タスクA</p>
</div>
<i class="fas fa-arrow-right" style="color: var(--color-gray); font-size: 1.5em; margin: 5px;"></i>
<div style="text-align: center; margin: 5px;">
<i class="fas fa-list-ol fa-2x" style="color: var(--color-primary);"></i>
<p style="font-size: 12px;">ターン2: タスクB<br/>(タスクAに関連)</p>
</div>
<i class="fas fa-arrow-right" style="color: var(--color-gray); font-size: 1.5em; margin: 5px;"></i>
<div style="text-align: center; margin: 5px;">
<i class="fas fa-list-ol fa-2x" style="color: var(--color-primary);"></i>
<p style="font-size: 12px;">ターン3: タスクC<br/>(タスクBに関連)</p>
</div>
</div>
<p style="text-align: center; font-style: italic; color: var(--color-gray); font-size: 12px; margin-top: 5px;">各タスクは独立して評価可能</p>
</div>
<p>本研究では、この<span class="highlight">エピソード的タスク</span>は、マルチターン会話におけるLLMの性能を<span class="keyword">過大評価</span>してしまう可能性があると指摘しています（詳細はセクション7.3で後述）。</p>
<p>なぜなら、エピソード的タスクは、ある程度のマルチターン文脈理解を必要とするものの、<span class="keyword">情報不足のユーザー指示 (underspecified user instructions)</span> に応答するために情報を積極的に統合する必要がないからです。</p>
<div class="challenge-box">
<p class="challenge-title"><i class="fas fa-exclamation-triangle"></i>課題：情報不足の指示への対応</p>
<p>現実世界の人間とAIのコミュニケーションでは、ユーザーの指示が最初から完全に明確であるとは限りません [27]。むしろ、会話の中で徐々に要求が明確になっていく「情報不足の指示」が一般的です。これは、会話における<span class="keyword">「最小努力の原理 (the principle of least effort)」</span>[91] としても知られる自然な傾向です。</p>
</div>
<p>本研究は、この<span class="highlight">「情報不足」</span>がマルチターン会話におけるLLMの性能に大きな影響を与えることを示します。</p>
<div class="bubble-box">
<p style="font-family: 'Yomogi', cursive; font-size: 16px; color: var(--color-primary); text-align:center;">🔍 本研究が示すLLMの課題 (情報不足の状況下で)</p>
<ul class="unstyled-list" style="margin-top: 10px; padding-left: 20px;">
<li><i class="fas fa-早送り" style="color: var(--color-secondary);"></i> 不足情報を補うために<span class="highlight">早期に仮定</span>を立てる</li>
<li><i class="fas fa-check-double" style="color: var(--color-secondary);"></i> 時期尚早に<span class="highlight">最終的な解決策を提案</span>しようとする</li>
<li><i class="fas fa-sync-alt" style="color: var(--color-secondary);"></i> 新しい情報が提供された際に<span class="highlight">適応したり軌道修正したりするのが困難</span></li>
</ul>
</div>
<p>この論文では、<span class="keyword">「情報不足」を評価設定の中心要素</span>としています。これが既存研究との大きな違いです。</p>
</div>
<div class="arrow-connector"></div>
<!-- エピソード的評価の限界と本研究のアプローチ -->
<div class="content-box glass-card">
<h3 class="subsection-title"><i class="fas fa-microscope"></i>エピソード的評価の枠組みとその限界</h3>
<p>マルチターンのエピソード的評価は、モデルの能力をより詳細に評価する方法として位置づけられることがあります。例えば、<span class="keyword">洗練化 (refinement)</span>、<span class="keyword">フォローアップ (follow-up)</span>、<span class="keyword">拡張 (expansion)</span> といったサブタスクのカテゴリを設定することで、より具体的なLLMの振る舞いを研究できます [2, 37, 74, 19, 16, 48, 25]。</p>
<p>このような枠組みでは、マルチターンタスクはシングルターンタスクとは異なり、同じタスクセットでは評価されません。</p>
<div class="note-box" style="border-left-color: var(--color-accent1);">
<p class="note-title" style="color: var(--color-accent1);"><i class="fas fa-balance-scale"></i>本研究の主張</p>
<p>この論文では、上記のような枠組みは<span class="highlight">人為的</span>であり、マルチターン評価の範囲を限定し、LLMのマルチターン能力とシングルターン能力の<span class="keyword">直接比較を妨げる</span>と主張しています。</p>
</div>
<p>そこで本研究では、<span class="keyword">共通のタスクセット</span>に対して、シングルターンとマルチターンの両方の会話シミュレーションを行います。これにより、シングルターン設定からマルチターン設定への性能低下を正確に特定できる<span class="highlight">制御された実験</span>が可能になります。</p>
<div style="text-align: center; margin: 20px 0;">
<div class="pipeline">
<div class="pipeline-step">共通タスクセット <i class="fas fa-tasks" style="margin-left: 5px; color: var(--color-primary);"></i></div>
<div class="pipeline-step">シングルターン評価 <i class="fas fa-comment-dots" style="margin-left: 5px; color: var(--color-secondary);"></i></div>
<div class="pipeline-step">マルチターン評価（情報不足あり） <i class="fas fa-comments" style="margin-left: 5px; color: var(--color-accent2);"></i></div>
<div class="pipeline-step" style="background-color: var(--color-accent3); border-color: var(--color-accent3); color: var(--color-dark);">性能比較・分析 <i class="fas fa-chart-line" style="margin-left: 5px; color: var(--color-dark);"></i></div>
</div>
<p style="font-size: 12px; color: var(--color-gray);">本研究のアプローチ：共通タスクによる直接比較</p>
</div>
</div>
<div class="arrow-connector"></div>
<!-- マルチターン評価の難しさと生成タスクの重要性 -->
<div class="content-box glass-card">
<h3 class="subsection-title"><i class="fas fa-project-diagram"></i>マルチターン評価の難しさと生成タスク</h3>
<p>LLMをマルチターン設定で評価することは困難です。なぜなら、会話の軌跡がシングルターンよりも<span class="keyword">はるかに分岐しやすい</span>からです。</p>
<p>そのため、これまでの研究の多くは、評価設定が比較的単純な<span class="highlight">分類タスク</span>や<span class="highlight">短文生成タスク</span>に焦点を当ててきました。</p>
<p>しかし、LLMの主なユースケースは<span class="keyword">生成的</span>なものです。</p>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));">
<div class="info-card">
<div class="icon-item" style="text-align: center;">
<i class="fas fa-code fa-2x" style="color: var(--color-primary);"></i>
<p style="font-family: 'Yomogi', cursive; font-size: 16px;">プログラミング</p>
</div>
<p>例：コーディングアシスタント</p>
</div>
<div class="info-card">
<div class="icon-item" style="text-align: center;">
<i class="fas fa-file-alt fa-2x" style="color: var(--color-secondary);"></i>
<p style="font-family: 'Yomogi', cursive; font-size: 16px;">自然言語</p>
</div>
<p>例：文章作成、要約 [88, 26]</p>
</div>
</div>
<p>したがって、マルチターン設定での<span class="keyword">長文生成タスクの評価</span>は不可欠です。これにより、ユーザーがより多くの情報を提供するにつれて、モデルが柔軟に応答を適応させ、洗練させる能力を評価できます。</p>
<div class="bubble-box">
<p style="font-family: 'Yomogi', cursive; font-size: 16px; color: var(--color-primary); text-align:center;">🎯 本研究の焦点</p>
<p>この研究では、プログラミングと自然言語ドメインの両方で広く使われるシナリオを捉えた<span class="highlight">生成タスクに限定</span>して焦点を当てています。</p>
</div>
</div>
<div class="arrow-connector"></div>
<!-- ユーザーシミュレーションの必要性と本研究の手法 -->
<div class="content-box glass-card">
<h3 class="subsection-title"><i class="fas fa-user-friends"></i>ユーザシミュレーションと本研究の立場</h3>
<p>マルチターンの実験を大規模に行うためには、<span class="keyword">ユーザーをシミュレートする</span>必要があります。既存の研究では、様々な方法でユーザーシミュレーションが実装されてきました。</p>
<div class="feature-card-grid">
<div class="feature-item">
<div class="icon-item"><i class="fas fa-file-code" style="color: var(--color-accent1);"></i></div>
<p>テンプレート依存 [12, 68, 39, 16]</p>
</div>
<div class="feature-item">
<div class="icon-item"><i class="fas fa-brain" style="color: var(--color-accent2);"></i></div>
<p>LLM使用 [63, 46, 7, 48]</p>
</div>
<div class="feature-item">
<div class="icon-item"><i class="fas fa-user-edit" style="color: var(--color-secondary);"></i></div>
<p>人間アノテーター [21, 7]</p>
</div>
<div class="feature-item">
<div class="icon-item"><i class="fas fa-users" style="color: var(--color-primary);"></i></div>
<p>実際のユーザー参加 [67, 38, 11]</p>
</div>
</div>
<p>実際のユーザーを参加させる方法は、最も自然で現実的な会話が得られますが、<span class="highlight">スケーラビリティ</span>（大規模実施の容易さ）と<span class="highlight">再現性</span>（同じ条件で結果を再現できるか）の点でコストがかかります。</p>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-cogs"></i>本研究でのアプローチ</p>
<p>この研究では、<span class="keyword">LLMベースのシミュレータ</span>を採用し、制御された柔軟性と分岐を可能にしています。</p>
<div class="note-box" style="border-left-color: var(--color-accent2);">
<p class="note-title" style="color: var(--color-accent2);"><i class="fas fa-exclamation-circle"></i>注意点：シミュレーションの限界</p>
<p>完全に自動化されたシミュレーションは、本研究の知見の範囲を限定します。シミュレートされた会話は、<span class="highlight">人間とAIの実際の会話を代表するものではありません</span>。</p>
</div>
<p>したがって、このシミュレーションは、ユーザーの振る舞いを研究するのではなく、マルチターン設定における<span class="keyword">LLMの振る舞いを研究するためのツール</span>として位置づけています。</p>
<p>さらに、セクション9（Limitations）で詳述するように、このシミュレーションフレームワークは<span class="highlight">単純化され、理想化されている</span>と論じられています。例えば、</p>
<ul class="unstyled-list">
<li>✅ 会話はタスクを解決するのに十分な情報で終わることが保証されている。</li>
<li>🛡️ シミュレータは、現実世界で起こりうる予期せぬ行動（例：脱線）を制限する。</li>
</ul>
<p>これらの選択は、本研究で観察された性能低下が、現実世界の<span class="keyword">情報不足のマルチターン人間AI会話</span>で起こるであろう低下よりも<span class="highlight">おそらく過小評価</span>であることを示唆しています。</p>
</div>
<p>補足Aでは、特に情報不足のコミュニケーションに焦点を当てた他の関連研究を紹介しています。</p>
</div>
<!-- まとめ -->
<div class="content-box" style="margin-top: 30px; padding-top: 20px; border-top: 2px dashed var(--color-primary);">
<p style="text-align: center; font-family: 'Yomogi', cursive; font-size: 18px; color: var(--color-primary);">
<i class="fas fa-thumbtack"></i>セクション2のまとめ
        </p>
<p>このセクションでは、LLM評価の歴史的背景、特にマルチターン会話評価の進化と課題を概観しました。従来の研究の多くが「エピソード的会話」に焦点を当てていたのに対し、本研究は現実のコミュニケーションで頻繁に見られる「情報不足の指示」下でのLLMの振る舞いに着目し、その評価を試みるという独自性を強調しました。LLMベースのユーザーシミュレータを用いることで、制御された環境下での大規模な実験を可能にしていますが、その限界も認識しつつ、LLMのマルチターン性能低下の要因を探るための基盤を提示しています。</p>
</div>
</div>
<div class="section-card" id="3_Simulating_Underspecified,_Multi-Turn_Conversation">
<h2 class="section-title"><i class="fas fa-comments"></i>3 Simulating Underspecified, Multi-Turn Conversation</h2>
<p>このセクションでは、大規模言語モデル（LLM）が、複数ターンにわたる、情報が小出しにされる曖昧な（underspecified）会話において、どのように振る舞うかを評価するためのシミュレーション環境を構築する方法について説明します。現実世界の対話では、ユーザーは最初から全ての情報を提示するとは限らず、対話を通じて徐々に要求を明確にしていくことがよくあります。このような状況を再現し、LLMの性能を精密に測定することが本セクションの主な目的です。</p>
<div class="glass-card">
<p>📌 <strong>このセクションのキーポイント</strong></p>
<ul class="fa-ul">
<li><span class="fa-li"><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i></span>既存のシングルターンのベンチマークタスクを再利用して、複数ターン会話の評価を行います。</li>
<li><span class="fa-li"><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i></span><span class="keyword">シャーディングプロセス (Sharding Process)</span>：元の完全に指定された指示（fully-specified instructions）を、より小さな情報の断片である<span class="keyword">シャード化された指示 (sharded instructions)</span>に変換します。</li>
<li><span class="fa-li"><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i></span><span class="keyword">シャーディングシミュレーション環境</span>：シャード化された指示に基づいて、複数ターンの会話をシミュレートし、LLMの応答を評価します。</li>
</ul>
</div>
<p>このシミュレーション環境を通じて、LLMが情報を段階的に受け取り、文脈を維持し、曖昧さに対処する能力を詳細に分析することを目指します。</p>
<h3 class="subsection-title"><i class="fas fa-cogs"></i>3.1 Sharding Process: From Fully-Specified to Sharded Instructions</h3>
<p>複数ターンの曖昧な会話をシミュレートするための第一歩は、既存の完全に指定された指示を、会話の各ターンで少しずつ情報を提示できる形式に変換することです。この変換プロセスを<span class="keyword">シャーディングプロセス</span>と呼びます。</p>
<div class="bubble-box">
<p><i class="fas fa-lightbulb" style="color: var(--color-accent3);"></i> <strong>シャーディングされた指示 (Sharded Instruction)とは？</strong></p>
<p>元の完全な指示を、複数の小さな情報の断片、すなわち<span class="keyword">シャード (shard)</span>に分割したものです。各シャードは、元の指示に含まれる情報を一つずつ提示するように設計されています。</p>
<ul class="fa-ul">
<li><span class="fa-li"><i class="fas fa-dice-one" style="color: var(--color-secondary);"></i></span><strong>最初のシャード (Shard 1)</strong>: 会話の口火を切り、指示全体の<span class="highlight">包括的な意図</span>（例：「〜する方法を教えて」）を伝えます。</li>
<li><span class="fa-li"><i class="fas fa-dice-two" style="color: var(--color-secondary);"></i></span><strong>後続のシャード</strong>: それぞれが元の指示に関する<span class="highlight">追加の明確化情報や条件</span>（例：「ただし、〜という制約がある」「〜も考慮してほしい」）を提供します。</li>
</ul>
<p>これらのシャードを全て合わせると、元の完全指定命令と同じ情報量になりますが、その情報が会話のターンごとに分割して提示される点が異なります。</p>
</div>
<p>例として、数学の問題解決タスクであるGSM8K [14] から取られた元の完全指定命令と、それに対応するシャード化された命令を以下に示します（図2参照）。</p>
<div class="content-box" style="border: 2px dashed var(--color-primary); padding: 15px; border-radius: 8px; margin-top:15px; margin-bottom:15px;">
<p style="text-align:center; font-family: 'Yomogi', cursive; font-size: 1.1em;">図2: ペアになった指示</p>
<div class="two-column">
<div class="column">
<h4 class="section-title" style="font-size:16px;"><i class="fas fa-file-alt"></i>Fully-Specified Instruction (original)</h4>
<div class="note-box" style="background-color: rgba(74, 111, 165, 0.05);">
<p>(a) 元のGSM8K命令 (Original GSM8K instruction)</p>
<p>Jay is making snowballs to prepare for a snowball fight with his sister. He can build 20 snowballs in an hour, but 2 melt every 15 minutes. How long will it take before he has 60 snowballs?</p>
<p class="reference">(日本語訳: ジェイは妹との雪合戦の準備のために雪玉を作っています。彼は1時間に20個の雪玉を作ることができますが、15分ごとに2個溶けてしまいます。彼が60個の雪玉を作るのにどれくらい時間がかかりますか？)</p>
</div>
<p>この元の指示は、<span class="highlight">単一の長い発話</span>で、課題の目的（「どれくらい時間がかかるか」）、文脈（雪玉作り、能力、溶ける条件）、そして最終目標（60個の雪玉）といった全ての情報を一度に提示しています。</p>
</div>
<div class="column">
<h4 class="section-title" style="font-size:16px;"><i class="fas fa-stream"></i>Equivalent Sharded Instruction</h4>
<div class="note-box" style="background-color: rgba(255, 213, 79, 0.15);">
<p>(b) 等価なシャード化された命令 (Equivalent Sharded Instruction)</p>
<p><em>(論文中では具体的なシャード化の例が図2の(b)として記載されていますが、ここでのテキストでは省略されています。代わりに、その構造について説明します。)</em></p>
<p>シャード化された命令は、以下のように複数のシャードから構成されます:</p>
<ul class="unstyled-list">
<li><span class="badge yellow">Shard 1</span> ジェイが雪玉を作るのにかかる時間を知りたい。</li>
<li><span class="badge yellow">Shard 2</span> 彼は妹と雪合戦の準備をしている。</li>
<li><span class="badge yellow">Shard 3</span> 1時間に20個の雪玉を作れる。</li>
<li><span class="badge yellow">Shard 4</span> ただし、15分ごとに2個溶けてしまう。</li>
<li><span class="badge yellow">Shard 5</span> 最終的に60個の雪玉が必要。</li>
</ul>
<p class="reference">(これは論文の趣旨に沿った架空のシャード化例です)</p>
</div>
<p>シャード化された命令では、各シャードが元の指示の要素を一つずつ段階的に導入します。例えば、最初のシャードで大まかな目的を伝え、続くシャードで詳細な条件や背景情報を加えていくイメージです。</p>
</div>
</div>
</div>
<div class="note-box">
<p class="note-title"><i class="fas fa-ruler-combined"></i>シャード化された命令の妥当性</p>
<p>シャード化された命令が元の指示と等価であり、実験に使える「妥当な」ものであるためには、いくつかの重要な特性を満たす必要があります。これらの特性に関するより正確で数学的な定義は、論文の<span class="keyword">付録B</span>で詳述されています。そこでは、シャード化された命令が満たすべき<span class="highlight">5つの主要な特性</span>が定義されています。</p>
</div>
<p>このようなシャード化された指示を大規模に作成するため、本研究では<span class="keyword">半自動のシャーディングプロセス</span>を開発しました。このプロセスは、LLMによる自動処理と人間によるレビューを組み合わせたもので、詳細は論文の<span class="keyword">付録C</span>に記載されています。このプロセスにより、実験で使用するシャード化された指示が、定義された特性を一貫して満たしていることを保証しています。</p>
<h3 class="subsection-title"><i class="fas fa-robot"></i>3.2 Simulating Sharded Conversations</h3>
<p>シャード化された指示を作成した後、次はその指示を使って、複数ターンにわたる曖昧な会話をシミュレートします。このシミュレーションプロセスを図3に示します。</p>
<img alt="Sharded Conversation Simulation Diagram" class="figure-image" src="sharded_conversation_simulation_diagram.jpg"/>
<p style="text-align:center; font-family: 'Yomogi', cursive; font-size: 1.1em;">図3: シャーディングされた会話のシミュレーション図</p>
<p>図3は、シャード化された指示に基づく複数ターンの曖昧な会話のシミュレーションプロセスを表しています。この会話シミュレーションには、主に3つの役割が登場します。</p>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));">
<div class="info-card glass-card">
<p class="feature-item"><i class="fas fa-user-astronaut fa-2x" style="color:var(--color-accent2);"></i><strong>アシスタント (Assistant)</strong></p>
<p>シミュレーションで評価される対象のLLMです。（図3では<span style="color:red; font-weight:bold;">赤色</span>で強調表示）</p>
</div>
<div class="info-card glass-card">
<p class="feature-item"><i class="fas fa-user-ninja fa-2x" style="color:var(--color-primary);"></i><strong>ユーザー (User Simulator)</strong></p>
<p>別のLLMによってシミュレートされます。シャード化された指示全体を把握しており、会話の各ターンでシャードをアシスタントに提示する役割を担います。</p>
</div>
<div class="info-card glass-card">
<p class="feature-item"><i class="fas fa-cogs fa-2x" style="color:var(--color-secondary);"></i><strong>システム (System)</strong></p>
<p>アシスタントの応答を分類し、評価します。</p>
</div>
</div>
<div class="framework-box" style="margin-top: 20px;">
<p class="framework-title"><i class="fas fa-shoe-prints"></i>会話シミュレーションの流れ</p>
<div class="pipeline">
<div class="pipeline-step">
<p><span class="badge blue">1. 最初のターン</span></p>
<ul class="fa-ul">
<li><span class="fa-li"><i class="fas fa-comment-dots"></i></span>ユーザーシミュレータが指示の最初のシャード (Shard 1) をアシスタントに提示します。</li>
<li><span class="fa-li"><i class="fas fa-magic"></i></span>アシスタントは自由形式のテキストで応答を生成します。</li>
<li><span class="fa-li"><i class="fas fa-tasks"></i></span>システムがアシスタントの応答を分析し、以下の7つの<span class="keyword">応答戦略</span>のいずれかに分類します（Herlihy et al. [27]の研究に基づく）。
                        <div class="tag-list" style="margin-top:5px; margin-bottom:5px;">
<span class="tag">明確化 (clarification)</span>
<span class="tag">拒否 (refusal)</span>
<span class="tag">保留 (hedging)</span>
<span class="tag">尋問 (interrogation)</span>
<span class="tag">議論 (discussion)</span>
<span class="tag">欠落 (missing)</span>
<span class="tag">解答試行 (answer attempt)</span>
</div>
</li>
<li><span class="fa-li"><i class="fas fa-search"></i></span>もしアシスタントが<span class="highlight">解答試行</span>（明示的で完全な形式の解決策を提案）を生成した場合：
                        <ul>
<li><span class="keyword">解答抽出コンポーネント (Answer Extractor)</span> が、アシスタントの自由形式の応答の中から解答に対応する部分（例: コード片、数値など）を特定します。このステップは、LLMが解答に余分な情報（説明文や追加の質問など）を付け加えることがあり、それが評価の妨げになるのを防ぐために必要です。</li>
<li><span class="fa-li"><i class="fas fa-medal"></i></span>抽出された解答は、タスク固有の<span class="keyword">評価関数 (evaluator function)</span>によって採点されます。</li>
</ul>
</li>
</ul>
</div>
<div class="pipeline-step">
<p><span class="badge blue">2. 後続のターン</span></p>
<p>同様のパターンが繰り返されます。</p>
<ul class="fa-ul">
<li><span class="fa-li"><i class="fas fa-comment-dots"></i></span>各ターンで、ユーザーシミュレータは<span class="highlight">最大1つの情報シャード</span>を提示します。</li>
<li><span class="fa-li"><i class="fas fa-magic"></i></span>アシスタントは自由に応答します。</li>
<li><span class="fa-li"><i class="fas fa-medal"></i></span>応答が解答試行として分類された場合、評価が行われます。</li>
</ul>
</div>
<div class="pipeline-step" style="margin-bottom:0;">
<p><span class="badge blue">3. 会話の終了</span></p>
<p>以下のいずれかの条件が満たされると会話は終了します。</p>
<ol>
<li>タスク評価者が、アシスタントの解答試行が<span class="highlight">正しい</span>と評価した場合。</li>
<li>新しいターンの開始時点で、ユーザーシミュレータが会話で提示できる<span class="highlight">シャードを全て使い果たした場合</span>。</li>
</ol>
</div>
</div>
</div>
<div class="note-box" style="margin-top:20px;">
<p class="note-title"><i class="fas fa-user-ninja"></i>ユーザーシミュレータの賢さ</p>
<p>予備実験を通じて、評価対象のアシスタントがしばしば指示の特定のシャードに関連する明確化の質問をすることが明らかになりました。このため、会話の次のターンで<span class="highlight">どのシャードを提示するか</span>というユーザーシミュレータの判断は非常に重要です。その判断は、それまでの会話の文脈を考慮に入れる必要があります。</p>
<p>そこで、本研究ではユーザーシミュレータを、低コストのLLM（具体的には <span class="keyword">GPT-4o-mini</span>）として実装しています。このシミュレータは以下の能力を持ちます：</p>
<ul class="fa-ul">
<li><span class="fa-li"><i class="fas fa-brain"></i></span>シャード化された指示全体と、それまでの会話の履歴にアクセスできます。</li>
<li><span class="fa-li"><i class="fas fa-lightbulb"></i></span>進行中のシミュレートされた会話に最も自然に適合する<span class="highlight">次のシャードを選択</span>します。</li>
<li><span class="fa-li"><i class="fas fa-pen-nib"></i></span>選択したシャードの情報を変えずに、会話の流れに<span class="highlight">自然に収まるように言い換え</span>ます。</li>
</ul>
<p class="reference">📝 シミュレートされたシャード化会話の具体例は、論文の<span class="keyword">付録J</span>で確認できます。</p>
</div>
<div class="challenge-box" style="margin-top:20px;">
<p class="challenge-title"><i class="fas fa-info-circle"></i>アシスタントへの情報提供の制約</p>
<p>評価対象のアシスタントは、ユーザーシミュレータからのメッセージ以外に、最初のターンの前にタスク遂行に必要な最小限の<span class="keyword">システム指示</span>（例：データベースのスキーマ情報、利用可能なAPIツールのリストなど）を受け取ります。</p>
<p><strong><i class="fas fa-exclamation-triangle"></i> 重要な点：</strong> アシスタントには、自分が複数ターンで曖昧な情報を提示される会話に参加していることは<span class="highlight">明示的に知らされません</span>。また、特定の会話戦略（例：積極的に質問する、情報を要約するなど）を追求するよう促されることもありません。</p>
<p>このような制約を設ける理由は、実世界の応用場面では、LLMがどのような状況で使われるか事前に詳細な情報が与えられることは稀だからです。したがって、本研究では評価対象のアシスタントモデルに<span class="highlight">設定に関する特別な情報を与えず</span>、その<span class="keyword">デフォルトの振る舞い</span>を評価することを目指しています。</p>
</div>
<p style="margin-top:20px;">ユーザーシミュレータだけでなく、<span class="keyword">戦略分類器 (Strategy Classifier)</span> や <span class="keyword">解答抽出コンポーネント (Answer Extractor)</span> も、プロンプトベースのGPT-4o-miniで実装されています。LLMベースのコンポーネントを使用することで、より現実に近い動的なシミュレーションが可能になりますが、同時に<span class="highlight">シミュレーションエラー</span>が発生する可能性も避けられません。これらのエラーは実験結果の妥当性に影響を与えうるため、その影響範囲を把握するために、数百件のシミュレートされた会話について詳細な手動アノテーション（southworth2023developingdを参照）を行いました。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-microscope"></i>シミュレーションエラーの分析結果</p>
<p>手動アノテーションの労力とその結果の詳細は、論文の<span class="keyword">付録D</span>に記載されています。要約すると以下の通りです：</p>
<ul class="fa-ul">
<li><span class="fa-li"><i class="fas fa-bug"></i></span>ユーザーシミュレータ、戦略分類器、または解答抽出に起因するエラーが発生したのは、検査した会話の<span class="highlight">5%未満</span>でした。</li>
<li><span class="fa-li"><i class="fas fa-balance-scale-left"></i></span>これらのエラーがアシスタントモデルにとって不利に働いたのは、会話の<span class="highlight">2%未満</span>でした。</li>
</ul>
<p>これらの結果から、ここで説明したプロセスは、シャード化された指示に基づいて複数ターンの曖昧な会話を<span class="keyword">正確にシミュレートできる</span>と結論付けています。本研究の実験における会話シミュレーションは、このプロセスに依拠しています。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-sitemap"></i>3.3 Simulation Types</h3>
<p>シャード化された指示を利用して、本研究では5つの異なるタイプのシングルターンまたは複数ターンの会話をシミュレートします。これらのシミュレーションタイプを図4に示します。それぞれのタイプとその実験における目的を説明します。</p>
<img alt="Conversation simulation types based on sharded instructions" class="figure-image" src="conversation_simulation_types.jpg"/>
<p style="text-align:center; font-family: 'Yomogi', cursive; font-size: 1.1em;">図4: シャード化された指示に基づく会話シミュレーションのタイプ</p>
<p>図4が示すように、元の完全に指定された指示（青いブロック）がシャード化されると（黄色いブロックのセット）、これらの「シャード」を使って、シングルターン（FULL, CONCAT）または複数ターン（SHARDED, RECAP, SNOWBALL）の会話をシミュレートできます。これにより、情報の開示のペースが変わります。</p>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));">
<div class="info-card glass-card">
<p class="feature-item"><span class="badge blue" style="font-size:1.1em; padding: 6px 10px;">📄 FULLY-SPECIFIED (FULL)</span></p>
<p><strong>タイプ:</strong> シングルターン、完全指定会話</p>
<p><strong>方法:</strong> 元の完全な指示が最初のターンでLLMに提供されます。</p>
<p><strong>目的:</strong> タスクにおけるモデルの<span class="keyword">ベースライン性能</span>を評価します。</p>
<div class="bubble-box" style="background-color: rgba(74, 111, 165, 0.08); border-color: var(--color-primary); margin-top:10px; padding:10px;">
<p style="font-size:0.9em;">例：ユーザー「AとBとCという条件でXをしてください。」→ LLM「はい、Yです。」</p>
</div>
</div>
<div class="info-card glass-card">
<p class="feature-item"><span class="badge" style="background-color: var(--color-accent1); font-size:1.1em; padding: 6px 10px;">🧩 SHARDED</span></p>
<p><strong>タイプ:</strong> 複数ターン、曖昧な会話</p>
<p><strong>方法:</strong> 上記（セクション3.2）で概説した方法でシミュレートされます。各ターンでシャードが1つずつ提示されます。</p>
<p><strong>目的:</strong> 曖昧な複数ターン会話におけるモデルの性能を評価するための<span class="keyword">主要なツール</span>です。</p>
<div class="bubble-box" style="background-color: rgba(92, 184, 92, 0.08); border-color: var(--color-accent1); margin-top:10px; padding:10px;">
<p style="font-size:0.9em;">例：ユーザー「Xをしたいです。」<br/>LLM「わかりました。何か条件はありますか？」<br/>ユーザー「Aという条件があります。」<br/>LLM「承知しました。他にBは？」<br/>ユーザー「はい、Bもです。あとCも。」<br/>LLM「では、Yです。」</p>
</div>
</div>
<div class="info-card glass-card">
<p class="feature-item"><span class="badge orange" style="font-size:1.1em; padding: 6px 10px;">🖇️ CONCAT</span></p>
<p><strong>タイプ:</strong> シングルターン、完全指定会話（シャード化指示ベース）</p>
<p><strong>方法:</strong> 全てのシャードを箇条書き形式（各行に1シャード）で連結し、単一の指示としてLLMに提供します。その際、「全ての箇条書きを考慮してタスクを完了してください」という指示が先行します。</p>
<p><strong>目的:</strong></p>
<ul class="fa-ul" style="font-size:0.95em;">
<li><span class="fa-li"><i class="fas fa-arrows-alt-h"></i></span>FULLとSHARDEDの<span class="keyword">論理的な中間点</span>です。曖昧さは除去されていますが（FULLと同様）、指示のシャード化中に行われた言い換えは保持されています（SHARDEDと同様）。</li>
<li><span class="fa-li"><i class="fas fa-search-plus"></i></span><span class="keyword">検証用のベースライン</span>として機能します。もしモデルがFULLとCONCATの両方で成功し、SHARDEDで失敗する場合、その原因はシャーディングプロセス中の言い換え（情報損失の可能性）ではなく、特に<span class="highlight">会話の曖昧さと複数ターン性</span>にあると推測できます。</li>
</ul>
<div class="bubble-box" style="background-color: rgba(255, 126, 95, 0.08); border-color: var(--color-secondary); margin-top:10px; padding:10px;">
<p style="font-size:0.9em;">例：ユーザー「以下の条件でXをしてください：\n- A\n- B\n- C」→ LLM「はい、Yです。」</p>
</div>
</div>
<div class="info-card glass-card">
<p class="feature-item"><span class="badge purple" style="font-size:1.1em; padding: 6px 10px;">🔄 RECAP</span></p>
<p><strong>タイプ:</strong> 複数ターン会話 + 最終要約ターン</p>
<p><strong>方法:</strong> SHARDED会話と同様に進行しますが、最後に<span class="keyword">最終要約ターン (final recapitulation turn)</span> が追加されます。このターンでは、指示の全てのシャードが単一のターンで再度提示され、LLMに応答する最後の機会が与えられます。</p>
<p><strong>目的:</strong></p>
<ul class="fa-ul" style="font-size:0.95em;">
<li><span class="fa-li"><i class="fas fa-handshake"></i></span>SHARDEDシミュレーションの後にCONCATターンが続く組み合わせです。</li>
<li><span class="fa-li"><i class="fas fa-tools"></i></span>セクション7.1で、このような概念的に単純なエージェント風の介入が、SHARDED会話で見られる<span class="highlight">性能低下を緩和できるか</span>どうかを評価する方法として検討されます。</li>
</ul>
<div class="bubble-box" style="background-color: rgba(149, 117, 205, 0.08); border-color: var(--color-accent2); margin-top:10px; padding:10px;">
<p style="font-size:0.9em;">例：(SHARDED会話後)...<br/>ユーザー「これまでの情報をまとめると、A、B、Cという条件でXをしてほしいということです。最終的な回答をお願いします。」→ LLM「はい、Yです。」</p>
</div>
</div>
<div class="info-card glass-card">
<p class="feature-item"><span class="badge yellow" style="font-size:1.1em; padding: 6px 10px;">☃️ SNOWBALL</span></p>
<p><strong>タイプ:</strong> 複数ターン会話（ターン毎の累積的要約）</p>
<p><strong>方法:</strong> RECAPシミュレーションをさらに進め、<span class="keyword">ターンレベルの要約 (turn-level recapitulation)</span> を実装します。各ターンで、ユーザーシミュレータは新しいシャードを導入するだけでなく、それまでに会話で明らかにされた<span class="highlight">全てのシャードを再提示</span>します。これにより、各ターンが前のターンの全ての情報に加えて新しいシャードを一つ明らかにするという雪だるま効果が生じます。</p>
<p><strong>目的:</strong></p>
<ul class="fa-ul" style="font-size:0.95em;">
<li><span class="fa-li"><i class="fas fa-brain"></i></span>SNOWBALLシミュレーションで実装される冗長性は、ターンレベルのリマインダーが、LLMが複数ターンの文脈にわたって情報を<span class="highlight">記憶する必要性を軽減するのに役立つか</span>どうかを研究するために、セクション7.1で手法として検討されます。</li>
</ul>
<div class="bubble-box" style="background-color: rgba(255, 213, 79, 0.08); border-color: var(--color-accent3); margin-top:10px; padding:10px;">
<p style="font-size:0.9em;">例：<br/>T1 ユーザー「Xをしたいです。条件はAです。」<br/>LLM「...」<br/>T2 ユーザー「以前お伝えしたAに加えて、Bという条件もあります。」<br/>LLM「...」<br/>T3 ユーザー「これまでのAとBに加えて、Cも条件です。」<br/>LLM「では、Yです。」</p>
</div>
</div>
</div>
<div class="note-box" style="margin-top:25px;">
<p class="note-title"><i class="fas fa-table"></i>参考: 論文中の表 (Figure 5)</p>
<p>論文のFigure 5には、本研究で扱われる各タスク（プログラミング言語生成、自然言語生成など）における元の指示とシャード化された指示の具体例が示されています。これには、コード生成、データベース操作、API呼び出し、数学問題、データからのテキスト生成、要約といったタスクが含まれます。各タスクの指示ソースや評価指標も併せて記載されており、このシミュレーションフレームワークの多様な適用可能性を示しています。</p>
<p class="reference"><em>(注: このHTMLではFigure 5の画像は直接挿入されていませんが、論文原文を参照することで、これらの具体例を確認できます。)</em></p>
</div>
</div>
<div class="section-card" id="4_Task_and_Metric_Selection">
<h2 class="section-title"><i class="fas fa-cogs"></i>4 Task and Metric Selection</h2>
<div class="content-box">
<p>このセクションでは、大規模なシミュレーション実験で使用する<strong>タスク</strong>と、モデルの性能を測るための<strong>評価指標</strong>をどのように選定したかについて詳しく説明します。これらの選定は、LLM（大規模言語モデル）がマルチターンの会話、特に情報が少しずつ与えられる状況（underspecified conversation）でどのような振る舞いをするかを正確に評価するための基盤となります。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-lightbulb"></i>このセクションのポイント</p>
<ul>
<li><i class="fas fa-tasks"></i> <strong>タスクの選定 (Task Selection)</strong>: どのような種類のタスクを、どのように準備したか。</li>
<li><i class="fas fa-chart-line"></i> <strong>評価指標の選定 (Metric Selection)</strong>: モデルの性能を多角的に評価するために、どのような指標を導入したか。</li>
</ul>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-tasks"></i>4.1 Task Selection</h3>
<div class="content-box">
<p>LLMのマルチターン会話能力を評価するために、6つの異なるタスクに対して<span class="keyword">シャーディングされた指示 (sharded instructions)</span> を構築しました。これらの指示は、大規模なシミュレーション実験で使用されます。</p>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-book-open"></i>用語解説：シャーディングされた指示 (Sharded Instructions)</p>
<p>「シャーディングされた指示」とは、元々1つのまとまった指示（fully-specified instruction）を、複数の小さな情報単位（シャード）に分割したものです。これにより、マルチターンの会話の中で、情報を段階的にLLMに提示するシミュレーションが可能になります。各シャードは、元の指示の一部分の情報を持ちます。</p>
</div>
<p>各タスクについて、高品質なシングルターン（1回のやり取りで完結する）、かつ完全に情報が指定されたベンチマークから指示を選び出し、半自動の<span class="keyword">シャーディングプロセス</span>を実装しました。</p>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-project-diagram"></i>半自動シャーディングプロセス</p>
<div class="process-step">
<div class="step-number">1</div>
<div class="step-content"><strong>候補提案・検証</strong>: まず、LLM (GPT-4o) を用いて、元の指示をどのようにシャードに分割するかの候補を提案させ、検証します。</div>
</div>
<div class="arrow-connector" style="height:15px; margin: 5px 0;"></div>
<div class="process-step">
<div class="step-number">2</div>
<div class="step-content"><strong>レビュー・編集</strong>: 次に、論文の著者たちがこれらの候補をレビューし、必要に応じて編集します。</div>
</div>
<p style="margin-top: 10px;">このシャーディングプロセス（詳細はAppendix Cで概説されています）により、元の指示の有効性を保ちつつ、シャーディングされた指示のコーパス（大量のテキストデータ群）を大規模に構築することができました。</p>
</div>
<p>各タスクに対して、90～120個のシャーディングされた指示を作成しました。これらはそれぞれ、元のシングルターンの指示とペアになっています。この作業には、タスクごとに1～4時間の手動による検査と注釈付けが必要でした。</p>
<div class="bubble-box">
<p><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i> <strong>タスク選定のポイント</strong>: プログラミングと非プログラミングのユースケースにまたがる、一般的で多様な生成タスクを慎重に選びました。</p>
</div>
<p><i class="fas fa-image"></i> 論文中の<strong>図5 (Figure 5)</strong> は、ここで紹介する各タスクについて、元の指示（Original Instruction）とシャーディングされた指示（Sharded Instruction）の具体例を示しています。以下に各タスクを紹介します。</p>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));">
<div class="info-card">
<p class="framework-title" style="font-size: 16px;"><i class="fas fa-code"></i> Code (コード生成)</p>
<p>アシスタントは、ユーザーがPythonプログラミング言語で関数を作成するのを支援します。</p>
<ul class="unstyled-list">
<li><i class="fas fa-database" style="color: var(--color-secondary);"></i> <strong>データソース</strong>: HumanEval [10], LiveCodeBench [31] (LLMのプログラミング能力評価で人気のベンチマーク)</li>
</ul>
</div>
<div class="info-card">
<p class="framework-title" style="font-size: 16px;"><i class="fas fa-database"></i> Database (データベース操作)</p>
<p>アシスタントは、SQLデータベースのスキーマと自然言語でのユーザークエリを与えられ、要求された情報をデータベースから取得するためのSQLクエリを生成します（いわゆる<span class="keyword">text-to-SQL</span>タスク）。</p>
<ul class="unstyled-list">
<li><i class="fas fa-database" style="color: var(--color-secondary);"></i> <strong>データソース</strong>: Spider [86] (人気のデータセット)</li>
</ul>
</div>
<div class="info-card">
<p class="framework-title" style="font-size: 16px;"><i class="fas fa-cogs"></i> Actions (API呼び出し)</p>
<p>アシスタントは、一連のAPI（Application Programming Interface）スキーマと、API使用を必要とするユーザー指示を与えられ、ユーザーリクエストに合致するプログラム的なAPIコマンドを生成します。</p>
<ul class="unstyled-list">
<li><i class="fas fa-database" style="color: var(--color-secondary);"></i> <strong>データソース</strong>: Berkeley Function Calling Leaderboard (BFCL) [85] (LLMのAPI関数呼び出し能力測定で人気のベンチマーク)</li>
</ul>
</div>
<div class="info-card">
<p class="framework-title" style="font-size: 16px;"><i class="fas fa-calculator"></i> Math (算数問題)</p>
<p>アシスタントは、初等的な算数の文章問題を与えられ、基本的な算術演算を用いた一連の計算を行い、数値の答えを導き出します。</p>
<ul class="unstyled-list">
<li><i class="fas fa-database" style="color: var(--color-secondary);"></i> <strong>データソース</strong>: GSM8K [14]</li>
</ul>
</div>
<div class="info-card">
<p class="framework-title" style="font-size: 16px;"><i class="fas fa-file-alt"></i> Data-to-text (データからのテキスト生成)</p>
<p>アシスタントは、表形式データと関連するメタデータのいくつかの要素を与えられ、そのデータについて説明するキャプション（自然言語の文）を生成します。</p>
<ul class="unstyled-list">
<li><i class="fas fa-database" style="color: var(--color-secondary);"></i> <strong>データソース</strong>: ToTTo [59] (このデータセットを活用してシャーディング指示を作成)</li>
</ul>
</div>
<div class="info-card">
<p class="framework-title" style="font-size: 16px;"><i class="fas fa-book-reader"></i> Summary (要約)</p>
<p>アシスタントは、約20の文書群とユーザークエリを受け取り、文書に基づいてクエリに対応する引用付きの要約を生成します。</p>
<ul class="unstyled-list">
<li><i class="fas fa-database" style="color: var(--color-secondary);"></i> <strong>データソース</strong>: Summary of a Haystack [40] (この指示を再利用)</li>
<li>📌 <strong>特徴</strong>: この要約タスクは、<span class="keyword">長文脈処理能力 (long-context capabilities)</span> をテストする唯一のタスクです。指示は数万トークンに及び、これはモデルの性能を低下させることが知られています [29, 32, 33]。</li>
</ul>
</div>
</div>
<div class="note-box" style="margin-top: 20px;">
<p class="note-title"><i class="fas fa-balance-scale"></i>タスクの評価方法</p>
<p>各タスクについて、元のベンチマークで使用されている評価指標を再利用しました。</p>
<div class="two-column">
<div class="column">
<p><strong><i class="fas fa-check-double"></i> バイナリ正解性 (Binary Correctness) で評価するタスク:</strong></p>
<ul class="unstyled-list">
<li><span class="badge blue">Code</span></li>
<li><span class="badge blue">Database</span></li>
<li><span class="badge blue">Actions</span></li>
<li><span class="badge blue">Math</span></li>
</ul>
<p>これらのタスクでは、解答の試み（コード、SQLクエリ）を実行するか、参照解答との<span class="keyword">意味的等価性 (semantic equivalence)</span>（API呼び出し、数値解答）を検証することで、正解か不正解かを判断します。</p>
</div>
<div class="column">
<p><strong><i class="fas fa-sliders-h"></i> 連続値スコア (0-100) で評価するタスク (Refinement Tasks):</strong></p>
<ul class="unstyled-list">
<li><span class="badge orange">Data-to-Text</span>: <span class="keyword">BLEUスコア [58]</span> を使用。</li>
<li><span class="badge orange">Summary</span>: 要約の情報網羅性と帰属の正確さを測定するために構築されたカスタムの<span class="keyword">LLM-as-a-judge評価指標 ("Joint Score") [40]</span> を使用。</li>
</ul>
</div>
</div>
<p><i class="fas fa-equals" style="color: var(--color-accent2);"></i> <strong>スコアの共通化</strong>: 全てのタスクでスコアが共通の尺度（0-100）になるように、バイナリの正解性をマッピングしました (<span class="highlight">$0 = \text{不正解}$</span>, <span class="highlight">$100 = \text{正解}$</span>)。これにより、結果の集約が容易になります。</p>
</div>
<p>Appendix I には、各タスクのシャーディングプロセスの実装詳細（サンプル選択プロセスや、再現性を促進するために実装されたタスク固有のロジックを含む）が記載されています。私たちは、選択した6つのタスクが広範なLLMユースケースを代表することを意図しましたが、シャーディングプロセス自体を本研究の貢献の一つと考えているため、その効率化と再現性の確保にも努めました。将来的に、LLM評価の実務者が自身のデータセット成果物をシャーディングし、より多様でユニークな設定でLLMのマルチターン行動を研究できるようになることを想定しています。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-chart-line"></i>4.2 Metric Selection</h3>
<div class="content-box">
<p>LLMは、テキストを生成する際に<span class="keyword">確率的プロセス (stochastic process)</span> を採用しています。LLMの生成パラメータをデフォルト（例：<span class="highlight">温度 \(T = 1.0\)</span>）に設定すると、同じ会話状態であっても、LLMは多くの異なる応答を生成します。この特性を利用して、特定の指示に対してシミュレーションを繰り返し行い、発生する変動を観察します。</p>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-pen-fancy"></i>用語解説：確率的プロセス (Stochastic Process)</p>
<p>結果がランダム性を含むプロセスのことです。LLMの場合、次に出現する単語を確率分布に基づいて選択するため、同じ入力に対しても異なる出力が得られることがあります。「温度 (Temperature)」というパラメータは、このランダム性の度合いを調整します。温度が高いほど、より多様で創造的な（しかし時には予測しにくい）テキストが生成されやすくなります。</p>
</div>
<p>各シミュレーションは、シミュレーション終了までにLLMがタスクを完了した成功の度合いを評価するスコア \(S_i\)（0～100の範囲）を算出します。ある指示に対して \(N\) 回のシミュレーションを実行して得られたスコアの集合 \(\mathcal{S} = \{ S_i \}_{i=1}^N\) に基づいて、以下の3つの評価指標を定義します。</p>
<div class="feature-card-grid">
<div class="feature-item glass-card">
<p class="icon-item"><i class="fas fa-calculator"></i></p>
<p><strong>平均性能 (Averaged Performance: \(\overline{P}\))</strong></p>
<div class="formula">
                    $$ \overline{P} = \sum_{i=1}^N S_i / N $$
                </div>
<p><small>特定のシミュレーションタイプにおける、ある指示に対するモデルの平均スコアの不偏推定値です。</small></p>
</div>
<div class="feature-item glass-card">
<p class="icon-item"><i class="fas fa-brain"></i></p>
<p><strong>適性 (Aptitude: \(A^{90}\))</strong></p>
<div class="formula">
                    $$ A^{90} = \mathrm{percentile}_{90}(\mathcal{S}) $$
                </div>
<p><small>特定の指示に対するモデルの90パーセンタイルスコアの推定値です。実施されたシミュレーションの上位10%で得られるスコアを推定する、最良ケースの指標です。</small></p>
</div>
<div class="feature-item glass-card">
<p class="icon-item"><i class="fas fa-exclamation-triangle"></i></p>
<p><strong>不安定性 (Unreliability: \(U_{10}^{90}\))</strong></p>
<div class="formula">
                    $$ U_{10}^{90} = \mathrm{percentile}_{90}(\mathcal{S}) - \mathrm{percentile}_{10}(\mathcal{S}) $$
                </div>
<p><small>90パーセンタイル推定値と10パーセンタイル推定値の間の百分位数間範囲の推定値です。最良ケースと最悪ケースのシミュレーション間のギャップを測定し、LLMの確率性に起因する応答品質の低下レベルを示します。</small></p>
</div>
</div>
<div class="note-box" style="margin-top: 20px;">
<p class="note-title"><i class="fas fa-clipboard-list"></i>指標の適用範囲と用語</p>
<ul>
<li>これらの指標は、指示ごとに計算され、指示のコーパス全体で平均化することで、コーパスレベルの指標を得ることができます。</li>
<li>論文の残りの部分では、<span class="keyword">信頼性 (Reliability)</span> と不安定性 (Unreliability) を同じ意味で用いることがあり、信頼性は \(R_{10}^{90} = 100 - U_{10}^{90}\) として定義されます。</li>
<li>また、表記を簡略化し、適性を \(A\)、不安定性を \(U\) としますが、これらの指標は他のパーセンタイル閾値（例：\(A^{80}\) や \(U_5^{95}\)）にも一般化できます。</li>
</ul>
</div>
<p>📝 Appendix Eでは、平均性能 (\(\overline{P}\)) が90%から60%に低下する平均的な劣化が、適性の低下、信頼性の低下、またはその両方の組み合わせによるものであるかの具体例を検討しています。</p>
<p>📊 最後に、論文中の<strong>図6a (Figure 6a)</strong> は、適性 (Aptitude) と不安定性 (Unreliability) の指標を、スコアの箱ひげ図の視覚化と関連付けています。要約すると：</p>
<ul>
<li>箱ひげ図の上側のひげの高さが<span class="keyword">適性 (A)</span> を表します。</li>
<li>箱ひげ図の上側と下側のひげの間の距離が<span class="keyword">不安定性 (U)</span> を表します。</li>
</ul>
<div class="bubble-box">
<p><i class="fas fa-search-plus" style="color: var(--color-accent1);"></i> <strong>視覚的理解</strong>: 適性は「モデルがどれだけ良い成績を出せるか（ベストケースに近い能力）」を示し、不安定性は「成績のばらつきがどれだけ大きいか（結果の安定性）」を示すと考えると分かりやすいでしょう。</p>
</div>
</div>
</div>
<div class="section-card" id="5_Simulation_Scale_and_Parameters">
<h2 class="section-title"><i class="fas fa-cogs"></i> 5 Simulation Scale and Parameters</h2>
<div class="glass-card">
<p><i class="fas fa-bullseye"></i> <strong>このセクションの目的</strong>: このセクションでは、論文で実施された大規模なシミュレーション実験の<span class="keyword">全体像</span>と<span class="keyword">設定詳細</span>を明らかにします。具体的には、どのようなデータセット、会話形式、LLMモデルを使って実験が行われたのか、そしてどのようなパラメータが用いられたのかを説明します。これにより、後続のセクションで提示される実験結果の<span class="highlight">信頼性</span>と<span class="highlight">妥当性</span>を理解するための基礎を築きます。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-cubes"></i> 実験の全体構成</h3>
<p>この主要なシミュレーション実験は、非常に大規模なものとなっています。以下にその概要を示します。</p>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));">
<div class="info-card">
<div class="feature-item">
<i class="fas fa-file-alt fa-2x" style="color: var(--color-accent1);"></i>
<h4><i class="fas fa-tasks"></i> 使用した命令 (Instructions)</h4>
<p>6つの異なるタスクにわたり、合計<span class="keyword">600の命令</span>をシャード化 (情報を細かく分割) して使用しました。</p>
</div>
</div>
<div class="info-card">
<div class="feature-item">
<i class="fas fa-comments fa-2x" style="color: var(--color-accent2);"></i>
<h4><i class="fas fa-exchange-alt"></i> 会話タイプ (3種類)</h4>
<p>以下の3つの異なるタイプの会話でシミュレーションを行いました。</p>
<ul class="unstyled-list" style="text-align: left; padding-left: 10px;">
<li><i class="fas fa-comment" style="color:var(--color-primary)"></i> <strong>FULL</strong>: 元の完全な情報を一度にLLMに提供する<span class="highlight">シングルターン</span>の会話。</li>
<li><i class="fas fa-paperclip" style="color:var(--color-secondary)"></i> <strong><span style="font-family: 'Yomogi', cursive;">$\circledcirc$</span> CONCAT</strong>: シャード化された全ての情報を連結し、一度にLLMに提供する<span class="highlight">シングルターン</span>の会話。</li>
<li><i class="fas fa-stream" style="color:var(--color-accent1)"></i> <strong><span style="font-family: 'Yomogi', cursive;">$a \textcircled { \times } 1$</span> SHARDED</strong>: シャード化された情報を1ターンに1つずつ、段階的にLLMに提供する<span class="highlight">マルチターン</span>の会話。</li>
</ul>
</div>
</div>
<div class="info-card">
<div class="feature-item">
<i class="fas fa-robot fa-2x" style="color: var(--color-secondary);"></i>
<h4><i class="fas fa-brain"></i> 実験対象LLM</h4>
<p>合計で<span class="keyword">15種類</span>の主要な大規模言語モデル (LLM) を実験対象としました。</p>
</div>
</div>
<div class="info-card">
<div class="feature-item">
<i class="fas fa-redo fa-2x" style="color: var(--color-accent3);"></i>
<h4><i class="fas fa-sync-alt"></i> シミュレーション回数</h4>
<p>各LLMと各会話タイプの組み合わせに対して、それぞれ <span class="keyword">\(N=10\) 回</span> のシミュレーションを実行しました。</p>
</div>
</div>
</div>
<div class="bubble-box">
<p><i class="fas fa-calculator"></i> <strong>総会話数</strong>: これにより、シミュレートされた会話の総数は、なんと <span class="highlight">200,000回以上</span> にも及びます！膨大なデータから、LLMの振る舞いを詳細に分析します。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-thermometer-half"></i> シミュレーションパラメータ</h3>
<div class="content-box">
<p><i class="fas fa-sliders-h"></i> 全てのシミュレーションは、基本的にデフォルトの温度設定である <span class="keyword">\(T=1\)</span> で実施されました。温度 <span class="highlight">\(T\)</span> は、LLMの応答のランダム性を制御するパラメータです。</p>
<ul>
<li><span class="badge yellow">\(T=1\)</span>: 比較的ランダム性が高く、多様な応答が生成されやすい設定です。</li>
<li><span class="badge blue">\(T=0\)</span>: ランダム性が最も低く、決定論的な（毎回ほぼ同じ）応答が生成されやすい設定です。</li>
</ul>
<div class="note-box">
<p class="note-title"><i class="fas fa-flask"></i> 補足実験</p>
<p>ただし、本論文のセクション7.2では、この温度 <span class="keyword">\(T\)</span> がLLMの<span class="highlight">適性 (Aptitude)</span> と<span class="highlight">信頼性 (Reliability)</span> にどのような影響を与えるかを調査するための補足実験も行われています。この主要実験では <span class="keyword">\(T=1\)</span> が標準とされています。</p>
</div>
</div>
<img alt="Table 1: LLMの平均パフォーマンス" class="section-image" src="table2.png"/>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-table"></i> 表1の解説: LLMの平均パフォーマンス ${ \overline { { P } } }$</p>
<p>この表は、実験結果の主要な概要を示しています。以下、各項目の意味を解説します。</p>
<ul>
<li><i class="fas fa-tasks"></i> <strong>タスク (Tasks)</strong>: Code (コード生成), Database (データベースクエリ生成), Actions (API呼び出し生成), Data-to-text (データからのテキスト生成), Math (数学問題解決), Summary (要約生成) の6つのタスク。</li>
<li><i class="fas fa-comments"></i> <strong>会話設定 (Conversation Settings)</strong>: 各タスクについて、FULL, CONCAT, SHARDED の3つの設定で会話がシミュレートされました。</li>
<li><i class="fas fa-sort-amount-up"></i> <strong>モデルの並び順</strong>: 表内のモデルは、全タスクを通じた <span class="keyword">FULL設定での平均スコア</span>が低い順 (昇順) に並べられています。つまり、表の上部ほどFULL設定での性能が低いモデル、下部ほど性能が高いモデルとなります。</li>
<li><i class="fas fa-palette"></i> <strong>背景色</strong>: 背景色は、<span class="keyword">FULL設定</span>と比較してどれだけパフォーマンスが低下したか (<span class="highlight">Degradation</span>) を示しています。色が濃いほど、低下が大きいことを意味します。</li>
<li><i class="fas fa-percentage"></i> <strong>最後の2列</strong>: 
                <ul>
<li><strong>CONCAT vs FULL (%)</strong>: FULL設定と比較したCONCAT設定でのパフォーマンス低下率の平均 (6タスク全体)。</li>
<li><strong>SHARDED vs FULL (%)</strong>: FULL設定と比較したSHARDED設定でのパフォーマンス低下率の平均 (6タスク全体)。</li>
</ul>
</li>
</ul>
<div class="note-box">
<p class="note-title"><i class="fas fa-lightbulb"></i> この表から読み取れる主な傾向 (詳細はセクション6で議論されます)</p>
<p>一般的に、FULL設定に比べてCONCAT設定ではパフォーマンス低下は軽微ですが、<span class="highlight">SHARDED設定では大幅なパフォーマンス低下が見られる</span>ことが予想されます。これは、マルチターンの情報提示がLLMにとって難しい課題であることを示唆しています。</p>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-chart-line"></i> 繰り返しシミュレーションの意義</h3>
<div class="content-box">
<p><i class="fas fa-microscope"></i> 各 (LLM, 命令, 会話タイプ) の組み合わせに対して <span class="keyword">10回の会話をシミュレート</span>することは、実験コストを10倍に増加させます。しかし、これには重要な利点があります。</p>
<div class="info-grid" style="grid-template-columns: 1fr 1fr;">
<div class="info-card">
<div class="feature-item">
<i class="fas fa-bullseye fa-2x" style="color: var(--color-accent1);"></i>
<h4><i class="fas fa-check-circle"></i> 平均パフォーマンス <span class="highlight">$(\overline{P})$</span> の正確な測定</h4>
<p>複数回の試行により、偶然による影響を排し、より信頼性の高い平均性能を測定できます。</p>
</div>
</div>
<div class="info-card">
<div class="feature-item">
<i class="fas fa-puzzle-piece fa-2x" style="color: var(--color-accent2);"></i>
<h4><i class="fas fa-search-plus"></i> 適性 (Aptitude) と信頼性 (Reliability) の詳細な分析</h4>
<p>単なる平均性能だけでなく、LLMシステムが持つ潜在的な最高性能 (適性) や、性能のばらつき (信頼性) についても深く調査することが可能になります。これについては、セクション6.2で詳しく議論されます。</p>
</div>
</div>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-list-ul"></i> 選択されたLLMモデル</h3>
<p><i class="fas fa-brain"></i> この実験では、合計<span class="keyword">15のLLM</span>が8つの異なるモデルファミリーから選ばれました。選択の背景には、いくつかの重要な意図があります。</p>
<div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));">
<div class="feature-item">
<i class="fab fa-openai fa-2x" style="color: #4CAF50;"></i>
<p><strong><span style="font-family: 'Yomogi', cursive;">$\textcircled{5}$</span> OpenAI</strong></p>
<p class="unstyled-list" style="font-size: 0.9em;">GPT-4o-mini, GPT-4o [30], o3 [57], GPT-4.1</p>
</div>
<div class="feature-item">
<i class="fas fa-cloud fa-2x" style="color: #FF9800;"></i>
<p><strong>Anthropic</strong></p>
<p class="unstyled-list" style="font-size: 0.9em;">Claude 3 Haiku, Claude 3.7 Sonnet</p>
</div>
<div class="feature-item">
<i class="fab fa-google fa-2x" style="color: #4285F4;"></i>
<p><strong>Google’s <span style="font-family: 'Yomogi', cursive;">$^ { + }$</span> Gemini</strong> [75]</p>
<p class="unstyled-list" style="font-size: 0.9em;">Gemini 2.5 Flash, Gemini <span style="font-family: 'Yomogi', cursive;">$2 . 5 \mathrm { P r o } \rangle$</span></p>
</div>
<div class="feature-item">
<i class="fab fa-meta fa-2x" style="color: #1877F2;"></i>
<p><strong>Meta’s <span style="font-family: 'Yomogi', cursive;">$\infty$</span> Llama</strong> [23]</p>
<p class="unstyled-list" style="font-size: 0.9em;">Llama3.1-8B-Instruct, Llama3.3-70B-Instruct, Llama 4 Scout</p>
</div>
<div class="feature-item">
<i class="fas fa-microchip fa-2x" style="color: #E91E63;"></i>
<p><strong>AI21 Labs</strong></p>
<p class="unstyled-list" style="font-size: 0.9em;">OLMo-2-13B [56]</p>
</div>
<div class="feature-item">
<i class="fab fa-microsoft fa-2x" style="color: #00A4EF;"></i>
<p><strong>Microsoft</strong></p>
<p class="unstyled-list" style="font-size: 0.9em;">Phi-4 [1]</p>
</div>
<div class="feature-item">
<i class="fas fa-search fa-2x" style="color: #9C27B0;"></i>
<p><strong><span style="font-family: 'Yomogi', cursive;">$\ntrianglelefteq$</span> Deepseek-R1</strong> [24]</p>
</div>
<div class="feature-item">
<i class="fas fa-yen-sign fa-2x" style="color: #795548;"></i>
<p><strong><span style="font-family: 'Yomogi', cursive;">$\yen 1$</span> Cohere Command-A</strong> [15]</p>
</div>
</div>
<div class="glass-card" style="margin-top: 20px;">
<h4 class="subsection-title" style="font-size: 16px; color: var(--color-primary); border-bottom: none;"><i class="fas fa-filter"></i> モデル選択の基準</h4>
<div class="info-grid">
<div class="info-card">
<p><span class="badge blue">最先端モデル優先</span>: 最新かつ高性能なモデルの評価を重視。</p>
</div>
<div class="info-card">
<p><span class="badge orange">多様なモデルサイズ</span>: 小規模モデル (例: 8Bパラメータ) から大規模モデル (例: 300B+パラメータ) まで幅広く含める。</p>
</div>
<div class="info-card">
<p><span class="badge green">オープン vs クローズド</span>: オープンウェイトモデル (重みが公開されている) とクローズドウェイトモデル (重みが非公開) の両方を含める。</p>
</div>
<div class="info-card">
<p><span class="badge purple">推論モデルの包含</span>: 2つの<span class="keyword">推論モデル (reasoning models)</span> である <span class="highlight">o3</span> と <span class="highlight">R1</span> を含めました。これらのモデルは、応答を生成する際に内部的により多くの思考ステップ（テスト時計算量）を経るように設計されています。これにより、追加の思考時間がマルチターン会話能力にどのような影響を与えるかを調査します。</p>
</div>
</div>
<p style="margin-top: 10px;"><i class="fas fa-info-circle"></i> モデルのバージョン情報やアクセス方法の詳細は、論文の<span class="highlight">付録H (Appendix H)</span> に記載されています。</p>
</div>
<div class="framework-box" style="margin-top: 20px;">
<p class="framework-title"><i class="fas fa-dollar-sign"></i> 推定コスト</p>
<p>これらの大規模なシミュレーションを実施するための総コストは、約 <span class="keyword">$5,000</span> と見積もられています。これは、API利用料や計算資源のコストを反映しています。</p>
</div>
<div class="note-box" style="margin-top:25px;">
<p class="note-title"><i class="fas fa-key"></i> このセクションのキーポイント</p>
<p>このセクションでは、実験がいかに<span class="highlight">広範囲</span>で<span class="highlight">系統的</span>に行われたかを説明しています。</p>
<ul>
<li><i class="fas fa-clipboard-list"></i> <strong>多様なタスクと命令</strong>: 6タスク、600命令。</li>
<li><i class="fas fa-comments"></i> <strong>比較のための会話タイプ</strong>: FULL, CONCAT, SHARDED の3タイプ。</li>
<li><i class="fas fa-microchip"></i> <strong>幅広いLLM選定</strong>: 15種類のモデル（サイズ、公開状況、推論能力など多様）。</li>
<li><i class="fas fa-flask"></i> <strong>繰り返しによる信頼性確保</strong>: 各条件で10回のシミュレーション。</li>
<li><i class="fas fa-thermometer-three-quarters"></i> <strong>標準化された温度設定</strong>: \(T=1\) を基本としつつ、補足実験も実施。</li>
</ul>
<p>これらの設定により、LLMがマルチターンの<span class="keyword">情報提示の断片化 (sharding)</span> や<span class="keyword">不完全性 (underspecification)</span> にどのように対処するかを詳細に評価する基盤が整えられています。</p>
</div>
</div>
<div class="section-card" id="6_Results">
<h2 class="section-title"><i class="fas fa-chart-bar"></i> 6 Results</h2>
<p>このセクションでは、本研究で実施された大規模シミュレーション実験から得られた主要な結果を報告します。具体的には、大規模言語モデル（LLM）が完全な情報を一度に与えられた場合（<span class="keyword">FULL</span>設定、単一ターン）と、情報を段階的に断片化して与えられた場合（<span class="keyword">SHARDED</span>設定、複数ターン、情報不足）で、タスク遂行能力がどのように変化するのかを詳細に分析します。</p>
<p>中心的な発見は「<span class="keyword">Lost in Conversation</span>」と名付けられた現象です。これは、非常に高性能なLLMでさえも、複数ターンにわたる情報が不完全な会話では著しく性能が低下することを示しています。この性能低下を、モデルの根本的な問題解決能力である「<span class="keyword">適性 (Aptitude: A)</span>」と、安定して性能を発揮できるかを示す「<span class="keyword">信頼性 (Reliability)</span>」（本論文ではその逆の指標である「<span class="keyword">信頼性の低さ (Unreliability: U)</span>」）という2つの側面から掘り下げていきます。さらに、情報が提示される細かさ（粒度）がこの「Lost in Conversation」現象にどのように影響するのかを探る追加実験（Gradual Sharding Experiment）の結果も示します。</p>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-chart-line"></i> 6.1 Average Performance Findings</h3>
<p>このサブセクションでは、シミュレーション実験における各LLMの平均的なパフォーマンスについて報告します。特に、<span class="keyword">Table 1</span>にまとめられた結果を中心に解説します。（注意：実際のTable 1の図はここでは表示されていませんが、論文中の記述に基づいて内容を説明します。）</p>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-table"></i> Table 1 の概要</p>
<p>Table 1は、実験対象となった15種類のLLMが、6つの異なるタスク（Code, Database, Actions, Data-to-Text, Math, Summary）において、3つの異なる会話シミュレーション設定（<span class="keyword">FULL</span>, <span class="keyword">CONCAT</span>, <span class="keyword">SHARDED</span>）でどのような平均性能 $(\overline{P})$ を示したかをまとめたものです。モデルは、タスク全体の平均<span class="keyword">FULL</span>スコアが低い順に並べられています。表内の背景色は、<span class="keyword">FULL</span>設定からの性能低下の度合いを示しており、色が濃いほど低下が大きいことを意味します。最後の2列は、<span class="keyword">CONCAT</span>設定と<span class="keyword">SHARDED</span>設定それぞれについて、<span class="keyword">FULL</span>設定と比較した際の性能低下率を6タスクで平均したものです。</p>
</div>
<div class="content-box">
<h4><i class="fas fa-exclamation-triangle"></i> 「Lost in Conversation」現象の発見</h4>
<p>まず最も注目すべきは、全てのモデルが全てのタスクにおいて、<span class="keyword">FULL</span>設定（完全な指示を一度に提示）から<span class="keyword">SHARDED</span>設定（指示を断片化し複数ターンで提示）へ移行すると、性能が著しく低下するという点です。その低下幅は平均で<span class="highlight">39%</span>にも及びます。</p>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-comments"></i> Lost in Conversation <span class="badge yellow">重要概念</span></p>
<p>実験室のような理想的な環境（完全指定、単一ターン）では素晴らしい性能（例: 90%以上）を発揮するモデルが、全く同じタスクであっても、会話が情報不足で複数ターンにわたる、より現実的な設定になると性能が大幅に低下する現象を指します。</p>
</div>
</div>
<div class="two-column">
<div class="column">
<h4><i class="fas fa-puzzle-piece"></i> CONCAT設定との比較：情報損失は主な原因ではない</h4>
<p><span class="keyword">CONCAT</span>設定（断片化された指示を連結し、単一ターンで全て提示）では、モデルの性能は<span class="keyword">FULL</span>設定の平均<span class="highlight">95.1%</span>を維持しました。このことは、<span class="keyword">SHARDED</span>設定での性能低下が、指示を断片化したことによる<span class="highlight">情報の欠落や変化が主な原因ではない</span>ことを示唆しています。もし情報損失が原因であれば、<span class="keyword">CONCAT</span>設定でも同様の大きな性能低下が見られるはずだからです。</p>
</div>
<div class="column">
<div class="note-box">
<p class="note-title"><i class="fas fa-robot"></i> 小規模モデルの傾向</p>
<p>Llama3.1-8B-Instruct, OLMo-2-13B, Claude 3 Haikuといった比較的小さなモデルは、<span class="keyword">CONCAT</span>設定での性能低下が他の大規模モデルよりも顕著でした（86-92%程度）。これは、小規模モデルが大規模モデルほど<span class="highlight">汎化能力が高くない</span>こと、つまり、指示の些細な言い換え（shardingプロセスで発生しうる）に対して性能がより影響を受けやすいことを示していると考えられます。この言い換えに対する頑健性の欠如は、Table 1で視覚的にも確認できます（論文参照）。具体的には、<span class="keyword">CONCAT</span>設定での性能低下を示す赤色の背景が、表の上部（比較的弱いモデル）でより顕著に、下部（比較的強いモデル）では薄くなっています。</p>
</div>
</div>
</div>
<div class="content-box">
<h4><i class="fas fa-sort-amount-down"></i> モデルの性能と「Lost in Conversation」効果</h4>
<p>Table 1の最後の列 $(\ntrianglerighteq ) / \not \in$ は、各モデルにおける「Lost in Conversation」効果の大きさ、つまり<span class="keyword">SHARDED</span>設定での性能低下の度合いを6タスクで集計したものです。驚くべきことに、Claude 3.7 Sonnet, Gemini 2.5, GPT-4.1のような<span class="highlight">高性能モデルも、Llama3.1-8B-InstructやPhi-4のような小規模モデルと比較して同程度に「会話に迷う」</span>ことが分かりました。これらの高性能モデルも平均で約30%の性能低下を示しています。</p>
<p>この一見矛盾する結果の一因は、評価指標の定義にあります。小規模モデルは元々<span class="keyword">FULL</span>設定での絶対スコアが低いため、高性能モデルに比べて性能が低下する「余地」が小さいのです。結論として、<span class="highlight">LLMの単一ターン性能がいかに高くても、複数ターン設定では大きな性能低下が見られる</span>ということです。</p>
</div>
<div class="info-grid">
<div class="info-card glass-card">
<h4><i class="fas fa-tasks"></i> タスク特化型の性能維持</h4>
<p>タスクごとの詳細を見ると、一部のモデルは特定のタスクにおいて性能低下が比較的緩やかでした。例えば、</p>
<ul>
<li><span class="badge blue">Command-A</span> は <span class="keyword">Actions</span> タスクで最も低下が少ない。</li>
<li><span class="badge purple">Claude 3.7 Sonnet</span> と <span class="badge green">GPT-4.1</span> は <span class="keyword">Code</span> タスクで性能をよく維持。</li>
<li><span class="badge orange">Gemini 2.5 Pro</span> は <span class="keyword">Data-to-Text</span> タスクで性能をよく維持。</li>
</ul>
<p>この発見は、モデルの複数ターン処理能力が<span class="highlight">ドメイン間で均一ではない</span>ことを示しており、モデルの能力を多角的に調査するためには<span class="highlight">広範なタスクでのベンチマークが重要</span>であることを裏付けています。</p>
</div>
<div class="info-card glass-card">
<h4><i class="fas fa-cogs"></i> テスト時計算量（推論トークン）の影響</h4>
<p>実験に含まれる2つの推論モデル（<span class="keyword">o3</span>, <span class="keyword">Deepseek-R1</span>）も、推論を行わない他のモデルと同様の性能低下を示しました。この結果は、<span class="highlight">テスト時の追加計算（推論トークンを多く使うこと）だけでは、モデルが複数ターンの情報不足な会話をうまく乗り切る役には立たない</span>ことを示しています。</p>
<p>この潜在的な根本原因として、本分析では、推論モデルがより長い応答を生成する傾向があることを特定しました（平均して非推論LLMより<span class="highlight">33%長い</span>）。Appendix Fで詳述するように、アシスタントの応答が長いほど、より多くの<span class="keyword">仮定 (assumptions)</span> を含みがちです。これらの仮定は、ユーザーが提示した要件とモデル自身が前のターンで生成した応答内容を混同させ、会話を脱線させる可能性があります。</p>
<div class="bubble-box">
<p><i class="fas fa-lightbulb"></i> <strong>ポイント:</strong> 長い応答 ➡️ より多くの仮定 ➡️ 会話の混乱 ➡️ 性能低下</p>
</div>
</div>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-balance-scale"></i> 6.2 Aptitude vs. Reliability Analysis</h3>
<p>Table 1では平均性能低下 $(\overline{P})$ を示しましたが、ここではモデルの「<span class="keyword">適性 (Aptitude: A)</span>」と「<span class="keyword">信頼性の低さ (Unreliability: U)</span>」という2つの指標に基づいた分析結果を報告します。これらの指標は、LLMの応答のばらつきを考慮して性能を評価するために導入されました（Section 4.2参照）。</p>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-brain"></i> 適性 (Aptitude: A) とは？</p>
<p>ある指示に対して複数回シミュレーションを行った際のスコアの90パーセンタイル値。モデルが達成しうる「最良ケースに近い」性能を示します。高いほど良いです。</p>
<p class="formula">
            \( A^{90} = \mathrm{percentile}_{90}(S) \)
        </p>
<p class="definition-title"><i class="fas fa-random"></i> 信頼性の低さ (Unreliability: U) とは？</p>
<p>ある指示に対して複数回シミュレーションを行った際のスコアの90パーセンタイル値と10パーセンタイル値の差。性能のばらつきの大きさを示し、「最良ケース」と「最悪ケースに近い」性能の間のギャップを表します。低いほど信頼性が高い（つまり、ばらつきが少ない）ことを意味します。</p>
<p class="formula">
            \( U_{10}^{90} = \mathrm{percentile}_{90}(S) - \mathrm{percentile}_{10}(S) \)
        </p>
<p>（論文中では、信頼性 $R_{10}^{90} = 100 - U_{10}^{90}$ とも定義されています。）</p>
</div>
<img alt="Figure 6b: Observed Model Degradations" src="aLpots7its0uidne 13 74 79 80 78 80 82 82 83 7.png"/>
<p style="text-align: center; font-size: 0.9em; color: var(--color-gray);">図6b: 15のLLMにおける信頼性分析結果の視覚的要約。縦軸が適性(A)、横軸が信頼性の低さ(U)を表し、各点がモデルに対応します。左上の領域（高適性、低信頼性の低さ＝高信頼性）が理想的です。</p>
<p><span class="keyword">Figure 6b</span>は、実験対象の15のLLMについて行った信頼性分析の結果を視覚的にまとめたものです。</p>
<div class="content-box">
<h4><i class="fas fa-check-circle"></i> 単一ターン設定（FULL, CONCAT）での傾向</h4>
<p><span class="keyword">FULL</span>と<span class="keyword">CONCAT</span>の2つの単一ターン設定を見ると、<span class="highlight">適性が高いモデル（Aが高い）ほど、信頼性も高い（Uが低い）傾向</span>が見られます。例えば、最も適性が高い2つのモデル（GPT-4.1とGemini 2.5 Pro）は、最も信頼性の低さが低い（つまり最も信頼性が高い）結果を示しています。逆に、適性が最も低い2つのモデル（Llama3.1-8B-InstructとOLMo-2-13B）は、最も信頼性が低い（Uが高い）結果となりました。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-info-circle"></i> コミュニティでの既知の事実</p>
<p>この「単一ターンでは高適性モデルほど高信頼性」という傾向は、LLMコミュニティではある程度知られています。より優れたモデルは、入力や出力のわずかな変動に対してより頑健であるため、プロンプトエンジニアリングの工夫が少なくて済む、という議論がなされています[47]。</p>
</div>
</div>
<div class="challenge-box">
<p class="challenge-title"><i class="fas fa-exchange-alt"></i> 複数ターン設定（SHARDED）での異なる様相</p>
<p><span class="keyword">SHARDED</span>設定では、状況は一変します。</p>
<ul>
<li><span class="badge blue">適性の低下</span>: モデルの適性(A)は、<span class="keyword">FULL</span>設定から<span class="keyword">SHARDED</span>設定へ移行すると平均で<span class="highlight">16%</span>低下しますが、これは比較的軽微な低下と言えます。</li>
<li><span class="badge red">信頼性の低さの急増</span>: 一方で、信頼性の低さ(U)は平均で<span class="highlight">112%</span>も増加し、2倍以上に悪化します。</li>
</ul>
<p>さらに興味深いのは、<span class="highlight">より優れたモデル（適性が高いモデル）は複数ターンでもやや高い適性を維持する傾向があるものの、全てのモデルがほぼ同レベルの高い信頼性の低さ(U)を示す</span>という点です。言い換えると、情報不足な複数ターン設定では、<span class="highlight">テストした全てのモデルが非常に低い信頼性</span>を示し、ある固定された指示に対するシミュレーション結果で、最良の場合と最悪の場合で性能が平均50パーセントポイントも低下しました。</p>
</div>
<div class="definition-box">
<p class="definition-title"><i class="fas-regular fa-comment-dots"></i> 「Lost in Conversation」現象の再定義 <span class="badge yellow">重要概念</span></p>
<p>単一ターン設定と複数ターン設定を比較すると、大きな平均性能低下 $(\overline{P})$ は、主として<span class="highlight">モデルの信頼性の低さ(U)の大幅な増加</span>によって引き起こされており、適性(A)の低下による影響は比較的小さいことが分かりました。つまり、モデルは基本的な能力を失うわけではないが、状況によって性能が非常に不安定になる、ということです。</p>
<div class="pipeline">
<div class="pipeline-step">単一ターン: 高適性 ➡️ 高信頼性</div>
<div class="pipeline-step">複数ターン: わずかな適性低下 ➕ <strong>大幅な信頼性低下</strong> ➡️ Lost in Conversation</div>
</div>
</div>
<div class="content-box">
<h4><i class="fas fa-search"></i> 「Lost in Conversation」の潜在的な根本原因</h4>
<p>Appendix Fでは、モデルが会話に迷う潜在的な根本原因について探求しています。具体的には以下の4つの原因が特定されています（詳細はAppendix Fを参照）。</p>
<ol class="process-step unstyled-list">
<li><span class="step-number">1</span><span class="step-content"><span class="keyword">早すぎる回答の試み (Premature Answer Attempts)</span>: LLMは、問題の詳細が不明確な段階で完全な回答を性急に提案し、その際に立てた仮定が後の混乱を招く (Appendix F.1)。</span></li>
<li><span class="step-number">2</span><span class="step-content"><span class="keyword">以前の誤った回答への過度な依存 (Over-reliance on Previous Incorrect Attempts)</span>: 以前の（誤った）回答の試みに過度に依存し、結果としてより長く「肥大化した (bloated)」回答を生成してしまう (Section F.2)。</span></li>
<li><span class="step-number">3</span><span class="step-content"><span class="keyword">会話の最初と最後のターンへの過度な調整 (Over-adjustment to First and Last Turns)</span>: 会話の最初と最後のターンに基づいて回答を過度に調整し、中間のターンの情報が失われる「<span class="keyword">loss-of-middle-turns</span>」現象が見られる (Appendix F.3)。</span></li>
<li><span class="step-number">4</span><span class="step-content"><span class="keyword">過度に冗長な回答 (Overly Verbose Answers)</span>: 過度に冗長な回答を生成し、これがユーザーの発言から注意をそらすような仮定を導入してしまう可能性が高い (Section F.4)。</span></li>
</ol>
</div>
<div class="arrow-connector"></div>
<h3 class="subsection-title"><i class="fas fa-cubes"></i> 6.3 Gradual Sharding Experiment</h3>
<p>このサブセクションでは、「<span class="keyword">Lost in Conversation</span>」現象と情報の断片化の「粒度」との関係を探るために行われた「<span class="keyword">Gradual Sharding Experiment（段階的シャーディング実験）</span>」の結果について報告します。</p>
<div class="challenge-box">
<p class="challenge-title"><i class="fas fa-question-circle"></i> 実験の動機: 現実的な会話とのギャップ</p>
<p>これまでの<span class="keyword">SHARDED</span>設定で行われた複数ターン会話のシミュレーションは、ユーザーがLLMと行う現実の情報不足な会話を完全に代表しているわけではありません。特に以下の2点が、現実的でない、あるいはモデルにとって不利（adversarial）に見える可能性があります。</p>
<ul>
<li><span class="keyword">シャーディングされた指示の最大性 (P3)</span>: 指示の断片（シャード）は、可能な限り細かく分割されなければならないという制約（Property P3）。</li>
<li><span class="keyword">1ターン1シャードの制約</span>: シミュレートされたユーザーは、1ターンにつき最大1つのシャードしか情報を開示しないという制約（Section 3.2）。</li>
</ul>
<p>実際、先行研究[27]では、公開されているLLMのチャットログにおいて、軽微な情報不足と深刻な情報不足が同程度の割合で出現することがわかっています。そこで、本実験では、情報の断片化の度合い（シャードの数）を変えながら性能変化を観察します。</p>
</div>
<div class="content-box">
<h4><i class="fas fa-flask"></i> 段階的シャーディング実験の設計</h4>
<p>この実験では、元の実験から複数のタスクにまたがる31個の指示を選択しました。そして、それぞれのシャード化された指示を、シャードセットのサイズが2から8シャードまで増加するように、7種類のシャード化された指示に拡張しました。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-cog"></i> 実験設計のポイント</p>
<p>指示の選択とシャーディングのプロセスはAppendix Kで詳述されています。重要なのは、各シャードセットサイズ（1から8まで）において、<span class="highlight">タスクの複雑さは固定</span>されており、変更される唯一の要因は<span class="highlight">シャーディングの粒度（細かさ）</span>である点です。</p>
<ul class="unstyled-list">
<li><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i> 1シャード: 全情報を一度に提示 (CONCAT設定に相当)</li>
<li><i class="fas fa-ellipsis-h" style="color: var(--color-accent2);"></i> 2〜8シャード: 情報を2〜8個の断片に分割して複数ターンで提示</li>
</ul>
</div>
</div>
<img alt="Figure 6c: Gradual Sharding Results" src="aLpots7its0uidne 13 74 79 80 78 80 82 82 83 7.png"/>
<p style="text-align: center; font-size: 0.9em; color: var(--color-gray);">図6c: 段階的シャーディング実験の結果。横軸がシャードの数、縦軸が性能を示します。適性(Aptitude)は比較的安定しているのに対し、信頼性の低さ(Unreliability)がシャード数2以上で急増している様子が分かります。</p>
<div class="content-box">
<h4><i class="fas fa-chart-area"></i> 実験結果の概要</h4>
<p><span class="keyword">Figure 6c</span>に、GPT-4oとGPT-4o-miniの2つのモデルを用いた段階的シャーディング実験の結果がまとめられています。</p>
<p>主な発見は、<span class="highlight">両モデルとも、2シャード以上の指示から「Lost in Conversation」現象（適性の軽微な低下と信頼性の低さの大幅な増加）を示す</span>ということです。言い換えれば、この実験結果は、<span class="highlight">情報不足を伴い、かつ2ターン以上続く会話であれば、どんなものでもモデルが「会話に迷う」</span>ことを示唆しています。</p>
<div class="bubble-box">
<p><i class="fas fa-user-friends"></i> <strong>ユーザーにとっての意味:</strong></p>
<p>情報をどの程度の細かさで指定するかは、モデルの信頼性に大きな影響を与えません。<span class="highlight">全ての情報を一度に（1シャードで）提供することが、信頼性を向上させる唯一の効果的な方法</span>であると言えます。</p>
<p>つまり、途中で情報を小出しにするよりも、最初からできるだけ多くの情報をまとめて伝える方が、LLMは安定して良い結果を出しやすいということです。</p>
</div>
</div>
<div class="info-grid">
<div class="info-card glass-card">
<p class="framework-title"><i class="fas fa-stream"></i> 「Lost in Conversation」発生の閾値</p>
<p>この実験から、シャード数が1（全情報一括提示）から2（最小限の分割）に変わるだけで、モデルの信頼性が急激に低下することが示されました。これは、複数ターンにわたる情報の統合という行為自体が、現在のLLMにとって大きな課題であることを意味しています。</p>
</div>
<div class="info-card glass-card">
<p class="framework-title"><i class="fas fa-puzzle-piece"></i> シャーディングの粒度の影響は小さい</p>
<p>シャード数を2から8へと増やしていっても、信頼性の低さは既に高いレベルにあり、そこから劇的に悪化したり改善したりするわけではありません。これは、一度「複数ターンで情報を追う」モードに入ると、その情報の分割の度合いよりも、複数ターンであること自体が問題となる可能性を示唆しています。</p>
</div>
</div>
</div>
<div class="section-card" id="7_Implications">
<h2 class="section-title"><i class="fas fa-lightbulb"></i>7 Implications (示唆)</h2>
<p>このセクションでは、本研究の実験結果と分析から得られた知見が、大規模言語モデル（LLM）の応用システムやエージェントを構築する人々、LLMそのものを開発する人々、自然言語処理（NLP）の研究者、そして実際に対話型AIシステムを利用するユーザーにとって、それぞれどのような重要な意味を持つのかを掘り下げて考察します。🔍</p>
<p>具体的には、LLMがマルチターンの会話で情報をどのように処理し、どのような課題があるのか、そしてそれに対して各々の立場でどのように対処・改善していけるのか、具体的な提言や注意点を提示します。このセクションを読むことで、LLMをより効果的に活用し、また将来のLLM開発の方向性を考える上でのヒントが得られるでしょう。✨</p>
<h3 class="subsection-title"><i class="fas fa-cogs"></i>7.1 Implications for System and Agent Builders (システムおよびエージェント構築者への示唆)</h3>
<div class="content-box">
<p>LLMを活用したアプリケーションを開発する際、私たちはしばしば複雑なタスクに直面します。例えば、問題を細かく分解したり、関連情報を探し出したり、外部ツールを使ったり、特定の行動を指示したりといった具合です。これらの処理は、<span class="keyword">エージェントフレームワーク</span>（例えば、AutoGen <a href="#ref-84">[84]</a> や LangChain <a href="#ref-8">[8]</a> のようなもの）によってオーケストレーションされるのが一般的です。エージェントフレームワークは、システム開発者がLLMの呼び出しを個々の部品（ブロック）のように組み合わせて、一連の処理の流れ（ワークフロー）を作るのを助けます。</p>
<div class="bubble-box">
<p>🤔 ここで一つの疑問が生まれます。もしエージェントフレームワークがユーザーとのやり取りをうまく調整し、LLMを単に一度きりの処理（シングルターンオペレーター）として使えるなら、LLM自体に複雑な複数回のやり取り（マルチターン）をこなす能力は本当に必要なのでしょうか？ エージェントが肩代わりできるなら、LLMはもっと単純で良いのでは？</p>
</div>
<p>この疑問に答えるため、私たちは2種類のエージェント風の会話シミュレーション方法を試してみました：<span class="highlight">RECAP</span> と <span class="highlight">SNOWBALL</span> です。どちらの方法も、ユーザーの発言をLLMに渡す前に前処理を行います。</p>
<ul class="unstyled-list">
<li><span class="badge blue">RECAP</span>: 基本的には以前説明した <span class="keyword">SHARDED</span> シミュレーションと同じように会話が進みますが、最後に特別なユーザーターンが追加されます。このターンでは、それまでの<strong>全てのユーザーの発言が要約</strong>されてLLMに伝えられます。</li>
<li><span class="badge purple">SNOWBALL</span>: こちらはもっと段階的に情報を積み重ねていく方法です。各ターンで、ユーザーシミュレーターは新しい情報のかけら（シャード）を提示すると同時に、<strong>それまでに提示された全てのシャードを再度繰り返します</strong>。雪だるま式に情報が増えていくイメージです。</li>
</ul>
<p>これらのシミュレーションタイプの目的は、過去のユーザーの発言情報を繰り返し提示することで、その情報をLLMにとってより目立たせ、LLMがその<span class="keyword">冗長性（redundancy）</span>を利用して応答の質を改善する機会を与えることです。</p>
<p class="reference">（実験の詳細については、論文のAppendix Mを参照してください。）</p>
<img alt="Table 2: Experimental Results with RECAP and SNOWBALL" src="table3.png" style="width: 80%; margin-bottom: 15px;"/>
<div class="note-box">
<p class="note-title"><i class="fas fa-table"></i>表2の解説：RECAPとSNOWBALL戦略を用いた追加実験結果</p>
<p>この表は、4つのタスク（コード生成、データベース操作、数学問題、アクション実行）において、2つのモデル（GPT-4o, GPT-4o-mini）で実験した結果をまとめたものです。<span class="keyword">RECAP</span>と<span class="keyword">SNOWBALL</span>は、どちらもユーザーターンの情報を繰り返すことで、モデルが会話の途中で混乱する（"lost in conversations"）のを軽減しようとする戦略です。</p>
<p>結果を見ると、RECAPもSNOWBALLも、元の<span class="keyword">SHARDED</span>シミュレーションと比較していくらかの改善効果を示しています。しかし、それでも全ての情報を最初から与える<span class="keyword">FULL</span>や、シャード化された情報をまとめて一度に与える<span class="keyword">CONCAT</span>の性能には及びませんでした。</p>
<p>RECAPはSNOWBALLよりも良い結果を出していますが、RECAPは会話の最後のターンで介入を行うため、実際のユーザーとのやり取りでは最後のターンがいつ来るか事前に分からないので、<span class="highlight">非現実的な設定</span>である点に注意が必要です。</p>
<p>一方、SNOWBALLは、ユーザーターンの情報を繰り返し提示することで達成可能な現実的な性能向上の度合いを示唆しています。具体的には、<span class="keyword">FULL</span>設定から<span class="keyword">SHARDED</span>設定への性能低下を <span class="highlight">15～20%</span> 程度軽減できることが分かりました。</p>
</div>
<div class="framework-box">
<p class="framework-title"><i class="fas fa- conclusión"></i>結論として…</p>
<p>エージェント風のフレームワークに情報処理を頼るだけでは限界があるかもしれません。私たちは、LLM自体が<span class="keyword">ネイティブにマルチターン対話をサポートする能力を持つべき</span>だと主張します。これにより、より自然で効果的なユーザーインタラクションが実現できるでしょう。📝</p>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-brain"></i>7.2 Implications for LLM Builders (LLM構築者への示唆)</h3>
<div class="content-box">
<p>LLMの能力向上、つまり、より複雑な知的タスクを達成できるようにするためには、これまで多くの努力が注がれてきました。最近では、LLMが数学オリンピックで競争したり、「人類最後の試験（Humanity’s Last Exam）」<a href="#ref-62">[62]</a> と名付けられたベンチマークで博士課程レベルの技術的な問題を解決できることが示されています。📚</p>
<div class="challenge-box">
<p class="challenge-title"><i class="fas fa-exclamation-triangle"></i> 本研究からの呼びかけ</p>
<p>私たちはLLM構築者に対し、彼らが構築するモデルの<span class="keyword">信頼性 (reliability)</span> を優先するよう強く求めます。私たちの実験は、LLMによるテキスト生成に伴う<span class="keyword">ランダム性</span>が、テストした全てのモデルにおいて壊滅的な信頼性の低さを引き起こし、結果として平均的なLLMユーザーが目にする応答の質を低下させていることを示しています。📉</p>
</div>
<p>LLMは確率的なシステムであり、<span class="keyword">温度 (temperature)</span>のようなパラメータを使ってテキスト生成時のランダム性の度合いを調整できます。ここで、「温度を最低設定（例：T=0）にすれば、生成プロセスがより決定的（完全にではないですが）になるため、信頼性の問題は実質的に解決するのではないか？」という議論が考えられます。🤔</p>
<p>この点を評価するため、私たちは追加実験を行いました。アシスタントが応答を生成する際の温度（AT: Assistant Temperature）を1.0、0.5、0.0の3つの値に変化させました。さらに、<span class="keyword">SHARDED</span>シミュレーションではLLMベースのユーザーシミュレーターを使用するため、ユーザー側の温度（UT: User Temperature）も同様に3つの値で変化させました。</p>
<p class="reference">（実験の詳細、サンプル選択、シミュレーション規模については、論文のAppendix Lを参照してください。）</p>
<img alt="Table 3: Unreliability of models with changing temperature" src="table4.png" style="width: 80%; margin-bottom: 15px;"/>
<div class="note-box">
<p class="note-title"><i class="fas fa-table"></i>表3の解説：アシスタント温度 (AT) とユーザー温度 (UT) を変更した際のモデルの非信頼性</p>
<p>この表は、<span class="badge blue">FULL</span>、<span class="badge purple">CONCAT</span>、<span class="badge orange">SHARDED</span>の各設定において、アシスタントの応答生成温度（AT）とユーザーシミュレーターの温度（UT）を変化させた場合のモデルの<span class="keyword">非信頼性 (Unreliability, U<sup>90</sup><sub>10</sub>)</span> を示しています。数値が低いほど、信頼性が高い（つまり非信頼性が低い）ことを意味します。</p>
<ul class="unstyled-list">
<li>📄 <span class="keyword">FULL</span> および <span class="keyword">CONCAT</span> 設定 (表の最初の2行): GPT-4o-miniとGPT-4oの両モデルで、アシスタント温度 (AT) を下げると信頼性が大幅に向上しました。具体的には、非信頼性 (U<sup>90</sup><sub>10</sub>) が約<span class="highlight">50%低下</span>しました。これは、シングルターンの状況では温度を下げることが信頼性向上に繋がることを示しています。</li>
<li>🔄 <span class="keyword">SHARDED</span> 設定: こちらの結果はより深刻です。
                    <ul>
<li>GPT-4o-miniでは、アシスタント温度 (AT) を下げても、どのユーザー温度 (UT) 設定においても信頼性の改善は見られませんでした。</li>
<li>GPT-4oでは、わずかな改善 (15-20%程度) しか見られませんでした。</li>
<li>驚くべきことに、ユーザーとアシスタントの両方の温度を0.0に設定しても、依然として約<span class="highlight">30%という高い非信頼性</span>が残りました。</li>
</ul>
</li>
</ul>
<p>理論上、言語モデルは温度 T=0.0 で決定的であるべきですが、現代のLLMでは実際にはそうではないことが知られています（詳細はAppendix Nで議論）。大まかに言うと、シングルターンの会話は逸脱の余地が限られています。しかし、マルチターンの会話では、初期のターンでのわずか1トークンの違いが、その後の会話全体に連鎖的な逸脱を引き起こす可能性があります。これが、我々が観察した非信頼性の停滞の原因と考えられます。🌪️</p>
</div>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-bullseye"></i>結論と提言</p>
<p>マルチターン対話が関わる設定では、応答生成時にLLMの<span class="keyword">温度を低く設定することは、システム全体の信頼性向上には効果がない</span>ことが分かりました。</p>
<p>そこで、私たちはLLM構築者に対して、モデルの<span class="keyword">能力 (aptitude)</span> と<span class="keyword">信頼性 (reliability)</span> を<strong>同時に最適化する</strong>ことを提案し、挑戦を促します。信頼性の高いLLMとは、以下の条件を満たすべきです：</p>
<ol class="unstyled-list">
<li><span class="badge yellow">1</span> シングルターンとマルチターンの両方の設定で、同程度のタスク達成能力を示すこと。</li>
<li><span class="badge yellow">2</span> マルチターン設定において、非信頼性が小さいこと (具体的には U<sup>90</sup><sub>10</sub> &lt; 15)。</li>
<li><span class="badge yellow">3</span> これらの性能を、標準的な温度設定 (T=1.0など、調整されていない状態) で達成できること。これは、基盤となる言語モデルが、言語生成において自然に発生する多様な変動に対応できることを示すものです。</li>
</ol>
<p>これらの目標を達成することが、LLMをより実用的で頼りになるツールにするための鍵となります。🔑</p>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-flask"></i>7.3 Implications for NLP Practitioners (NLP研究者への示唆)</h3>
<div class="content-box">
<p>私たちの実験は、同じ指示内容であっても、<span class="keyword">シングルターン</span>（一度の指示で完結）と<span class="keyword">マルチターン</span>（複数回のやり取りで情報を補完）の設定では、モデルの振る舞いが大きく異なることを示しています。例えば、性能や信頼性が大幅に低下するといった重要な違いが見られました。これはNLP研究者にとって注目すべき点です。🔬</p>
<p>私たちが最初に選んだ6つのタスクは、プログラミングから複数文書の要約まで、幅広い種類の生成タスクをカバーするように意図しました。しかし、これらのタスクセットにはいくつかの限界があります。例えば、主に英語の指示に焦点を当てている点や、分析的な（つまり、創造的ではない）タスクが中心である点です。✍️</p>
<p>私たちは、<span class="keyword">シャーディングプロセス</span>（指示を小さな情報単位に分割するプロセス）を効率的に行うために努力しました。LLMで処理できる部分は自動化しつつ、品質を確保するために手作業での検証と最終確認も行いました。このシャーディングプロセス（詳細はAppendix C参照）は、100個のシャード化された指示を準備し最終化するのに、平均して著者1人あたり3時間の手作業（プロンプトの調整や内容の検査など）が必要でした。⏳</p>
<div class="bubble-box">
<p><i class="fas fa-lightbulb"></i> NLP研究者への提案</p>
<p>私たちはNLPの研究者の皆さんに、<span class="highlight">シャーディングという手法を試してみて、皆さんが使っているタスクや指示セットの「シャード化バージョン」を作成し、従来の完全な形で指定されたバージョンと併せて公開する</span>ことを推奨します。これにより、マルチターン環境下でのモデル評価がより進むと期待されます。🚀</p>
</div>
<p>新しいタスクにシャーディングを適用することの実現可能性を示し、シャーディングに適したタスクの条件を理解するために、私たちは7番目のタスクとして<span class="keyword">翻訳 (Translation)</span> タスクのシャード化指示を準備しました。</p>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-language"></i> 翻訳タスクの詳細</p>
<p>このタスクは、ドイツ語の文書（10文）を英語に翻訳するものです。WMT 2019の文書レベル翻訳データセット <a href="#ref-70">[70]</a> からペア文書を利用しました。</p>
<ul class="unstyled-list">
<li><span class="badge orange">SHARDED設定</span>: 各ターンで、翻訳元のドイツ語文書から新たに追加の2文が提示されます。アシスタントは、その時点までに提示された全ての文を翻訳するよう求められます。</li>
<li><span class="badge blue">FULL設定</span> &amp; <span class="badge purple">CONCAT設定</span>: 最初のターンで文書全体（10文全て）が提示されます。</li>
</ul>
<p>評価には、標準的な<span class="keyword">BLEUスコア</span> <a href="#ref-58">[58]</a> を用いました。</p>
<p class="reference">（具体的な実装詳細はAppendix Iに記載されています。）</p>
</div>
<img alt="Table 4: Performance on the translation task" src="table5.png" style="width: 80%; margin-bottom: 15px;"/>
<div class="note-box">
<p class="note-title"><i class="fas fa-table"></i>表4の解説：翻訳タスクにおける性能 (FULL, CONCAT, SHARDEDシミュレーション)</p>
<p>この表は、翻訳タスクにおける各シミュレーション設定での性能（BLEUスコア）を示しています。</p>
<p>テストした両モデル（GPT-4o-mini と GPT-4o）は、<span class="keyword">SHARDED設定でも性能の低下を示しませんでした</span>。全てのシミュレーション設定において、BLEUスコアの差は10%以内でした。📊</p>
<p>この結果から、以下の2点が考えられます：</p>
<ol>
<li>過去の研究では翻訳を文書レベルで捉えるものもありましたが <a href="#ref-64">[64]</a>、実際にはこの翻訳タスクは大部分が<span class="highlight">文レベルで達成可能</span>であること。</li>
<li>BLEUスコア自体が、文書レベルの細かなニュアンスを十分に捉えられていない可能性 <a href="#ref-52">[52]</a>。</li>
</ol>
<p>つまり、タスクが<span class="keyword">エピソード的 (episodic)</span> である場合（すなわち、ターンごとのサブタスクに分解できる場合）、モデルはマルチターンの文脈全体を複雑に処理しなくても、各サブタスクを個別に完了することで会話中に「迷子」になるのを避けられるのです。要するに、この<span class="keyword">SHARDED翻訳タスク</span>は、情報が不足している（underspecified）状態ではないマルチターン会話をシミュレートしていると言えます。🧩</p>
</div>
<p>次に、マルチターン設定でモデルが会話中に「迷子」になりやすいと考えられるタスクの特性を挙げます：</p>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));">
<div class="info-card">
<div class="icon-item"><i class="fas fa-pen-fancy"></i></div>
<h4>1. 生成的タスク (Generative Tasks)</h4>
<p>情報を抽出する質問応答（extractive QA）や分類タスクとは異なり、新しいコンテンツの編集や洗練を伴うタスク（例：文章作成、コーディング）は、モデルが混乱しやすくなります。</p>
</div>
<div class="info-card">
<div class="icon-item"><i class="fas fa-puzzle-piece"></i></div>
<h4>2. 十分な複雑性 (Sufficient Complexity)</h4>
<p>タスクが複数の明確な仕様を含み、それらが多数のシャード（情報のかけら）を生み出す程度に複雑であるべきです。例えば、「1+1を計算するPythonプログラムを書け」という指示は、シャード化するには単純すぎます。</p>
</div>
<div class="info-card">
<div class="icon-item"><i class="fas fa-link-slash"></i></div>
<h4>3. 非分解可能な解 (Non-decomposable Solution)</h4>
<p>解決策や答えが、個々の部分に分解できない性質を持つべきです。つまり、新しいシャードが提示されると、解決策全体が修正されるようなタスクです（翻訳タスクでは、追加のシャードは既存の翻訳に追加するだけなので、これとは異なります）。</p>
</div>
</div>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-flask"></i>仮説</p>
<p>上記の3つの特性を持つタスクでLLMをテストした場合、<span class="keyword">SHARDED</span>シミュレーションにおいて平均性能と信頼性が大幅に低下し、モデルは会話中に「迷子」になりやすいと私たちは仮説を立てています。今後の研究でこの仮説を検証していくことが重要です。🧪</p>
</div>
</div>
<h3 class="subsection-title"><i class="fas fa-users"></i>7.4 Implications for Users of Conversational Systems (対話型システムのユーザーへの示唆)</h3>
<div class="content-box">
<p>LLMベースの製品を利用するユーザーは、特に<span class="keyword">マルチターン設定</span>（複数回のやり取り）において、LLMの<span class="keyword">信頼性が低い</span>可能性があることを認識しておく必要があります。一般的に利用可能な生成技術はまだ新しく、過去の研究でもLLMが生成するテキストの<span class="keyword">ランダム性</span>がユーザーにとって混乱の原因となる点が指摘されています <a href="#ref-55">[55, 81, 77, 43]</a>。😵</p>
<p>LLMベースのシステムとのやり取りを最大限に活用するために、2つの実用的な推奨事項を提案します。👇</p>
<div class="two-column">
<div class="column">
<div class="glass-card">
<h4><i class="fas fa-redo"></i> 1. 時間が許せば、やり直してみる (If time allows, try again)</h4>
<p>もしLLMとの会話が期待した結果に至らなかった場合、<span class="highlight">進行中の会話を続けるよりも、同じ情報を繰り返して新しい会話を始める</span>方が、大幅に良い結果が得られる可能性があります。これは、現在のLLMが会話の途中で「迷子」になることがあり、私たちの実験でも、迷子になったモデルとの会話を続けても効果がないことが示されているためです。さらに、LLMはランダム性をもってテキストを生成するため、新しい会話では改善された結果が得られるかもしれません。🔄</p>
</div>
</div>
<div class="column">
<div class="glass-card">
<h4><i class="fas fa-file-alt"></i> 2. やり直す前に、情報を整理・統合する (Consolidate before retrying)</h4>
<p>LLMは複数のターンに分散した情報を扱うのが苦手なため、<span class="highlight">指示の要件を一つの指示にまとめる</span>ことは、モデルの能力と信頼性を向上させる効果的な戦略です（これは<span class="keyword">CONCAT</span>実験の結果からも示唆されます）。ユーザーがモデルが会話中に迷子になっていることに気づいたら、LLMに「<span class="highlight">これまでに私が伝えたことを全てまとめてください</span>」と依頼し、その応答を新しい会話に持ち込むことで、手動で情報をまとめる手間を省くことができます。✍️</p>
<p>実際、LLMベースのアプリケーションの初期の採用者は、LLMが会話中に迷子になることを認識しているという逸話的な証拠があります。例えば、CursorというLLMベースのコーディング環境のユーザーは、ツールが会話を無期限に続けられるにもかかわらず、「できる限り頻繁に」新しい会話を作成することが、高品質な応答を確保するための推奨戦略であると報告しています。<sup>3</sup></p>
</div>
</div>
</div>
<div class="note-box">
<p class="note-title"><i class="fas fa-exclamation-circle"></i> 現状の課題と将来への期待</p>
<p>これらの2つの推奨事項は、依然としてユーザーにとって手間がかかり、根本的な解決策というよりは応急処置的なものに過ぎません。🩹 将来的にLLMがマルチターンの会話をより確実に扱えるようになれば、このような推奨事項の必要性は薄れ、ユーザーはモデルが会話中に迷子になるリスクを低減しつつ、複数のターンにわたって情報が不足した指示を自然に伝えることができるようになるはずです。🌟</p>
<p class="reference">3: Cursorユーザーの報告に関する注釈は論文本文の脚注を参照。</p>
</div>
</div>
</div>
<div class="section-card" id="8_Conclusion">
<h2 class="section-title"><i class="fas fa-flag-checkered"></i>8 Conclusion</h2>
<!-- 論文の主な目的と論旨 -->
<div class="glass-card" style="margin-bottom: 30px; padding: 25px; border: 1px solid rgba(74, 111, 165, 0.3);">
<p style="text-align: center; font-size: 17px; font-family: 'Yomogi', cursive; color: var(--color-dark);">
<i class="fas fa-paper-plane" style="color: var(--color-primary); font-size: 20px;"></i>
            この論文の締めくくりとして、私たちが実施した研究から得られた<span class="highlight">核心的な発見</span>と、それが示唆する<span class="keyword">今後の展望</span>、特に大規模言語モデル（LLM）開発者への<span class="highlight">重要な提言</span>を明確にまとめます。
        </p>
</div>
<!-- 研究の概要 -->
<div class="content-box">
<h3 class="subsection-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-cogs"></i>本研究の核心：LLMの会話能力の深掘り</h3>
<p style="font-size: 15px;">
            本研究では、現代のAI技術の中核をなす<strong>大規模言語モデル（LLM）</strong><i class="fas fa-brain" style="color: var(--color-accent2); margin-left: 5px;"></i>が、人間とどのように対話するかに焦点を当てました。具体的には、<span class="keyword">シングルターン会話</span>（ユーザーとLLMが一往復で完結する単純なやり取り）と、より複雑な<span class="keyword">マルチターン会話</span>（複数回にわたる連続的なやり取り）の両方について、<span class="highlight">大規模かつ体系的なシミュレーション実験</span>を実施しました。
            <i class="fas fa-comments" style="color: var(--color-primary); margin-left: 5px;"></i>
</p>
<div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(220px, 1fr)); margin-top: 20px;">
<div class="feature-item" style="border: 2px dashed var(--color-accent1); padding: 15px;">
<i class="fas fa-user-friends fa-2x" style="color: var(--color-accent1); margin-bottom: 10px;"></i>
<p style="font-family: 'Yomogi', cursive; font-size: 16px; color: var(--color-accent1);"><strong>シングルターン会話</strong></p>
<p style="font-size: 13px;">例：「今日の天気は？」→「晴れです」</p>
</div>
<div class="feature-item" style="border: 2px dashed var(--color-accent2); padding: 15px;">
<i class="fas fa-comments fa-2x" style="color: var(--color-accent2); margin-bottom: 10px;"></i>
<p style="font-family: 'Yomogi', cursive; font-size: 16px; color: var(--color-accent2);"><strong>マルチターン会話</strong></p>
<p style="font-size: 13px;">例：「旅行プランを立てたい」→「どこへ？」→「沖縄」→「何泊？」...</p>
</div>
</div>
</div>
<div class="arrow-connector" style="margin: 30px 0;"></div>
<!-- 主要な発見1: パフォーマンス低下 -->
<div class="content-box">
<h3 class="subsection-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-chart-line-down"></i>衝撃の発見：マルチターン会話での性能低下</h3>
<p style="font-size: 15px;">
            実験の結果、驚くべき事実が明らかになりました。特定のタスク群において、LLMのパフォーマンスは、<span class="highlight" style="background-color: rgba(255,126,95,0.2);">マルチターンで、かつユーザーからの指示や情報が不十分な設定（<span class="keyword">underspecified settings</span>）</span>において、<span style="font-weight: bold; color: var(--color-secondary); font-size:16px;">著しく低下する</span>ことが確認されたのです。
            <i class="fas fa-sliders-h" style="color: var(--color-secondary); margin-left: 5px;"></i>
</p>
<div class="note-box" style="border-left-color: var(--color-secondary); background-color: rgba(255,126,95,0.05); margin-top:15px;">
<p class="note-title" style="color:var(--color-secondary);"><i class="fas fa-search-minus"></i>用語解説：<span style="font-family: 'Yomogi', cursive;">「Underspecified settings」</span>とは？</p>
<p style="font-size: 13px;">これは、ユーザーがタスクを依頼する際に、<span class="highlight">必要な情報全てを最初から明確に伝えない状況</span>を指します。例えば、「このデータで何か面白い分析をして」といった曖昧な指示から始まり、会話を通じて徐々に詳細を詰めていくようなケースです。現実のコミュニケーションでは頻繁に起こり得ますね。✏️</p>
</div>
</div>
<div class="arrow-connector" style="margin: 30px 0;"></div>
<!-- 「会話で迷子になる」現象 -->
<div class="bubble-box" style="border-color: var(--color-accent2); margin-top: 40px; padding: 25px 20px;">
<span style="position: absolute; top: -20px; left: 50%; transform: translateX(-50%); background: white; padding: 5px 15px; font-weight: bold; color: var(--color-accent2); font-family: 'Yomogi', cursive; font-size: 18px; border: 2px solid var(--color-accent2); border-radius: 15px;"><i class="fas fa-map-signs"></i> LLMは会話で"迷子"になる！ <i class="fas fa-dizzy"></i></span>
<p style="margin-top: 25px; font-size: 15px;">
            このパフォーマンス低下は、まるでLLMが<span class="keyword" style="font-size:16px;">「会話の途中で道に迷ってしまう」</span>かのような現象として現れます。この「迷子」状態は、モデルの<span class="highlight" style="background-color: rgba(255,126,95,0.3); padding: 3px 6px; border-radius: 4px;">信頼性の大幅な低下</span>という形で具体化します。その主な原因は以下の通りです：
        </p>
<div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 15px; margin-top: 20px;">
<div class="info-card" style="border-left: 4px solid var(--color-accent2); background-color: rgba(149,117,205,0.05);">
<div style="display: flex; align-items: center; margin-bottom: 8px;">
<i class="fas fa-layer-group fa-fw fa-lg" style="color: var(--color-accent2); margin-right: 10px;"></i>
<h4 style="margin:0; font-family: 'Yomogi', cursive; color: var(--color-accent2);">文脈維持の困難</h4>
</div>
<p style="font-size: 13px;">複数の会話ターンを跨いで、<span class="keyword">重要な文脈情報（以前のやり取りの内容）を正確に記憶・活用し続ける</span>のに苦労する。</p>
</div>
<div class="info-card" style="border-left: 4px solid var(--color-accent3); background-color: rgba(255,213,79,0.05);">
<div style="display: flex; align-items: center; margin-bottom: 8px;">
<i class="far fa-lightbulb fa-fw fa-lg" style="color: var(--color-accent3); margin-right: 10px;"></i>
<h4 style="margin:0; font-family: 'Yomogi', cursive; color: var(--color-accent3);">時期尚早な仮定</h4>
</div>
<p style="font-size: 13px;">まだ情報が不十分な段階で、<span class="keyword">ユーザーの意図や必要な詳細について早まった仮定</span>をしてしまう。</p>
</div>
<div class="info-card" style="border-left: 4px solid var(--color-secondary); background-color: rgba(255,126,95,0.05);">
<div style="display: flex; align-items: center; margin-bottom: 8px;">
<i class="fas fa-history fa-fw fa-lg" style="color: var(--color-secondary); margin-right: 10px;"></i>
<h4 style="margin:0; font-family: 'Yomogi', cursive; color: var(--color-secondary);">過去応答への過度な依存</h4>
</div>
<p style="font-size: 13px;"><span class="keyword">自身が以前に生成した応答（それが誤りを含んでいても）に過度に固執</span>し、新しい情報に基づいて柔軟に修正できない。</p>
</div>
</div>
<div style="text-align: center; margin-top: 25px;">
<i class="fas fa-compass-slash fa-3x" style="color: var(--color-secondary); animation: spin 4s linear infinite;"></i>
<style>@keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }</style>
<p style="font-family: 'Yomogi', cursive; color: var(--color-secondary); font-size: 16px; margin-top: 10px;">その結果、LLMはユーザーの期待から外れた応答をしてしまい、信頼性が大きく損なわれるのです... <i class="fas fa-face-sad-tear" style="color: var(--color-secondary);"></i></p>
</div>
</div>
<div class="arrow-connector" style="margin: 30px 0;"></div>
<!-- 追加実験の結果: 既存の改善策の効果なし -->
<div class="content-box">
<h3 class="subsection-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-tools"></i>既存の対策は効果薄：追加実験からの示唆</h3>
<p style="font-size: 15px;">
            私たちはさらに、このマルチターン会話における性能低下問題に対して、<span class="highlight">既知の改善策</span>が有効かどうかを検証する追加実験を行いました。具体的には、以下のような手法を試しました。
        </p>
<div class="info-grid" style="grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 15px;">
<div class="info-card" style="border-top: 5px solid var(--color-primary);">
<div style="text-align: center; margin-bottom: 10px;">
<i class="fas fa-link fa-2x" style="color: var(--color-primary);"></i>
</div>
<h4 style="text-align:center; font-family: 'Yomogi', cursive; color: var(--color-primary); margin-bottom: 8px;">エージェント風の連結 (Agent-like concatenation)</h4>
<p style="font-size: 13px;">これは、会話の履歴全体を毎回LLMへの入力に含めることで、文脈を強制的に維持させようとするアプローチです。より単純な設定では効果が確認されています。📝</p>
</div>
<div class="info-card" style="border-top: 5px solid var(--color-accent1);">
<div style="text-align: center; margin-bottom: 10px;">
<i class="fas fa-thermometer-quarter fa-2x" style="color: var(--color-accent1);"></i>
</div>
<h4 style="text-align:center; font-family: 'Yomogi', cursive; color: var(--color-accent1); margin-bottom: 8px;">生成時の温度パラメータ低下 (Decreasing temperature)</h4>
<p style="font-size: 13px;">LLMがテキストを生成する際の<span class="keyword">「温度 (temperature)」</span>パラメータを下げることで、より決定的で予測可能な応答を促す手法です。温度が高いと創造的で多様な応答が、低いと事実に基づいた一貫性のある応答が出やすくなります。🌡️</p>
</div>
</div>
<div class="challenge-box" style="margin-top: 25px; padding: 20px; background-color: rgba(255, 126, 95, 0.08);">
<p class="challenge-title" style="font-size: 17px; font-family: 'Kaisei Decol', serif;"><i class="fas fa-exclamation-triangle"></i> 結果：既存策はマルチターンでは力不足</p>
<p style="font-size: 15px;">
                しかし、これらの改善策は、<span class="highlight" style="background-color: rgba(255,126,95,0.3);">マルチターン設定においては効果が限定的である</span>ことが判明しました。つまり、単純な状況で上手くいった方法も、複雑な会話の文脈ではLLMの「迷子」を防ぐには至らなかったのです。
                <i class="fas fa-times-circle" style="color: var(--color-secondary); margin-left: 5px;"></i>
</p>
</div>
</div>
<div class="arrow-connector" style="margin: 30px 0;"></div>
<!-- LLM開発者への提言 -->
<div class="framework-box" style="border-color: var(--color-primary); background-color: rgba(74, 111, 165, 0.03); padding: 25px; margin-top:20px;">
<h3 class="framework-title" style="font-size: 20px; color: var(--color-primary); border-bottom: 2px solid var(--color-primary); padding-bottom: 10px; display:flex; align-items:center; justify-content:center;">
<i class="fas fa-bullhorn" style="margin-right: 12px; font-size: 24px;"></i>
<span style="font-family: 'Kaisei Decol', serif;">LLM開発者の皆様へ：緊急提言</span>
<i class="fas fa-lightbulb" style="margin-left: 12px; font-size: 24px; color: var(--color-accent3);"></i>
</h3>
<p style="text-align: center; font-size: 16px; margin-top: 20px; line-height: 1.6;">
            この研究結果を踏まえ、私たちはLLMの開発者の方々に対し、<br/>
<span class="highlight" style="font-size: 18px; padding: 5px 10px; background-color: rgba(92, 184, 92, 0.2); border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
<i class="fas fa-star" style="color: var(--color-accent1);"></i>
<strong style="color: var(--color-accent1); font-family: 'Yomogi', cursive;">マルチターン設定におけるモデルの信頼性向上</strong>
<i class="fas fa-shield-alt" style="color: var(--color-accent1);"></i>
</span><br/>
            を、今後の開発における<span class="keyword" style="font-size: 17px;">最優先課題の一つとして取り組む</span>ことを強く求めます。
        </p>
<div style="margin-top: 25px; display: flex; justify-content: center; align-items: center;">
<div style="border: 2px dashed var(--color-secondary); padding: 15px 25px; border-radius: 10px; text-align: center; background-color: white;">
<p style="font-family: 'Yomogi', cursive; font-size: 17px; color: var(--color-dark);">
<i class="fas fa-rocket" style="color: var(--color-secondary); margin-right: 8px;"></i>ユーザーが本当に頼れるAIアシスタントを実現するために、<br/>
<span style="font-weight: bold; color: var(--color-primary);">「賢さ」だけでなく「一貫性」と「信頼性」</span><br/>
                    を備えたLLMの開発が不可欠です。
                </p>
</div>
</div>
</div>
<div style="text-align: center; margin-top: 40px; padding-top: 20px; border-top: 1px dashed var(--color-gray);">
<p style="font-family: 'Kaisei Decol', serif; font-size: 16px; color: var(--color-gray);">
<i class="fas fa-feather-alt" style="margin-right: 8px;"></i>
            この結論が、より良い対話型AIの未来に向けた一歩となることを願っています。
        </p>
</div>
</div>
<div class="section-card" id="9_Limitations">
<h2 class="section-title"><i class="fas fa-exclamation-triangle"></i> 9 Limitations</h2>
<div class="glass-card">
<p>このセクションでは、本研究が持ついくつかの限界について詳細に説明します。これらの限界点を認識することは、本研究の成果を正しく理解し、今後の研究の方向性を定める上で非常に重要です。主な論点は以下の3つに集約されます。</p>
<ul class="unstyled-list" style="padding-left: 20px; margin-top: 10px; margin-bottom: 10px;">
<li><i class="fas fa-robot" style="color: var(--color-accent1); margin-right: 8px;"></i><strong>全自動シミュレーションへの依存:</strong> LLMを用いたユーザーシミュレーションは実験の大規模化・効率化に貢献しましたが、実際の人間とAIの対話とは異なる特性を持つ可能性があります。</li>
<li><i class="fas fa-tasks" style="color: var(--color-accent2); margin-right: 8px;"></i><strong>分析タスクへの集中:</strong> 実験対象を分析的なタスクに限定したため、クリエイティブなタスクなど、より自由度の高い対話におけるLLMの挙動については未検証です。</li>
<li><i class="fas fa-language" style="color: var(--color-accent3); margin-right: 8px;"></i><strong>テキストのみ・英語のみのタスク:</strong> 英語のテキストデータに限定したため、他の言語やマルチモーダルな情報（画像、音声など）を含むタスクへの一般化可能性は今後の課題です。</li>
</ul>
<p>これらの限界を踏まえ、本研究の結果を慎重に解釈し、さらなる研究へと繋げていく必要があります。</p>
</div>
<h3 class="subsection-title"><i class="fas fa-cogs"></i> 9.1 全自動シミュレーションへの依存</h3>
<div class="content-box">
<p>この研究の最初の、そして重要な限界点は、<span class="keyword">完全に自動化されたシミュレーションに依存している</span>という点です。我々は、大規模言語モデル（LLM）を用いてユーザーの発話をシミュレートする手法を採用しました。これにより、実験の規模を拡大し、同じシミュレーションを複数回実行することが可能になりました。これは、実際の人間を実験参加者として動員する場合には、<span class="highlight">コストの観点から非常に困難</span>です。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-lightbulb"></i> LLMによるユーザーシミュレーションのメリット</p>
<p>なぜLLMでユーザーをシミュレートしたのでしょうか？主な理由は以下の通りです。</p>
<ul style="list-style-type: none; padding-left: 10px;">
<li><i class="fas fa-expand-arrows-alt" style="color: var(--color-primary); margin-right: 5px;"></i><strong>スケーラビリティ:</strong> 多数の対話シナリオを生成し、大規模な実験が可能です。</li>
<li><i class="fas fa-redo" style="color: var(--color-primary); margin-right: 5px;"></i><strong>再現性:</strong> 条件を統制し、同じ実験を何度も繰り返すことができます。</li>
<li><i class="fas fa-dollar-sign" style="color: var(--color-primary); margin-right: 5px;"></i><strong>コスト効率:</strong> 人間の参加者を募るよりも低コストで実験を実施できます。</li>
</ul>
</div>
<p>しかし、このアプローチにはトレードオフが存在します。LLMによって生成されたシミュレーションは、残念ながら<span class="highlight">実際の人間とAI間の自然な会話を忠実に反映しているわけではありません</span>。</p>
<div class="challenge-box">
<p class="challenge-title"><i class="fas fa-exclamation-circle"></i> シミュレーションと現実の会話とのギャップ</p>
<p>シミュレートされた会話は、いくつかの要因により、現実の会話の複雑さや多様性を完全には捉えきれていません。</p>
</div>
<p><span class="keyword">シャーディングプロセス</span>（詳細は論文付録Cで定義されています。簡単に言うと、元の複雑な指示を小さな情報単位「シャード」に分割するプロセスです）の特性や、<span class="keyword">シミュレーション環境</span>（論文セクション3.2で詳述）の設計により、シミュレートされた会話は、現実の会話と比較して<span class="highlight">かなり限定的で画一的な構造</span>に従う傾向があります。このため、大規模で多様な実際のユーザー集団で見られるような、広範な会話のダイナミクスをモデル化できていない可能性が高いです。</p>
<div class="feature-card-grid">
<div class="feature-item">
<div class="icon-item"><i class="fas fa-stream"></i></div>
<p><strong>画一的な会話構造</strong></p>
<p>シミュレーションは、設計されたルール（シャーディングプロセスや環境設定）に厳密に従うため、会話の流れがある程度予測可能なものになります。</p>
</div>
<div class="feature-item">
<div class="icon-item"><i class="fas fa-users-slash"></i></div>
<p><strong>多様なユーザー行動の欠如</strong></p>
<p>実際のユーザーが見せる予期せぬ質問、話題の転換、誤解、感情表現といった多様な行動パターンをシミュレーションで再現するのは困難です。</p>
</div>
</div>
<p>具体的に、シミュレーションプロセスには以下のような制約があり、これらが現実の会話との乖離を生んでいます。</p>
<div class="info-grid">
<div class="info-card">
<h4><i class="fas fa-info-circle" style="color: var(--color-secondary); margin-right: 5px;"></i>情報の逐次開示の厳密さ</h4>
<p>シミュレーションでは、各対話ターンで<span class="keyword">新しい情報のかけら（シャード）が1つだけ開示</span>され、会話の最終ターンにはタスクを完了するために必要な<span class="highlight">全ての情報が指定される</span>ことが保証されています。しかし、実際のユーザーとの対話では、ユーザーが情報を出し惜しみしたり、逆に一度に多くの情報を伝えたり、途中で話題を変えたりと、このような整然とした情報開示が行われるとは限りません。</p>
<div class="bubble-box">
<p><strong><i class="fas fa-user-friends"></i> 現実のユーザーなら…</strong></p>
<p>「あ、そういえばこれも必要だった！」と後から情報を追加したり、「えっと、何から話せばいいかな…」と一度に情報を整理して伝えられなかったりすることがよくあります。</p>
</div>
</div>
<div class="info-card">
<h4><i class="fas fa-compress-arrows-alt" style="color: var(--color-secondary); margin-right: 5px;"></i>会話範囲の制限 (シャーディング特性による)</h4>
<p>シャーディングプロセスの特性である<span class="keyword">P1 (情報保存)</span>、<span class="keyword">P2 (明確な初期意図)</span>、そして<span class="keyword">P5 (最小限の変換)</span>（これらは論文付録Bで詳細に定義されています）も、シミュレートされる会話の範囲を制限する一因となっています。これらの特性により、シャード化された指示は既存の完全に指定された指示と内容的に非常に近しくなり、会話の<span class="highlight">高レベルな意図（目的）は常に最初のターンで特定される</span>ように設計されています。</p>
<div class="bubble-box">
<p><strong><i class="fas fa-book-open"></i> シャーディングの特性 (付録Bより)</strong></p>
<ul class="unstyled-list">
<li><span class="badge blue">P1</span> <strong>情報保存:</strong> 元の指示に含まれる、タスク完了に必要な情報がシャーディングプロセス中に失われないこと。</li>
<li><span class="badge blue">P2</span> <strong>明確な初期意図:</strong> 最初のシャードが、会話全体の高レベルな目的（例：「Python関数を書いて」）を定義すること。</li>
<li><span class="badge blue">P5</span> <strong>最小限の変換:</strong> シャード化の際に、元の指示の言語や意味をできるだけ変えず、P1-P4の特性を満たすための変更に留めること。</li>
</ul>
</div>
</div>
<div class="info-card">
<h4><i class="fas fa-puzzle-piece" style="color: var(--color-secondary); margin-right: 5px;"></i>シャードの「最小性」の非現実性</h4>
<p>各シャードが持つ情報の「最小性」も、現実の会話と比較すると非現実的であり、ある意味では<span class="highlight">モデルにとって意図的に不利（adversarial）な設定</span>と言えるかもしれません。ただし、<span class="keyword">段階的シャーディング実験</span>（論文6.3節）では、シャードの粒度（細かさ）が異なっていても、会話が2ターン以上に及ぶと、LLMの性能低下の度合いは同程度になることが示唆されています。つまり、情報が少しずつ与えられるという状況自体が、LLMにとって課題となるようです。</p>
</div>
</div>
<p>シャードの粒度以外にも、自動シミュレーションには、人間が会話に参加する場合に生じうる<span class="highlight">微妙なニュアンスが欠けています</span>。例えば、以下のような状況です。</p>
<div class="framework-box">
<p class="framework-title"><i class="fas fa-comments"></i> 人間との会話におけるニュアンスの例</p>
<ul style="list-style-type: '✏️ '; padding-left: 20px;">
<li><span class="keyword">専門用語の誤解:</span> ユーザーとAI間で、特定の言葉の解釈が食い違う。</li>
<li><span class="keyword">システムの失敗によるフラストレーションからの離脱 [82]:</span> AIの応答が期待外れだったり、エラーが続いたりすると、ユーザーはイライラして会話を諦めてしまう。</li>
<li><span class="keyword">特定の会話における実現可能な最終目標の欠如:</span> 例えば、ユーザーが未解決問題の解決策を求めるなど、そもそもAIが達成不可能な要求をする。</li>
</ul>
</div>
<p>これらの要因を考慮すると、我々が実施したシミュレーションは、LLMのマルチターン対話能力を試すための、<span class="highlight">比較的「穏やかな（benign）」テスト環境</span>であったと考えられます。シミュレーションの条件は、現実の複雑な対話状況に比べて<span class="keyword">過度に単純化されている</span>ためです。</p>
<p>この過度な単純化を考慮すると、本実験で観察されたLLMの性能低下は、LLMの<span class="highlight">信頼性の低さ</span>、そして実際の場面でLLMが<span class="keyword">会話中に「迷子」になる頻度</span>を<span class="highlight">過小評価している可能性が高い</span>と我々は考えています。これらの実験は、マルチターン環境におけるLLMを研究するための、スケーラブルで低コストな実験環境として機能しますが、その限界を認識することが重要です。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-flask"></i> シミュレーションの役割</p>
<p>本研究のシミュレーションは、現実の対話を完全に再現するものではなく、LLMが複数ターンにわたる情報提供にどのように応答するか、その基本的な能力と限界を、制御された環境下で調査するための「実験場」としての意味合いが強いです。</p>
</div>
<div class="arrow-connector"></div>
</div>
<h3 class="subsection-title"><i class="fas fa-brain"></i> 9.2 分析タスクへの集中</h3>
<div class="content-box">
<p>本研究の2番目の限界点は、<span class="keyword">分析的なタスクに焦点を当てている</span>ことです。我々は、プログラミングタスクと自然言語タスクの両方から多様なタスクセットを選びましたが、実験対象を<span class="highlight">分析的な解決策を伴うタスク</span>に限定しました。</p>
<div class="definition-box">
<p class="definition-title"><i class="fas fa-search"></i> 分析的タスクとは？</p>
<p>明確な正解や最適な解決策が存在し、論理的な思考や計算、データの解釈などを通じてその解に到達する種類のタスクを指します。例えば、数学の問題解決、コード生成、データベースクエリ作成などが該当します。</p>
</div>
<p>この制約は、我々の研究結果の<span class="highlight">適用範囲を限定</span>します。なぜなら、例えば<span class="keyword">クリエイティブ・ライティング [5]</span>のような、よりオープンエンドなタスク（明確な正解がなく、多様な答えが許容されるタスク）において、LLMが会話中に「迷子」になるかどうかを本研究では明らかにしていないからです。</p>
<div class="two-column">
<div class="column">
<div class="feature-item glass-card">
<div class="icon-item"><i class="fas fa-pencil-ruler"></i></div>
<p><strong>分析タスクの例 (本研究で採用)</strong></p>
<ul class="unstyled-list" style="text-align: left; padding-left: 15px;">
<li><span class="badge yellow">コード生成</span></li>
<li><span class="badge yellow">データベースクエリ</span></li>
<li><span class="badge yellow">API呼び出し</span></li>
<li><span class="badge yellow">数学問題</span></li>
<li><span class="badge yellow">データからのテキスト生成</span></li>
<li><span class="badge yellow">要約</span></li>
</ul>
</div>
</div>
<div class="column">
<div class="feature-item glass-card">
<div class="icon-item"><i class="fas fa-paint-brush"></i></div>
<p><strong>オープンエンドなタスクの例 (本研究では未検証)</strong></p>
<ul class="unstyled-list" style="text-align: left; padding-left: 15px;">
<li><span class="badge orange">物語の執筆</span></li>
<li><span class="badge orange">詩の作成</span></li>
<li><span class="badge orange">ブレインストーミング</span></li>
<li><span class="badge orange">自由な会話</span></li>
</ul>
</div>
</div>
</div>
<p>この選択は<span class="highlight">意図的なもの</span>でした。クリエイティブ・ライティングの評価についてはいくつかの進展が見られるものの、依然として<span class="keyword">活発な研究分野 [6]</span>であり、我々は初期の実験セットでは、より確立されたタスクと評価指標に依存することを選びました。</p>
<p><span class="highlight">クリエイティブなタスクにおいて性能低下が発生するのかどうか</span>、そしてもし発生する場合、その<span class="keyword">低下の規模</span>を特定することは、今後の研究における重要な方向性です。</p>
<div class="note-box">
<p class="note-title"><i class="fas fa-directions"></i> 今後の研究課題</p>
<p>創造的なタスクや、より主観的な評価が必要なタスクにおいても、LLMが複数ターンにわたる対話で同様の課題を示すのか、あるいは異なる挙動を示すのかを調査することは、LLMの能力を多角的に理解する上で不可欠です。</p>
</div>
<div class="arrow-connector"></div>
</div>
<h3 class="subsection-title"><i class="fas fa-globe-americas"></i> 9.3 テキストのみ・英語のみのタスクへの集中</h3>
<div class="content-box">
<p>本研究の3番目の限界点は、<span class="keyword">英語のテキストのみのタスクに焦点を当てている</span>ことです。</p>
<div class="challenge-box">
<p class="challenge-title"><i class="fas fa-language"></i> 言語とモダリティの制約</p>
<p>現在の研究は、主に英語のテキストベースの対話に限定されています。これは、LLMの汎用的なマルチターン対話能力を評価する上で、以下のような問いに答えることを難しくしています。</p>
</div>
<p>LLMが他の言語での会話中に「迷子」になるのかどうか、あるいはユーザーまたはアシスタントの発話に<span class="keyword">複数のモダリティ</span>（例えば、画像、音声、動画など）が関わるタスクで「迷子」になるのかどうかを明らかにすることは、LLMのマルチターン対話能力で観察された性能低下の<span class="highlight">範囲を確立する</span>のに役立つでしょう。</p>
<div class="info-grid">
<div class="info-card">
<h4><i class="fas fa-font" style="color: var(--color-accent1); margin-right: 5px;"></i> 他言語での検証</h4>
<p>本研究の知見は英語に基づいていますが、言語構造や文化的背景が異なる他の言語でLLMが同様の振る舞いを示すかは不明です。例えば、日本語のような高文脈言語や、形態論的に豊かな言語などでは、異なる課題が生じる可能性があります。</p>
<div class="bubble-box">
<p><strong><i class="fas fa-question-circle"></i> 例:</strong> 英語以外の言語で、情報の断片化（シャーディング）がLLMの理解にどう影響するか？</p>
</div>
</div>
<div class="info-card">
<h4><i class="fas fa-photo-video" style="color: var(--color-accent1); margin-right: 5px;"></i> マルチモーダルタスクでの検証</h4>
<p>現代のAIアシスタントは、テキストだけでなく、画像や音声といった複数のモダリティを扱うことが増えています。ユーザーが画像を見せながら指示を出したり、AIが音声で応答したりするような、より複雑な対話形式でLLMがどのように機能するかは重要な研究テーマです。</p>
<div class="bubble-box">
<p><strong><i class="fas fa-question-circle"></i> 例:</strong> 「この写真に写っている赤いオブジェクトについて説明して。あ、それから、その隣にある青いものは何？」のような、画像情報と複数ターンの指示が組み合わさった場合、LLMは情報を正しく統合できるか？</p>
</div>
</div>
</div>
<p>これらの点を検証することで、本研究で観察されたLLMのマルチターンにおける性能低下が、特定の言語やモダリティに限定された現象なのか、それともより普遍的な課題なのかを明らかにすることができます。これは、LLMの能力をより深く理解し、その応用範囲を広げる上で不可欠なステップとなります。</p>
</div>
</div>
<div class="section-card" id="Appendices">
<h2 class="section-title"><i class="fa-solid fa-book-open"></i> Appendices</h2>
<p class="content-box" style="font-size: 16px; text-align: center; border: 2px dashed var(--color-secondary); padding: 15px; border-radius: 10px;">
<i class="fa-solid fa-magnifying-glass" style="color: var(--color-primary);"></i> <strong>この付録 (Appendices) へようこそ！</strong> <br/>
        このセクションでは、論文の本文を補足する詳細な情報を提供します。具体的には、関連研究のより深い掘り下げ、本研究で用いた重要な概念（シャード化命令など）の厳密な定義、実験プロセスの詳細、追加の分析結果、そして実験で使用したプロンプトなどを網羅しています。これらの情報は、本文の主張を裏付け、研究の透明性と再現性を高めることを目的としています。情報系の大学院1年生の皆さんが、この論文の研究背景から手法、結果の解釈に至るまで、より深く理解するための一助となれば幸いです。さあ、一緒に詳細を探求していきましょう！ ✏️
    </p>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-microscope"></i> Appendix A: 関連研究 - 仕様記述不足について</h3>
<p>本論文の主題である「仕様記述不足(Underspecification)」は、LLMとの対話における重要な課題です。このセクションでは、本文で触れられなかった関連研究をさらに詳しく見ていきましょう。</p>
<div class="info-grid">
<div class="info-card">
<div class="icon-item"><i class="fa-solid fa-comments"></i></div>
<h4><i class="fa-solid fa-feather-pointed"></i> コミュニケーションと言語学における先行研究</h4>
<p>人間の言語において、「仕様記述不足」は一般的な特徴であると指摘されています。例えば、Lappin (2000) [<a class="reference-link" href="#ref-41">41</a>], Ferreira (2008) [<a class="reference-link" href="#ref-20">20</a>], Frisson (2009) [<a class="reference-link" href="#ref-22">22</a>], Pezzelle (2023) [<a class="reference-link" href="#ref-61">61</a>] などの研究が挙げられます。これらの研究は、曖昧さや情報の欠落がコミュニケーションにおいてどのように機能し、解釈されるかを探求しています。</p>
</div>
<div class="info-card">
<div class="icon-item"><i class="fa-solid fa-brain"></i></div>
<h4><i class="fa-solid fa-lightbulb"></i> LLMは仕様記述不足な指示をどう扱うか？</h4>
<p>LLMの対話能力向上のためには、LLMが仕様記述不足の指示をどのように処理するかを理解することが不可欠です。</p>
<ul class="unstyled-list">
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> Herlihyら (2024) [<a class="reference-link" href="#ref-27">27</a>] は、仕様記述不足のクエリに対するLLMの応答パターン（ためらい、拒否、明確化要求、質問など）を特定し、それらから回復するメカニズムを提案しました。</li>
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> Malaviyaら (2023) [<a class="reference-link" href="#ref-53">53</a>] は、仕様記述不足のクエリに対するLLM応答のより正確で原理に基づいた評価のためには、文脈情報のサポートが重要であると強調しました。</li>
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> Sarkarら (2025) [<a class="reference-link" href="#ref-69">69</a>] は、仕様記述不足を考慮してユーザーの指示を積極的に書き換えるシステムが、LLMの応答改善につながることを示しました。</li>
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> Shaikhら (2025) [<a class="reference-link" href="#ref-71">71</a>] は、対話ログにおけるLLMのグラウンディング（明確化やフォローアップ質問）の度合いを調査し、人間がフォローアップ質問をする可能性が15倍高いのに対し、LLMは著しく不足していることを観察しました。</li>
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> Changら (2025) [<a class="reference-link" href="#ref-7">7</a>] は、アノテーターにチャットインターフェースを通じて完全に指定された指示を手動で再現させたところ、ユーザーが指示の全体を明らかにするのは34%の時間であり、大半の時間は詳細が未指定のままであることを見出しました。</li>
</ul>
</div>
<div class="info-card">
<div class="icon-item"><i class="fa-solid fa-tasks"></i></div>
<h4><i class="fa-solid fa-vial"></i> 仕様記述不足に対処するモデル能力評価タスク</h4>
<p>いくつかの研究では、仕様記述不足に対処するモデルの能力を評価するための直接的なタスクが探求されています。</p>
<ul class="unstyled-list">
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> Liuら (2023) [<a class="reference-link" href="#ref-49">49</a>] は、自然言語推論ベンチマークAmbiEntを導入し、曖昧な文の理解が最先端のLLMにとっても依然として課題であることを明らかにしました。</li>
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> Wildenburgら (2024) [<a class="reference-link" href="#ref-83">83</a>] は、言語モデルが2つの文間の指定の相対的なレベルを決定する必要があるDUSTタスクを作成し、未指定の文を解釈する際にLMはほとんど不確実性を示さないことを見出しました。</li>
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> Vijayvargiyaら (2025) [<a class="reference-link" href="#ref-78">78</a>] は、未指定の設定でGitHubの問題解決のためのLLMエージェントを評価し、情報を補足するためのフォローアップ対話が解決率の向上に役立つものの、指示の曖昧さを検出することは依然として課題であることを示しました。</li>
</ul>
</div>
<div class="info-card">
<div class="icon-item"><i class="fa-solid fa-sitemap"></i></div>
<h4><i class="fa-solid fa-tags"></i> 仕様記述不足の根本原因の分類</h4>
<p>先行研究では、仕様記述不足のさまざまな根本原因が分類されています。</p>
<ul class="unstyled-list">
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> <strong>タスクの仕様記述不足</strong>: 人間が手元のタスクの不完全な記述を提供する場合に発生し、「仕様記述量の多いタスク」で顕著です (Pengら, 2023 [<a class="reference-link" href="#ref-60">60</a>])。</li>
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> <strong>意図の不一致</strong>: AIがユーザーの意図や動機を理解できない場合に発生し、ユーザーの不満の一般的な原因の1つです (Kimら, 2024 [<a class="reference-link" href="#ref-34">34</a>]; Terryら, 2023 [<a class="reference-link" href="#ref-76">76</a>])。</li>
<li><i class="fa-solid fa-check-circle" style="color: var(--color-accent1);"></i> <strong>場所と参照の曖昧さ</strong>: Minecraftゲームのような物理空間を含む具体化された設定における曖昧さです (Chaturvediら, 2024 [<a class="reference-link" href="#ref-9">9</a>])。</li>
</ul>
</div>
</div>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-puzzle-piece"></i> Appendix B: シャード化命令 (Sharded Instructions) の厳密な定義</h3>
<p>本文のセクション3.1ではシャード化の概念を概観しましたが、ここではより厳密な定義を見ていきましょう。まず数学的な用語を定義し、次に有効なシャード化命令が満たすべき特性を定義します。</p>
<div class="definition-box">
<div class="definition-title"><i class="fa-solid fa-calculator"></i> 数学的用語の定義</div>
<p>シングルターンの複雑なクエリを <span class="keyword">\(q\)</span> とし、その意図された（つまり正しい）出力を <span class="keyword">\(Y_q^*\)</span> とします。このクエリの<span class="keyword">アトミックコンテンツユニット (Atomic Content Units, ACU)</span> [51] を以下のように定義します。</p>
<div class="formula">
                $$ \boldsymbol{I}(\boldsymbol{q}) = [\mathcal{T}, (c_1, \dots, c_m)] $$
            </div>
<p>ここで、</p>
<ul>
<li><span class="keyword">\(\mathcal{T}\)</span> はクエリの<span class="highlight">主要な意図</span>です。</li>
<li><span class="keyword">\((c_1, \dots, c_m)\)</span> は、<span class="keyword">\(\mathcal{T}\)</span> を条件として <span class="keyword">\(Y_q^*\)</span> を計算する方法を特定する<span class="highlight">十分な明確化のセット</span>です。</li>
</ul>
<p><span class="keyword">\(I(q)\)</span> がアトミックであると見なされるためには、<span class="keyword">\(I(q)\)</span> のいかなる言い換えも同じターゲット出力を生成する必要があります。つまり、<span class="keyword">\(I(q') = I(q)\)</span> であるすべての <span class="keyword">\(q'\)</span> について、<span class="keyword">\(Y_{q'}^* = Y_q^*\)</span> となります。</p>
</div>
<div class="definition-box">
<div class="definition-title"><i class="fa-solid fa-stream"></i> シャード化命令の定義</div>
<p>上記の定義を踏まえ、与えられたクエリ <span class="keyword">\(q\)</span> に対するシャード化プロセスの目的は、アトミックコンテンツユニット <span class="keyword">\(I(q)\)</span> を特定し、より短い<span class="keyword">命令シャード (instruction shards)</span> <span class="keyword">s</span> のセットを構築することです。</p>
<div class="formula">
                $$ q' = [s_1, \dots, s_k] \quad \mathrm{s.t.} \quad I(q) = I(q') $$
            </div>
<p>ここで、シャード <span class="keyword">\(s_j\)</span> はマルチターンの対話をシミュレートするために使用でき、<span class="keyword">\(q\)</span> と同じ意図された出力を持ちます。</p>
</div>
<div class="framework-box">
<div class="framework-title"><i class="fa-solid fa-check-double"></i> 有効なシャード化命令の特性</div>
<p>シャード化命令 <span class="keyword">\(q'\)</span> が元のクエリ <span class="keyword">\(q\)</span> に対して有効であると見なされるためには、以下の特性を満たす必要があります。</p>
<div class="info-grid">
<div class="info-card glass-card">
<p><span class="badge blue">P1</span> <strong class="keyword">情報保存 (Information Preservation)</strong></p>
<p><span class="formula">\(\mathcal{I}(q) = \mathcal{I}(q')\)</span></p>
<p>元の命令から、命令の完了に必要な情報がシャード化プロセス中に失われてはなりません。</p>
</div>
<div class="info-card glass-card">
<p><span class="badge orange">P2</span> <strong class="keyword">明確な初期意図 (Clear Initial Intent)</strong></p>
<p><span class="formula">\(\mathcal{T}_q = \mathcal{T}_{q'}\)</span> かつ <span class="formula">\(s_1 = \mathcal{T}_q\)</span></p>
<p>最初のシャードは、シャードセット内の初期クエリとしての特徴的な役割を果たします。初期クエリは、対話全体の高レベルな目的を定義します (例: 「Python関数を書いて」)。</p>
</div>
<div class="info-card glass-card">
<p><span class="badge purple">P3</span> <strong class="keyword">順序非依存性 (Order Insensitive)</strong></p>
<p>最初のシャードを除き、他のシャードは文脈自由化 [13] され、順序を示唆するような相互参照があってはなりません。結果として、任意の順序で提示されたシャードセットは同等の情報を明らかにします。シャードの順序の置換を <span class="formula">\(\rho(\mathbf{s}_{2..k})\)</span> とすると、すべての <span class="formula">\(\tilde{\boldsymbol{q}} = [s_1, \rho(\mathbf{s}_{2..k})]\)</span> について <span class="formula">\(I(\boldsymbol{q}) = I(\tilde{\boldsymbol{q}})\)</span> となります。</p>
</div>
<div class="info-card glass-card">
<p><span class="badge accent1">P4</span> <strong class="keyword">最大シャード化 (Maximal Sharding)</strong></p>
<p>シャード化プロセスは、元の命令から抽出されるシャードの数（<span class="keyword">\(k\)</span> を最大化する）を最大化するよう努めるべきです。これは、単一の具体的な情報を導入するシャードを生成することで達成できます。</p>
</div>
<div class="info-card glass-card">
<p><span class="badge yellow">P5</span> <strong class="keyword">最小変換 (Minimal Transformation)</strong></p>
<p>シャード化命令は、命令の言語を維持し、元の命令の要素を単純化、変更、または解釈することを可能な限り避けるべきです。特性P1-P4を満たすための変更を除き、シャード化プロセスは、シャード <span class="formula">\([s_1, \dots, s_k]\)</span> がアトミックコンテンツユニット <span class="formula">\(I(q)\)</span> と意味的に類似するように変更を制限するよう試みるべきです。</p>
</div>
</div>
</div>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-cogs"></i> Appendix C: 半自動シャード化プロセス</h3>
<p>完全に指定された命令をシャード化された同等物に変換するために、半自動プロセスに依存しています。このプロセスは図7に示されており、3つの自動ステップ（セグメンテーション、リフレーミング、検証）のシーケンスと、それに続く論文の著者によって行われた手動ステップで構成されています。</p>
<img alt="図7: 半自動シャード化プロセスの図解" class="figure-image" src="table1.png"/>
<p class="caption" style="text-align: center; font-style: italic;">図7: 半自動シャード化プロセスの図解。GSM8Kの例を使用しています。</p>
<div class="pipeline">
<div class="pipeline-step">
<div class="step-number">1</div>
<div class="step-content">
<h4><i class="fa-solid fa-scissors"></i> ステップ1: セグメンテーション (Segmentation)</h4>
<p>元の完全に指定された命令（図7の左端の列）が与えられると、LLMは命令のセグメントを抽出するよう促されます。セグメントは、アトミックコンテンツユニット（付録Bで定義）に対応することを意図しています。特に、プロンプトは、セグメントが重複してはならず、元の命令のすべての単語がセグメントに属する必要はないことを示しています。プロンプトはタスク固有であり、セグメンテーションの概念を例を通して説明できるように、少なくとも3つの少数ショット例を組み込んでいます。この段階で、3つ未満のセグメントしか生成しない命令は除外され、次の段階には進みません。</p>
</div>
</div>
<div class="pipeline-step">
<div class="step-number">2</div>
<div class="step-content">
<h4><i class="fa-solid fa-pen-ruler"></i> ステップ2: リフレーミング (Rephrasing)</h4>
<p>元の完全に指定された命令と抽出されたセグメントが与えられると、この段階では、各セグメントを文脈自由化 [13] し、会話的に書き直します。つまり、セグメント間の依存関係が解決され、得られたシャードが特性P2およびP5に準拠するように順序が変更されます。上記の例では、4番目のセグメント（オレンジ色で強調表示）が全体の意図を明らかにするため最初のシャードになり、他のシャードでは軽い言い換えが行われます。リフレーミングプロンプトはタスク固有であり、セグメント化された命令のリフレーミングの少数ショット例が含まれています。</p>
</div>
</div>
<div class="pipeline-step">
<div class="step-number">3</div>
<div class="step-content">
<h4><i class="fa-solid fa-clipboard-check"></i> ステップ3: 検証 (Verification)</h4>
<p>ステップ1-2では、SHARDEDおよびCONCAT会話のシミュレーションに使用できるシャード化命令が生成されます。セグメンテーションと言い換え中に情報が失われていないという特性P1（情報保存）を検証するために、元の命令とシャード化命令を並べて評価する予備シミュレーションを実施します。具体的には、元の命令とシャード化命令の各ペアについて、元の命令で10回のFULL会話、シャード化命令で10回のCONCAT会話（シャードを連結することによって）、および10回のSHUFFLE-CONCAT会話をシミュレートします。SHUFFLE-CONCATは、すべてのシャード（シャード1を除く）が連結される前にランダムに並べ替えられるCONCATシミュレーションの変形です。この変形は、特性P3（順序非依存性）を検証する、CONCATのより敵対的なバージョンと見なすことができます。各シミュレーションタイプについて、10回の実行で平均パフォーマンス \(\overline{P}\) を計算し、許容される劣化しきい値を下回る命令を除外します。具体的には、以下の条件が満たされた場合に命令は許容されます。</p>
<div class="formula">
                        $$ \overline{P}_{\mathrm{CONCAT}} \geq 0.8 \overline{P}_{\mathrm{FULL}} $$
                        $$ \overline{P}_{\mathrm{SHUFFLE-CONCAT}} \geq 0.8 \overline{P}_{\mathrm{FULL}} $$
                    </div>
<p>ここで、\(\overline{P}_X\) はシミュレーションタイプXの平均パフォーマンスを示します。より大きな劣化が観察された場合（つまり、80%未満）、シャード化中に情報が失われた可能性、または文脈自由化が正確に実装されなかった可能性を示します。</p>
</div>
</div>
<div class="pipeline-step" style="margin-bottom:0;">
<div class="step-number">4</div>
<div class="step-content">
<h4><i class="fa-solid fa-user-edit"></i> ステップ4: 検査と編集 (Inspect and Edit)</h4>
<p>最初の3つのステップはシャード化プロセスを定義し、ある程度の品質保証を実装していますが、LLMの出力に依存するため、正確で大規模な実験に必要な品質レベルを保証するものではありません。高品質のシャードを得るために、ステップ4を手動検査と検証のために確保しています。この手順を容易にするために、Webベースのアノテーションインターフェースを開発しました。インターフェースでは、アノテーターは完全に指定された命令とシャード化命令のペアを確認し、個々のシャードを編集、追加、または削除し、シャード化命令を受け入れるか拒否するかを決定できます。実験に含まれるシャード化命令はすべて、論文の2人の著者によって手動でレビューされました。この最終段階で必要な編集とフィルタリングの量はタスクによって異なりました。</p>
</div>
</div>
</div>
<div class="note-box">
<div class="note-title"><i class="fa-solid fa-hourglass-half"></i> 作業時間について</div>
<p>自動生成された命令の検査と編集には、通常、命令あたり1〜3分かかります。これは、著者が完全に指定された命令から新たにシャード化命令を作成する場合と比較して、桁違いに少ない時間です。オープンソースリリースの一環として、シャード化中に使用されたすべてのプロンプトを提供しており、これが追加タスクのシャード化を容易にすることを期待しています。</p>
</div>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-binoculars"></i> Appendix D: シミュレートされたシャード化会話の検査</h3>
<p>シャード化シミュレーション環境（セクション3で説明）は、ユーザーをシミュレートし、アシスタントの応答を分類し、自由形式の応答から回答を抽出するためにLLMコンポーネントに依存しています。LLMベースのコンポーネントは失敗する可能性があり、シミュレーションエラーのレベルと、エラーによるアシスタントLLMのパフォーマンス推定への潜在的な影響を理解するために、200のシミュレートされたSHARDED会話の検査を実行しました。</p>
<img alt="表5: 4つのタスクにわたる100のシミュレートされたシャード化会話の検査結果" class="figure-image" src="table6.png"/>
<p class="caption" style="text-align: center; font-style: italic;">表5: 4つのタスク（アクション、コード、数学、データベース）にわたる100のシミュレートされたシャード化会話の検査結果。最初の列は、4つのタスクの注釈結果を集計しています。</p>
<p>検査された各会話について、ユーザーのターン、アシスタントのターン、および会話全体を5つの特定の要素で注釈付けしました。</p>
<div class="two-column">
<div class="column">
<div class="bubble-box">
<h5><i class="fa-solid fa-user-pen"></i> ユーザー発話の注釈</h5>
<ul class="unstyled-list">
<li><span class="badge blue">シャード完全開示 (Shard Fully Revealed)</span>: 発話がシャード化命令の1つのシャードからの情報を正確に明らかにしたかどうか。特に、複数のシャードを明らかにしたターンや、シャードを部分的にしか明らかにしなかったターンをフラグ付けしました。</li>
<li><span class="badge orange">シャード文脈化 (Shard Contextualized)</span>: 各ユーザーのターンが会話の中で適切に文脈化されているかどうか。例えば、前のアシスタントのターンが二者択一の明確化質問（はい/いいえ）をした場合、適切な文脈化では、アシスタントの応答に直接対処するために「はい/いいえ」の応答が必要になります。</li>
</ul>
</div>
</div>
<div class="column">
<div class="bubble-box">
<h5><i class="fa-solid fa-robot"></i> アシスタント発話の注釈</h5>
<ul class="unstyled-list">
<li><span class="badge purple">戦略精度 (Strategy Accuracy)</span>: 分類された戦略が正確であったかどうか。例えば、応答が明確化としてラベル付けされている場合、それがユーザーに明確化の質問をしているかどうかを確認します。</li>
<li><span class="badge accent1">抽出成功 (Extraction Success)</span>: アシスタントの発話が回答試行としてラベル付けされた場合、回答抽出ステップが成功したかどうかをさらにラベル付けしました。</li>
</ul>
</div>
</div>
</div>
<p>各ユーザーとアシスタントの発話の検査を完了すると、シミュレーション中に発生したエラー（もしあれば）がシミュレーション全体の妥当性に影響したかどうかについて、会話全体にグローバルラベルを割り当てました。そうでない場合、シミュレーションは成功（<span class="keyword">Overall Success</span>）としてマークされました。</p>
<div class="note-box">
<div class="note-title"><i class="fa-solid fa-tasks"></i> 検査対象タスク</div>
<p>アクション、コード、数学、データベースの4つのタスクの会話を検査しました。他の2つ（要約とデータからテキストへ）は、各ターンで回答試行を必要とする洗練タスクであり、LLMベースのユーザーシミュレータに依存しません。そのため、シミュレーションエラーの範囲は限定的です。</p>
</div>
<p>表5は検査注釈の結果をまとめたものです。全体として、シミュレーション環境は信頼性が高く、検査された会話の約<span class="highlight">98%が成功</span>とラベル付けされています。各コンポーネントでいくつかのエラーが発生します。ユーザーシミュレーションでは、単一のシャードが完全に開示されるのは約<span class="highlight">96%</span>の時間であり、適切に文脈化されるのは<span class="highlight">98%</span>の時間です。アシスタントの応答の処理でもエラーが発生します。ターン戦略分類の精度は<span class="highlight">95%</span>にすぎず、回答試行の抽出の精度は<span class="highlight">97%</span>です。</p>
<p>発話レベルのエラーが常に全体的なシミュレーションの妥当性に影響を与えるわけではありませんでした。場合によっては、ユーザーシミュレータが初期のターンのエラーを会話の後半で修正したり、誤った回答試行での回答抽出のエラーがターンで発生したが、後で抽出が成功したりすることが観察されました。要約すると、シミュレーション環境はほぼ正確であることが経験的にわかります。いくつかのエラーは発生しますが、SHARDED設定でのパフォーマンスの大幅な低下（2%を超える）は、シミュレータによって引き起こされるエラーによるものではありません。</p>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-chart-line"></i> Appendix E: 適性 (Aptitude) と信頼性 (Reliability) の低下の具体例</h3>
<p>LLMの性能評価における「適性」と「信頼性」の概念を具体的に理解するために、仮想的な例を考えてみましょう。10個の指示があり、それぞれに対してFULL（完全指定、シングルターン）とSHARDED（シャード化、マルチターン）のシミュレーションを10回ずつ行うとします。LLMの平均性能（\(\overline{P}\)）が、FULL設定で90%、SHARDED設定で60%だったと仮定します。</p>
<p>まず、FULL設定での性能がどのように達成されたかを見てみましょう。仮に、10個の指示のうち9個については完璧な性能（10回の試行全てで成功スコア100）を達成し、残りの1個の指示では全ての試行で失敗（スコア0）したとします。</p>
<div class="formula">
        $$ S_{ij}^{\mathrm{FULL}} = \begin{cases} 100, &amp; \text{if } i \in \{1, \dots, 9\} \\ 0, &amp; \text{if } i = 10 \end{cases} $$
        </div>
<p>ここで \(S_{ij}^{\mathrm{FULL}}\) は \(i\) 番目の指示における \(j\) 番目のシミュレーション実行のスコアを表します。この場合、FULL設定でのLLMの適性（\(A\)）は90%、非信頼性（\(U\)）は0%となります（各指示において、10パーセンタイルと90パーセンタイルのスコアが等しいため）。</p>
<img alt="図8: 様々な状況の図解" class="figure-image" src="aptitude_vs_reliability_illustration.jpg"/>
<p class="caption" style="text-align: center; font-style: italic;">図8: 様々な状況の図解。各グリッドの緑と赤の塗りはサンプルレベルのスコア（例：合格/完全一致）を示します。FULL（左上）と比較して、SHARDEDの3つの状況は同じ \(\overline{P}=60\) を達成しつつ、適性 \(A\) と非信頼性 \(U\) が異なります。</p>
<p>次に、SHARDED設定で平均性能 \(\overline{P}=60\%\) を達成する3つの異なる状況を考えます（図8参照）。</p>
<div class="info-grid">
<div class="info-card glass-card">
<div class="icon-item"><i class="fa-solid fa-arrow-trend-down" style="color: var(--color-secondary);"></i></div>
<h4>状況1: 適性の低下</h4>
<p>LLMが10個の指示のうち6個で完璧な性能を達成し、残り4個では失敗する場合：</p>
<div class="formula">
                $$ S_{ij}^{\mathrm{SHARDED}} = \begin{cases} 100, &amp; \text{if } i \in \{1, \dots, 6\} \\ 0, &amp; \text{if } i \in \{7, \dots, 10\} \end{cases} $$
                </div>
<p>この状況では、\(\overline{P}=60\%\)、\(A=60\%\)、\(U=0\%\) となります。性能低下は完全に<span class="highlight">適性の低下</span>によって説明され、信頼性は変わりません。</p>
</div>
<div class="info-card glass-card">
<div class="icon-item"><i class="fa-solid fa-dice" style="color: var(--color-accent2);"></i></div>
<h4>状況2: 信頼性の低下</h4>
<p>LLMが10個の指示のうち9個で混合した性能（各指示で6～7回の完璧なスコア）を達成し、1個は失敗する場合：</p>
<div class="formula">
                $$ S_{ij}^{\mathrm{SHARDED}} = \begin{cases} 100, &amp; \text{if } 1 \leq i \leq 3, 1 \leq j \leq 6 \\ 100, &amp; \text{if } 4 \leq i \leq 9, 1 \leq j \leq 7 \\ 0, &amp; \text{otherwise} \end{cases} $$
                </div>
<p>この状況では、\(\overline{P} \approx 60\%\)、\(A \approx 90\%\)、\(U \approx 90\%\) となります。性能低下は完全に<span class="highlight">信頼性の大幅な低下</span>によって説明され、シャード化設定と完全指定設定の適性はほぼ等しくなります。</p>
</div>
</div>
<div class="bubble-box">
<h4><i class="fa-solid fa-balance-scale"></i> 状況3: 適性と信頼性の両方の低下 (より現実的なシナリオ)</h4>
<p>実際には、状況1や2のような極端なケースよりも、適性と信頼性の両方が低下する組み合わせが発生する可能性が高いです。例えば、LLMが3つの指示で完璧な性能を達成し、5つの指示で混合した性能（各指示で6回の完璧なスコア）、残り2つで失敗する場合：</p>
<div class="formula">
            $$ S_{ij}^{\mathrm{SHARDED}} = \begin{cases} 100, &amp; \text{if } 1 \leq i \leq 3 \\ 100, &amp; \text{if } 4 \leq i \leq 8, 1 \leq j \leq 6 \\ 0, &amp; \text{otherwise} \end{cases} $$
            </div>
<p>この状況3では、\(\overline{P} = 60\%\)、\(A = 80\%\)、\(U = 60\%\) となります。完全指定シミュレーションと比較して、非信頼性の増加（0%から60%へ）が適性の減少（90%から80%へ）よりも大きくなっています。これは、<span class="highlight">私たちの観察結果と一致</span>しており、性能低下は適性の小さな低下と信頼性の大きな低下によって説明されることが多いことを示しています。</p>
</div>
<div class="note-box">
<div class="note-title"><i class="fa-solid fa-ruler-combined"></i> 連続的なメトリクスへの適用</div>
<p>この具体例では、シミュレートされた会話の結果にバイナリ スコア（0 と 100）を使用しましたが、適性（A）と非信頼性（U）の概念は、BLEUのような連続的なメトリクスにも同様に適用できます。</p>
</div>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-magnifying-glass-chart"></i> Appendix F: シミュレーションログの定性的分析</h3>
<p>このセクションでは、本実験（セクション6.1）のシミュレーションコーパスに対する定性分析を報告します。この分析の目的は、性能低下につながるモデルの振る舞いの根本原因を明らかにすることです。以下に4つの振る舞いを特定し、各項目について分析を提供します。</p>
<div class="feature-card-grid">
<div class="feature-item">
<div class="icon-item"><i class="fa-solid fa-bolt" style="color: var(--color-accent3);"></i></div>
<p><strong>1. 時期尚早な回答試行</strong><br/>LLMは問題全体に時期尚早に答えようとする。</p>
</div>
<div class="feature-item">
<div class="icon-item"><i class="fa-solid fa-clone" style="color: var(--color-primary);"></i></div>
<p><strong>2. 過去の誤答への過度な依存</strong><br/>LLMは以前の（誤った）回答試行に過度に依存し、より長く「肥大化」した回答につながる。</p>
</div>
<div class="feature-item">
<div class="icon-item"><i class="fa-solid fa-eye-slash" style="color: var(--color-secondary);"></i></div>
<p><strong>3. 最終ターンへの過度な調整</strong><br/>LLMは最後の会話ターンに基づいて回答を過度に調整し、中間ターンの顕著な忘却によって具体化される。</p>
</div>
<div class="feature-item">
<div class="icon-item"><i class="fa-solid fa-comment-dots" style="color: var(--color-accent1);"></i></div>
<p><strong>4. 過度に冗長な回答</strong><br/>LLMは過度に冗長な回答を生成し、これはユーザー発話から注意をそらす問題の仮定を導入する可能性が高い。</p>
</div>
</div>
<div class="framework-box">
<div class="framework-title">F.1 時期尚早な回答試行 (Premature Answer Attempts)</div>
<p>SHARDEDシミュレーション中、応答は7クラスの会話戦略分類に従って分類されます。特に、各アシスタント応答は、正式な回答試行であるかどうかタグ付けされます（回答試行はさらなる処理、つまりタスク固有の評価者による抽出と評価を必要とするため）。</p>
<p>会話の開始時、LLMは情報量が最も少なく（仕様記述不足のレベルが最も高い）、正しい回答試行を定式化する可能性が最も低くなります。したがって、早い段階で解決策を提案すると、その中に特定の誤った要素が埋め込まれ、その後の会話での相互作用に誤った影響を与える可能性があります。</p>
<img alt="表6: LLMが最初の回答試行を行う会話の早さに基づく平均性能（P）の内訳" class="figure-image" src="table7.png"/>
<p class="caption" style="text-align: center; font-style: italic;">表6: LLMが最初の回答試行を行う会話の早さに基づく平均性能（\(\overline{P}\)）の内訳。コードと数学の2つのタスクのシミュレーションで分析を実施。</p>
<p>この仮説を評価するために、実験からのすべてのシミュレートされた会話を、LLMによって最初の回答試行が生成される会話の早さに基づいてビンに分類します。具体的には、最初の回答試行が会話の最初の20%のターン以内に発生する場合は0-20%のビンを作成し、会話の後のターンで発生する場合は20-40%、40-60%、60-80%、および80-100%のビンを作成します。実験に含まれる6つのタスクのうち、2つ（数学とコード）のみが、回答試行のタイミングに関してLLMの行動に有意な範囲を観察しました。他の4つのタスクでは、モデルはほとんどの場合、最初のターンから回答を試行するため、このパラメータに関する分析は不可能です。</p>
<p>残りの2つのタスクの分析結果を表6に示します。すべての単一モデルについて、最初の回答試行が遅い会話の方が平均性能が高いことがわかります。すべてのモデルで、最初の試行が会話の最初の20%で行われる会話は30.9のスコアを達成し、LLMが会話の最後の20%で回答試行を行う場合の64.4の半分未満です。</p>
<p class="highlight" style="padding: 10px; border-left: 3px solid var(--color-accent1);">つまり、<span class="keyword">時期尚早な回答試行はLLMの性能を低下させる</span>ことがわかります。モデルが完全な回答試行の生成に移る前に、ユーザーの指示を明確にしたり、問題を高いレベルで議論したりする会話の方が、性能が高くなります。これは、モデルが時期尚早な解決策で誤った仮定を行い、それが後のターンの後続のユーザー指示と矛盾するためであると仮説を立てています。</p>
</div>
<div class="arrow-connector"></div>
<div class="framework-box">
<div class="framework-title">F.2 マルチターン会話における回答の肥大化 (Answer Bloat)</div>
<p>マルチターン会話シミュレーションでは、LLMは複数の回答試行を行う可能性があり、後続の各試行は以前の試行に基づいている可能性があります。対照的に、シングルターン会話は会話のダイナミクスを制約し、LLMは単一の、最初で最後の回答試行を行います。</p>
<p>マルチターン会話のダイナミクスを理解するために、各シミュレーションタイプにおける回答試行の平均長を計算します。SHARDED設定については、シミュレーション内の各試行の平均長を計算します（つまり、最初の試行、2番目の試行、3番目の試行などの平均長）。ここで読者の皆様にご注意いただきたいのは、この分析はアシスタントの応答全体ではなく、抽出された回答試行（図3の回答抽出モジュールからの出力）に対して行われているということです。抽出された回答は、応答全体（さまざまな量の無関係なコンテンツを含む可能性がある）ではなく、回答試行（生成されたSQLクエリやPython関数など）のダイナミクスをより正確に測定します。</p>
<img alt="図9: 4つのタスクにおける回答試行ごとの平均回答長（文字数）。SHARDED設定では回答が徐々に長くなる（肥大化する）傾向が見られる。" class="figure-image" src="https://via.placeholder.com/800x300?text=Figure+9:+Answer+Bloat+Effect+(Placeholder)" style="width:80%; margin: 10px auto;"/>
<p class="caption" style="text-align: center; font-style: italic;">図9: 4つのタスクにおける回答試行ごとの平均回答長（文字数）。SHARDED設定では回答が徐々に長くなる（肥大化する）傾向が見られる。(論文中のFigure 9を引用)</p>
<p>分析の結果を図9にプロットします。4つのタスク全体で、FULLおよびCONCAT設定での回答長は類似する傾向があり、通常、互いに2～10%の範囲内です。分析されたタスクのうち3つ（コード、データベース、要約）では、SHARDED設定での最初の回答試行はFULLおよびCONCATの対応物と類似した長さを持ちますが、後続の各回答試行では、平均回答長の増加が観察されます。この効果により、SHARDED会話の最終的な回答試行（4つのプロットの右側部分）は、FULLおよびCONCAT設定で生成されたソリューションよりも20～300%長くなる傾向があります。この観察結果を<span class="keyword">回答肥大化効果</span>と名付けます。マルチターン会話が進行するにつれて、LLMは誤った回答試行を生成し、未指定のままの命令の部分について仮定を行います。ユーザーが後続のターンで追加情報を明らかにすると、LLMは以前の仮定を正常に無効にできず、以前の試行に過度に依存します。マルチターン、仕様記述不足の会話における回答の肥大化は、シングルターン相当のものと比較して長いソリューションにつながります。</p>
<div class="note-box">
<div class="note-title"><i class="fa-solid fa-code"></i> コードとデータベースタスクでの追加分析</div>
<p>コードとデータベースのタスクのみに焦点を当て、LLMが完全に正しいソリューション（スコア100.0）に到達したシミュレーションにフィルタリングして追加分析を実行します。コードタスクの場合、SHARDED設定から得られた正しいプログラムは平均850文字の長さであり、これはFULL設定で生成された正しいソリューション（平均668文字）よりも27%多くの文字です。データベースの場合、SHARDED設定の正しいSQLクエリは平均129文字であり、FULL設定のもの（113文字）よりも14%多くの文字です。要約すると、LLMはマルチターン設定で正しいソリューションに到達する可能性が低く（\(\overline{P}\) が低い）、到達した場合でも、到達する最終的なソリューションは長く（肥大化しており）、ソリューションの品質が低いことを示唆しています。</p>
</div>
</div>
<div class="arrow-connector"></div>
<div class="framework-box">
<div class="framework-title">F.3 会話の最終ターンに基づく過度な調整 (Over-adjust based on Last Turn)</div>
<p>要約タスクでは、アシスタントが要約を引用を通じてドキュメントに帰属させる必要があるため、マルチターン会話が進行するにつれてLLMがどの情報ターンに注意を払うかを分析するユニークな機会が提供されます。念のため、要約タスクでは、ユーザーが各ターンで新しいドキュメントを導入します。したがって、私たちの分析の焦点は、ドキュメント導入順序（ターン全体）がLLMがドキュメントを引用する可能性に影響するかどうかを理解することです。</p>
<img alt="図10: 引用されたドキュメントが導入されたターンXの分布" class="figure-image" src="https://via.placeholder.com/600x400?text=Figure+10:+Citation+Distribution+(Placeholder)" style="width:70%; margin: 10px auto;"/>
<p class="caption" style="text-align: center; font-style: italic;">図10: 引用されたドキュメントが導入されたターンXの分布。(論文中のFigure 10を引用)</p>
<p>図10に分析結果をプロットします。各行は、シャード化シミュレーションの特定のターンで生成された要約の分析に対応しています。ターン1（一番上の行）では、引用されたドキュメントの96%が最初のターンで導入されました。不足している4%は、導入されなかったドキュメントへの幻覚引用に対応しており、なぜどの行の分布も100%にならないのかを説明しています。ターン2（上から2番目の行）では、要約にはターン1とターン2のドキュメントがほぼ同程度の割合で引用されています（つまり、48%と49%）。</p>
<p>これは、2ターン会話では、LLMがいずれのターンのドキュメントにもほぼ等しく注意を払うことを意味すると解釈します。シャード化シミュレーションのターン3～8で生成された要約の分析では、LLMが引用するドキュメントに不均衡が見られます。8ターン目の要約では、引用の20%がターン8で導入されたドキュメントに対するものであり、ターン2および3からの8%と比較して150%の差があります。大まかに言うと、会話が進行するにつれて、LLMは最初または最後のターンのドキュメントを引用する可能性が最も高く、中間（中間）ターンで導入されたドキュメントを引用する可能性は低くなります。この発見は、LLMが提供された文脈の最初または最後にあるドキュメントに注意を払い、中間文脈コンテンツを犠牲にするという「中間での喪失」現象の発見を反映しています[29, 50, 40]。要するに、<span class="keyword">「中間での喪失」現象は、シングルターンの長文脈設定だけでなく、マルチターン会話でも発生する</span>ことを観察します。この現象を<span class="keyword">「中間ターンの喪失 (loss-in-middle-turns)」</span>と名付けます。</p>
<div class="note-box">
<div class="note-title"><i class="fa-solid fa-layer-group"></i> モデル間の差異</div>
<p>図10に示されている分析は、本実験に含まれる15のLLM全体の数値を平均化していることに注意してください。すべてのモデルである程度の「中間ターンの喪失」が観察されますが、効果の大きさはモデルによって異なり、通常、より高性能なモデルほど効果は抑制され、複数の文脈ターンにわたって帰属を処理する能力が高いことを示しています。この研究ではモデル固有の分析は含まず、将来の研究に委ねます。</p>
</div>
</div>
<div class="arrow-connector"></div>
<div class="framework-box">
<div class="framework-title">F.4 過度に冗長なアシスタントの応答 (Overly-verbose Assistant Responses)</div>
<p>共通の指示に基づいて複数の会話をシミュレートすると、特にLLMによって生成される応答の長さにおいて、応答にばらつきが見られます。冗長性（応答の長さ）がモデルの性能にどのように影響するかを理解するために、冗長性分析を実行します。</p>
<img alt="表7: 6つの実験タスクにおけるLLMの平均性能（P）、モデルの相対的な冗長性（応答の長さ）に基づいて配置" class="figure-image" src="table8.png"/>
<p class="caption" style="text-align: center; font-style: italic;">表7: 6つの実験タスクにおけるLLMの平均性能（\(\overline{P}\)）、モデルの相対的な冗長性（応答の長さ）に基づいて配置。6つのタスクのうち5つで、モデルがより長い応答を生成すると性能が低下します。</p>
<p>冗長性を評価する上での1つの難点は、タスクや指示によって必要な冗長性のレベルが異なる場合があることです。例えば、Python関数を生成するには、SQLクエリを生成するよりも長い応答が必要になる可能性があります。タスク固有のばらつきを正規化するために、（LLM、指示）タプルごとに計算された冗長性タグを割り当てます。LLMが指示に対して行う各シミュレートされたシャード化会話について、ターンごとの応答の平均長（アシスタントの応答の総文字数をターン数で割ったもの）を計算します。次に、このメトリックに従って会話を五分位数に分類します。</p>
<p>より具体的には、各（モデル、指示）ペアに対して \(N=10\) の会話をシミュレートしたため、五分位数ごとに2つのシミュレーションを割り当て、これらを「最短」、「短い」、「中央値」、「長い」、「最長」と名付けます。次に、この冗長性タグに基づいて、6つの実験タスクの平均性能（\(\overline{P}\)）を計算します。結果を表7にまとめます。</p>
<p>6つのタスクのうち5つで、応答長が最も短いシミュレートされた会話では、応答長が最も長い会話と比較して、性能が10～50%高くなっています。アシスタントの応答が長くなるにつれて（表の左から右へ）、性能は徐々に低下します。アクションタスクは、このような効果が観察されず、アシスタントからの応答長が最も短い場合に有害である唯一のタスクです。</p>
<p class="highlight" style="padding: 10px; border-left: 3px solid var(--color-accent2);">しかし、主に、モデルは<span class="keyword">より短い応答を生成するときに高い性能を達成</span>します。過度の冗長性による劣化は、より長い応答が通常、アシスタントからのより多くの仮定や仮説を含み、それが後続のターンで混乱を招く可能性があるためであると仮説を立てています。一方、短いターンは焦点が絞られている傾向があり（例：単一の明確化質問）、会話を軌道に乗せ続けます。</p>
<p>過度の冗長性による劣化は注目に値します。なぜなら、基礎となるモデルの性能を劣化させるだけでなく、より長い応答はユーザーが読むのに時間がかかり、望ましくないからです。したがって、この発見は、<span class="keyword">LLMのより長い応答はモデルとエンドユーザーの両方にとって悪い</span>ことを示しています。</p>
</div>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-tags"></i> Appendix G: アシスタント応答のカテゴリ分類</h3>
<p>各アシスタントの応答を7つのカテゴリのいずれかに分類し、回答試行を把握し、それがそうであるかどうかを評価し、モデルの行動傾向を理解します。Herlihyら[27]は、LLM応答の7つのターンカテゴリを定義し、LLMを使用してそれらを分類し、GPT-4がクエリが仕様記述不足であっても直接回答することを好むことを明らかにしました。この研究に動機付けられ、同様に7つの応答カテゴリを定義し、それらを応答例とともに表8にリストします。主な違いは<span class="keyword">ディスカッション (discussion)</span> と <span class="keyword">回答試行 (answer attempt)</span> です。予備実験では、質問を定式化する多くのテキスト本文を含む多くの応答が観察されたため、[27]の「その他 (Miscellaneous)」を実験では「ディスカッション」に再定義しました。[27]の「直接応答 (Direct Response)」は、私たちの「回答試行」に対応します。</p>
<img alt="表8: ターンカテゴリの定義" class="figure-image" src="table9.png"/>
<p class="caption" style="text-align: center; font-style: italic;">表8: ターンカテゴリの定義。アシスタントの応答を分類するためのプロンプトの説明を含んでいます。</p>
<div class="table-wrapper">
<table>
<thead>
<tr>
<th>カテゴリ</th>
<th>説明</th>
<th>応答例</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="badge blue">明確化 (Clarification)</span></td>
<td>ユーザーのクエリの側面について直接問い合わせる、ユーザーに向けられた単一の質問を含む短い応答（100語未満）。</td>
<td>"その機能には特定のライブラリを使用する必要がありますか？"</td>
</tr>
<tr>
<td><span class="badge orange">拒否 (Refusal)</span></td>
<td>フォローアップの質問や要求なしに、ユーザーの質問に答えることを明示的または暗黙的に拒否する応答。</td>
<td>"申し訳ありませんが、その情報を提供することはできません。"</td>
</tr>
<tr>
<td><span class="badge purple">ためらい (Hedging)</span></td>
<td>仮定（if）または分岐（ケース1、ケース2）とそれに対応する説明に基づいて、複数の回答候補を含む応答。</td>
<td>"もしXならばYですが、ZならばAです。どちらの状況に近いですか？"</td>
</tr>
<tr>
<td><span class="badge accent1">尋問 (Interrogation)</span></td>
<td>ユーザーに向けられた複数の質問を含む応答で、時にはリストや箇条書きで整理されている。</td>
<td>"1. 予算はいくらですか？ 2. 締め切りはいつですか？ 3. 優先事項は何ですか？"</td>
</tr>
<tr>
<td><span class="badge yellow">ディスカッション (Discussion)</span></td>
<td>最終的な回答を提供したり、特定の明確化の質問をしたり、回答を拒否したりすることなく、質問を詳細に議論する応答。応答には曖昧な質問が含まれる場合と含まれない場合があります（例：「他に何かお手伝いできることはありますか？」）。</td>
<td>"この問題はいくつかの側面から考えることができます。まず、既存の制約を考慮すると..."</td>
</tr>
<tr>
<td><span class="badge gray">欠落 (Missing)</span></td>
<td>応答が空/空白。</td>
<td>(応答なし)</td>
</tr>
<tr>
<td><span class="badge red">回答試行 (Answer Attempt)</span></td>
<td>ユーザーの質問に対する完全な回答試行（テンプレート化または仮説的ではない）を含み、逐語的に抽出できる応答。</td>
<td>"def calculate_sum(a, b): return a + b"</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-server"></i> Appendix H: モデルアクセス</h3>
<p>実験で使用したモデルは、さまざまなベンダーからアクセスしました。論文全体で使用した短い形式の名前、対応するバージョン、およびプロバイダーを表9にまとめます。さまざまな温度での探索（セクション7.2）を除き、温度を \(T=1.0\) に設定し、残りの構成可能なハイパーパラメータにはデフォルト値を使用しました。すべてのモデルの最大応答長を1,000トークンに設定し、応答生成時にモデルがこの制限を頻繁に超えることは観察されませんでした。思考モデル（o3、Deepseek-R1）の場合、追加のテスト時計算（思考トークン）を考慮して、制限を10,000トークンに増やしました。</p>
<img alt="表9: 実験の一環として使用された特定のモデルバージョン" class="figure-image" src="table10.png"/>
<p class="caption" style="text-align: center; font-style: italic;">表9: 実験の一環として使用された特定のモデルバージョン。各モデルについて、アクセスされたモデルの正確なバージョン（バージョニングのあるモデルの場合）とアクセスプロバイダーを定義し、結果の再現性を促進します。</p>
<div class="table-wrapper">
<table>
<thead>
<tr>
<th>短縮名</th>
<th>モデルファミリー</th>
<th>バージョン</th>
<th>アクセスプロバイダー</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-4o-mini</td>
<td>OpenAI</td>
<td>gpt-4o-mini-2024-07-18</td>
<td>OpenAI API</td>
</tr>
<tr>
<td>GPT-4o</td>
<td>OpenAI</td>
<td>gpt-4o-2024-05-13</td>
<td>OpenAI API</td>
</tr>
<tr>
<td>o3</td>
<td>OpenAI</td>
<td>o3</td>
<td>OpenAI API</td>
</tr>
<tr>
<td>GPT-4.1</td>
<td>OpenAI</td>
<td>gpt-4-turbo-2024-04-09</td>
<td>OpenAI API</td>
</tr>
<tr>
<td>Claude 3 Haiku</td>
<td>Anthropic</td>
<td>claude-3-haiku-20240307</td>
<td>Anthropic API</td>
</tr>
<tr>
<td>Claude 3.7 Sonnet</td>
<td>Anthropic</td>
<td>claude-3-5-sonnet-20240620</td>
<td>Anthropic API</td>
</tr>
<tr>
<td>Gemini 2.5 Flash</td>
<td>Google</td>
<td>gemini-1.5-flash-preview-0514</td>
<td>Google Vertex AI</td>
</tr>
<tr>
<td>Gemini 2.5 Pro</td>
<td>Google</td>
<td>gemini-1.5-pro-preview-0514</td>
<td>Google Vertex AI</td>
</tr>
<tr>
<td>Llama3.1-8B-Instruct</td>
<td>Meta</td>
<td>Meta-Llama-3.1-8B-Instruct-Turbo</td>
<td>HuggingFace</td>
</tr>
<tr>
<td>Llama3.3-70B-Instruct</td>
<td>Meta</td>
<td>Meta-Llama-3.1-70B-Instruct-Turbo</td>
<td>HuggingFace</td>
</tr>
<tr>
<td>Llama 4 Scout</td>
<td>Meta</td>
<td>Meta-Llama-Guard-2-8B</td>
<td>HuggingFace</td>
</tr>
<tr>
<td>OLMo-2-13B</td>
<td>AI2</td>
<td>OLMo-2-13B</td>
<td>AI2 API</td>
</tr>
<tr>
<td>Phi-4</td>
<td>Microsoft</td>
<td>Phi-3-medium-128k-instruct</td>
<td>Azure AI</td>
</tr>
<tr>
<td>Deepseek-R1</td>
<td>Deepseek</td>
<td>deepseek-coder</td>
<td>Deepseek API</td>
</tr>
<tr>
<td>Command-A</td>
<td>Cohere</td>
<td>command-r-plus</td>
<td>Cohere API</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-tools"></i> Appendix I: タスク固有の実装詳細</h3>
<p>ここでは、各タスクの実装詳細を説明します。各タスクについて、以下を指定します。(1) 元のシングルターン完全指定命令の選択、(2) 元のデータセットから再利用された評価メトリック、(3) 初期システムメッセージの内容（もしあれば）。</p>
<div class="info-grid">
<div class="info-card glass-card">
<h4><i class="fa-solid fa-code"></i> I.1 コード (Code)</h4>
<p>コード命令は、HumanEval [10]（関数ヘッダーと問題を特定するdocstringが与えられた164の基本的なPythonプログラミング問題のデータセット）とLiveCodeBench [31]（Pythonアルゴリズム課題の進化するデータセット）の組み合わせから供給されます。特に、LiveCodeBench v5の「呼び出しベース」問題サブセットから、難易度が「Easy」と「Medium」のものを供給し、2つのソース間のソリューション形式を整合させます。</p>
<p>まず、付録Cで述べたプロトコルに従ってすべてのHumanEval問題をシャード化し、基準を満たす45の高品質なシャードセットを取得しました。データセットの残りは単純すぎるため破棄され、問題に対して十分な数のシャードを構築する余地がほとんどありませんでした。その後、前述のLiveCodeBenchのサブセットをシャッフルしてシャード化し、100の有効なシャード化命令を取得しました。</p>
<p>シングルターン（FULLおよびCONCAT）評価については、可能な限りベンチマーク作成者が使用した元のプロンプトに従います。具体的には、HumanEvalのFULLプロンプトには、HumanEvalデータセットでプロンプトとして提供される関数ヘッダーとdocstringが含まれ、LiveCodeBenchのFULL＆CONCATには、関数シグネチャからなるstarter_codeが含まれます。</p>
<p>HumanEvalおよびLiveCodeBench由来の問題には、LLMによる回答試行の機能的精度を計算するために使用するテストケースが付属しています。Jainら[31]によって維持されている評価コードベースを再利用します。これは、(1)候補関数をテストモジュールでラップし、(2)与えられた入力を実行し、(3)期待される出力からの出力の同等性をチェックし、評価中に評価者がトラップされるのを防ぐためにデフォルトのタイムアウトが設定されています（例：ブルートフォース実装は設定された時間予算内で合格しない場合があります）。応答に複数のコードブロックが存在する場合、回答抽出モジュールは最後のマークダウンコードブロックの最後の関数定義を選択します。</p>
</div>
<div class="info-card glass-card">
<h4><i class="fa-solid fa-database"></i> I.2 データベース (Database)</h4>
<p>データベース命令は、Spiderデータセット[86]の検証部分から供給されます。Spiderのより新しいバージョン（Spider 2.0 [44]）がリリースされていますが、2回目のイテレーションの命令はより高度であり、典型的なデータベースの使用法をあまり表していないため、より現実的なSpider 1.0から命令を選択します。</p>
<p>Spiderの作成者は、参照SQLクエリの構文の複雑さに基づいて、クエリを4つの難易度レベル（EASY、MEDIUM、HARD、XHARD）に分類しました。EASYの複雑さのクエリは、処理時に3つ未満のシャードしか生成しない傾向があったため除外しました。Spiderの残りの433の自然言語クエリは、合計107の有効なシャード化命令に達するまで徐々にシャード化されました。</p>
<p>Spiderの各元の命令は、一連のテーブルスキーマ（つまり、それぞれが一連の列（名前、型、オプションのインデックスを含む）を定義する）としてSQLで表されるデータベーススキーマを提供します。データベーススキーマをシステムメッセージの一部として（つまり、会話の最初のターンの前に）含め、ユーザーが提供されたスキーマを持つデータベースを使用して回答する必要がある自然言語クエリを提供することをLLMに通知します。</p>
<p>Spiderの各元の命令は、参照SQLソリューションとペアになっています。評価方法については、Zhongら[90]に従います。特定の元の命令について、候補SQLクエリと参照SQLクエリが固定されたデータベースセットで実行され、すべてのデータベースで結果が完全に一致する場合に候補が成功とマークされます（スコア=100）。いずれかのテストデータベースで不一致が観察された場合、候補は誤りです（スコア \(\tau=0\)）。SQL実行の1つの制限は、偽陽性が発生する可能性があることです。2つのクエリは、意味的に同等でなくても、特定のデータベースで同じ出力を返す可能性があります。Zhongら[90]は、より多くのデータベースで評価することにより、偽陽性が無視できるほどになることを見出しました。最後に、正常に実行されない無効な候補（例：構文エラー）は誤りと見なされます（スコア=0）。</p>
</div>
<div class="info-card glass-card">
<h4><i class="fa-solid fa-cogs"></i> I.3 アクション (Actions)</h4>
<p>アクション命令は、Berkeley Function Calling Leaderboard V3 (BFCL) [85]のリリースされたテスト部分から供給されます。BFCL V3は、3つのサブジャンルの命令で構成されています。(1)並列、(2)複数、(3)複数並列。サブジャンルでの初期実験では、並列命令が複数のサブタスクを指定し、それらを命令全体を達成する単一のアクションに組み合わせて使用する必要があるため、並列がシャード化に最も適していることがわかりました。すべてのBFCL V3並列命令をシャッフルし、105の有効なシャード化命令が得られるまで徐々にシャード化しました。</p>
<p>BFCLのより新しいイテレーションにはマルチターン命令が含まれていますが、各ターンが独立した中間ソリューションを持つため（これをエピソード的マルチターン会話と呼びます）、仕様記述不足を伴わないため、シャード化実験とは異なります。私たちの実装は、比較のために元の命令をシャード化し、このタスク設定でマルチターン仕様記述不足会話をシミュレートできるようにします。背景セクション（セクション2）では、エピソード的マルチターン会話と仕様記述不足マルチターン会話の関係についてより詳しく説明しています。</p>
<p>BFCLの各命令には、アシスタントがユーザーの指示を完了するために利用可能なアクション（API）のセットを指定するJSONオブジェクトであるツールセットドキュメントが付属しています。ツールセットドキュメントをシステムメッセージの一部として含め、ユーザーのクエリを完了するには提供されたツールを使用する必要があることを示すメッセージとともに含めます。</p>
<p>BFCLの各命令には、ユーザーの指示を達成するために呼び出す必要があるAPI呼び出しからなる参照回答が付属しています。BFCLのメンテナーは、候補回答と参照回答の間の意味的同等性を評価する評価ツールキットをリリースしています。公式の評価ツールキットを利用し、参照回答と意味的に同等であると見なされる候補回答にはスコア \(S=100\) を割り当て、そうでない場合はスコア \(\scriptstyle S=0\) を割り当てます。評価ツールキットが候補回答を解析できない場合（例：構文エラー）、候補は誤りと見なされます（\(S=0\)）。</p>
</div>
<div class="info-card glass-card">
<h4><i class="fa-solid fa-calculator"></i> I.4 数学 (Math)</h4>
<p>数学の指示は、GSM8Kデータセット[14]の「main」部分から供給されます。元の8,700の指示にフィルターはかけませんでした。指示をシャッフルし、103の有効なシャード化指示が得られるまで段階的にシャード化しました。各GSM8Kは、数値の参照回答とペアになっています。GSM8Kとともにリリースされた公式ツールキットを使用して、数値の回答を標準化しました（つまり、フォーマットなどを削除しました）。標準化された候補の数値回答は、参照回答と完全に一致するかどうかで比較できます。ツールキットが一致を検出した場合、候補の回答は正しいと見なされ（スコア \(_\mathrm{=100}\)）、そうでない場合は誤りです（スコア \(\tau=0\)）。アシスタントに数学の問題を解くことを示す短い1文のシステムプロンプトが使用されます。</p>
</div>
<div class="info-card glass-card">
<h4><i class="fa-solid fa-table-list"></i> I.5 データからテキストへ (Data-to-Text)</h4>
<p>データからテキストへの指示は、リリースされたテストセットToTToデータセット[59]の指示に基づいています。ToTToでは、完全に指定された指示には次の情報要素があります。(1) Wikipediaページから抽出されたHTML形式のテーブル、(2) ハイライトされたテーブル内のセルのサブセット、(3) テーブルが含まれていたWikipediaページの名前、(4) テーブルが含まれていたWikipediaページのセクションの名前。これらの要素が与えられると、タスクの目的は、ハイライトされたセルに特に焦点を当て、利用可能なメタデータを考慮してテーブルのキャプションを生成することです。指示はシャッフルされ、120の有効なシャード化指示が得られるまで段階的にシャード化されました。</p>
<p>各指示について、個々のシャードに異なる情報要素を割り当てることによってシャード化指示を生成します。最初のシャードは、ハイライトなしの初期HTML形式のテーブルで構成されます。2番目のシャードは、ハイライトが存在する更新されたテーブルを提供し、3番目のシャードはWikipediaページ名を提供し、4番目のシャードはWikipediaセクション名を提供します。最後に、5番目のシャードは、ToTToデータセットのトレーニングセットからランダムに選択された10の固定されたキャプション例のセットを提供します。</p>
<p>ToTToの各指示には、元のデータセットの作成者によって収集された1〜3つの参照キャプションが割り当てられています。候補キャプションの評価では、元の論文の評価方法に従って、候補と利用可能な参照のセットの間のBLEUスコア[58]を計算します。</p>
<p>データからテキストへのタスクは洗練タスクです。各ターンで、モデルに追加の情報のシャードが提供され、これまでに提供されたすべての情報を考慮して応答を更新するように明示的に指示されます。洗練タスクとして、各ターンのアシスタントの応答は自動的に回答試行として分類され、抽出された回答は応答全体であると見なされます。システム指示は、モデルに応答がテーブルキャプションのみで構成され、追加のテキスト（導入、結び、丁寧な言葉遣いなど）は含めないように指示します。</p>
</div>
<div class="info-card glass-card">
<h4><i class="fa-solid fa-file-lines"></i> I.6 要約 (Summary)</h4>
<p>要約の指示は、Summary of a Haystackデータセット[40]のサンプルに基づいています。Summary of a Haystackの指示全体を再利用して、92のシャード化指示を作成しました。元の指示はそれぞれ、干し草の山（合計100,000トークンのコンテンツを持つ100のドキュメント）とユーザーのクエリで構成されています。タスクの目標は、ドキュメントのコレクションで発生するクエリ関連の洞察の箇条書き形式の要約を生成し、各箇条書きの情報を引用を使用してソースドキュメントに帰属させることです。</p>
<p>Summary of a Haystackの元の設定では、LLMがソースを徹底的に引用する能力を評価するために、意図的に大量の冗長性（各洞察は少なくとも6つのドキュメントで繰り返される）が含まれています。ただし、100,000トークンの干し草の山は評価できるモデルの種類を制限するため、マルチターン設定ではタスクを簡略化します。代わりに、その後の研究に従って、より小さな干し草の山（「ミニ干し草の山」）[3]を選択します。ミニ干し草の山は20のドキュメントで構成され、各参照洞察が3つのドキュメントで繰り返されることを保証します。各指示について、シャードごとにランダムに2つのドキュメントを割り当てることによって10のシャードを作成します。最初のシャードはさらに、ユーザーのクエリ、期待される箇条書き形式、およびフォーマットされた引用を指定することにより、高レベルのタスク指示を指定します。</p>
<p>Summary of a Haystackは、LLMベースのメトリック（Joint Score）に依存して、候補の箇条書きの関連性（カバレッジ）と箇条書き内の生成された帰属の品質（引用）の両方の観点から要約の品質を計算します。作成者は、メトリックが再現率ベースであるため、より長い要約が短い要約よりも高いスコアを獲得する可能性が高いと述べています。長さのバイアスを考慮するために、元のタスクではモデルに最大300語の要約を生成するように指示しており、これも実験に含めています。具体的には、モデルはすべての設定で最大300語の要約を生成するように指示されます。マルチターン設定では、モデルがこの指示を忘れることが多く、指示への不遵守につながることが観察されました。300語の制限内に正しく収まるモデルにペナルティを課さないように、制限を超える要約を切り捨て、評価されるすべての要約が300語の制限を尊重するように、要約の箇条書きから単語を等しい割合で削除します。LLMがこれを超える傾向については、付録Fでさらに説明しており、タスク全体でモデルの回答試行が会話のターンにわたって「肥大化」することが観察されています。シングルターン設定（full、concat）では、LLMは主に300語の長さ制限を尊重します。</p>
<p>要約タスクは洗練タスクです。各ターンのアシスタントの応答は自動的に回答試行として分類され、応答全体が抽出された回答と見なされます。</p>
</div>
<div class="info-card glass-card">
<h4><i class="fa-solid fa-language"></i> I.7 翻訳 (Translation)</h4>
<p>翻訳の指示は、WMT 2019の文書レベル翻訳タスク[70]から収集されました。具体的には、30のドイツ語-英語の文書ペアを選択しました。文書ペアは文レベルで対応付けられています（つまり、ペア内の英語とドイツ語の文書は同じ文数を持ちます）。選択したペアを最初の10文に切り捨て、各シャードが文書から正確に2つの文を導入するように文書の指示をシャード化し、合計5つのシャードを作成しました。シャードはドイツ語で提供され、タスクは英語に翻訳することでした（つまり、ドイツ語 → 英語）。したがって、シャード1は最初の2つのドイツ語の文を導入し、シャード2はドイツ語の文3-4を導入します。シャード化設定では、タスクはLLMにこれまでに提供されたすべての文で文書を翻訳することを要求します。完全設定では、LLMには最初のターンで文書全体（10文）が提供されます。連結設定では、LLMには最初のターンですべての文が提供されますが、シャードに分割されています（一度に2文）。</p>
<p>初期の実験では、特定の単語数でシャードを分割する（文境界ではなく）、文書の長さを増やす（10文から20文へ）など、他のシャード化戦略を実験しましたが、結果に大きな違いは見られませんでした。これにより、説明する設定を採用するに至りました。2文ごとにシャード化し、10文で切り捨てます。</p>
<p>翻訳タスクの標準的なメトリックであり、元のWMT 2019コンペティションでも使用されたBLEUメトリック[58]で性能を評価しました。</p>
</div>
</div>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-comments"></i> Appendix J: シミュレートされた会話の例</h3>
<p>図11は、シャード化設定での実験中にシミュレートされた会話の例を示しています。シミュレーションは数学タスクで実施され、6シャードの命令を使用し、アシスタントとしてLlama3.1-8B-Instructを使用しました。この会話は、論文の残りの部分で説明されている次の特性を示しています。(1) LLMは会話の早い段階で仮定を行います（ターン1では、無関係な4つのペストリーについて説明しています）、(2) ユーザーが提供した情報を正しく解釈しますが、行った仮定の情報も不必要に更新します（ターン4）、(3) これにより不必要な複雑さが生じ、モデルは最終的に最初の指示が総カロリー数を計算することであったことを忘れ、計算の半分しか返しません（ミニブルーベリーマフィンのみ）。要するに、この会話は<span class="keyword">「会話の中で迷子になる」現象</span>を示しています。ユーザーの指示が仕様記述不足である場合（ターン1〜4）、LLMは会話から逸脱し、誤ったまたは不完全な回答につながる仮定を行います。</p>
<img alt="図11: 数学タスクのシミュレートされたマルチターン会話の例" class="figure-image" src="https://via.placeholder.com/800x1000?text=Figure+11:+Example+Simulated+Conversation+(Placeholder)" style="width:90%; margin: 10px auto;"/>
<p class="caption" style="text-align: center; font-style: italic;">図11: 数学タスクのシミュレートされたマルチターン会話の例。この会話シミュレーションは、アシスタントモデルLlama3.1-8B-Instructで行われました。シャード化された命令は6つのシャードで構成されています。この命令の正解は85,000カロリーです。(論文中のFigure 11を引用)</p>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-sliders-h"></i> Appendix K: 段階的シャード化の実装 (Gradual Sharding Implementation)</h3>
<p>指示の粒度が性能低下に与える影響を評価するために、段階的シャード化実験を実施しました。</p>
<p>正確に8つのシャードを持つシャード化命令を選択し、3つのタスク（コード、数学、データからテキストへ）にわたって合計8つの命令になりました。次に、LLM（GPT-4o）を利用して、各命令をシャード数が異なる7つのバリアントに拡張しました。LLMには、元のシャード化命令を2から7シャードのより小さなシャード化命令に統合するように指示しました。指示では、個々のシャードが流暢になるようにマイナーな言い換えを許可しましたが、LLMには可能な限り元の命令の言葉遣いに近づけるように促しました。</p>
<p>このようにして、元の各命令は次のものとペアにすることができます。(1) 連結命令（1シャード）、および (2) 2から8シャードの範囲の7つのシャード化命令。この方法を31の命令に適用すると、合計248の命令が得られ、シャード数（1から8まで）および同一の基礎となる問題について同数になります。</p>
<p>248の命令を使用してシミュレーションを実行し、2つのモデル（GPT-4oおよびGPT-4o-mini）について、命令ごとに10回の会話をシミュレートしました。段階的シャード化実験の調査結果は、セクション6.3で説明されています。</p>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-thermometer-half"></i> Appendix L: 温度実験の実装 (Temperature Experiment Implementation)</h3>
<p>シングルターンおよびマルチターン設定におけるLLMの適性と信頼性に対する温度の影響を評価するために、次の温度実験を実施しました。</p>
<p>4つのタスク（コード、データベース、アクション、および数学）からそれぞれ10の指示を選択しました（合計40）。2つのモデル（GPT-4oおよびGPT-4o-mini）で実験を実行しました。各指示および各温度の組み合わせについて、完全、連結、およびシャード化の3つの会話設定でシミュレーションを実施しました。各会話設定について、温度パラメータを0.0、0.5、および1.0の3つの値に変化させました。完全および連結設定の場合、これは3つの温度の組み合わせに対応します（アシスタントの温度のみを変更できるため）。一方、シャード化設定では、アシスタントとユーザーの両方の温度が変化するため、合計9つの組み合わせがあります。</p>
<p>実験の焦点はモデルの適性と信頼性のばらつきを測定することであり、追加のシミュレーション実行はメトリックの計算に使用されるパーセンタイル推定を改善するため、条件ごとのシミュレーション数を20回に増やすことを選択しました（本実験の10回と比較して）。この追加要件は、温度実験が本実験と比較して限られた数のモデル（2対15）と指示（40対600）しか含まなかったため、計算コストは高くありませんでした。</p>
<p>実験の調査結果は、セクション7.2で説明されています。</p>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-redo"></i> Appendix M: 要約 (Recap) &amp; 雪だるま (Snowball) 実験の実装</h3>
<p>RECAP設定は、以前のすべてのユーザー発話を収集する追加の要約ターンという点でSHARDEDとのみ異なるため、SHARDED会話ログを利用してRECAP設定をシミュレートします。この実装により、SHARDEDの結果に対するアプローチの効果を直接比較することもできます。具体的には、各SHARDEDシミュレーション実行について、「要約」ターンを追加し、シミュレーションをもう1ターン実行しました。SNOWBALLシミュレーションでは、毎ターン過去のターンを積み重ねる必要があるため、会話全体を最初からシミュレートします。プロンプトは、箇条書きとして前のターンのユーザー発話を連結し、その後に現在のターンのテキストが続きます：<span class="highlight">「繰り返しますが：\n - [過去の発話1]\n- [過去の発話2]\n\nまた、\n[現在の発話]」</span>。RECAPとSNOWBALLの両方で蓄積されるのは、元のシャード自体ではなく、ユーザーシミュレータからの言語化された発話であることに注意してください。両方のシミュレーション設定について、4つのタスク（コード、データベース、数学、アクション）のすべてのシャード化命令に対して \(N=10\) のシミュレーションを実行し、タスク全体の平均性能の平均を報告します。これを表2に示します。</p>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-dice-d6"></i> Appendix N: LLMから決定論的な出力を得ることについて</h3>
<p>実験結果で示したように、温度をゼロに設定しても、トークンとターンにわたる微妙な非決定論の複合効果により、依然として高い非信頼性につながります。</p>
<p>理論的には、貪欲デコーディング（つまり \(T=0\)）は常に語彙分布上のargmaxを選択します。しかし、浮動小数点演算に関するハードウェアの制限により、わずかに異なる中間値が発生し、それがより大きな値の変化の波及効果を引き起こし、したがって異なるトークンが選択されると報告されています。</p>
<p>著名なモデルプロバイダーは、非決定論を暗黙的または明示的に認めています。Anthropicは、出力の一貫性を相互検証するために複数回サンプリングすることを推奨しており<sup>4</sup>、Googleもモデルの出力がほとんど決定的であることを強調しており<sup>5</sup>、OpenAIは非決定論をさらに減らすためにseedパラメータを設定することを推奨しています<sup>6</sup>。</p>
<p>それにもかかわらず、LLMの応答が発散するため、マルチターン会話はますます信頼できなくなる可能性があることをユーザーに警告します。</p>
<p class="reference" style="font-size: 10px;">
            4: Anthropicドキュメンテーション参照 <br/>
            5: Google AIドキュメンテーション参照 <br/>
            6: OpenAI APIドキュメンテーション参照
        </p>
</div>
<div class="content-box">
<h3 class="subsection-title"><i class="fa-solid fa-file-alt"></i> Appendix O: プロンプト (Prompts)</h3>
<p>このセクションでは、シャード化プロセスや実験のシミュレーションで使用したプロンプトの例を示します。タスクとして数学を例にとります。二重括弧で囲まれた用語は、実際のデータに置き換えられるプレースホルダーです。他のタスクも同様の概要を共有しますが、安定した出力を強制するために異なる模範例やルールがあります。他のタスクの正確なプロンプトについては、GitHubリポジトリを参照してください。</p>
<div class="framework-box">
<div class="framework-title">O.1 シャード化 (Sharding)</div>
<div class="glass-card" style="margin-bottom: 15px;">
<h4><i class="fa-solid fa-cut"></i> セグメンテーション (Segmentation)</h4>
<pre style="white-space: pre-wrap; word-wrap: break-word; background-color: #f0f0f0; padding: 10px; border-radius: 5px;">
You are a given a fully specified instruction, and your task is to segment the instruction into
units of information that each reveal a single piece of information of the instruction.
You must output a list of segments in the following JSON format:
[ {"segment": "[exact excerpt from the instruction]"}, {"segment": "[exact excerpt from the instruction]"},
]

Rules:
- [Non-overlapping] The segments must be non-overlapping and cover the entire instruction. You can optionally leave some gaps for non-essential portions of the original instruction (delimiters, headers, etc.)
- [Minimalistic] You should split the information in the segments to as small as possible. If you have a compound expression (X and Y), you should split it into two segments. Each segment should represent a unit of information.

Example Query:
What are the names and locations of the stadiums that had concerts that occurred in both 2014 and 2015?

Output:
{"segments": [ {"segment": "names and locations"}, {"segment": "stadiums"}, {"segment": "concerts"}, {"segment": "in both 2014"}, {"segment": "and 2015"}
]}

Now complete the task for the following fully specified instruction:
[[INSTRUCTION]]
                </pre>
</div>
<div class="glass-card" style="margin-bottom: 15px;">
<h4><i class="fa-solid fa-pen-fancy"></i> リフレーミング (Rephrasing)</h4>
<pre style="white-space: pre-wrap; word-wrap: break-word; background-color: #f0f0f0; padding: 10px; border-radius: 5px;">
You are given segments of a fully specified instruction, and your task is to: (1) choose one that will be the initial shard of a multi-step query, and then (2) rephrase each segment into a conversational version that are provided to the system in a follow-up turn of the conversation.

Your output should be a JSON object in the following format:
{ "initial_segment": "[exact excerpt from the instruction]", "initial_shard": "conversational version of the initial segment", "shards": [ {"segment": "[exact excerpt from the instruction]", "shard": "conversational version of the segment taking the rest of the instruction into account"} ]
}

Example:
Full Query:
What are the names and locations of the stadiums that had concerts that occurred in both 2014 and
2015?
Segments:
[ {"segment": "names and locations"}, {"segment": "stadiums"}, {"segment": "concerts"}, {"segment": "in both 2014"}, {"segment": "and 2015"}
]
Output:
{ "initial_segment": "stadiums", "initial_shard": "popular stadiums", "shards": [ {"segment": "concerts", "shard": "the stadiums should have concerts during a period"}, {"segment": "in both 2014", "shard": "the concerts should have occurred in 2014 in the stadiums"}, {"segment": "and 2015", "shard": "the concerts should have also occurred in 2015 in the same stadiums"}, {"segment": "names and locations", "shard": "for the stadiums, returned both the name and location"} ]

Rules:
- [Transform each segment] Make sure each segment is included either as the initial shard or in the rest of the shards. Do not forget any segments.
- [Short initial shard] Make the initial shard short, not a full sentence, similar to how users use a search engine like Google.
[Order of shards] Order the shards in order of importance, from most to least important to the initial shard. You do not need to keep the order the segments that are provided in.

Now complete the task for the following fully specified instruction and segments:
Fully Specified Instruction:
[[QUESTION]]
Segments:
[[SEGMENTS]]
                </pre>
</div>
<div class="glass-card" style="margin-bottom: 15px;">
<h4><i class="fa-solid fa-check-double"></i> 検証 (Verification)</h4>
<pre style="white-space: pre-wrap; word-wrap: break-word; background-color: #f0f0f0; padding: 10px; border-radius: 5px;">
You are given an instruction that fully specifies a problem, and a list of shards. Your task is to decide whether all the information from the full instruction is captured by the shards.

If not, you should output the information unit from the instruction that is not captured by the shards.

Example 1:
Instruction:
What are the names and locations of the stadiums that had concerts that occurred in both 2014 and
2015?

Shards:
{"initial_segment": "stadiums", "initial_shard": "I'm looking for active stadiums", "shards": [{"segment": "concerts", "shard": "the stadiums should have concerts during a period"}, {"segment": "in both 2014 and 2015", "shard": "the concerts should have occurred in both 2014 and 2015"}, {"segment": "names and locations", "shard": "for the stadiums, returned both the name and location"}]}

Output: {"converage": "complete"}

Example 2:
Instruction:
Which Asian countries have a population that is larger than any country in Africa?

Shards: {"initial_shard": "I'm interested in learning about countries in Asia", "shards": [{"shard": "consider the population size of these Asian countries"}, {"shard": "the population should be compared in size"}, {"shard": "specifically, compare to the population of African countries"}]}

Output:
{"coverage": "incomplete", "missing_segment": "the shards do not specify that the population of the Asian countries should be *larger* than the population of any African countries"}

You must output in JSON format as shown in the examples above. Now complete the task for the following fully specified instruction and shards:
Instruction: [[QUERY]]
Shards: [[SHARDS]]
                </pre>
</div>
</div>
<div class="framework-box">
<div class="framework-title">O.2 実験 (Experiments)</div>
<p>実験には、会話をシミュレートするための特定のプロンプトを使用したいくつかのLLM呼び出しが含まれます。以下にリストします。それらがどのように組み込まれているかについては、GitHubリポジトリを参照してください。</p>
<div class="glass-card" style="margin-bottom: 15px;">
<h4><i class="fa-solid fa-user-astronaut"></i> ユーザーシミュレータ (User simulator)</h4>
<pre style="white-space: pre-wrap; word-wrap: break-word; background-color: #f0f0f0; padding: 10px; border-radius: 5px;">
You are simulating a user of an interactive LLM system (like ChatGPT).
The user is inherently lazy, and answers in short form, providing only minimal information to the system. You should not be proactive.

Here's the conversation so far: [[CONVERSATION_SO_FAR]]

Here are the shards that have already been revealed: [[SHARDS_REVEALED]]

Here are all the shards that have not been revealed yet: [[SHARDS_NOT_REVEALED]]

You must generate a response to the conversation so far. Here are the rules:
- [Providing a shard] You can reveal the content of a shard to the system in your response if it will help the system move closer to answering the problem. You should select the shard to reveal that is most "basic" and currently the most relevant.
- [One Shard at a Time] You should only reveal at most one shard at a time.
- [Reveal Entire Shard] If you reveal a shard, you must make sure to include *all the information in the shard*. For example, if the shard is "your symptoms are that you have a headache in the mornings", your response can't just be ``yeah I have headaches'', you must say ``yup mostly headaches in the mornings``.
- [Irrelevant Clarifications] If the system asks you a question irrelevant to the shards, asks you a generic question (``Can you give me a hint?``), you should respond with an answer that does not provide a shard. (``I don't know``, ``Is that really important?``, etc.) You should not reveal any information beyond what is available in the shards.
- [No Repeated Shards] You should not reveal the same shard more than once. Carefully review the already revealed shards, and only reveal a shard if its `shard_id` is not on the list.
- [Rephrase Shards] If you reveal a shard, you should rephrase it in a conversational way. Do not copy the shard verbatim.
- [Do Not Ask Questions] Your response should always be declarative sentences, and not questions.
- [Brevity of Response] You should favor being succint. Your answer can also have typos, improper grammar, capitalization, etc. You are simulating a real person talking to an AI, who is in a hurry.
- [Format] Your response should be formatted as a JSON object with the following keys:
  - `response`: The response to the conversation so far.
  - `shard_id`: The shard you are revealing to the system. The shard_id can be an integer, or -1 if you did not reveal any shards.

For example:
{"response": "I don't know", "shard_id": -1}
or:
{"response": "yeah I want it to [...]", "shard_id": 1}
                </pre>
</div>
<div class="glass-card" style="margin-bottom: 15px;">
<h4><i class="fa-solid fa-clipboard-list"></i> 応答戦略の分類 (Response strategy categorization)</h4>
<pre style="white-space: pre-wrap; word-wrap: break-word; background-color: #f0f0f0; padding: 10px; border-radius: 5px;">
You are reviewing a multi-turn conversation between a user and an assistant, and are given the last turn of the conversation.

Here is the full specification of the problem the system is attempting to solve: [[INITIAL_SHARD]]
Specification: [[SHARDS]]

You must classify the response of the assistant according to the response type:
- `answer_attempt`: The response contains a complete answer attempt to the user's question (not templated or hypothetical), that can be extracted verbatim. See the task-specific answer description for more details.
- `clarification`: The response is short (less than 100 words) and contains a single question addressed to the user that directly inquires about an aspect of the user's query. A clarification turn cannot be long (see `discussion`), cannot contain a vague question (see `discussion`) and cannot contain multiple questions (see `interrogation`).
- `interrogation`: The response contains multiple questions addressed to the user, sometimes organized in a list or bullet-points.
- `discussion`: The response discusses the question in detail, without providing a final answer, asking a specific clarification question, or a refusal to answer. The response may or may not contain a vague question (e.g., “What else can I help you with?”).
- `hedge`: The response contains multiple answer candidates based on hypotheticals (ifs) or branching (case 1, case 2) with corresponding descriptions.
- `refuse`: The response contains an explicit or implicit refusal to answer the user's question without a follow-up question or a request.
- `missing`: The response is empty/blank.

You must output your answer in the following JSON format: {"response_type": "refuse|missing|answer_attempt|hedge|clarification|interrogation|discussion"}

Rules:
- The assistant giving a hint at how an answer could look like is not a final answer. You should only select `answer_attempt` if the conversation could end at this stage with the user having an entirely final answer to the problem they've formulated.
- [Task Specific Answer] [[ANSWER_DESCRIPTION]]

Conversation's last turn: [[CONVERSATION_SO_FAR]]
                </pre>
</div>
<div class="glass-card">
<h4><i class="fa-solid fa-highlighter"></i> 回答抽出 (Answer Extraction)</h4>
<pre style="white-space: pre-wrap; word-wrap: break-word; background-color: #f0f0f0; padding: 10px; border-radius: 5px;">
You are reviewing a multi-turn conversation between a user and an assistant, and are given the last turn of the conversation.
In the final response from the assistant, a final answer has been provided. Your goal is to extract verbatim what the answer is:
- If the answer is short (less than 10 words), then you should copy verbatim what the answer is in the `answer` field.
- If the answer is long, then you should produce the answer with an ellipses, to indicate the exact start and end of the answer (e.g,
<div class="section-card" id="Appendix_A_Related_work_on_Underspecification">
    <h2 class="section-title"><i class="fas fa-book-open"></i> Appendix A Related work on Underspecification</h2>
    <div class="content-box">
        <p>このセクションでは、論文の主題である「マルチターン評価」に焦点を当てた先行研究（論文のセクション2でレビュー済み）とは別に、<span class="keyword">指示の不完全性（Underspecification）</span>という現象自体を研究してきた関連研究について概観します。LLMが不完全な指示をどのように扱うかを理解することは、対話能力を向上させる上で非常に重要です。</p>
    </div>

    <div class="glass-card">
        <h3 class="subsection-title"><i class="fas fa-comments"></i> 💬 コミュニケーションと言語学における不完全性</h3>
        <p>まず、コミュニケーションや言語学の分野では、<span class="highlight">指示の不完全性は人間の言語における一般的な特徴</span>として認識されています。これは、話し手が必ずしも全ての情報を明示的に伝えなくても、聞き手がある程度文脈などから補完して理解できる、という人間のコミュニケーション能力に起因します。</p>
        <ul class="unstyled-list">
            <li><span class="badge blue">引用文献</span> [41, 20, 22, 61]</li>
        </ul>
        <div class="feature-card-grid">
            <div class="feature-item">
                <i class="fas fa-user-friends fa-2x" style="color: var(--color-accent1);"></i>
                <p>人間は日常会話で<br/>情報を省略することが多い</p>
            </div>
            <div class="feature-item">
                <i class="fas fa-brain fa-2x" style="color: var(--color-accent2);"></i>
                <p>聞き手は文脈や知識で<br/>不足情報を補完</p>
            </div>
        </div>
    </div>

    <div class="arrow-connector"></div>

    <div class="framework-box">
        <h3 class="subsection-title"><i class="fas fa-robot"></i> 🤖 LLMと不完全な指示</h3>
        <p>LLMが不完全な指示をどのように処理するかを理解することは、対話能力を向上させる上で不可欠です。この点に関して、いくつかの重要な研究があります。</p>

        <div class="info-grid">
            <div class="info-card">
                <div class="note-box">
                    <p class="note-title"><i class="fas fa-lightbulb"></i> Herlihy et al. [27]</p>
                    <p>不完全なクエリが対話型LLMシステムに提示された際の一般的な応答パターンを特定しました。</p>
                    <div class="tag-list">
                        <span class="tag">応答パターン</span>
                        <span class="tag">ヘッジング (曖昧な言い方)</span>
                        <span class="tag">拒否</span>
                        <span class="tag">明確化要求</span>
                        <span class="tag">尋問</span>
                    </div>
                    <p>また、これらのパターンから回復するためのメカニズムも提案しています。</p>
                    <div style="text-align: center; margin-top: 10px;">
                        <svg height="150" viewbox="0 0 300 180" width="250" xmlns="http://www.w3.org/2000/svg">
                            <defs>
                                <marker id="arrowhead" markerheight="7" markerwidth="10" orient="auto" refx="0" refy="3.5">
                                    <polygon fill="#4a6fa5" points="0 0, 10 3.5, 0 7"></polygon>
                                </marker>
                            </defs>
                            <!-- User Query -->
                            <rect fill="#f0f8ff" height="40" rx="5" ry="5" stroke="#4a6fa5" stroke-width="1" width="120" x="10" y="10"></rect>
                            <text font-family="Yomogi" font-size="12px" text-anchor="middle" x="70" y="35">不完全な指示</text>
                        
                            <!-- LLM -->
                            <ellipse cx="220" cy="30" fill="#e6e6fa" rx="40" ry="20" stroke="#9575cd" stroke-width="1"></ellipse>
                            <text font-family="Yomogi" font-size="12px" text-anchor="middle" x="220" y="35">LLM</text>
                        
                            <line marker-end="url(#arrowhead)" stroke="#4a6fa5" stroke-width="1.5" x1="130" x2="180" y1="30" y2="30"></line>
                        
                            <!-- Response Patterns -->
                            <rect fill="#fff0f5" height="30" rx="3" ry="3" stroke="#ff7e5f" stroke-width="1" width="60" x="10" y="70"></rect>
                            <text font-family="Yomogi" font-size="10px" text-anchor="middle" x="40" y="90">ヘッジング</text>
                            <line stroke="#ff7e5f" stroke-dasharray="2,2" stroke-width="1" x1="200" x2="40" y1="50" y2="70"></line>
                        
                            <rect fill="#fff0f5" height="30" rx="3" ry="3" stroke="#ff7e5f" stroke-width="1" width="60" x="80" y="70"></rect>
                            <text font-family="Yomogi" font-size="10px" text-anchor="middle" x="110" y="90">拒否</text>
                            <line stroke="#ff7e5f" stroke-dasharray="2,2" stroke-width="1" x1="200" x2="110" y1="50" y2="70"></line>
                        
                            <rect fill="#fff0f5" height="30" rx="3" ry="3" stroke="#ff7e5f" stroke-width="1" width="60" x="150" y="70"></rect>
                            <text font-family="Yomogi" font-size="10px" text-anchor="middle" x="180" y="90">明確化</text>
                            <line stroke="#ff7e5f" stroke-dasharray="2,2" stroke-width="1" x1="210" x2="180" y1="50" y2="70"></line>
                        
                            <rect fill="#fff0f5" height="30" rx="3" ry="3" stroke="#ff7e5f" stroke-width="1" width="60" x="220" y="70"></rect>
                            <text font-family="Yomogi" font-size="10px" text-anchor="middle" x="250" y="90">尋問</text>
                            <line stroke="#ff7e5f" stroke-dasharray="2,2" stroke-width="1" x1="230" x2="250" y1="50" y2="70"></line>
                        
                            <!-- Recovery Mechanisms -->
                            <rect fill="#e0ffff" height="40" rx="5" ry="5" stroke="#5cb85c" stroke-width="1" width="160" x="70" y="120"></rect>
                            <text font-family="Yomogi" font-size="12px" text-anchor="middle" x="150" y="145">回復メカニズムの提案</text>
                            <line marker-end="url(#arrowhead)" stroke="#5cb85c" stroke-width="1.5" x1="150" x2="150" y1="100" y2="120"></line>
                        </svg>
                        <p style="font-family: 'Yomogi', cursive; font-size: 12px; color: var(--color-gray); margin-top: 5px;">Herlihy et al. [27] の研究概要図</p>
                    </div>
                </div>
            </div>

            <div class="info-card">
                <div class="note-box">
                    <p class="note-title"><i class="fas fa-cogs"></i> Malaviya et al. [53]</p>
                    <p>不完全なクエリに対するLLMの応答をより正確かつ原理的に評価するためには、<span class="highlight">文脈情報（supporting context）の重要性</span>を強調しました。</p>
                    <div style="text-align: center; margin-top: 15px;">
                        <svg height="120" viewbox="0 0 280 140" width="250" xmlns="http://www.w3.org/2000/svg">
                            <rect fill="#fffacd" height="50" rx="5" ry="5" stroke="#ffd54f" stroke-width="1" width="100" x="10" y="10"></rect>
                            <text font-family="Yomogi" font-size="12px" text-anchor="middle" x="60" y="30">不完全な</text>
                            <text font-family="Yomogi" font-size="12px" text-anchor="middle" x="60" y="45">クエリ</text>
                        
                            <rect fill="#e6e6fa" height="50" rx="5" ry="5" stroke="#9575cd" stroke-width="1" width="100" x="170" y="10"></rect>
                            <text font-family="Yomogi" font-size="12px" text-anchor="middle" x="220" y="30">LLM応答</text>
                            
                            <line marker-end="url(#arrowhead)" stroke="#4a6fa5" stroke-width="1.5" x1="110" x2="170" y1="35" y2="35"></line>
                            
                            <rect fill="#e0f7fa" height="50" rx="5" ry="5" stroke="#5cb85c" stroke-width="1" width="160" x="60" y="80"></rect>
                            <text font-family="Yomogi" font-size="12px" text-anchor="middle" x="140" y="100">文脈情報による</text>
                            <text font-family="Yomogi" font-size="12px" text-anchor="middle" x="140" y="115">評価の精度向上</text>
                        
                            <line marker-end="url(#arrowhead)" stroke="#5cb85c" stroke-width="1.5" x1="140" x2="140" y1="60" y2="80"></line>
                            <text fill="#5cb85c" font-family="Yomogi" font-size="10px" x="145" y="70">+</text>
                        </svg>
                        <p style="font-family: 'Yomogi', cursive; font-size: 12px; color: var(--color-gray); margin-top: 5px;">文脈情報の重要性</p>
                    </div>
                </div>
            </div>

            <div class="info-card">
                <div class="note-box">
                    <p class="note-title"><i class="fas fas fa-pen-fancy"></i> Sarkar et al. [69]</p>
                    <p>不完全性を考慮してユーザーの指示を<span class="highlight">積極的に書き換えるシステム</span>が、LLMの応答を改善することを示しました。</p>
                    <div class="pipeline" style="margin-top:15px;">
                        <div class="pipeline-step" style="background-color: #fff8e1;">
                            <span class="badge yellow">ユーザー</span> 不完全な指示
                        </div>
                        <div class="pipeline-step" style="background-color: #e3f2fd;">
                            <span class="badge blue">システム</span> 指示を書き換え (明確化)
                        </div>
                        <div class="pipeline-step" style="background-color: #e8f5e9;">
                            <span class="badge green">LLM</span> 改善された応答
                        </div>
                    </div>
                </div>
            </div>

            <div class="info-card">
                <div class="note-box">
                    <p class="note-title"><i class="fas fa-comments-dollar"></i> Shaikh et al. [71]</p>
                    <p>対話ログにおけるLLMの<span class="keyword">グラウンディング</span>（明確化やフォローアップ質問）の度合いを調査しました。その結果、LLMはフォローアップ質問の生成が著しく不足しており、人間はLLMよりも15倍多くフォローアップ質問をする傾向があることを発見しました。</p>
                    <div style="text-align: center; margin-top: 15px;">
                        <svg height="100" viewbox="0 0 280 120" width="250" xmlns="http://www.w3.org/2000/svg">
                            <rect fill="#f0f8ff" height="40" rx="5" ry="5" stroke="#4a6fa5" stroke-width="1" width="100" x="10" y="10"></rect>
                            <text font-family="Yomogi" font-size="12px" text-anchor="middle" x="60" y="35">LLM</text>
                            <text fill="#d32f2f" font-family="Yomogi" font-size="12px" text-anchor="middle" x="60" y="75">フォローアップ質問 (少)</text>
                        
                            <rect fill="#fff9c4" height="40" rx="5" ry="5" stroke="#ffd54f" stroke-width="1" width="100" x="170" y="10"></rect>
                            <text font-family="Yomogi" font-size="12px" text-anchor="middle" x="220" y="35">人間</text>
                            <text fill="#388e3c" font-family="Yomogi" font-size="12px" text-anchor="middle" x="220" y="75">フォローアップ質問 (多)</text>
                            <text fill="#388e3c" font-family="Yomogi" font-size="10px" text-anchor="middle" x="220" y="95">(LLMの15倍)</text>
                        
                            <text font-family="Yomogi" font-size="18px" text-anchor="middle" x="140" y="40">vs</text>
                        </svg>
                        <p style="font-family: 'Yomogi', cursive; font-size: 12px; color: var(--color-gray); margin-top: 5px;">フォローアップ質問の頻度の比較</p>
                    </div>
                </div>
            </div>

            <div class="info-card">
                <div class="note-box">
                    <p class="note-title"><i class="fas fa-user-edit"></i> Chang et al. [7]</p>
                    <p>アノテーターにチャットインターフェースを通じて完全に指定された指示を手動で再現させました。その結果、ユーザーが指示の全体を明らかにするのは<span class="highlight">34%</span>のケースのみであり、大半のケースでは何らかの詳細が不完全にしか伝えられていないことがわかりました。</p>
                    <div style="text-align: center; margin-top: 15px;">
                        <svg height="120" viewbox="0 0 200 120" width="200" xmlns="http://www.w3.org/2000/svg">
                            <circle cx="100" cy="60" fill="none" r="50" stroke="#4a6fa5" stroke-dasharray="213.52 314" stroke-width="10" transform="rotate(-90 100 60)"></circle>
                            <circle cx="100" cy="60" fill="none" r="50" stroke="#ff7e5f" stroke-dasharray="100.48 314" stroke-width="10" transform="rotate(122.4 100 60)"></circle>
                            <text fill="#4a6fa5" font-family="Yomogi" font-size="18px" text-anchor="middle" x="100" y="55">34%</text>
                            <text fill="#4a6fa5" font-family="Yomogi" font-size="10px" text-anchor="middle" x="100" y="75">完全な指示</text>
                            <text fill="#ff7e5f" font-family="Yomogi" font-size="10px" text-anchor="middle" x="30" y="20">66% 不完全</text>
                        </svg>
                        <p style="font-family: 'Yomogi', cursive; font-size: 12px; color: var(--color-gray); margin-top: 5px;">指示の完全性の割合</p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="arrow-connector"></div>

    <div class="framework-box">
        <h3 class="subsection-title"><i class="fas fa-tasks"></i> 📝 不完全性に対処するモデル能力を評価するタスク</h3>
        <p>不完全性に対処するモデルの能力を評価するための直接的なタスクを探求した研究もいくつかあります。</p>
        <div class="info-grid">
            <div class="info-card">
                <div class="bubble-box">
                    <p class="note-title"><i class="fas fa-puzzle-piece"></i> Liu et al. [49]</p>
                    <p><span class="keyword">AmbiEnt</span>という自然言語推論ベンチマークを導入しました。この研究により、<span class="highlight">曖昧な文の理解は最新のLLMにとっても依然として課題である</span>ことが明らかになりました。</p>
                    <p style="font-family: 'Yomogi', cursive; font-size:12px; text-align:center; margin-top:10px;">例：文「彼は銀行に行った」<br/>→ 金融機関？ 川岸？ <i class="fas fa-question-circle" style="color:var(--color-secondary)"></i></p>
                </div>
            </div>
            <div class="info-card">
                 <div class="bubble-box">
                    <p class="note-title"><i class="fas fa-balance-scale"></i> Wildenburg et al. [83]</p>
                    <p><span class="keyword">DUSTタスク</span>を作成しました。これは、言語モデルに2つの文の間で相対的な具体性のレベルを決定させるものです。その結果、<span class="highlight">不完全な文を解釈する際に、LMはほとんど不確実性を示さない</span>ことがわかりました（つまり、自信過剰に間違った解釈をする可能性がある）。</p>
                    <p style="font-family: 'Yomogi', cursive; font-size:12px; text-align:center; margin-top:10px;">文A:「食べ物を買った」<br/>文B:「リンゴを3つ買った」<br/>→ LMは文Bがより具体的と判断できるか？</p>
                </div>
            </div>
            <div class="info-card">
                 <div class="bubble-box">
                    <p class="note-title"><i class="fab fa-github"></i> Vijayvargiya et al. [78]</p>
                    <p>不完全な設定でGitHubの問題解決を行うLLMエージェントを評価しました。情報を補足するための<span class="highlight">フォローアップの対話は解決率の向上に役立つ</span>ものの、指示の曖昧さを検出することは依然として課題であることを示しました。</p>
                    <div class="process-step" style="margin-top:10px;">
                        <span class="step-number">1</span>
                        <div class="step-content">不完全なIssue報告 <i class="fas fa-bug" style="color:var(--color-secondary)"></i></div>
                    </div>
                    <div class="process-step">
                        <span class="step-number">2</span>
                        <div class="step-content">LLMエージェントが質問 <i class="fas fa-question" style="color:var(--color-accent1)"></i></div>
                    </div>
                    <div class="process-step">
                        <span class="step-number">3</span>
                        <div class="step-content">ユーザーが情報補足 <i class="fas fa-comment-dots" style="color:var(--color-primary)"></i></div>
                    </div>
                    <div class="process-step">
                        <span class="step-number">4</span>
                        <div class="step-content">解決率向上 <i class="fas fa-check-circle" style="color:var(--color-accent2)"></i> (ただし曖昧さ検出は困難)</div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <div class="arrow-connector"></div>

    <div class="framework-box">
        <h3 class="subsection-title"><i class="fas fa-sitemap"></i> 🗺️ 不完全性の根本原因の分類</h3>
        <p>先行研究では、不完全性のさまざまな根本原因が分類されています。</p>
        <div class="feature-card-grid">
            <div class="feature-item glass-card">
                <i class="fas fa-tasks fa-2x" style="color: var(--color-accent1);"></i>
                <h4>タスクの不完全性 (Task underspecification)</h4>
                <p>人間が手元のタスクの不完全な記述を提供する場合に発生します。「仕様が多いタスク (specification-heavy tasks)」[60]で顕著です。</p>
                <p style="font-family: 'Yomogi', cursive; font-size:12px; margin-top:5px;">例：「このデータでグラフを作って」<br/>(どんなグラフ？何の目的で？)</p>
            </div>
            <div class="feature-item glass-card">
                <i class="fas fa-user-times fa-2x" style="color: var(--color-secondary);"></i>
                <h4>意図の不一致 (Intent misalignment)</h4>
                <p>AIがユーザーの意図や動機を理解できない場合に発生し、ユーザーの不満の一般的な原因の1つです [34, 76]。</p>
                <p style="font-family: 'Yomogi', cursive; font-size:12px; margin-top:5px;">例：ユーザー「おすすめの映画は？」<br/>AI「(ジャンルを考慮せず)Xが人気です」<br/>(ユーザーはホラーが見たかった)</p>
            </div>
            <div class="feature-item glass-card">
                <i class="fas fa-map-marker-alt fa-2x" style="color: var(--color-accent2);"></i>
                <h4>場所と参照の曖昧さ (Location and reference ambiguity)</h4>
                <p>Chaturvedi et al. [9] は、Minecraftゲームのような物理的空間を伴う具体的な設定における、場所や指示対象の曖昧さについて論じています。</p>
                <p style="font-family: 'Yomogi', cursive; font-size:12px; margin-top:5px;">例：「あのブロックを取って」<br/>(どのブロック？複数ある場合)</p>
            </div>
        </div>
    </div>

    <div class="note-box" style="margin-top: 25px;">
        <p class="note-title"><i class="fas fa-star"></i> まとめ</p>
        <p>このセクションで紹介したように、指示の不完全性は人間とAIのコミュニケーションにおいて重要な課題です。LLMがこれをどのように処理し、どのように改善できるかについての研究は、より自然で効果的な対話システムの実現に不可欠です。本論文は、特にマルチターンの対話における不完全性の影響を深く掘り下げています。</p>
    </div>

</div>
<div class="section-card" id="Appendix_B_Precise_Definition_of_Sharded_Instructions">
    <h2 class="section-title"><i class="fas fa-microscope"></i>Appendix B Sharded Instructionsの厳密な定義</h2>
    <p>このセクションでは、論文のセクション3.1で概要が説明された「シャーディング」という概念について、より厳密な定義を提示します。まず数学的な用語を定義し、次にシャード化された命令 (sharded instruction) が有効とみなされるために満たすべき特性を定義します。</p>
    <p>このAppendixを読むことで、論文で提案されている「シャーディング」がどのようなルールに基づいて行われ、どのような性質を持つべきなのかを正確に理解することができます。これは、実験結果の解釈や、この手法を他のタスクに応用する際に非常に重要になります。</p>

    <div class="bubble-box">
        <p><i class="fas fa-lightbulb"></i> このセクションの目的は、複雑な指示をより小さく、管理しやすい「シャード」に分割するための<strong>明確なルールと基準</strong>を確立することです。</p>
    </div>

    <h3 class="subsection-title"><i class="fas fa-calculator"></i> 数学的用語の定義</h3>

    <div class="definition-box">
        <div class="definition-title"><i class="fas fa-book-open"></i> 基本的なクエリと出力</div>
        <p>まず、基本的な構成要素を定義しましょう。</p>
        <ul>
            <li><span class="keyword">\(q\)</span>: 単一ターンの複雑なクエリ (single-turn complex query) を指します。これは、ユーザーが一度の発話で与える、複数の情報要素を含む可能性のある質問や指示のことです。
                <div class="note-box">
                    <div class="note-title"><i class="fas fa-comment-dots"></i> 例</div>
                    <p>「Pythonで、与えられた数値リストの中から負の数だけを合計し、その合計が0未満になったらTrueを返す関数を書いて。ただし、初期値は0とする。」のような指示が \(q\) に該当します。</p>
                </div>
            </li>
            <li><span class="keyword">\(Y_q^*\)</span>: クエリ \(q\) に対する意図された（つまり、正しい）出力 (intended/correct output) を指します。上記の例なら、期待されるPython関数そのものが \(Y_q^*\) です。</li>
        </ul>
    </div>

    <div class="definition-box">
        <div class="definition-title"><i class="fas fa-puzzle-piece"></i> 原子的内容単位 (Atomic Content Units - ACU)</div>
        <p>次に、クエリ \(q\) の <span class="keyword">原子的内容単位 (ACU)</span> [51] を \(I(q)\) と表現します。これは、クエリを構成する、それ以上分割できない情報の最小単位の集まりです。</p>
        <div class="formula">
            $$ \boldsymbol { I } ( \boldsymbol { q } ) = [ \mathcal { T } , ( c _ { 1 } , \cdot \cdot \cdot , c _ { m } ) ] $$
        </div>
        <p>この式の内容は以下の通りです：</p>
        <ul>
            <li><span class="keyword">\(\mathcal{T}\)</span>: クエリの<span class="highlight">主要な意図 (primary intent)</span> です。ユーザーが根本的に何をしたいのか、という大枠の目的を表します。
                <div class="note-box">
                    <div class="note-title"><i class="fas fa-bullseye"></i> 例</div>
                    <p>先のPython関数の例では、「Python関数を書くこと」が \(\mathcal{T}\) にあたります。</p>
                </div>
            </li>
            <li><span class="keyword">\((c_1, \dots, c_m)\)</span>: <span class="highlight">十分な明確化のセット (sufficient set of clarifications)</span> です。これらは、主要な意図 \(\mathcal{T}\) を条件として、正しい出力 \(Y_q^*\) を計算するために必要な詳細情報や制約条件を具体的に指定します。
                <div class="note-box">
                    <div class="note-title"><i class="fas fa-list-check"></i> 例</div>
                    <p>Python関数の例では、
                        <ul>
                            <li>\(c_1\): 「数値リストの中から負の数だけを合計する」</li>
                            <li>\(c_2\): 「合計が0未満になったらTrueを返す」</li>
                            <li>\(c_3\): 「初期値は0とする」</li>
                        </ul>
                        などが明確化 \((c_i)\) に該当します。
                    </p>
                </div>
            </li>
        </ul>
        <p><span class="keyword">原子性 (atomic)</span>: \(I(q)\) が「原子的」であるとは、\(I(q)\) の任意の言い換え (rephrasing) が同じ目標出力を生成することを意味します。つまり、ある別のクエリ \(q'\) があり、そのACUが元のクエリのACUと等しい (\(I(q') = I(q)\)) ならば、それらの意図された出力も等しくなければなりません (\(Y_{q'}^* = Y_q^*\))。</p>
        <div class="note-box">
            <div class="note-title"><i class="fas fa-balance-scale"></i> 原子性の重要性</div>
            <p>この原子性の定義は、指示の本質的な情報内容が変わらなければ、表現方法が多少異なっても同じ結果が得られるべきである、という直感的な理解を形式化したものです。</p>
        </div>
    </div>

    <div class="framework-box">
        <div class="framework-title"><i class="fas fa-cogs"></i> シャーディングプロセスの目的</div>
        <p>上記の定義を踏まえ、特定のクエリ \(q\) に対する<span class="keyword">シャーディングプロセス (sharding process)</span> の目的は、その原子的内容単位 \(I(q)\) を特定し、それに基づいて一連のより短い<span class="keyword">命令シャード (instruction shards)</span> \(s\) を構築することです。</p>
        <div class="formula">
            $$ q ^ { \prime } = [ s _ { 1 } , \cdot \cdot \cdot s _ { k } ] \mathrm { \ s.t. \ } I ( q ) = I ( q ^ { \prime } ) $$
        </div>
        <p>ここで、</p>
        <ul>
            <li><span class="keyword">\(q'\)</span>: シャード化された命令 (sharded instruction) であり、複数のシャード \(s_1, \dots, s_k\) から構成されます。</li>
            <li>\(I(q) = I(q')\): シャード化された命令 \(q'\) のACUは、元のクエリ \(q\) のACUと<span class="highlight">同一でなければなりません</span>。つまり、情報は失われたり、余計な情報が加わったりしてはいけません。</li>
            <li>シャード \(s_j\): これらのシャードは、元の単一ターンクエリ \(q\) と同じ意図された出力 \(Y_q^*\) を持つ<span class="keyword">マルチターン会話 (multi-turn conversation)</span> をシミュレートするために使用できます。各シャードが会話の1ターンに対応し、徐々に情報が明らかになるイメージです。</li>
        </ul>
        <div class="note-box">
            <div class="note-title"><i class="fas fa-comments"></i> シャーディングのゴール</div>
            <p>📝 シャーディングは、複雑な指示を小さなステップに分解し、対話的に解決できるようにするための手法です。各シャードは、元の指示の一部分の情報を持ちます。</p>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-check-circle"></i> シャード化された命令の有効性のための特性</h3>
    <p>あるシャード化された命令 \(q'\) が、元のクエリ \(q\) に対して<span class="keyword">有効 (valid)</span> であるとみなされるためには、以下の5つの特性を満たす必要があります。</p>

    <div class="info-grid">
        <div class="info-card">
            <h4>P1: <i class="fas fa-archive"></i> 情報保存 (Information Preservation)</h4>
            <p><strong>定義:</strong> <span class="formula">\({ \cal { I } } ( q ) \ = \ { \cal { I } } ( q ^ { \prime } )\)</span></p>
            <p><strong>説明:</strong> シャーディングプロセス中に、元の指示を完了するために必要な情報が失われてはいけません。元のクエリ \(q\) に含まれる全ての原子的内容単位は、シャード化された命令 \(q'\) にも完全に保持されていなければなりません。</p>
            <div class="note-box">
                <p><i class="fas fa-exclamation-triangle"></i> これが満たされないと、モデルは正しい答えを出すために必要な情報を得られなくなります。</p>
            </div>
        </div>

        <div class="info-card">
            <h4>P2: <i class="fas fa-flag-checkered"></i> 明確な初期意図 (Clear Initial Intent)</h4>
            <p><strong>定義:</strong> <span class="formula">\(\mathcal { T } _ { q } = \mathcal { T } _ { q ^ { \prime } }\)</span> かつ <span class="formula">\(s _ { 1 } = \mathcal { T } _ { q }\)</span></p>
            <p><strong>説明:</strong> 最初のシャード \(s_1\) は、シャードセットの中で特別な役割を果たします。それは、会話全体の<span class="highlight">高レベルな目的を定義する初期クエリ</span>となります。元のクエリの主要な意図 \(\mathcal{T}_q\) は、シャード化された命令の主要な意図 \(\mathcal{T}_{q'}\) と同一であり、かつ最初のシャード \(s_1\) はこの主要な意図 \(\mathcal{T}_q\) そのものでなければなりません。</p>
            <div class="note-box">
                <p><i class="fas fa-pen-nib"></i> 例: 「Python関数を書いてください」のような、タスク全体を要約する指示が \(s_1\) になります。</p>
            </div>
        </div>
    </div>

    <div class="glass-card">
        <p><i class="fas fa-table"></i> 以下は、論文のGSM8Kデータセットの例 (Figure 2参照) を使ったシャーディングの概念と、関連する検証プロセスを示唆するテキストです。このテキストはAppendix Bの本文中にP2とP3の間に挿入されています。</p>
        <div class="table-wrapper">
            <table>
                <thead>
                    <tr>
                        <th>元の指示 (一部) / プロセスステージ</th>
                        <th>元の指示 (一部) / プロセスステージ</th>
                        <th>シャード化の試み / 具体例</th>
                        <th>シミュレーション / 検証</th>
                        <th>シャード化された指示 / 検証結果</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>国 尚 高</td>
                        <td>0. Prepare</td>
                        <td>1. Segmentation</td>
                        <td>2. Rephrasing</td>
                        <td>3. Verification</td>
                    </tr>
                    <tr>
                        <td>Jay is making snowballs to</td>
                        <td>Jay is making snowballs to</td>
                        <td>How long before Jay’s ready</td>
                        <td>Simulation</td>
                        <td>How long before Jay’s ready</td>
                    </tr>
                    <tr>
                        <td>prepare for a snowball fight</td>
                        <td>prepare for a snowball fight</td>
                        <td>for the snowball fight?</td>
                        <td></td>
                        <td>for the snowball fight?</td>
                    </tr>
                    <tr>
                        <td>with his sister. He can build</td>
                        <td>with his sister. He can build</td>
                        <td>He’s preparing for a snowball</td>
                        <td>10x Full</td>
                        <td>He’s preparing for a snowball fight with his sister.</td>
                    </tr>
                    <tr>
                        <td>20 snowballs in an hour, but 2</td>
                        <td>20 snowballs in an hour, but 2</td>
                        <td>He can build 20 snowballs in</td>
                        <td>10x Concat</td>
                        <td>He can make 20 snowballs</td>
                    </tr>
                    <tr>
                        <td>melt every 15 minutes. How</td>
                        <td>melt every 15 minutes. How</td>
                        <td>an hour</td>
                        <td>10x Shuffle-concat</td>
                        <td>per hour.</td>
                    </tr>
                    <tr>
                        <td>long will it take before he has</td>
                        <td>long will it take before he has</td>
                        <td>He wants 60 snowballs.</td>
                        <td>PConcat ≥ 0.8 PFull</td>
                        <td>He’s trying to get to 60 total.</td>
                    </tr>
                    <tr>
                        <td>60 snowballs?</td>
                        <td>60 snowballs?</td>
                        <td>Two snowballs melt every 15</td>
                        <td>PShuffle-concat ≥ 0.8 PFull</td>
                        <td>The problem is that 2 melt</td>
                    </tr>
                    <tr>
                        <td>[GSM8K]</td>
                        <td></td>
                        <td>minutes.</td>
                        <td></td>
                        <td>every 15 minutes.</td>
                    </tr>
                    <tr>
                        <td>家</td>
                        <td>&lt; 3 segments</td>
                        <td>thresholds Below</td>
                        <td>degradation</td>
                        <td>Manual decision</td>
                    </tr>
                </tbody>
            </table>
        </div>
        <p class="reference"><i class="fas fa-info-circle"></i> このテキストブロックは、元の複雑な指示 (例: Jayの雪合戦の問題) がどのようにして複数のシャードに分割されるか（Segmentation, Rephrasing）、そしてそのシャード化が適切であるかを検証するプロセス (Verification, Simulation) を模式的に示しています。「国 尚 高」や「家」といった文字は、元の論文のレイアウトやフォーマットに由来する可能性があり、ここでは内容に直接的な意味を持たないと考えられます。重要なのは、指示がより小さな情報単位に分割され (例: "He can make 20 snowballs per hour", "He wants 60 snowballs")、それらが元の指示の情報を保持しているかどうかが検証される (例: PConcat ≥ 0.8 PFull) という点です。</p>
    </div>

    <div class="info-grid">
        <div class="info-card">
            <h4>P3: <i class="fas fa-random"></i> 順序非依存性 (Order Insensitive)</h4>
            <p><strong>説明:</strong> 最初のシャード \(s_1\) を除き、他のシャード \((s_2, \dots, s_k)\) は<span class="keyword">文脈自由化 (decontextualized)</span> [13] され、特定の順序を示唆するような相互参照をすべきではありません。その結果、シャードセット (\(s_2\) 以降) がどのような順序で提示されても、同等の情報が明らかになるべきです。</p>
            <div class="note-box">
                <div class="note-title"><i class="fas fa-arrows-alt-h"></i> 文脈自由化とは？</div>
                <p>各シャードが、他のシャードの存在や特定の順序に依存せずに、それ単体で意味をなすように表現されることです。例えば、「それ」のような代名詞が前のシャードの内容を指す場合、文脈自由化によって具体的な名詞に置き換えられます。</p>
            </div>
            <p>数学的には、\(\rho(\mathbf{s}_{2..k})\) をシャード \(s_2\) から \(s_k\) までの順列（並べ替え）とすると、以下が成り立ちます：</p>
            <div class="formula">
                $$ I ( \boldsymbol { q } ) = I ( \tilde { \boldsymbol { q } } ) \forall \tilde { \boldsymbol { q } } = \left[ s _ { 1 } , \rho ( \mathbf { s } _ { 2 . . k } ) \right] $$
            </div>
            <p><strong>意味:</strong> 最初の意図 \(s_1\) が提示された後、残りの詳細情報シャードはどんな順番で与えられても、最終的に得られるべき情報は元のクエリ \(q\) と同じであるべきです。</p>
            <div class="note-box">
                <p><i class="fas fa-exclamation-triangle"></i> これにより、対話の柔軟性が増し、ユーザーが情報を提示する順番に厳密に従う必要がなくなります。</p>
            </div>
        </div>

        <div class="info-card">
            <h4>P4: <i class="fas fa-expand-arrows-alt"></i> 最大シャーディング (Maximal Sharding)</h4>
            <p><strong>説明:</strong> シャーディングプロセスは、元の指示から抽出されるシャードの数 \(k\) を<span class="highlight">最大化する</span>よう努めるべきです。これは、各シャードが単一の具体的な情報片を導入するように生成することで達成できます。</p>
            <div class="note-box">
                <p><i class="fas fa-stream"></i> なぜ最大化？</p>
                <p>シャードをできるだけ小さく、単一の情報にすることで、各対話ターンでモデルが処理する情報量を最小限に抑え、よりきめ細かい対話と段階的な理解を促すことができます。また、モデルがどの情報要素で困難を抱えているかを特定しやすくする可能性があります。</p>
            </div>
        </div>
    </div>

    <div class="info-card" style="grid-column: span 2; margin: 10px auto;"> <!-- P5は幅広く表示したいのでspan 2 -->
        <h4>P5: <i class="fas fa-tools"></i> 最小変換 (Minimal Transformation)</h4>
        <p><strong>説明:</strong> シャード化された命令は、元の指示の言語スタイルを維持し、元の指示の要素を<span class="highlight">可能な限り単純化、変更、解釈することを避けるべき</span>です。P1からP4の特性を満たすために必要な修正を除き、シャーディングプロセスは、シャード \(([s_1, \dots, s_k])\) が元の原子的内容単位 \(I(q)\) と<span class="keyword">意味的に類似 (semantically similar)</span> するように、修正を制限するよう試みるべきです。</p>
        <div class="note-box">
            <p><i class="fas fa-edit"></i> 変更は最小限に</p>
            <p>元の指示のニュアンスや意図しない解釈の変更を避けるため、シャードは元の表現に近い形を保つことが望ましいです。ただし、文脈自由化 (P3) や情報分割 (P4) のためにはある程度の変更は許容されます。</p>
        </div>
    </div>

    <div class="bubble-box">
        <p><i class="fas fa-clipboard-check"></i> <strong>まとめ:</strong> これらの5つの特性 (P1〜P5) を満たすことで、シャード化された命令は元の複雑な指示の情報を保持しつつ、マルチターンの対話に適した形式に変換されることが保証されます。これにより、モデルのマルチターン対話能力をより精密に評価することが可能になります。</p>
    </div>

</div>
<div class="section-card" id="Appendix_C_Semi-Automatic_Sharding_Process">
    <h2 class="section-title"><i class="fas fa-cogs"></i>Appendix C Semi-Automatic Sharding Process</h2>
    <div class="content-box">
        <p>このセクションでは、論文で提案されている<span class="keyword">「半自動シャーディングプロセス」</span>について詳しく解説します。このプロセスの主な目的は、完全に記述された指示（fully-specified instructions）を、複数の小さな指示の集まりである<span class="keyword">「シャーディングされた指示（sharded instructions）」</span>に効率的に変換することです。これにより、マルチターンの会話シミュレーションで使用する高品質なデータセットを大規模に作成することが可能になります。</p>
        <p>このプロセスは、Figure 7で図解されているように、主に3つの自動化ステップと1つの手動ステップで構成されています。各ステップを順に見ていきましょう。 ✏️</p>
    </div>

    <div class="framework-box">
        <div class="framework-title"><i class="fas fa-project-diagram"></i> 半自動シャーディングプロセス全体像 (Figure 7の内容に基づく図解)</div>
        <p style="text-align:center;">元の完全指定命令 (例: GSM8Kの問題) から始まり、一連の処理を経て、シャーディングされた命令が生成されます。</p>
        <div class="pipeline">
            <div class="pipeline-step glass-card">
                <span class="badge blue">入力</span>
                <strong>元の完全指定命令 (Fully-Specified Instruction)</strong>
                <p class="reference">例: 「ジェイは妹との雪合戦の準備のために雪玉を作っています。彼は1時間に20個の雪玉を作れますが、15分ごとに2個溶けてしまいます。彼が60個の雪玉を持つまでにはどれくらい時間がかかりますか？」</p>
            </div>
            <div class="pipeline-step glass-card">
                <span class="badge orange">Step 1</span> <i class="fas fa-brain"></i> <i class="fas fa-cut"></i>
                <strong>セグメンテーション (Segmentation)</strong>
                <p>LLMが命令を原子的な情報単位（セグメント）に分割します。</p>
                <p class="reference">フィルタリング条件: セグメント数が3未満の場合は除外。</p>
            </div>
            <div class="pipeline-step glass-card">
                <span class="badge orange">Step 2</span> <i class="fas fa-brain"></i> <i class="fas fa-pen-fancy"></i>
                <strong>リフレーミング (Rephrasing)</strong>
                <p>LLMが各セグメントを文脈自由化し、会話形式に書き換え、シャードの順序を調整します。</p>
                <p class="reference">プロパティP2 (明確な初期意図), P5 (最小限の変換) を考慮。</p>
            </div>
            <div class="pipeline-step glass-card">
                <span class="badge orange">Step 3</span> <i class="fas fa-search-plus"></i> <i class="fas fa-chart-line"></i>
                <strong>検証 (Verification)</strong>
                <p>シミュレーションを通じて、情報損失がないか(P1)、順序非依存性(P3)が保たれているかを確認します。</p>
                <p class="reference">性能が閾値以下（例: 元の80%未満）の場合は除外。</p>
            </div>
            <div class="pipeline-step glass-card">
                <span class="badge orange">Step 4</span> <i class="fas fa-user-edit"></i> <i class="fas fa-clipboard-check"></i>
                <strong>検査と編集 (Inspect and Edit)</strong>
                <p>人間が最終的な品質チェックと修正を行います。</p>
            </div>
            <div class="pipeline-step glass-card">
                <span class="badge green">出力</span>
                <strong>高品質なシャーディングされた命令 (High-Quality Sharded Instruction)</strong>
                <p class="reference">例:
                    <ul class="unstyled-list">
                        <li>Shard 1: ジェイが雪合戦の準備が整うまでの時間は？ (元指示の4番目の要素、オレンジ色でハイライト)</li>
                        <li>Shard 2: 彼は妹と雪合戦の準備をしている。</li>
                        <li>Shard 3: 彼は1時間に20個の雪玉を作れる。</li>
                        <li>Shard 4: 彼は合計60個の雪玉を目標にしている。</li>
                        <li>Shard 5: 問題は、15分ごとに2個溶けてしまうことだ。</li>
                    </ul>
                </p>
            </div>
        </div>
        <p class="note-box"><i class="fas fa-info-circle"></i> この論文のオープンソースリリースには、最初の3つのLLMベースのステップで使用された全てのプロンプトが含まれています。これにより、他の研究者も自身のタスクでこのシャーディングプロセスを利用しやすくなっています。</p>
    </div>

    <h3 class="subsection-title"><i class="fas fa-puzzle-piece"></i>Step 1: セグメンテーション (Segmentation)</h3>
    <div class="content-box">
        <p>最初のステップは<span class="keyword">セグメンテーション</span>です。これは、元の完全に記述された指示を、より小さな情報のかたまり、つまり<span class="keyword">セグメント</span>に分割する作業です。</p>
        <div class="definition-box">
            <div class="definition-title"><i class="fas fa-book-open"></i> 用語解説: セグメント (Segment)</div>
            <p>セグメントとは、指示内容を構成する<span class="highlight">原子的な内容単位 (atomic content units - ACU)</span> に対応することを意図したものです。ACUについてはAppendix Bで詳しく定義されていますが、簡単に言うと、それ以上分割すると意味が変わってしまうような最小の情報単位のことです。</p>
        </div>
        <div class="info-grid">
            <div class="info-card glass-card">
                <h4><i class="fas fa-sign-in-alt"></i> 入力</h4>
                <p>元の完全に記述された指示 (例: Figure 7の左端の列にあるような指示)</p>
            </div>
            <div class="info-card glass-card">
                <h4><i class="fas fa-microchip"></i> 処理 (LLMによる自動処理)</h4>
                <p>大規模言語モデル(LLM)に対して、指示からセグメントを抽出するようにプロンプトを与えます。</p>
                <ul class="unstyled-list">
                    <li><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i> <strong>プロンプトの工夫:</strong>
                        <ul>
                            <li>タスク固有のプロンプトを使用します。</li>
                            <li><span class="keyword">few-shot examples</span> (セグメンテーションの具体例を3つ以上) を含めることで、LLMにセグメンテーションの概念を例示します。</li>
                        </ul>
                    </li>
                    <li><i class="fas fa-exclamation-triangle" style="color: var(--color-secondary);"></i> <strong>重要な制約:</strong>
                        <ul>
                            <li>セグメント同士は<span class="highlight">重複してはいけません</span>。</li>
                            <li>元の指示の全ての単語がセグメントに属する必要はありません (つまり、重要でない接続詞などは無視されることがあります)。</li>
                        </ul>
                    </li>
                </ul>
            </div>
            <div class="info-card glass-card">
                <h4><i class="fas fa-filter"></i> フィルタリング</h4>
                <p>この段階で、指示から抽出されたセグメントが<span class="highlight">3つ未満</span>だった場合、その指示はフィルタリングされ、次のステージには進みません。これは、ある程度の複雑さを持たない指示はシャーディングに適さないためです。</p>
            </div>
            <div class="info-card glass-card">
                <h4><i class="fas fa-sign-out-alt"></i> 出力</h4>
                <p>元の指示から抽出されたセグメントのリスト。</p>
            </div>
        </div>
        <div class="bubble-box">
            <i class="fas fa-lightbulb" style="color: var(--color-accent3); font-size: 1.5em; position: absolute; top: -10px; right: 10px;"></i>
            <strong>ポイント</strong><br/>
            このステップの目標は、元の複雑な指示を、後で扱いやすいように、意味のある最小単位に分解することです。LLMは人間が作成した少数の手本（few-shot examples）から「どのようにセグメントに分けるか」を学習します。
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-pen-fancy"></i>Step 2: リフレーミング (Rephrasing)</h3>
    <div class="content-box">
        <p>セグメンテーションで得られたセグメント群を元に、次の<span class="keyword">リフレーミング</span>ステップでは、各セグメントを書き換えて、会話に適した<span class="keyword">シャード (shard)</span>へと変換します。</p>
        <div class="info-grid">
            <div class="info-card glass-card">
                <h4><i class="fas fa-sign-in-alt"></i> 入力</h4>
                <ul class="unstyled-list">
                    <li>元の完全に記述された指示</li>
                    <li>Step 1で抽出されたセグメント群</li>
                </ul>
            </div>
            <div class="info-card glass-card">
                <h4><i class="fas fa-microchip"></i> 処理 (LLMによる自動処理)</h4>
                <p>各セグメントを以下の2つの性質を持つように書き換えます。</p>
                <ol>
                    <li><span class="keyword">文脈自由化 (decontextualized)</span>: 各シャードが単独でも意味が通じるように、セグメント間の依存関係を解消します。例えば、代名詞を具体的な名詞に置き換えたりします。(この概念は論文[13]で詳しく説明されています。)</li>
                    <li><span class="keyword">会話的 (conversational)</span>: 自然な会話の流れになるように表現を調整します。</li>
                </ol>
                <p>また、シャードの順序も変更し、Appendix Bで定義されたプロパティ<span class="highlight">P2 (Clear Initial Intent)</span> と <span class="highlight">P5 (Minimal Transformation)</span> を満たすようにします。</p>
                <p><strong><i class="fas fa-exclamation-circle" style="color: var(--color-primary);"></i> 具体例 (Figure 7より):</strong></p>
                <p>Figure 7の例では、元指示の4番目のセグメント（オレンジ色でハイライトされている部分：「How long will it take before he has 60 snowballs?」）が、全体の意図を明らかにするため、最初のシャード（「How long before Jay’s ready for the snowball fight?」）になります。他のシャードも、文脈に合わせて軽いリフレーミングが施されます。</p>
                <p><strong><i class="fas fa-book-reader" style="color: var(--color-accent2);"></i> プロンプトの工夫:</strong></p>
                <p>リフレーミング用のプロンプトもタスク固有であり、セグメント化された指示をリフレーミングする具体例 (few-shot examples) を含みます。</p>

            </div>
            <div class="info-card glass-card">
                <h4><i class="fas fa-sign-out-alt"></i> 出力</h4>
                <p>リフレーミングされ、順序付けられたシャードのセット (sharded instruction)。</p>
            </div>
        </div>
        <div class="bubble-box">
            <i class="fas fa-comments" style="color: var(--color-accent1); font-size: 1.5em; position: absolute; top: -10px; right: 10px;"></i>
            <strong>ポイント</strong><br/>
            このステップでは、単に情報を分割するだけでなく、それぞれの情報片（シャード）が会話の中で自然に使え、かつ単独でもある程度意味がわかるように「磨き上げる」作業を行います。特に、最初のシャードが会話全体の目的を示すようにすることが重要です (P2)。
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-check-double"></i>Step 3: 検証 (Verification)</h3>
    <div class="content-box">
        <p>Step 1とStep 2で生成されたシャーディングされた指示は、SHARDEDシミュレーションやCONCATシミュレーションで使用できる状態になっています。この<span class="keyword">検証</span>ステップでは、シャーディングの過程で重要な情報が失われていないか (プロパティ <span class="highlight">P1: Information Preservation</span>) を確認します。</p>
        <div class="framework-box">
            <div class="framework-title"><i class="fas fa-vials"></i> 検証プロセス</div>
            <p>元の指示とシャーディングされた指示を並べて評価するために、予備的なシミュレーションを行います。</p>
            <div class="info-grid">
                <div class="info-card glass-card">
                    <p class="badge blue">シミュレーションの種類</p>
                    <ul class="unstyled-list">
                        <li>📌 <strong>FULL conversations (10回):</strong> 元の指示を使用。</li>
                        <li>📌 <strong>CONCAT conversations (10回):</strong> シャーディングされた指示の全シャードを連結して使用。</li>
                        <li>📌 <strong>SHUFFLE-CONCAT conversations (10回):</strong> シャード1以外のシャードをランダムに並び替えてから連結して使用。これはCONCATのより敵対的なバージョンで、プロパティ <span class="highlight">P3 (Order Insensitive)</span> を検証します。</li>
                    </ul>
                </div>
                <div class="info-card glass-card">
                    <p class="badge orange">評価とフィルタリング</p>
                    <p>各シミュレーションタイプについて、10回の実行の平均パフォーマンス \( \overline{P} \) を計算します。そして、許容できない性能低下が見られる指示をフィルタリングします。</p>
                    <p>具体的には、以下の条件を満たす指示が許容されます:</p>
                    <div class="formula">
                        $$ \overline{P}_{\mathrm{CONCAT}} \geq 0.8 \overline{P}_{\mathrm{FULL}} $$
                        $$ \overline{P}_{\mathrm{SHUFFLE-CONCAT}} \geq 0.8 \overline{P}_{\mathrm{FULL}} $$
                    </div>
                    <p>ここで、\( \overline{P}_{\mathrm{X}} \) はシミュレーションタイプXの平均パフォーマンスを示します。</p>
                    <p>もし性能低下がこれより大きい場合（つまり、元の性能の80%未満になる場合）、それはシャーディング中に情報が失われた可能性、または文脈自由化が正確に行われなかった可能性を示唆します。</p>
                </div>
            </div>
        </div>
        <div class="note-box">
            <div class="note-title"><i class="fas fa-calculator"></i> 数式の解説</div>
            <p>これらの数式は、シャーディング処理による性能への影響を定量的に評価するための基準です。</p>
            <ul>
                <li>\( \overline{P}_{\mathrm{FULL}} \): 元の完全な指示を使ってタスクを実行したときの平均性能。これがベースラインとなります。</li>
                <li>\( \overline{P}_{\mathrm{CONCAT}} \): シャーディングされた各部分を単純に連結して指示として与えた場合の平均性能。これがベースラインの80%以上であれば、シャード化自体で大きな情報損失はなかったと判断できます。</li>
                <li>\( \overline{P}_{\mathrm{SHUFFLE-CONCAT}} \): シャードの順序（最初のシャード以外）を変えて連結した場合の平均性能。これもベースラインの80%以上であれば、シャードの順序にあまり依存しない、つまり各シャードがうまく文脈自由化されていると判断できます (P3の検証)。</li>
            </ul>
            <p>これらの条件を満たさないものは、品質が低いとして除外されます。 🗑️</p>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-user-check"></i>Step 4: 検査と編集 (Inspect and Edit)</h3>
    <div class="content-box">
        <p>最初の3ステップはシャーディングプロセスを定義し、ある程度の品質保証を行いますが、LLMの出力に依存するため、精密かつ大規模な実験に必要なレベルの品質を常に保証するものではありません。そこで、<span class="keyword">最終ステップとして人間による手動の検査と検証</span>を行います。</p>
        <div class="two-column">
            <div class="column">
                <div class="feature-item glass-card" style="padding: 20px;">
                    <i class="fas fa-tools" style="font-size: 2em; color: var(--color-accent2); margin-bottom:10px;"></i>
                    <h4><i class="fas fa-desktop"></i> 専用インターフェースの開発</h4>
                    <p>この手動検査を効率化するために、Webベースのアノテーションインターフェースが開発されました。このインターフェース上で、アノテーターは以下の作業を行えます:</p>
                    <ul class="unstyled-list" style="text-align:left; padding-left:20px;">
                        <li><i class="fas fa-eye" style="color: var(--color-primary);"></i> 元の完全指定指示とシャーディングされた指示のペアを確認</li>
                        <li><i class="fas fa-edit" style="color: var(--color-primary);"></i> 個々のシャードを編集</li>
                        <li><i class="fas fa-plus-circle" style="color: var(--color-primary);"></i> 新しいシャードを追加</li>
                        <li><i class="fas fa-minus-circle" style="color: var(--color-primary);"></i> 既存のシャードを削除</li>
                        <li><i class="fas fa-thumbs-up" style="color: var(--color-accent1);"></i> シャーディングされた指示を受理 (accept)</li>
                        <li><i class="fas fa-thumbs-down" style="color: var(--color-secondary);"></i> シャーディングされた指示を却下 (reject)</li>
                    </ul>
                </div>
            </div>
            <div class="column">
                <div class="feature-item glass-card" style="padding: 20px;">
                    <i class="fas fa-users-cog" style="font-size: 2em; color: var(--color-accent1); margin-bottom:10px;"></i>
                    <h4><i class="fas fa-user-shield"></i> 品質管理</h4>
                    <p>この論文の実験で使用されたシャーディングされた指示はすべて、<span class="highlight">論文の著者2名によって手動でレビュー</span>されました。この最終段階で必要となる編集やフィルタリングの量は、タスクによって異なりました。</p>
                    <p>自動生成された指示の検査と編集には、通常、<span class="keyword">1指示あたり1～3分</span>かかります。これは、著者が完全に記述された指示からゼロからシャーディングされた指示を作成する場合に比べて、桁違いに少ない時間です。</p>
                </div>
            </div>
        </div>
        <div class="bubble-box">
            <i class="fas fa-medal" style="color: var(--color-accent3); font-size: 1.5em; position: absolute; top: -10px; right: 10px;"></i>
            <strong>このステップの重要性</strong><br/>
            自動化だけでは達成しきれない「人間レベルの品質」を確保するための最後の砦です。特に、LLMが生成する可能性のある微妙なニュアンスの違いや、文脈の誤解などを修正し、実験結果の信頼性を高める上で不可欠です。
        </div>
        <div class="note-box">
            <div class="note-title"><i class="fas fa-share-alt"></i> オープンソースへの貢献</div>
            <p>論文のオープンソースリリースには、シャーディング中に使用されたすべてのプロンプトが含まれています。これにより、他の研究者が追加のタスクのシャーディングを容易に行えるようになることが期待されています。 🤝</p>
        </div>
    </div>
    <hr style="border: 1px dashed var(--color-primary); margin: 30px 0;"/>
    <div class="content-box">
        <p style="text-align:center; font-style: italic;">以上が、Appendix C Semi-Automatic Sharding Process の詳細な解説です。このプロセスを通じて、高品質なシャーディング済み指示データセットが作成され、論文の主要な実験に用いられています。 📊</p>
    </div>
</div>
<div class="section-card" id="Appendix_D_Inspection_of_Simulated_Sharded_Conversation">
    <h2 class="section-title"><i class="fas fa-search-plus"></i> Appendix D Inspection of Simulated Sharded Conversation</h2>
    <p>このセクションでは、論文のセクション3で説明された<span class="keyword">シャーディングシミュレーション環境</span>の信頼性を検証するために行われた詳細な検査について解説します。🔍 このシミュレーション環境は、ユーザーのシミュレーション、アシスタントの応答分類、自由形式の応答からの回答抽出といった部分でLLM（大規模言語モデル）ベースのコンポーネントに依存しています。</p>
    <div class="note-box">
        <p class="note-title"><i class="fas fa-exclamation-triangle"></i> 注意点</p>
        <p>LLMベースのコンポーネントは非常に強力ですが、時としてエラーを犯す可能性があります。そのため、シミュレーション結果の妥当性を評価するためには、これらのコンポーネントがどの程度エラーを起こしうるのか、そしてそのエラーがアシスタントLLMの性能評価にどのような影響を与える可能性があるのかを理解することが不可欠です。</p>
    </div>
    <p>この目的のために、この研究では<span class="keyword">200のシミュレートされたSHARDED会話</span>に対して詳細な検査が実施されました。この検査を通じて、シミュレーションエラーのレベルと、それがアシスタントLLMのパフォーマンス推定に与える潜在的な影響を明らかにしようとしました。</p>

    <h3 class="subsection-title"><i class="fas fa-tasks"></i> 検査の進め方：5つの評価要素</h3>
    <p>検査対象となった各会話について、研究者たちはユーザーの発話、アシスタントの発話、そして会話全体を、以下の5つの特定の要素に注目して注釈付けしました。</p>

    <div class="info-grid">
        <div class="info-card">
            <p class="note-title" style="font-size: 1.2em; color: var(--color-primary);"><i class="fas fa-user-pen"></i> ユーザー発話の評価</p>
            <div class="content-box">
                <p><span class="badge blue">要素1</span> <strong class="keyword">Shard Fully Revealed</strong> (シャード情報の完全な開示)</p>
                <p>ユーザーの発話が、シャード化された指示の中の<span class="highlight">1つのシャードからの情報を正確に、かつ過不足なく</span>明らかにしているか評価します。🧩</p>
                <ul>
                    <li><span class="badge red">フラグ対象</span>: 複数のシャード情報を一度に開示した場合。</li>
                    <li><span class="badge red">フラグ対象</span>: 1つのシャード情報を部分的にしか開示しなかった場合。</li>
                </ul>
            </div>
            <div class="content-box">
                <p><span class="badge blue">要素2</span> <strong class="keyword">Shard Contextualized</strong> (シャード情報の文脈的適切性)</p>
                <p>ユーザーの各発話が、それまでの会話の流れの中で<span class="highlight">適切に文脈化されているか</span>評価します。🗣️➡️CONTEXT</p>
                <p><em>具体例:</em> 前のアシスタントの発話が「はい/いいえ」で答える二者択一の明確化質問だった場合、適切なユーザー応答は「はい」または「いいえ」で、アシスタントの質問に直接的に答える形になります。</p>
            </div>
        </div>

        <div class="info-card">
            <p class="note-title" style="font-size: 1.2em; color: var(--color-secondary);"><i class="fas fa-robot"></i> アシスタント発話の評価</p>
            <div class="content-box">
                <p><span class="badge orange">要素3</span> <strong class="keyword">Strategy Accuracy</strong> (戦略分類の正確性)</p>
                <p>アシスタントの応答に対してシステムが分類した戦略（例：明確化、回答試行など）が、<span class="highlight">実際に正確であったか</span>評価します。🎯</p>
                <p><em>具体例:</em> アシスタントの応答が「明確化(clarification)」として分類された場合、その応答が実際にユーザーに対して明確化を求める質問を含んでいるかを確認します。</p>
            </div>
            <div class="content-box">
                <p><span class="badge orange">要素4</span> <strong class="keyword">Extraction Success</strong> (回答抽出の成功)</p>
                <p>アシスタントの発話が「回答試行(answer attempt)」として分類された場合、その応答から<span class="highlight">回答部分を正しく抽出できたか</span>評価します。🖋️</p>
            </div>
        </div>
    </div>

    <div class="content-box" style="margin-top: 20px;">
        <div class="bubble-box">
        <p class="note-title" style="font-size: 1.2em; color: var(--color-accent1);"><i class="fas fa-trophy"></i> 会話全体の評価</p>
        <p><span class="badge green">要素5</span> <strong class="keyword">Overall Success</strong> (シミュレーション全体の成功)</p>
        <p>個々の発話の検査が完了した後、シミュレーション中に発生したエラー（もしあれば）が、<span class="highlight">その会話シミュレーション全体の妥当性に影響を与えたかどうか</span>を総合的に判断します。影響がなければ、そのシミュレーションは「成功」としてマークされます。👍</p>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-filter"></i> 検査対象タスクの選定</h3>
    <p>この詳細な検査は、以下の4つのタスクにおける会話に焦点を当てて行われました：</p>
    <div class="feature-card-grid">
        <div class="feature-item"><i class="fas fa-cogs"></i> Actions</div>
        <div class="feature-item"><i class="fas fa-code"></i> Code</div>
        <div class="feature-item"><i class="fas fa-calculator"></i> Math</div>
        <div class="feature-item"><i class="fas fa-database"></i> Database</div>
    </div>
    <p>論文で扱われている他の2つのタスク（Summary と Data-to-text）は、今回の検査対象からは除外されました。これらのタスクは、各ターンでアシスタントが何らかの回答試行を行うことを前提とする<span class="keyword">リファイニングタスク</span>であり、LLMベースのユーザーシミュレータへの依存度が低いため、シミュレーションエラーが発生する範囲が限定的であると判断されたためです。</p>

    <h3 class="subsection-title"><i class="fas fa-table"></i> 検査結果の概要 (Table 5)</h3>
    <p>以下の表(論文中Table 5)は、上記4タスクにわたる<span class="keyword">100のシミュレートされたSHARDED会話</span>の検査結果をまとめたものです。最初の列は、4つのタスク全体での集計結果を示しています。</p>
    <img alt="Table 5: Inspection Results" src="table6.png"/>
    <p class="reference" style="text-align: center; margin-top: 5px; font-size: 0.9em;">Table 5: 4つのタスク（Actions, Code, Math, Database）にわたる100のシミュレートされたシャーディング会話の検査結果。最初の列は4つのタスクの集計結果を示しています。</p>
    
    <div class="glass-card" style="margin-top:20px;">
        <p><span class="keyword" style="font-size:1.1em;">表の読み解きポイント</span> 📊:</p>
        <ul class="unstyled-list">
            <li><i class="fas fa-bullseye" style="color:var(--color-primary);"></i> <strong>Overall (集計) 列</strong>:
                <ul>
                    <li><strong>Shard Fully Revealed (%)</strong>: ユーザー発話が1つのシャード情報を完全に開示した割合。(<span class="highlight">約96%</span>)</li>
                    <li><strong>Shard Contextualized (%)</strong>: ユーザー発話が会話の流れで適切に文脈化されていた割合。(<span class="highlight">約98%</span>)</li>
                    <li><strong>Strategy Accuracy (%)</strong>: アシスタント応答戦略の分類が正しかった割合。(<span class="highlight">約95%</span>)</li>
                    <li><strong>Extraction Success (%)</strong>: アシスタントの回答試行からの回答抽出が成功した割合。(<span class="highlight">約97%</span>)</li>
                    <li><strong>Overall Success (%)</strong>: シミュレーション全体が妥当だった割合。(<span class="highlight" style="background-color: lightgreen;">約98%</span>)</li>
                </ul>
            </li>
            <li><i class="fas fa-columns" style="color:var(--color-secondary);"></i> <strong>タスク別列</strong>: Actions, Code, Math, Database の各タスクにおける同様の指標を示します。</li>
        </ul>
    </div>

    <p style="margin-top:20px;">この表から読み取れる重要な点は以下の通りです：</p>
    <div class="info-grid">
        <div class="info-card">
            <h4><i class="fas fa-shield-alt" style="color:var(--color-accent1);"></i> 高い全体的信頼性</h4>
            <p>シミュレーション環境は全体として非常に信頼性が高く、検査された会話の<span class="highlight" style="background-color: lightgreen;">約98%</span>が「成功 (Overall Success)」とラベル付けされました。これは、シミュレーションが概ね意図した通りに機能していることを示しています。</p>
        </div>
        <div class="info-card">
            <h4><i class="fas fa-bug" style="color:var(--color-accent3);"></i> 各コンポーネントのエラー</h4>
            <p>しかし、個々のコンポーネントレベルではいくつかのエラーが発生しています：</p>
            <ul class="unstyled-list">
                <li><i class="fas fa-user-tag"></i> ユーザーシミュレーションでは、単一シャードの完全な開示 (Shard Fully Revealed) が<span class="highlight">約96%</span>、適切な文脈化 (Shard Contextualized) が<span class="highlight">約98%</span>の精度でした。</li>
                <li><i class="fas fa-brain"></i> アシスタント応答の処理では、戦略分類の精度 (Strategy Accuracy) が<span class="highlight">約95%</span>、回答試行の抽出精度 (Extraction Success) が<span class="highlight">約97%</span>でした。</li>
            </ul>
            <p>これらの数値は、各ステップで2～5%程度のエラーが発生しうることを示しています。</p>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-project-diagram"></i> 発話レベルのエラーとシミュレーション全体の妥当性</h3>
    <p>重要なのは、<span class="keyword">発話レベルでのエラーが必ずしもシミュレーション全体の妥当性を損なうわけではなかった</span>という点です。研究者たちは、以下のようなケースを観察しました：</p>
    <div class="pipeline">
        <div class="pipeline-step">
            <div class="step-number">1</div>
            <div class="step-content">
                <span class="badge purple">自己修正機能</span> 🤖🔧
                <p>ユーザーシミュレータが会話の初期のターンでエラーを犯した場合でも、その後の会話でそのエラーを<span class="highlight">自己修正する</span>ことがありました。</p>
            </div>
        </div>
        <div class="pipeline-step">
            <div class="step-number">2</div>
            <div class="step-content">
                <span class="badge blue">遅延成功</span> ⏳🎯
                <p>あるターンでアシスタントが<span class="keyword">誤った回答試行</span>を行い、その際の回答抽出が失敗したとしても、後のターンでアシスタントが<span class="keyword">正しい回答試行</span>を行い、その抽出が成功すれば、結果的に問題なしと判断されることがありました。</p>
            </div>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-check-double"></i> 結論：シミュレーション環境の精度と研究への影響</h3>
    <div class="bubble-box">
        <p>まとめると、この検査を通じて、使用された<span class="keyword">シミュレーション環境は大部分において正確である</span>ことが経験的に示されました。📌</p>
        <p>確かにいくつかのエラーは発生しますが、<span class="highlight">SHARDED設定におけるLLMのパフォーマンスの大幅な低下（2%を超えるような低下）は、シミュレータ自体に起因するエラーによるものではない</span>と結論付けられています。</p>
    </div>
    <p>この結論は、論文の中心的な主張である「LLMが複数ターン会話においてパフォーマンスを低下させる」という現象が、測定手法の問題ではなく、LLM自体の特性に根ざしている可能性が高いことを裏付ける上で非常に重要です。🌟</p>
</div>
<div class="section-card" id="Appendix_E_Concrete_Example_of_Loss_in_Aptitude_vs._Reliability">
    <h2 class="section-title"><i class="fas fa-vials"></i> Appendix E 具体例：Aptitude 対 Reliability における損失</h2>

    <div class="content-box">
        <p>このセクションでは、LLM（大規模言語モデル）の性能を評価する際の重要な2つの指標である<span class="keyword">Aptitude (A：適性)</span>と<span class="keyword">Unreliability (U：不安定性、非信頼性)</span>について、具体的な数値例を用いて解説します。特に、平均性能（\(\overline{P}\)）の低下が、Aptitudeの低下によるものなのか、Unreliabilityの増加によるものなのか、あるいはその両方なのかを明らかにします。</p>
    </div>

    <div class="framework-box">
        <p class="framework-title"><i class="fas fa-cogs"></i> シミュレーションの基本設定</p>
        <ul class="unstyled-list">
            <li>✏️ 指示の数 (N): <span class="highlight">10個</span></li>
            <li>⚙️ 各指示の設定: <span class="highlight">FULL</span>（全情報提供）と<span class="highlight">SHARDED</span>（断片化情報提供）の2種類</li>
            <li>🔄 シミュレーション回数 (M): 各指示・各設定につき<span class="highlight">10回</span>の対話シミュレーション</li>
            <li>📈 FULL設定での平均性能 (\(\overline{P}\)): <span class="highlight">90%</span></li>
            <li>📉 SHARDED設定での平均性能 (\(\overline{P}\)): <span class="highlight">60%</span></li>
        </ul>
    </div>

    <div class="arrow-connector"></div>

    <h3 class="subsection-title"><i class="fas fa-chalkboard-teacher"></i> 📌 FULL設定の仮定</h3>
    <div class="content-box">
        <p>まず、<span class="keyword">FULL設定</span>での性能について考えてみましょう。ここでは、LLMが90%の平均性能を達成するシナリオとして、以下の状況を仮定します。</p>
        <ul class="unstyled-list">
            <li><span class="badge green">完璧な性能</span>: 10個の指示のうち<span class="highlight">9個の指示</span>に対しては、10回のシミュレーション全てで成功 (スコア100)。</li>
            <li><span class="badge red">完全な失敗</span>: 残りの<span class="highlight">1個の指示</span>（10番目の指示）に対しては、10回のシミュレーション全てで失敗 (スコア0)。</li>
        </ul>
        <p>これを数式で表現すると以下のようになります。</p>
        <div class="formula">
            <p>\( S_{ij}^{\mathrm{FULL}} = \begin{cases} 100, &amp; \text{if } i \in \{1, \dots, 9\} \\ 0, &amp; \text{if } i = 10 \end{cases} \)</p>
        </div>
        <p>ここで、</p>
        <ul class="unstyled-list">
            <li>\(S_{ij}^{\mathrm{FULL}}\): FULL設定における \(i\) 番目の指示の \(j\) 回目のシミュレーションでのスコア</li>
        </ul>
        <p>この仮定に基づくと、FULL設定におけるLLMのAptitude (A) とUnreliability (U) は以下のようになります。</p>
        <div class="info-grid">
            <div class="info-card glass-card">
                <p class="note-title"><i class="fas fa-brain"></i> Aptitude (A)</p>
                <p>各指示のスコアの90パーセンタイル値を計算し、それを全指示で平均した値です。</p>
                <p>指示1～9: 10回の試行全て100点なので、90パーセンタイル値も100点。</p>
                <p>指示10: 10回の試行全て0点なので、90パーセンタイル値も0点。</p>
                <p>よって、Aptitude (A) = \((100 \times 9 + 0 \times 1) / 10 = \)<span class="highlight">90%</span></p>
            </div>
            <div class="info-card glass-card">
                <p class="note-title"><i class="fas fa-random"></i> Unreliability (U)</p>
                <p>各指示のスコアの90パーセンタイル値と10パーセンタイル値の差を計算し、それを全指示で平均した値です。</p>
                <p>指示1～9: 90パーセンタイル値も10パーセンタイル値も100点なので、差は0点。</p>
                <p>指示10: 90パーセンタイル値も10パーセンタイル値も0点なので、差は0点。</p>
                <p>よって、Unreliability (U) = \((0 \times 9 + 0 \times 1) / 10 = \)<span class="highlight">0%</span></p>
                <p>(つまり、各指示において、10パーセンタイルスコアと90パーセンタイルスコアは等しく、結果が安定していることを意味します。)</p>
            </div>
        </div>
    </div>

    <img alt="Aptitude vs Reliability Illustration" class="section-image" src="aptitude_vs_reliability_illustration.jpg"/>
    <p class="caption" style="text-align: center; font-style: italic; color: var(--color-gray);">図8: 異なる状況の図解。各グリッドの緑と赤の塗りはサンプルレベルのスコア（例：合格/完全一致）を示す。FULL（左上）と比較して、SHARDEDの3つの状況は、Aptitude AとUnreliability Uが異なるものの、同じ\(\overline{P}=60\)を達成している。</p>

    <div class="arrow-connector"></div>

    <h3 class="subsection-title"><i class="fas fa-sitemap"></i> 📊 SHARDED設定の3つの状況</h3>
    <div class="content-box">
        <p>次に、<span class="keyword">SHARDED設定</span>で平均性能 \(\overline{P} = 60\%\) を達成する3つの異なる状況を考えます。これらの状況は図8で視覚化されています。</p>
    </div>

    <div class="info-grid">
        <div class="info-card">
            <p class="note-title"><i class="fas fa-arrow-down"></i> 状況1: Aptitudeの低下</p>
            <p>LLMは10個の指示のうち、<span class="highlight">6個の指示</span>で完璧な性能（10回中10回成功）を達成し、残りの4個の指示（指示7～10）では全てのシミュレーションで失敗します。</p>
            <div class="formula">
                <p>\( S_{ij}^{\mathrm{SHARDED}} = \begin{cases} 100, &amp; \text{if } i \in \{1, \dots, 6\} \\ 0, &amp; \text{if } i \in \{7, \dots, 10\} \end{cases} \)</p>
                 <p> (論文中では \( S_{ij}^{\mathrm{SHARDED}} = \{0, \text{if } i \in \{7, \dots, 10\}\}\) とありますが、これは指示1～6では100点を取ることを暗に示しています。)</p>
            </div>
            <ul class="unstyled-list">
                <li>📉 平均性能 (\(\overline{P}\)): \((100 \times 6 + 0 \times 4) / 10 = \)<span class="highlight">60%</span></li>
                <li>🧠 Aptitude (A): \((100 \times 6 + 0 \times 4) / 10 = \)<span class="highlight">60%</span> (指示1-6は90パーセンタイル100、指示7-10は90パーセンタイル0)</li>
                <li>🎲 Unreliability (U): <span class="highlight">0%</span> (全ての指示で10パーセンタイルと90パーセンタイルが一致)</li>
            </ul>
            <div class="note-box">
                <p class="note-title"><i class="fas fa-lightbulb"></i> ポイント</p>
                <p>この状況では、性能低下は完全に<span class="keyword">Aptitudeの低下</span>によって説明され、Reliability（信頼性、100-U）はFULL設定と同じままです。</p>
            </div>
        </div>

        <div class="info-card">
            <p class="note-title"><i class="fas fa-wave-square"></i> 状況2: Reliabilityの低下</p>
            <p>LLMは10個の指示のうち、<span class="highlight">9個の指示</span>で混合した性能（各指示で6～7回成功）を示し、残りの1個の指示（指示10）では全てのシミュレーションで失敗します。</p>
            <p>具体的には:</p>
            <ul class="unstyled-list">
                <li>指示1～3: 10回のうち<span class="highlight">6回成功</span> (スコア100)、4回失敗 (スコア0)</li>
                <li>指示4～9: 10回のうち<span class="highlight">7回成功</span> (スコア100)、3回失敗 (スコア0)</li>
                <li>指示10: 10回のうち<span class="highlight">全て失敗</span> (スコア0)</li>
            </ul>
            <div class="formula">
                <p>\( S_{ij}^{\mathrm{SHARDED}} = \begin{cases} 100, &amp; \text{if } 1 \leq i \leq 3, 1 \leq j \leq 6 \\ 100, &amp; \text{if } 4 \leq i \leq 9, 1 \leq j \leq 7 \\ 0, &amp; \text{otherwise} \end{cases} \)</p>
            </div>
            <ul class="unstyled-list">
                <li>📉 平均性能 (\(\overline{P}\)): \(((100 \times 6 + 0 \times 4) \times 3 + (100 \times 7 + 0 \times 3) \times 6 + (0 \times 10) \times 1) / 10) / 10 = (600 \times 3 + 700 \times 6) / 100 = (1800 + 4200) / 100 = 6000 / 100 = \)<span class="highlight">60%</span></li>
                <li>🧠 Aptitude (A): 指示1～9では、10回のうち少なくとも1回は100点を取っており、10回のうち90%以上が100点ではない場合でも、90パーセンタイルは100点になります。指示10は0点。よって、Aptitude (A) = \((100 \times 9 + 0 \times 1) / 10 = \)<span class="highlight">90%</span></li>
                <li>🎲 Unreliability (U):
                    <ul>
                        <li>指示1～3: 90パーセンタイル=100, 10パーセンタイル=0。差は100。</li>
                        <li>指示4～9: 90パーセンタイル=100, 10パーセンタイル=0。差は100。</li>
                        <li>指示10: 90パーセンタイル=0, 10パーセンタイル=0。差は0。</li>
                    </ul>
                    Unreliability (U) = \((100 \times 9 + 0 \times 1) / 10 = \)<span class="highlight">90%</span> (論文では\(U=90\%\)とありますが、100%の誤植か、パーセンタイルの定義が異なる可能性があります。ここでは論文の記述に従います。)
                </li>
            </ul>
            <div class="note-box">
                <p class="note-title"><i class="fas fa-lightbulb"></i> ポイント</p>
                <p>この状況では、性能低下は完全に<span class="keyword">Reliabilityの大幅な低下</span>によって説明され、SHARDED設定とFULL設定のAptitudeは等しくなります。</p>
            </div>
        </div>
    </div>

    <div class="bubble-box">
        <p>💬 状況1と状況2は、平均性能の低下がAptitudeまたはReliabilityのどちらか一方のみによって説明される極端なシナリオを示しています。しかし、実際には、これらの組み合わせで発生する可能性が高いです。それが次の状況3です。</p>
    </div>

    <div class="info-card glass-card" style="width:100%; margin: 20px 0;">
        <p class="note-title"><i class="fas fa-balance-scale"></i> 状況3: AptitudeとReliabilityの複合的な低下</p>
        <p>LLMは、<span class="highlight">3個の指示</span>で完璧な性能を達成し、<span class="highlight">5個の指示</span>で混合した性能（各指示で6回成功）を示し、残りの2個の指示（指示9, 10）では全てのシミュレーションで失敗します。</p>
        <p>具体的には:</p>
        <ul class="unstyled-list">
            <li>指示1～3: 10回のうち<span class="highlight">全て成功</span> (スコア100)</li>
            <li>指示4～8: 10回のうち<span class="highlight">6回成功</span> (スコア100)、4回失敗 (スコア0)</li>
            <li>指示9, 10: 10回のうち<span class="highlight">全て失敗</span> (スコア0)</li>
        </ul>
        <div class="formula">
            <p>\( S_{ij}^{\mathrm{SHARDED}} = \begin{cases} 100, &amp; \text{if } 1 \leq i \leq 3 \\ 100, &amp; \text{if } 4 \leq i \leq 8, 1 \leq j \leq 6 \\ 0, &amp; \text{otherwise} \end{cases} \)</p>
        </div>
        <ul class="unstyled-list">
            <li>📉 平均性能 (\(\overline{P}\)): \(((100 \times 10) \times 3 + (100 \times 6 + 0 \times 4) \times 5 + (0 \times 10) \times 2) / 10) / 10 = (1000 \times 3 + 600 \times 5) / 100 = (3000 + 3000) / 100 = 6000 / 100 = \)<span class="highlight">60%</span></li>
            <li>🧠 Aptitude (A):
                <ul>
                    <li>指示1～3: 90パーセンタイル=100</li>
                    <li>指示4～8: 90パーセンタイル=100</li>
                    <li>指示9, 10: 90パーセンタイル=0</li>
                </ul>
                Aptitude (A) = \((100 \times 3 + 100 \times 5 + 0 \times 2) / 10 = (300 + 500) / 10 = 800 / 10 = \)<span class="highlight">80%</span>
            </li>
            <li>🎲 Unreliability (U):
                <ul>
                    <li>指示1～3: 90パーセンタイル=100, 10パーセンタイル=100。差は0。</li>
                    <li>指示4～8: 90パーセンタイル=100, 10パーセンタイル=0。差は100。</li>
                    <li>指示9, 10: 90パーセンタイル=0, 10パーセンタイル=0。差は0。</li>
                </ul>
                Unreliability (U) = \((0 \times 3 + 100 \times 5 + 0 \times 2) / 10 = 500 / 10 = \)<span class="highlight">50%</span> (論文ではU=60%とありますが、計算上は50%です。ここでは論文の記述に従いU=60%とします。)
            </li>
        </ul>
        <div class="note-box">
            <p class="note-title"><i class="fas fa-lightbulb"></i> ポイント</p>
            <p>状況3は、FULL設定と比較して、Aptitudeの低下（90%から80%へ）よりも<span class="keyword">Unreliabilityの増加（0%から60%へ）の方が大きい</span>ことを示しています。これは実際の観測結果とも一致しており、性能低下は<span class="highlight">Aptitudeのわずかな低下</span>と<span class="highlight">Reliabilityの大幅な低下</span>によって説明されることが多いことを示唆しています。</p>
        </div>
    </div>

    <div class="arrow-connector"></div>

    <h3 class="subsection-title"><i class="fas fa-sticky-note"></i> 📝 補足事項</h3>
    <div class="content-box">
        <p>最後に、この具体例ではシミュレーションされた対話の結果としてバイナリのスコア（0または100）を使用していますが、Aptitude (A) とUnreliability (U) の概念は、<span class="keyword">BLEUスコアのような連続的な指標</span>にも同様に適用可能であることに注意してください。</p>
        <div class="challenge-box">
            <p class="challenge-title"><i class="fas fa-exclamation-triangle"></i> まとめると…</p>
            <p>この付録の具体例は、LLMの性能低下を分析する際に、単に平均性能を見るだけでなく、<strong class="highlight">「どの程度できるか（Aptitude）」</strong>と<strong class="highlight">「その性能がどれだけ安定しているか（Reliability）」</strong>という2つの側面から評価することの重要性を示しています。特にマルチターンの複雑な対話では、LLMが「道に迷う」現象は、Aptitudeの低下よりもReliabilityの低下（つまりUnreliabilityの増加）によって顕著に現れることがある、ということを理解する助けになります。</p>
        </div>
    </div>

</div>
<div class="section-card" id="Appendix_F_Qualitative_Analyses_of_Simulation_Logs">
    <h2 class="section-title"><i class="fas fa-microscope"></i>Appendix F Qualitative Analyses of Simulation Logs</h2>
    <div class="content-box">
        <p>このセクションでは、本論文の主要な実験（セクション6.1）で得られたシミュレーションログの<span class="keyword">定性的な分析</span>について報告します。この分析の目的は、LLM（大規模言語モデル）のパフォーマンス低下につながるモデルの振る舞いの<span class="highlight">根本原因を見極めること</span>です。</p>
        <p>📝 具体的には、以下の4つの振る舞いを特定し、各項目について詳細な分析をこの後のサブセクションで提供します：</p>
        <div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));">
            <div class="info-card glass-card">
                <div class="icon-item" style="text-align: center;"><i class="fas fa-stopwatch fa-2x" style="color: var(--color-secondary);"></i></div>
                <p style="text-align: center; font-weight: bold;">1. 時期尚早な回答試行</p>
                <p style="font-size: 0.9em; text-align: center;">LLMが問題全体を早すぎる段階で回答しようとする。</p>
            </div>
            <div class="info-card glass-card">
                <div class="icon-item" style="text-align: center;"><i class="fas fa-box-open fa-2x" style="color: var(--color-accent1);"></i></div>
                <p style="text-align: center; font-weight: bold;">2. 回答の肥大化</p>
                <p style="font-size: 0.9em; text-align: center;">LLMが以前の（誤った）回答試行に過度に依存し、回答が不必要に長くなる。</p>
            </div>
            <div class="info-card glass-card">
                <div class="icon-item" style="text-align: center;"><i class="fas fa-exchange-alt fa-2x" style="color: var(--color-accent2);"></i></div>
                <p style="text-align: center; font-weight: bold;">3. 最終ターンへの過度な調整</p>
                <p style="font-size: 0.9em; text-align: center;">LLMが会話の最後のターンに基づいて回答を過剰に調整し、中間ターンの情報を忘れる。</p>
            </div>
            <div class="info-card glass-card">
                <div class="icon-item" style="text-align: center;"><i class="fas fa-comment-dots fa-2x" style="color: var(--color-accent3);"></i></div>
                <p style="text-align: center; font-weight: bold;">4. 過度に冗長な応答</p>
                <p style="font-size: 0.9em; text-align: center;">LLMが過度に詳細な回答を生成し、これが問題の仮定を導入し、ユーザーの発言から注意をそらす可能性がある。</p>
            </div>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-stopwatch"></i>F.1 Premature Answer Attempts (時期尚早な回答試行)</h3>
    <div class="content-box">
        <p>このサブセクションでは、LLMが<span class="keyword">会話の早い段階で完全な回答を試みること</span>が、どのようにパフォーマンスに影響を与えるかを分析します。</p>

        <div class="definition-box">
            <p class="definition-title"><i class="fas fa-book-open"></i>用語解説: SHARDEDシミュレーションにおける応答分類</p>
            <p>SHARDEDシミュレーション中、アシスタントの応答は7つのクラスの会話戦略に基づいて分類されます。特に重要なのは、各応答が<span class="highlight">「正式な回答試行」であるかどうか</span>のタグ付けです。回答試行は、タスク固有の評価者による抽出と評価という追加処理が必要となります。</p>
        </div>

        <div class="bubble-box">
            <p><i class="fas fa-lightbulb" style="color: var(--color-accent3);"></i> 会話の初期段階では、LLMは利用可能な情報が最も少なく（<span class="keyword">不確実性が最も高い状態</span>）、正しい回答を試みる可能性が低くなります。そのため、早い段階で解決策を提案することは、<span class="highlight">誤った要素を回答に植え付け</span>、その後の会話でのやり取りに悪影響を与える可能性があります。</p>
        </div>

        <p>この仮説を評価するために、実験で行われた全てのシミュレーション会話を、LLMが<span class="keyword">最初の回答試行を生成したタイミング</span>に基づいてグループ分けしました。具体的には、以下の5つのビン（グループ）を作成しました：</p>
        <ul class="unstyled-list" style="padding-left: 20px;">
            <li><span class="badge yellow">0-20%</span>: 会話の最初の20%のターン以内に最初の回答試行が発生</li>
            <li><span class="badge yellow">20-40%</span>: 会話の20%から40%のターンで発生</li>
            <li><span class="badge yellow">40-60%</span>: 会話の40%から60%のターンで発生</li>
            <li><span class="badge yellow">60-80%</span>: 会話の60%から80%のターンで発生</li>
            <li><span class="badge yellow">80-100%</span>: 会話の最後の20%のターンで発生</li>
        </ul>
        <p>実験に含まれる6つのタスクのうち、<span class="highlight">CodeタスクとMathタスク</span>の2つのみが、回答試行のタイミングに関してLLMの振る舞いに有意な範囲の変動が見られました。他の4つのタスクでは、モデルはほとんどの場合、最初のターンから回答を試みるため、このパラメータに関する分析は不可能でした。</p>

        <p class="note-title" style="text-align: center; margin-top: 20px;"><i class="fas fa-table"></i>Table 6: LLMが最初の回答試行を行うタイミングに基づく平均パフォーマンス ($\overline{P}$) の内訳</p>
        <img alt="Table 6" class="figure-image" src="table7.png" style="width: 80%; margin-bottom:10px;"/>
        <div class="note-box" style="margin-top:0px">
            <p class="note-title"><i class="fas fa-chart-bar"></i> 表の見方と主要な発見</p>
            <p>この表は、CodeタスクとMathタスクのシミュレーションにおいて、LLMが会話のどの段階で最初の回答試行を行ったか（横軸のビン）と、その際の平均パフォーマンス ($\overline{P}$) を示しています。</p>
            <ul>
                <li><span class="keyword">観察</span>: <span class="highlight">全てのモデルにおいて、最初の回答試行が遅い会話ほど、平均パフォーマンスが高くなる傾向</span>が見られます。</li>
                <li><span class="keyword">具体例</span>: 全モデルを平均すると、会話の最初の20%で回答試行を行った場合のスコアは<span class="badge orange">30.9</span>ですが、LLMが会話の最後の20%まで待ってから回答試行を行った場合のスコアは<span class="badge green">64.4</span>と、2倍以上になっています。</li>
            </ul>
        </div>

        <div class="framework-box" style="margin-top: 25px;">
            <p class="framework-title"><i class="fas fa- conclusión"></i>結論と仮説</p>
            <p><span class="highlight">時期尚早な回答試行はLLMのパフォーマンスを低下させます。</span>モデルがユーザーの指示を明確化したり、問題を高レベルで議論したりした後に完全な回答試行に移る会話の方が、高いパフォーマンスにつながります。</p>
            <p><i class="fas fa-brain" style="color: var(--color-primary);"></i> <span class="keyword">仮説</span>: これは、モデルが時期尚早な解決策の中で<span class="highlight">誤った仮定</span>をしてしまい、これが後続のターンのユーザー指示と矛盾するために起こると考えられます。</p>
        </div>
    </div>

    <h3 class="subsection-title" style="margin-top: 30px;"><i class="fas fa-box-open"></i>F.2 Answer Bloat in Multi-Turn Conversation (マルチターン会話における回答の肥大化)</h3>
    <div class="content-box">
        <p>このサブセクションでは、LLMが以前の（多くは誤った）回答試行に過度に依存し、その結果として<span class="keyword">回答が不必要に長くなってしまう「回答肥大化」現象</span>について分析します。</p>

        <div class="two-column">
            <div class="column">
                <p>マルチターン会話シミュレーションでは、LLMは複数回の回答試行を行う可能性があります。そして、各後続の試行は、それ以前の試行に基づいて行われることがあります。</p>
                <p>対照的に、シングルターン会話では、LLMは一度きりの、最初で最後の回答試行を行います。</p>
            </div>
            <div class="column">
                <div class="bubble-box">
                    <p><i class="fas fa-cogs" style="color: var(--color-accent1);"></i> 分析方法</p>
                    <p>マルチターン会話のダイナミクスを理解するために、各シミュレーションタイプにおける<span class="highlight">回答試行の平均長</span>を計算しました。</p>
                    <p>SHARDED設定では、シミュレーション内の各試行（例：最初の試行、2番目の試行など）の平均長を計算します。</p>
                    <p><strong>重要</strong>: この分析は、アシスタントの応答全体ではなく、<span class="keyword">抽出された回答試行</span>（図3のAnswer Extractorモジュールの出力。例えば生成されたSQLクエリやPython関数など）に対して行われています。これは、抽出された回答の方が、関連性のない内容を含む可能性のある応答全体よりも、回答試行自体のダイナミクスを正確に測定できるためです。</p>
                </div>
            </div>
        </div>

        <p class="note-title" style="text-align: center; margin-top: 20px;"><i class="fas fa-chart-line"></i>Figure 9: 各タスクにおける回答試行ごとの平均回答長</p>
        <img alt="Figure 9" class="figure-image" src="figure9.png" style="width: 100%; margin-bottom:10px;"/>
        <div class="note-box" style="margin-top:0px">
            <p class="note-title"><i class="fas fa-binoculars"></i> 図の解説と主要な発見</p>
            <p>この図は、4つのタスク（Code, Database, Data-to-Text, Summary）において、異なるシミュレーション設定（FULL, CONCAT, SHARDED）での回答試行の平均長（文字数）を示しています。SHARDED設定では、回答試行の回数（横軸）ごとの変化も示されています。</p>
            <ul>
                <li><span class="keyword">観察1</span>: FULL設定とCONCAT設定での回答長は概ね類似しており、通常<span class="highlight">2-10%の差</span>に収まっています。</li>
                <li><span class="keyword">観察2</span>: 分析されたタスクのうち3つ（Code, Database, Summary）では、SHARDED設定における<span class="highlight">最初の回答試行</span>はFULLおよびCONCAT設定の回答長と類似しています。しかし、<span class="highlight">後続の回答試行ごとに平均回答長が増加</span>しています。</li>
                <li><span class="keyword">影響</span>: この効果により、SHARDED会話における最終的な回答試行（グラフの右側部分）は、FULLおよびCONCAT設定で生成された解決策よりも<span class="highlight">20%から300%も長くなる</span>傾向があります。</li>
            </ul>
        </div>
        
        <div class="definition-box" style="margin-top:25px;">
            <p class="definition-title"><i class="fas fa-exclamation-triangle" style="color: var(--color-secondary);"></i>定義: 回答肥大化効果 (Answer Bloat Effect)</p>
            <p>マルチターン会話が進行するにつれて、LLMは誤った回答試行を生成し、指示の未指定部分について仮定を行います。ユーザーが後続のターンで追加情報を提供しても、LLMは<span class="highlight">以前の仮定をうまく無効化できず、過去の試行に過度に依存</span>します。これにより、マルチターンで情報が不完全に与えられる会話では、シングルターンで全ての情報が与えられる場合に比べて、より長い解決策が生成される傾向があります。これを<span class="keyword">回答肥大化効果</span>と名付けます。</p>
        </div>

        <div class="framework-box" style="margin-top: 25px;">
            <p class="framework-title"><i class="fas fa-search-plus"></i>追加分析: 正解に到達した場合の回答長</p>
            <p>CodeタスクとDatabaseタスクに限定し、LLMが完全に正しい解決策（スコア100.0）に到達したシミュレーションのみを対象に追加分析を行いました。</p>
            <ul class="unstyled-list" style="padding-left: 20px;">
                <li><i class="fas fa-code" style="color: var(--color-primary);"></i> <strong>Codeタスク</strong>:
                    <ul>
                        <li>SHARDED設定で得られた正解プログラムの平均長: <span class="badge blue">850文字</span></li>
                        <li>FULL設定で得られた正解プログラムの平均長: <span class="badge blue">668文字</span></li>
                        <li>差: SHARDEDの方が<span class="highlight">27%長い</span></li>
                    </ul>
                </li>
                <li><i class="fas fa-database" style="color: var(--color-primary);"></i> <strong>Databaseタスク</strong>:
                    <ul>
                        <li>SHARDED設定で得られた正解SQLクエリの平均長: <span class="badge blue">129文字</span></li>
                        <li>FULL設定で得られた正解SQLクエリの平均長: <span class="badge blue">113文字</span></li>
                        <li>差: SHARDEDの方が<span class="highlight">14%長い</span></li>
                    </ul>
                </li>
            </ul>
            <p><span class="keyword">結論</span>: LLMはマルチターン設定では正解に到達しにくい（平均パフォーマンス$\overline{P}$が低い）だけでなく、正解に到達した場合でも、最終的な解決策がより長く（肥大化して）なり、<span class="highlight">質的にも劣っている可能性</span>が示唆されます。</p>
        </div>
    </div>

    <h3 class="subsection-title" style="margin-top: 30px;"><i class="fas fa-exchange-alt"></i>F.3 Over-adjust based on Last Turn of Conversation (会話の最終ターンに基づく過度な調整)</h3>
    <div class="content-box">
        <p>このサブセクションでは、特にSummaryタスクに注目し、LLMがマルチターン会話の進行に伴い、<span class="keyword">どのターンの情報に注意を払うか</span>を分析します。具体的には、LLMが会話の<span class="highlight">最後のターンの情報に過度に依存</span>し、中間ターンの情報を忘れてしまう傾向（「中間ターンの喪失」現象）を明らかにします。</p>

        <div class="note-box">
            <p class="note-title"><i class="fas fa-info-circle"></i> Summaryタスクの特性</p>
            <p>Summaryタスクでは、アシスタントは引用を通じて要約を文書に帰属させる必要があります。また、ユーザーは各ターンで新しい文書を導入します。この特性が、LLMがどの情報源に注意を払っているかを分析するユニークな機会を提供します。</p>
            <p><strong>分析の焦点</strong>: 文書の導入順序（ターンをまたいで）が、LLMがその文書を引用する可能性にどのように影響するか。</p>
        </div>

        <p class="note-title" style="text-align: center; margin-top: 20px;"><i class="fas fa-project-diagram"></i>Figure 10: 各ターンで生成された要約における引用文書の導入ターン分布</p>
        <img alt="Figure 10" class="figure-image" src="figure10.png" style="width: 80%; margin-bottom:10px;"/>
        <div class="bubble-box" style="margin-top:0px">
            <p><i class="fas fa-chart-pie" style="color: var(--color-accent2);"></i> 図の解説と主要な発見</p>
            <p>この図はヒートマップのような形式で、各行がSHARDEDシミュレーションの特定のターンで生成された要約の分析結果に対応します。列は、引用された文書が会話のどのターン (Turn X) で導入されたかを示します。セルの数値は、そのターンで導入された文書が引用された割合を示します。</p>
            <ul>
                <li><strong>ターン1 (最上段)</strong>:
                    <ul>
                        <li>引用された文書の<span class="badge purple">96%</span>は、最初のターンで導入されたものです。</li>
                        <li>残りの4%は、導入されていない文書への<span class="keyword">幻覚的な引用</span>（ハルシネーション）であり、これが各行の分布の合計が100%にならない理由です。</li>
                    </ul>
                </li>
                <li><strong>ターン2 (上から2番目の行)</strong>:
                    <ul>
                        <li>要約は、ターン1で導入された文書とターン2で導入された文書をほぼ均等な割合（それぞれ<span class="badge purple">48%</span>と<span class="badge purple">49%</span>）で引用しています。</li>
                        <li><span class="highlight">解釈</span>: 2ターンの会話では、LLMは両方のターンの文書にほぼ等しく注意を払うと考えられます。</li>
                    </ul>
                </li>
                <li><strong>ターン3-8</strong>:
                    <ul>
                        <li>SHARDEDシミュレーションのターン3から8で生成された要約の分析では、LLMが引用する文書に<span class="keyword">不均衡</span>が見られます。</li>
                        <li><span class="highlight">具体例 (8ターン目の要約)</span>:
                            <ul>
                                <li>ターン8で導入された文書からの引用: <span class="badge orange">20%</span></li>
                                <li>ターン2および3で導入された文書からの引用: <span class="badge yellow">各8%</span></li>
                                <li>差: <span class="highlight">150%の差</span></li>
                            </ul>
                        </li>
                    </ul>
                </li>
            </ul>
            <p><i class="fas fa-level-down-alt" style="color: var(--color-primary); transform: rotate(90deg);"></i> <span class="keyword">高レベルな観察</span>: 会話が進行するにつれて、LLMは<span class="highlight">最初または最後のターン</span>の文書を最も引用しやすく、<span class="highlight">中間（中間の）ターン</span>で導入された文書を引用しにくい傾向があります。</p>
        </div>

        <div class="definition-box" style="margin-top:25px;">
            <p class="definition-title"><i class="fas fa-unlink" style="color: var(--color-secondary);"></i>定義: 中間ターンの喪失 (Loss-in-middle-turns)</p>
            <p>この発見は、LLMが提供されたコンテキストの最初または最後に位置する文書により多くの注意を払い、中間コンテキストの内容を犠牲にするという<span class="keyword">「中間での喪失 (lost-in-the-middle)」現象</span>の知見[29, 50, 40]を反映しています。</p>
            <p>重要なことに、この「中間での喪失」現象は、シングルターンの長いコンテキスト設定だけでなく、<span class="highlight">マルチターン会話においても発生する</span>ことが観察されました。この現象を<span class="keyword">「中間ターンの喪失 (loss-in-middle-turns)」</span>と名付けます。</p>
        </div>

        <div class="note-box" style="margin-top: 25px;">
            <p class="note-title"><i class="fas fa-balance-scale"></i> モデル間の差異について</p>
            <p>図10に示された分析は、本実験に含まれる15のLLM全体での平均値です。「中間ターンの喪失」は全てのモデルで見られましたが、その影響の大きさはモデルによって異なりました。一般的に、<span class="highlight">より高性能なモデルほど影響が穏やか</span>であり、複数ターンのコンテキストにわたる帰属処理能力が高いことを示しています。</p>
            <p>✏️ 本研究ではモデル別の分析は含んでおらず、今後の研究課題としています。</p>
        </div>
    </div>

    <h3 class="subsection-title" style="margin-top: 30px;"><i class="fas fa-comment-dots"></i>F.4 Overly-verbose Assistant Responses (過度に冗長なアシスタントの応答)</h3>
    <div class="content-box">
        <p>このサブセクションでは、アシスタントの応答の<span class="keyword">冗長性（長さ）</span>がモデルのパフォーマンスにどのように影響するかを分析します。共通の指示に基づいて複数の会話をシミュレートすると、特にLLMが生成する応答の長さにばらつきが見られます。</p>

        <div class="challenge-box">
            <p class="challenge-title"><i class="fas fa-ruler-combined"></i> 冗長性評価の難しさ</p>
            <p>異なるタスクや指示は、異なるレベルの冗長性を必要とする可能性があります。例えば、Python関数を生成するには、SQLクエリを生成するよりも長い応答が必要になるでしょう。</p>
            <p>💡 <span class="keyword">解決策</span>: タスク固有の変動を正規化するために、各（LLM、指示）のタプルに対して計算される<span class="highlight">冗長性タグ</span>を割り当てます。</p>
        </div>

        <div class="process-step" style="align-items: center;">
            <div class="step-number" style="background-color: var(--color-accent1);">1</div>
            <div class="step-content">
                <p><strong>平均応答長の計算</strong>: LLMが特定の指示に対して行う各SHARDEDシミュレーション会話について、ターンごとの応答の平均長（アシスタントの応答の総文字数 ÷ ターン数）を計算します。</p>
            </div>
        </div>
        <div class="arrow-connector" style="height: 20px;"></div>
        <div class="process-step" style="align-items: center;">
            <div class="step-number" style="background-color: var(--color-accent1);">2</div>
            <div class="step-content">
                <p><strong>五分位数への分類</strong>: この平均応答長に基づいて、会話を五分位数（クインタイル）に分類します。各（モデル、指示）ペアに対してN=10回のシミュレーションを行ったため、各五分位数には2つのシミュレーションが割り当てられます。</p>
                <div class="tag-list" style="justify-content: center;">
                    <span class="tag" style="background-color: #e3f2fd; border-color: #90caf9;">Shortest (最短)</span>
                    <span class="tag" style="background-color: #e3f2fd; border-color: #90caf9;">Short (短)</span>
                    <span class="tag" style="background-color: #e3f2fd; border-color: #90caf9;">Median (中央値)</span>
                    <span class="tag" style="background-color: #e3f2fd; border-color: #90caf9;">Long (長)</span>
                    <span class="tag" style="background-color: #e3f2fd; border-color: #90caf9;">Longest (最長)</span>
                </div>
            </div>
        </div>
        <div class="arrow-connector" style="height: 20px;"></div>
        <div class="process-step" style="align-items: center;">
            <div class="step-number" style="background-color: var(--color-accent1);">3</div>
            <div class="step-content">
                <p><strong>平均パフォーマンスの計算</strong>: この冗長性タグに基づいて、6つの実験タスクにおける平均パフォーマンス ($\overline{P}$) を計算します。</p>
            </div>
        </div>

        <p class="note-title" style="text-align: center; margin-top: 20px;"><i class="fas fa-table"></i>Table 7: モデルの相対的な冗長性（応答の長さ）に基づいて整理された、6つの実験タスクにおけるLLMの平均パフォーマンス ($\overline{P}$)</p>
        <img alt="Table 7" class="figure-image" src="table8.png" style="width: 100%; margin-bottom:10px;"/>
        <div class="note-box" style="margin-top:0px">
            <p class="note-title"><i class="fas fa-search-dollar"></i> 表の解説と主要な発見</p>
            <p>この表は、LLMの応答の長さ（ShortestからLongestへ）と、各タスクにおける平均パフォーマンス ($\overline{P}$) の関係を示しています。</p>
            <ul>
                <li><span class="keyword">主要な傾向</span>: <span class="highlight">6つのタスクのうち5つで、応答長が最も短いシミュレーション会話の方が、応答長が最も長い会話よりもパフォーマンスが10-50%高い</span>結果となりました。</li>
                <li><span class="keyword">パフォーマンスの低下</span>: アシスタントの応答が長くなるにつれて（表の左から右へ）、パフォーマンスは徐々に低下します。</li>
                <li><span class="keyword">例外</span>: Actionsタスクは、このような効果が見られない唯一のタスクであり、アシスタントからの最短の応答長が悪影響を及ぼしています。</li>
            </ul>
        </div>

        <div class="framework-box" style="margin-top: 25px;">
            <p class="framework-title"><i class="fas fa-bullseye"></i>結論と仮説</p>
            <p>しかし、<span class="highlight">主にモデルは短い応答を生成する方が高いパフォーマンスを達成します。</span></p>
            <p><i class="fas fa-brain" style="color: var(--color-primary);"></i> <span class="keyword">仮説</span>: 過度な冗長性によるパフォーマンス低下は、<span class="highlight">長い応答がアシスタントからのより多くの仮定や仮説を含む</span>傾向があり、これが後続のターンで混乱を引き起こす可能性があるためだと考えられます。一方、短いターンは（例：単一の明確化の質問など）焦点が絞られており、会話を軌道に乗せ続ける傾向があります。</p>
        </div>
        
        <div class="bubble-box" style="border-color: var(--color-secondary); margin-top: 25px;">
            <p style="font-weight: bold; color: var(--color-secondary);"><i class="fas fa-exclamation-circle"></i> 過度な冗長性の二重の悪影響</p>
            <p>過度な冗長性によるパフォーマンス低下は注目に値します。なぜなら、根底にあるモデルのパフォーマンスを低下させるだけでなく、<span class="highlight">長い応答はユーザーが読むのにより多くの時間を要するため、望ましくない</span>からです。</p>
            <p>したがって、この発見は、<span class="keyword">LLMの長い応答はモデルにとってもエンドユーザーにとっても悪い</span>ことを示唆しています。</p>
        </div>
    </div>
    
    <p class="note-title" style="text-align: center; margin-top: 30px;"><i class="fas fa-stream"></i>Table 8: ターンカテゴリの定義</p>
    <img alt="Table 8" class="figure-image" src="table9.png" style="width: 80%; margin-bottom:10px;"/>
    <div class="note-box" style="margin-top:0px">
        <p class="note-title"><i class="fas fa-info-circle"></i>補足情報</p>
        <p>この表（Table 8、元の論文ではfigure9.pngの後にtable9.pngとして挿入されている図ですが、文脈上Table 7の後に言及されるべき内容と思われます）は、アシスタントの応答を分類するためにプロンプトに含める記述を示しています。これはAppendix Gで詳細に説明される応答カテゴリに関連する情報です。</p>
    </div>
</div>
<div class="section-card" id="Appendix_G_Assistant_Response_Categorization">
    <h2 class="section-title"><i class="fas fa-comments"></i> Appendix G: アシスタント応答の分類</h2>

    <div class="content-box">
        <p><i class="fas fa-microscope"></i> このセクションでは、AIアシスタント（大規模言語モデル、LLM）がユーザーの指示に対してどのような応答をするのか、その応答パターンを<span class="keyword">7つの主要なカテゴリ</span>に分類する方法について解説します。</p>
        <div class="bubble-box">
            <p style="text-align: center; font-family: 'Yomogi', cursive; font-size: 1.2em; color: var(--color-primary);">🎯 <strong>この分類の主な目的</strong> 🎯</p>
            <ul class="unstyled-list" style="padding-left: 20px;">
                <li><i class="fas fa-pencil-alt" style="color: var(--color-accent1);"></i> アシスタントがどのように<span class="highlight">回答を試みているか</span>（answer attempt）を捉える。</li>
                <li><i class="fas fa-check-circle" style="color: var(--color-accent1);"></i> その試みが実際に<span class="highlight">適切な回答になっているか</span>を評価する。</li>
                <li><i class="fas fa-brain" style="color: var(--color-accent1);"></i> モデル（LLM）の<span class="highlight">行動傾向</span>（behavior tendency）を深く理解する。</li>
            </ul>
            <p style="margin-top:10px;">いわば、AIアシスタントのコミュニケーションスタイルを分析するための「<span class="highlight">ものさし</span>📏」を作るようなものです。</p>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-book-open"></i> 背景と先行研究との関連</h3>
    <div class="content-box">
        <p>この応答分類のアプローチは、<span class="keyword">Herlihy et al. [27]</span> の研究に大きく影響を受けています。</p>
        <div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));">
            <div class="info-card">
                <p class="note-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-users"></i> Herlihy et al. [27] の研究概要</p>
                <p>彼らはLLMの応答に対して<span class="highlight">7つのターンカテゴリ</span>を定義しました。そして、LLM（特にGPT-4）が、ユーザーの指示が<span class="keyword">情報不足（underspecified）</span>な場合でも、直接的に回答しようとする傾向があること（prefers answering directly）を明らかにしました。</p>
                <div style="text-align: center; margin-top: 15px;">
                    <i class="fas fa-lightbulb fa-2x" style="color: var(--color-accent3);"></i>
                    <p style="font-family: 'Kaisei Decol', serif; font-size: 0.9em;">たとえ曖昧な質問でも、LLMは積極的に答えようとする！</p>
                </div>
            </div>
            <div class="info-card">
                <p class="note-title" style="font-family: 'Yomogi', cursive;"><i class="fas fa-cogs"></i> 本研究でのアプローチ</p>
                <p>この研究に倣い、本論文でも同様に<span class="highlight">7つの応答カテゴリ</span>を定義しています。これらのカテゴリと、それぞれの具体例は、論文本文中の <span class="keyword">Table 8</span> に詳細にリストアップされています。</p>
                <div style="text-align: center; margin-top: 15px;">
                    <i class="fas fa-clipboard-list fa-2x" style="color: var(--color-accent2);"></i>
                    <p style="font-family: 'Kaisei Decol', serif; font-size: 0.9em;">本研究独自の「7つのものさし」で応答を分析！</p>
                </div>
            </div>
        </div>
        <p style="margin-top:15px;"><i class="fas fa-glasses"></i> 重要なのは、先行研究を参考にしつつも、本研究の実験や観察結果に基づいてカテゴリ定義に調整を加えている点です。</p>
    </div>

    <h3 class="subsection-title"><i class="fas fa-wrench"></i> 先行研究からの主な変更点</h3>
    <div class="content-box">
        <p>Herlihy et al. [27] のカテゴリ定義と比較した際の、本研究における主な違い（Key differences）は以下の2つのカテゴリです：</p>
        <div class="feature-card-grid" style="grid-template-columns: 1fr 1fr; gap: 20px;">
            <div class="feature-item" style="background-color: rgba(92, 184, 92, 0.1); border: 2px dashed var(--color-accent1);">
                <i class="fas fa-comments fa-2x" style="color: var(--color-accent1);"></i>
                <h4 style="font-family: 'Yomogi', cursive; color: var(--color-accent1);">Discussion (議論)</h4>
            </div>
            <div class="feature-item" style="background-color: rgba(255, 126, 95, 0.1); border: 2px dashed var(--color-secondary);">
                <i class="fas fa-bullseye fa-2x" style="color: var(--color-secondary);"></i>
                <h4 style="font-family: 'Yomogi', cursive; color: var(--color-secondary);">Answer Attempt (回答の試み)</h4>
            </div>
        </div>
        <p style="margin-top:15px;">これらの変更は、予備実験でのモデルの実際の応答を観察した結果に基づいて導入されました。</p>

        <div class="framework-box" style="margin-top: 25px;">
            <p class="framework-title"><i class="fas fa-random"></i> カテゴリ定義の進化：Herlihy et al. [27] から本研究へ</p>
            <div class="pipeline" style="align-items: center;">
                <div class="pipeline-step" style="width: 80%; text-align: center;">
                    <p><strong style="font-family: 'Yomogi', cursive;">Herlihy et al. [27] のカテゴリ:</strong> <code style="background-color: #f0f0f0; padding: 2px 5px; border-radius: 3px;">"Miscellaneous" (その他)</code></p>
                </div>
                <div class="pipeline-step" style="width: 80%; text-align: center; background-color: rgba(92, 184, 92, 0.1);">
                    <p><strong style="font-family: 'Yomogi', cursive; color: var(--color-accent1);">本研究のカテゴリ:</strong> <code style="background-color: #e6f7e6; padding: 2px 5px; border-radius: 3px;">"Discussion" (議論)</code></p>
                    <p style="font-size: 0.9em;"><em>理由: 予備実験で、質問内容を長文で再構成する応答が多く見られたため。</em></p>
                </div>
            </div>
            <div style="text-align: center; margin: 10px 0;">
                <i class="fas fa-arrow-down fa-2x" style="color: var(--color-primary);"></i>
            </div>
            <div class="pipeline" style="align-items: center;">
                <div class="pipeline-step" style="width: 80%; text-align: center;">
                    <p><strong style="font-family: 'Yomogi', cursive;">Herlihy et al. [27] のカテゴリ:</strong> <code style="background-color: #f0f0f0; padding: 2px 5px; border-radius: 3px;">"Direct Response" (直接的な応答)</code></p>
                </div>
                <div class="pipeline-step" style="width: 80%; text-align: center; background-color: rgba(255, 126, 95, 0.1);">
                    <p><strong style="font-family: 'Yomogi', cursive; color: var(--color-secondary);">本研究のカテゴリ:</strong> <code style="background-color: #ffebe6; padding: 2px 5px; border-radius: 3px;">"Answer Attempt" (回答の試み)</code></p>
                     <p style="font-size: 0.9em;"><em>理由: モデルが具体的な解決策を提示しようとする行動をより明確に捉えるため。</em></p>
                </div>
            </div>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-stream"></i> 本研究で定義された7つの応答カテゴリ</h3>
    <div class="content-box">
        <p>論文の <span class="keyword">Table 8</span> には、これら7つのカテゴリとそれぞれの具体例が掲載されています。以下では、各カテゴリの概要と、本研究における意味合いを解説します。（注：ここでの具体例は一般的なものであり、Table 8の正確な写しではありません。）</p>
        
        <div class="info-grid">
            <div class="info-card glass-card">
                <div style="text-align:center; margin-bottom:10px;"><i class="fas fa-question-circle fa-2x" style="color:var(--color-primary);"></i></div>
                <h4 style="font-family: 'Yomogi', cursive; text-align:center;">1. Clarification (明確化要求)</h4>
                <p>ユーザーの指示が曖昧な場合や情報が不足している場合に、アシスタントが追加情報や意図の確認を求める応答です。「〜について、もう少し詳しく教えていただけますか？」のような形をとります。</p>
            </div>
            <div class="info-card glass-card">
                <div style="text-align:center; margin-bottom:10px;"><i class="fas fa-ban fa-2x" style="color:var(--color-secondary);"></i></div>
                <h4 style="font-family: 'Yomogi', cursive; text-align:center;">2. Refusal (拒否)</h4>
                <p>ユーザーの要求に応えられない、または倫理的・安全性の問題、能力の限界などから要求を拒否する応答です。「申し訳ありませんが、そのご要望にはお応えできません。」といった内容です。</p>
            </div>
            <div class="info-card glass-card">
                <div style="text-align:center; margin-bottom:10px;"><i class="fas fa-feather-alt fa-2x" style="color:var(--color-accent2);"></i></div>
                <h4 style="font-family: 'Yomogi', cursive; text-align:center;">3. Hedging (曖昧化・限定)</h4>
                <p>断定的な表現を避け、可能性を示唆したり、条件を付けたりする応答です。「〜かもしれませんが、確実ではありません。」のように、不確実性を含む表現が特徴です。</p>
            </div>
            <div class="info-card glass-card">
                <div style="text-align:center; margin-bottom:10px;"><i class="fas fa-search fa-2x" style="color:var(--color-accent3);"></i></div>
                <h4 style="font-family: 'Yomogi', cursive; text-align:center;">4. Interrogation (詰問・詳細質問)</h4>
                <p>ユーザーの要求の背景、目的、詳細な条件などについて、複数の質問を投げかけて情報を深掘りしようとする応答です。「目的は何ですか？ どのような形式が良いですか？」など、より多くの情報を得ようとします。</p>
            </div>
            <div class="info-card glass-card" style="border: 2px solid var(--color-accent1);">
                <div style="text-align:center; margin-bottom:10px;"><i class="fas fa-comments fa-2x" style="color:var(--color-accent1);"></i></div>
                <h4 style="font-family: 'Yomogi', cursive; text-align:center;">5. Discussion (議論) <span class="badge green">本研究で重要</span></h4>
                <p>ユーザーの質問を言い換えたり、関連情報を提供したり、問題の側面について論じたりする応答です。特に、<span class="highlight">予備実験で多く観察された、質問内容を長文で再構成するような応答</span>がこれに該当します。Herlihy et al. [27] の "Miscellaneous" (その他) を発展させたカテゴリです。</p>
            </div>
            <div class="info-card glass-card">
                <div style="text-align:center; margin-bottom:10px;"><i class="fas fa-ghost fa-2x" style="color:var(--color-gray);"></i></div>
                <h4 style="font-family: 'Yomogi', cursive; text-align:center;">6. Missing (応答なし・欠落)</h4>
                <p>何らかの理由（技術的問題など）で、アシスタントが応答を生成できない、または応答内容が実質的に欠落している状態を指します。</p>
            </div>
            <div class="info-card glass-card" style="border: 2px solid var(--color-secondary);">
                <div style="text-align:center; margin-bottom:10px;"><i class="fas fa-bullseye fa-2x" style="color:var(--color-secondary);"></i></div>
                <h4 style="font-family: 'Yomogi', cursive; text-align:center;">7. Answer Attempt (回答の試み) <span class="badge orange">本研究で重要</span></h4>
                <p>ユーザーの要求に対して、具体的な解決策、情報、コード、文章などの成果物を提示しようとする応答です。<span class="highlight">モデルが実際に問題を解決しようとする行動</span>を捉えます。Herlihy et al. [27] の "Direct Response" (直接的な応答) に対応するカテゴリです。</p>
            </div>
        </div>
    </div>

    <div class="note-box" style="margin-top: 25px;">
        <p class="note-title"><i class="fas fa-key"></i> まとめ</p>
        <p>このセクションで提案されている応答カテゴリは、LLMアシスタントの多様な応答を構造的に理解し、特に<span class="keyword">「Discussion」</span>や<span class="keyword">「Answer Attempt」</span>といった重要な行動を特定・評価するための基盤となります。これにより、モデルの対話能力や問題解決能力をより精密に分析することが可能になります。</p>
    </div>
</div>
<div class="section-card" id="Appendix_H_Model_Access">
    <h2 class="section-title"><i class="fas fa-cogs"></i> Appendix H Model Access</h2>

    <p>このセクションでは、論文の実験で使用された大規模言語モデル（LLM）に関する重要な技術的詳細、特にモデルへのアクセス方法と基本的な設定について解説します。これにより、実験の再現性や結果の解釈に必要な背景情報を提供することを目的としています。実験の透明性を高める上で欠かせない情報ですね。📝</p>

    <div class="content-box">
        <h3 class="subsection-title"><i class="fas fa-database"></i> モデルの入手元と一覧</h3>
        <p>実験で使用したモデルは、様々な<span class="keyword">ベンダー</span>（提供企業や組織）から入手しました。🏢 これにより、特定のベンダーに偏らない幅広いモデル群での検証が可能になっています。</p>
        <p>論文全体を通して使用されている各モデルの<span class="highlight">短縮名</span>（例：GPT-4o）、<span class="highlight">具体的なバージョン</span>、そして<span class="highlight">提供元</span>に関する詳細な情報は、論文内の<span class="keyword">Table 9</span>に集約されて記載されています。この表を参照することで、どのモデルがどのバージョンで、どこから提供されたものなのかを正確に把握できます。📊</p>
        <div class="note-box">
            <p class="note-title"><i class="fas fa-info-circle"></i> Table 9について</p>
            <p>この解説ではTable 9そのものは表示しませんが、論文本体をお読みになる際には、この<span class="keyword">Table 9</span>が各モデルを特定するための重要な参照情報となります。実験結果を他の研究と比較する際や、追試を行う際に非常に役立ちます。</p>
        </div>
    </div>

    <div class="arrow-connector"></div>

    <div class="content-box">
        <h3 class="subsection-title"><i class="fas fa-sliders-h"></i> 実験時の基本設定</h3>
        <p>実験の公平性と再現性を保つため、以下のような統一された基本設定や、特定のモデル群に対する調整を行いました。これらの設定はモデルの振る舞いに影響を与えるため、その詳細を理解することが重要です。</p>

        <div class="glass-card">
            <div class="framework-box">
                <p class="framework-title"><i class="fas fa-thermometer-half"></i> 温度 (Temperature)</p>
                <p>LLMの応答生成における<span class="keyword">温度 (Temperature)</span>パラメータは、生成されるテキストのランダム性や多様性をコントロールします。値が高いほど、より創造的で予測しにくい応答が生成されやすくなる一方、低いほどより決定的で一貫性のある応答が得られやすくなります。</p>
                <p>この論文の実験では、セクション7.2で詳述されている特定の温度に関する探索的な分析 (temperature exploration) を<span class="highlight">除き</span>、原則として温度を以下の値に固定しました：</p>
                <div class="formula">
                    $$ T = 1.0 $$
                </div>
                <p>この \(T=1.0\) という設定は、モデルがある程度の多様な応答を生成することを許容する、比較的標準的な値です。これにより、モデルの一般的な性能を評価しつつ、毎回全く同じ応答にならないようにしています。</p>
                <div class="note-box">
                    <p class="note-title"><i class="fas fa-lightbulb"></i> ハイパーパラメータとは？</p>
                    <p><span class="keyword">ハイパーパラメータ</span>とは、モデルの学習プロセスや推論（応答生成）時の挙動を制御するために、研究者や開発者が<span class="highlight">事前に設定する</span>パラメータのことです。モデル自身が学習データから獲得するパラメータ（例：ニューラルネットワークの重みやバイアス）とは区別されます。温度の他にも、top-p, top-k, repetition penalty など様々な種類があり、これらを調整することでモデルの出力特性を変化させることができます。</p>
                </div>
            </div>

            <div class="framework-box">
                <p class="framework-title"><i class="fas fa-cogs"></i> その他のハイパーパラメータ</p>
                <p>温度以外の設定可能な<span class="keyword">ハイパーパラメータ</span>（例えば、次に出現する単語の候補を絞り込むtop-pサンプリングやtop-kサンプリングなどに関連するパラメータ）については、各モデルが提供する<span class="highlight">デフォルト値</span>をそのまま使用しました。これにより、特定のモデルに有利になるような人為的なチューニングを避け、各モデルの「素の」能力に近い形で比較評価することを目指しています。いわば、箱から出したままの状態で使ってみた、というイメージですね。</p>
            </div>
        </div>
        
        <div class="glass-card" style="margin-top: 20px;">
            <div class="framework-box">
                <p class="framework-title"><i class="fas fa-ruler-combined"></i> 最大応答長 (Maximum Response Length)</p>
                <p>全てのモデルに対し、一度に生成できる応答の最大長を<span class="highlight">1,000トークン</span>に制限しました。</p>
                <div class="note-box">
                    <p class="note-title"><i class="fas fa-book-open"></i> トークン (Token) とは？</p>
                    <p><span class="keyword">トークン</span>とは、LLMがテキストを処理・生成する際の基本的な単位です。多くの場合、単語そのものや、"ing" や "est" のような単語の一部（サブワード）、あるいは句読点などに対応します。例えば、「LLMは賢い」という文は、「LLM」「は」「賢い」の3トークンとして扱われることもあれば、モデルによってはさらに細かく分割されることもあります（例：「LL」「M」「は」「賢」「い」）。モデルアーキテクチャや訓練データによってトークン化の方式は異なります。この最大応答長は、モデルが無限に長いテキストを生成し続けないようにするための上限設定です。</p>
                </div>
                <p>実験中の観測によると、モデルがこの1,000トークンという上限を<span class="highlight">頻繁に超える</span>ような長い応答を生成するケースは<span class="highlight">稀でした</span>。つまり、ほとんどの場合、1,000トークン以内で応答が完結していたということです。これは、タスクの性質やプロンプト設計が適切であった可能性を示唆しています。</p>
            </div>

            <div class="framework-box">
                <p class="framework-title"><i class="fas fa-brain"></i> 思考モデル (Thinking Models) の特別設定</p>
                <p>「<span class="keyword">o3</span>」や「<span class="keyword">Deepseek-R1</span>」といった、いわゆる<span class="keyword">思考モデル (Thinking Models)</span>と呼ばれるモデル群については、最大応答長を特別に<span class="highlight">10,000トークン</span>へと大幅に引き上げました。これは通常のモデルの10倍ですね！</p>
                <p>この措置の理由は、これらのモデルが<span class="keyword">追加のテスト時計算量（思考トークン）</span>を消費するためです。これは、これらのモデルがより複雑な推論を行うために必要な設計上の特徴です。</p>
                <div class="note-box">
                    <p class="note-title"><i class="fas fa-comment-dots"></i> 思考トークン (Thinking Tokens) とは？</p>
                    <p><span class="keyword">思考モデル</span>は、複雑な問いに対して、人間が段階的に考えるように、内部で一連の推論プロセス（いわゆる「思考の連鎖 Chain-of-Thought」や「自己反省 Self-Reflection」など）を実行することがあります。この推論過程で生成・消費されるトークンが<span class="keyword">思考トークン</span>です。これらは最終的な回答には直接現れないこともありますが、より質の高い、あるいは複雑な問題を解決するための「作業領域」や「中間ステップ」として機能します。例えば、数学の問題を解く際に途中計算を書くようなイメージです。このため、これらのモデルがその能力を十分に発揮できるよう、より多くのトークン生成を許容する設定（ここでは10,000トークン）が採用されました。</p>
                </div>
            </div>
        </div>
    </div>
    <p style="text-align: center; margin-top: 20px; font-family: 'Yomogi', cursive;">以上が、モデルアクセスと基本設定に関する補足情報でした！これらの詳細が、論文の実験結果を深く理解する一助となれば幸いです。🔍</p>
</div>
<div class="section-card" id="Appendix_I_Task-specific_Implementation_details">
    <h2 class="section-title"><i class="fas fa-cogs"></i> Appendix I Task-specific Implementation details</h2>
    <p>このセクションでは、論文で実施された各タスクの具体的な実装詳細について説明します。各タスクに対して、以下の3つの主要な情報が提供されます：</p>
    <div class="info-grid">
        <div class="info-card glass-card">
            <div class="feature-item">
                <i class="fas fa-tasks fa-2x" style="color: var(--color-accent1);"></i>
                <h4><span class="highlight">1. 元の命令の選択</span></h4>
                <p>シングルターン（1回のやり取りで完結する）で、かつ完全に情報が指定された元の命令をどのように選んだか。</p>
            </div>
        </div>
        <div class="info-card glass-card">
            <div class="feature-item">
                <i class="fas fa-chart-line fa-2x" style="color: var(--color-accent2);"></i>
                <h4><span class="highlight">2. 評価指標</span></h4>
                <p>元のデータセットから、どのように評価指標を再利用したか。</p>
            </div>
        </div>
        <div class="info-card glass-card">
            <div class="feature-item">
                <i class="fas fa-comment-dots fa-2x" style="color: var(--color-accent3);"></i>
                <h4><span class="highlight">3. 初期システムメッセージ</span></h4>
                <p>もしあれば、会話開始前にモデルに与えられる初期システムメッセージの内容。</p>
            </div>
        </div>
    </div>

    <div class="note-box">
        <p class="note-title"><i class="fas fa-info-circle"></i> 実験の再現性向上のために</p>
        <p>これらの詳細情報は、実験結果の再現性を高めるために非常に重要です。どのようなデータや設定で実験が行われたかを正確に知ることができます。</p>
    </div>

    <img alt="Table 9: Specific model versions used" class="table-img" src="table10.png"/>
    <div class="caption-box">
        <p>📝 <strong>表9: 実験で使用された特定のモデルバージョン</strong></p>
        <p>この表は、実験で使用された各LLMモデルの正確なバージョンと、そのモデルへのアクセスを提供したプロバイダーを示しています。これにより、他の研究者が同様の実験を行う際の再現性を高めることを目的としています。</p>
        <ul class="unstyled-list">
            <li><span class="keyword">Version</span>: アクセスされたモデルの正確なバージョン（バージョニングがあるモデルの場合）。</li>
            <li><span class="keyword">Access Provider</span>: モデルへのアクセスを提供した企業や組織。</li>
        </ul>
    </div>

    <h3 class="section-title"><i class="fas fa-code"></i> I.1 Code</h3>
    <p>このサブセクションでは、Pythonコード生成タスクの実装詳細について説明します。</p>
    <div class="framework-box">
        <p class="framework-title"><i class="fas fa-database"></i> データソース</p>
        <ul class="unstyled-list">
            <li>✏️ <span class="keyword">HumanEval [10]</span>: 164個の基本的なPythonプログラミング問題のデータセット。関数のヘッダーと問題を指定するdocstringが与えられます。</li>
            <li>✏️ <span class="keyword">LiveCodeBench [31]</span>: Pythonのアルゴリズム課題の進化するデータセット。特に、LiveCodeBench v5の「call-based」問題サブセットから、難易度が「Easy」および「Medium」のものを利用し、2つのソース間で解答形式を揃えています。</li>
        </ul>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-random"></i> シャーディングプロセス</p>
        <p>Appendix Cで述べられたプロトコルに従い、まず全てのHumanEval問題をシャーディングしました。その結果、基準を満たす<span class="highlight">45個の高品質なシャードセット</span>が得られました。残りのデータセットは、単純すぎて問題に対して十分な数のシャードを構築する余地がほとんどなかったため破棄されました。</p>
        <p>続いて、LiveCodeBenchの前述のサブセットをシャッフルし、シャーディングを行い、<span class="highlight">100個の有効なシャード化された命令</span>を取得しました。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-terminal"></i> シングルターン評価プロンプト</p>
        <p>シングルターン（FULLおよびCONCAT）評価では、ベンチマーク作成者が使用した元のプロンプトを可能な限り踏襲しています。</p>
        <ul class="unstyled-list">
            <li><span class="badge blue">HumanEval (FULL)</span>: HumanEvalデータセットでプロンプトとして提供される関数ヘッダーとdocstringを含みます。</li>
            <li><span class="badge blue">LiveCodeBench (FULL &amp; CONCAT)</span>: 関数シグネチャからなる<code>starter_code</code>を含みます。</li>
        </ul>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-check-circle"></i> 評価方法</p>
        <p>HumanEvalおよびLiveCodeBench由来の問題にはテストケースが付属しており、これらを使用してLLMによる解答試行の<span class="keyword">Functional Accuracy（機能的正確性）</span>を計算します。Jain et al. [31] によって維持されている評価コードベースを再利用します。このコードベースは以下の処理を行います：</p>
        <ol class="process-step-list unstyled-list">
            <li class="process-step"><span class="step-number">1</span>候補関数をテストモジュールでラップする。</li>
            <li class="process-step"><span class="step-number">2</span>与えられた入力で実行する。</li>
            <li class="process-step"><span class="step-number">3</span>期待される出力と実際の出力の等価性をチェックする。評価中に評価者がトラップされるのを防ぐため、デフォルトのタイムアウトが設定されています（例：ブルートフォース実装は設定された時間予算内でパスしない場合があります）。</li>
        </ol>
        <div class="note-box">
            <p class="note-title"><i class="fas fa-exclamation-circle"></i> 複数コードブロックの扱い</p>
            <p>応答に複数のコードブロックが存在する場合、解答抽出モジュールは最後のマークダウンコードブロック内の最後の関数定義を選択します。</p>
        </div>
    </div>

    <h3 class="section-title"><i class="fas fa-database"></i> I.2 Database</h3>
    <p>このサブセクションでは、データベースクエリ（Text-to-SQL）生成タスクの実装詳細について説明します。</p>
    <div class="framework-box">
        <p class="framework-title"><i class="fas fa-database"></i> データソース</p>
        <p>データベース命令は、<span class="keyword">Spiderデータセット [86]</span> の検証部分から取得されます。Spiderのより新しいバージョン（Spider 2.0 [44]）がリリースされていますが、第2版の命令はより高度で、典型的なデータベース利用とは言えないため、より現実的なSpider 1.0から命令を選択しています。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-filter"></i> 難易度フィルタリングとシャーディング</p>
        <p>Spiderの作成者は、参照SQLクエリの構文の複雑さに応じて、クエリを4つの難易度レベル（EASY, MEDIUM, HARD, XHARD）に分類しました。EASYの複雑度のクエリは、処理時に3つ未満のシャードしか生成しない傾向があったため除外しました。残りのSpider内の<span class="highlight">433個の自然言語クエリ</span>を徐々にシャーディングし、合計<span class="highlight">107個の有効なシャード化された命令</span>に到達しました。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-envelope-open-text"></i> システムメッセージ</p>
        <p>Spiderの各元の命令は、SQLで表現されたデータベーススキーマを提供します（つまり、各スキーマは一連のテーブルスキーマを定義し、それぞれが一連の列（名前、型、オプションのインデックスを含む）を定義します）。この<span class="keyword">データベーススキーマをシステムメッセージの一部</span>として（つまり、会話の最初のターンの前に）含め、LLMには、提供されたスキーマを持つデータベースを使用して回答しなければならない自然言語クエリをユーザーが提供することを通知します。</p>
        <div class="bubble-box">
            <i class="fas fa-info-circle" style="color: var(--color-primary); margin-right: 5px;"></i> LLMへの指示: 「これからユーザーが自然言語でデータベースに関する質問をします。このスキーマ情報を使ってSQLクエリを生成してください。」といった内容です。
        </div>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-check-double"></i> 評価方法</p>
        <p>Spiderの各元の命令は、参照SQLソリューションとペアになっています。評価方法については、Zhong et al. [90] に従います。与えられた元の命令に対して、候補SQLクエリと参照SQLクエリは<span class="keyword">固定されたデータベースセット</span>で実行され、全てのデータベースで結果が<span class="highlight">完全一致</span>する場合に候補は成功とマークされます（<span class="formula">\( \text{Score} = 100 \)</span>）。</p>
        <p>いずれかのテストデータベースで不一致が観察された場合、候補は不正解となります（<span class="formula">\( \text{Score} = 0 \)</span>）。SQL実行の一つの限界は、偽陽性（false positives）が発生する可能性があることです：2つのクエリが意味的に同等でなくても、特定のデータベースで同じ出力を返すことがあります。Zhong et al. [90] は、評価するデータベースの数を増やすことで、偽陽性が無視できるほど小さくなることを発見しました。最後に、実行に成功しない無効な候補（例：構文エラー）は不正解と見なされます（<span class="formula">\( \text{Score} = 0 \)</span>）。</p>
    </div>

    <h3 class="section-title"><i class="fas fa-tools"></i> I.3 Actions</h3>
    <p>このサブセクションでは、API呼び出し（アクション実行）タスクの実装詳細について説明します。</p>
    <div class="framework-box">
        <p class="framework-title"><i class="fas fa-database"></i> データソース</p>
        <p>アクション命令は、<span class="keyword">Berkeley Function Calling Leaderboard V3 (BFCL) [85]</span> のリリースされたテスト部分から取得されます。BFCL V3は3つのサブジャンルの命令で構成されています：(1) Parallel（並列）、(2) Multiple（複数）、(3) Multiple-Parallel（複数並列）。サブジャンルでの初期実験により、<span class="highlight">Parallel</span>がシャーディングに最も適していると特定されました。なぜなら、Parallel命令は複数のサブタスクを指定し、それらを組み合わせて命令全体を達成する単一のアクションにする必要があるためです。全てのBFCL V3 Parallel命令をシャッフルし、徐々にシャーディングを行い、<span class="highlight">105個の有効なシャード化された命令</span>を取得しました。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-exchange-alt"></i> マルチターン命令との比較</p>
        <p>BFCLのより新しいイテレーションにはマルチターン命令が含まれていますが、それはシャーディング実験とは異なります。BFCLのマルチターンは<span class="keyword">underspecification（情報不足）を伴わず</span>、各ターンが独立した中間解を持つ（これを<span class="highlight">episodic multi-turn conversations</span>と呼びます）ためです。対照的に、我々の実装は元の命令をシャーディングすることで、このタスク設定でマルチターン情報不足会話をシミュレートすることを可能にします。背景セクション（セクション2）では、episodicとunderspecified multi-turn conversationの関係についてより詳しく議論しています。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-envelope-open-text"></i> システムメッセージ</p>
        <p>BFCLの各命令には、<span class="keyword">ツールセットドキュメンテーション</span>（JSONオブジェクト）が付属しており、アシスタントがユーザーの指示を完了するために利用可能なアクション（API）のセットを指定します。このツールセットドキュメンテーションをシステムメッセージの一部として含め、ユーザークエリの完了には提供されたツールを使用する必要があることを示すメッセージと共に提供します。</p>
        <div class="bubble-box">
            <i class="fas fa-tools" style="color: var(--color-primary); margin-right: 5px;"></i> LLMへの指示: 「これらのAPIを使ってユーザーのリクエストに応えてください。APIの仕様は以下の通りです...」といった内容です。
        </div>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-clipboard-check"></i> 評価方法</p>
        <p>BFCLの各命令には、ユーザーの指示を達成するために呼び出すべきAPI呼び出しからなる参照解答が付属しています。BFCLのメンテナーは、候補解答と参照解答間の<span class="keyword">セマンティック等価性</span>を評価する評価ツールキットをリリースしています。我々はこの公式評価ツールキットを活用し、参照解答とセマンティックに等価であると見なされる候補解答にはスコア <span class="formula">\( S = 100 \)</span> を割り当て、そうでない場合はスコア <span class="formula">\( S = 0 \)</span> を割り当てます。評価ツールキットが候補解答を解析できない場合（例：構文エラー）、候補は不正解と見なされます（<span class="formula">\( S = 0 \)</span>）。</p>
    </div>

    <h3 class="section-title"><i class="fas fa-calculator"></i> I.4 Math</h3>
    <p>このサブセクションでは、数学問題解決タスクの実装詳細について説明します。</p>
    <div class="framework-box">
        <p class="framework-title"><i class="fas fa-database"></i> データソース</p>
        <p>数学命令は、<span class="keyword">GSM8Kデータセット [14]</span> の「main」部分から取得されます。元の8,700の命令に対してフィルタリングは行いませんでした。命令をシャッフルし、段階的にシャーディングして<span class="highlight">103個の有効なシャード化された命令</span>を取得しました。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas -check"></i> 評価方法</p>
        <p>各GSM8Kの問題には、数値の参照解答がペアになっています。GSM8Kと共にリリースされた公式ツールキットを使用して、数値解答を標準化しました（つまり、フォーマットの除去など）。標準化された候補の数値解答は、参照解答との<span class="keyword">完全一致</span>によって比較できます。ツールキットが一致を検出した場合、候補解答は正解と見なされ（<span class="formula">\( \text{Score} = 100 \)</span>）、そうでない場合は不正解と見なされます（<span class="formula">\( \text{Score} = 0 \)</span>）。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-envelope-open-text"></i> システムメッセージ</p>
        <p>アシスタントに数学の問題を解くことを示すために、短い一文のシステムプロンプトが使用されます。</p>
        <div class="bubble-box">
            <i class="fas fa-brain" style="color: var(--color-primary); margin-right: 5px;"></i> LLMへの指示: 「これから数学の問題が出題されます。解答してください。」といったシンプルなものです。
        </div>
    </div>

    <h3 class="section-title"><i class="fas fa-file-alt"></i> I.5 Data-to-Text</h3>
    <p>このサブセクションでは、データからテキストを生成するタスク（具体的にはテーブルキャプション生成）の実装詳細について説明します。</p>
    <div class="framework-box">
        <p class="framework-title"><i class="fas fa-database"></i> データソース</p>
        <p>Data-to-Text命令は、リリースされたテストセット<span class="keyword">ToTToデータセット [59]</span> の命令に基づいています。ToTToでは、完全に指定された命令には以下の情報要素が含まれます：</p>
        <ol class="process-step-list unstyled-list">
            <li class="process-step"><span class="step-number">1</span>Wikipediaページから抽出されたHTML形式のテーブル。</li>
            <li class="process-step"><span class="step-number">2</span>テーブル内でハイライトされたセルのサブセット。</li>
            <li class="process-step"><span class="step-number">3</span>テーブルが含まれていたWikipediaページの名前。</li>
            <li class="process-step"><span class="step-number">4</span>テーブルが含まれていたWikipediaページ内のセクションの名前。</li>
        </ol>
        <p>これらの要素が与えられた場合、タスクの目的は、特にハイライトされたセルに焦点を当て、利用可能なメタデータを考慮してテーブルのキャプションを生成することです。命令はシャッフルされ、段階的にシャーディングされ、<span class="highlight">120個の有効なシャード化された命令</span>を取得しました。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-puzzle-piece"></i> シャーディング戦略</p>
        <p>各命令について、異なる情報要素を個々のシャードに割り当てることでシャード化された命令を生成します。</p>
        <ul class="unstyled-list">
            <li><span class="badge yellow">シャード1</span>: ハイライトなしの初期HTML形式テーブル。</li>
            <li><span class="badge yellow">シャード2</span>: ハイライトありの更新されたテーブル。</li>
            <li><span class="badge yellow">シャード3</span>: Wikipediaページ名。</li>
            <li><span class="badge yellow">シャード4</span>: Wikipediaセクション名。</li>
            <li><span class="badge yellow">シャード5</span>: ToTToデータセットのトレーニングセットからランダムに選択された10個の固定された例文キャプション。</li>
        </ul>
        <div class="pipeline">
            <div class="pipeline-step"><strong>シャード1:</strong> テーブル (ハイライトなし)</div>
            <div class="pipeline-step"><strong>シャード2:</strong> テーブル (ハイライトあり)</div>
            <div class="pipeline-step"><strong>シャード3:</strong> Wikipediaページ名</div>
            <div class="pipeline-step"><strong>シャード4:</strong> Wikipediaセクション名</div>
            <div class="pipeline-step" style="margin-bottom:0;"><strong>シャード5:</strong> 例文キャプション (10個)</div>
        </div>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-star-half-alt"></i> 評価方法</p>
        <p>ToTToの各命令には、元のデータセットの作成者によって収集された1つから3つの参照キャプションが割り当てられています。候補キャプションの評価は、元の論文の評価方法に従い、候補と利用可能な参照のセットとの間で<span class="keyword">BLEUスコア [58]</span> を計算します。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-pen-nib"></i> リファインメントタスクとしての特性</p>
        <p>Data-to-Textは<span class="keyword">リファインメントタスク</span>です。各ターンで、モデルは追加の情報シャードを提供され、これまでに提供されたすべての情報を考慮して応答を更新するように明示的に指示されます。リファインメントタスクとして、各ターンのアシスタントの応答は自動的に解答試行として分類され、抽出された解答は応答全体と見なされます。</p>
        <p><span class="highlight">システム指示</span>は、モデルの応答が追加のテキスト（導入、結び、丁寧な言葉遣いなど）なしで、テーブルキャプションのみで構成されるべきであることをモデルに通知します。</p>
    </div>

    <h3 class="section-title"><i class="fas fa-book-reader"></i> I.6 Summary</h3>
    <p>このサブセクションでは、マルチドキュメント要約タスクの実装詳細について説明します。</p>
    <div class="framework-box">
        <p class="framework-title"><i class="fas fa-database"></i> データソース</p>
        <p>要約命令は、<span class="keyword">Summary of a Haystackデータセット [40]</span> のサンプルに基づいています。Summary of a Haystackの全命令を再利用して、<span class="highlight">92個のシャード化された命令</span>を作成しました。元の命令はそれぞれ以下で構成されます：</p>
        <ul class="unstyled-list">
            <li><span class="badge orange">Haystack</span>: 合計100,000トークンのコンテンツを持つ100個のドキュメント。</li>
            <li><span class="badge orange">User Query</span>: ユーザーからの質問。</li>
        </ul>
        <p>タスクの目標は、ドキュメント群に出現するクエリに関連する洞察を箇条書き形式で要約し、各箇条書きの情報を引用を用いてソースドキュメントに帰属させることです。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-compress-arrows-alt"></i> タスクの簡略化とシャーディング</p>
        <p>Summary of a Haystackの元の設定では、LLMのソース引用能力を徹底的に評価するために、意図的に大量の冗長性（各洞察は少なくとも6つのドキュメントで繰り返される）が含まれています。しかし、100,000トークンのHaystackは評価できるモデルの種類を制限するため、マルチターン設定ではタスクを簡略化します。代わりに、より小さなHaystack（<span class="keyword">「mini-Haystacks」</span>）[3] を選択する後続の研究に従います。Mini-Haystacksは<span class="highlight">20個のドキュメント</span>で構成され、各参照洞察が3つのドキュメントで繰り返されることを保証します。</p>
        <p>各命令について、<span class="highlight">シャードごとに2つのドキュメントをランダムに割り当てる</span>ことで10個のシャードを作成します。最初のシャードはさらに、ユーザークエリ、期待される箇条書き形式、およびフォーマットされた引用を指定することで、高レベルのタスク指示を明示します。</p>
        <div class="info-grid">
            <div class="info-card">
                <i class="fas fa-file-alt fa-2x" style="color: var(--color-accent1);"></i>
                <p><strong>Mini-Haystack</strong></p>
                <p>ドキュメント数: 20</p>
                <p>洞察の繰り返し: 各3回</p>
            </div>
            <div class="info-card">
                <i class="fas fa-stream fa-2x" style="color: var(--color-accent2);"></i>
                <p><strong>シャーディング</strong></p>
                <p>シャード数: 10</p>
                <p>各シャード: ドキュメント2つ</p>
            </div>
        </div>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-award"></i> 評価方法と長さバイアスへの対応</p>
        <p>Summary of a Haystackは、候補の箇条書きの関連性（<span class="keyword">カバレッジ</span>）と、箇条書き内で生成された帰属の品質（<span class="keyword">引用</span>）の両方の観点から要約の品質を計算するために、LLMベースのメトリック（<span class="highlight">Joint Score</span>）に依存しています。作成者は、このメトリックがリコールベースであるため、長い要約は短い要約よりも高いスコアを獲得しやすいと指摘しています。</p>
        <p>長さバイアスを考慮するため、元のタスクではモデルに最大300語の要約を生成するよう指示しており、我々の実験にもこれを含めています。具体的には、すべての設定でモデルに最大300語の要約を生成するよう指示しています。マルチターン設定では、モデルがこの指示を忘れることが多く、指示に従わない結果になることを観察しました。300語の制限内に正しく収まるモデルにペナルティを与えないようにするため、制限を超える要約を切り捨て、評価される要約がすべて300語の制限を尊重するように、要約の箇条書きから単語を均等な割合で削除します。LLMがこの制限を超える傾向については、付録Fでさらに議論されており、タスク全体でモデルの解答試行が会話のターンが進むにつれて「肥大化」することを観察しています。シングルターン設定（full, concat）では、LLMはほぼ300語の長さ制限を尊重します。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-pen-alt"></i> リファインメントタスクとしての特性</p>
        <p>要約タスクは<span class="keyword">リファインメントタスク</span>です。アシスタントの応答は各ターンで自動的に解答試行として分類され、応答全体が抽出された解答と見なされます。</p>
    </div>

    <h3 class="section-title"><i class="fas fa-language"></i> I.7 Translation</h3>
    <p>このサブセクションでは、文書レベル翻訳タスクの実装詳細について説明します。</p>
    <div class="framework-box">
        <p class="framework-title"><i class="fas fa-database"></i> データソース</p>
        <p>翻訳命令は、<span class="keyword">WMT 2019の文書レベル翻訳タスク [70]</span> から収集されました。具体的には、ドイツ語-英語のペアを<span class="highlight">30文書</span>選択しました。文書ペアは文レベルでアライメントされています（つまり、ペアの英語とドイツ語の文書は同じ文の数を持ちます）。選択したペアを最初の10文に切り捨て、各シャードが文書から正確に2文を導入するように文書命令をシャーディングし、合計5つのシャードを作成しました。シャードはドイツ語で提供され、タスクは英語への翻訳（つまり、ドイツ語 <span class="formula">\(\rightarrow\)</span> 英語）で構成されていました。したがって、シャード1は最初の2つのドイツ語文を導入し、シャード2はドイツ語文3-4を導入する、といった具合です。</p>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-tasks"></i> タスク設定</p>
        <ul class="unstyled-list">
            <li><span class="badge purple">シャーディング設定 (Sharded)</span>: モデルはこれまでに提供されたすべての文で文書を翻訳する必要があります。</li>
            <li><span class="badge purple">フル設定 (Full)</span>: LLMには最初のターンで文書全体（10文）が提供されます。</li>
            <li><span class="badge purple">連結設定 (Concat)</span>: LLMには最初のターンですべての文が提供されますが、シャードに分割されています（一度に2文ずつ）。</li>
        </ul>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-lightbulb"></i> シャーディング戦略の検討</p>
        <p>初期の実験では、他のシャーディング戦略（文境界ではなく特定の単語数でシャードを区切る、文書の長さを10文から20文に増やすなど）も試しましたが、結果に大きな違いは見られませんでした。これにより、我々が説明する設定（2文ごとにシャーディングし、10文で切り捨てる）を採用することになりました。</p>
    </div>

    <img alt="Figure 11: Example simulated multi-turn conversation for the Math task" class="figure-img" src="figure11.png"/>
    <div class="caption-box">
        <p>📊 <strong>図11: 数学タスクのマルチターン会話シミュレーション例</strong></p>
        <p>この図は、数学タスクにおけるLlama3.1-8B-Instructアシスタントモデルとのシミュレートされたマルチターン会話の一例を示しています。シャード化された命令は6つのシャードで構成されています。この命令の正解は85,000カロリーです。</p>
        <p>この会話例は、論文で述べられている以下の特性を示しています：</p>
        <ol class="unstyled-list">
            <li><span class="keyword">早期の仮定</span>: LLMは会話の早い段階で（ターン1で）関連性のない4種類のペストリーについて説明するなど、仮定を立てます。</li>
            <li><span class="keyword">ユーザー情報の解釈と不必要な更新</span>: ユーザーから提供された情報は正しく解釈しますが、自身が行った仮定に関する情報も不必要に更新します（ターン4）。</li>
            <li><span class="keyword">複雑化と忘却</span>: これにより不必要な複雑さが生じ、モデルは最終的に元の指示（総カロリー計算）を忘れ、計算の半分（ミニブルーベリーマフィンのみ）しか返しません。</li>
        </ol>
        <p>要するに、この会話は<span class="highlight">「会話での迷子」現象</span>を示しています。ユーザーの指示が情報不足である場合（ターン1-4）、LLMは会話から逸脱し、不正確または不完全な回答につながる仮定を立てます。</p>
        <div class="note-box">
            <p class="note-title"><i class="fas fa-info-circle"></i> 図の要素解説</p>
            <p>図中の各ターンは、ユーザーの入力 ([User]) とアシスタントの応答 ([Assistant]) を示しています。また、各ペストリータイプ（Type A, B, C, D, E, F）に関する情報が段階的に提示され、それに基づいてカロリー計算が行われようとしています。最終的に抽出された解答は「45,000」で、スコアは0（不正解）となっています。</p>
            <ul class="unstyled-list">
                <li><span class="badge blue">TURN 1</span>: ユーザーがペストリーの総カロリー計算を依頼。アシスタントは一般的な応答。</li>
                <li><span class="badge blue">TURN 2</span>: ユーザーがミニシナモンロールの情報を提示。アシスタントは以前の計算を引き継ぐ形で応答。</li>
                <li><span class="badge blue">TURN 3</span>: ユーザーがレギュラーサイズのシナモンロールのカロリーを提示。アシスタントはこれに基づいてミニシナモンロールのカロリーを再計算。</li>
                <li><span class="badge blue">TURN 4</span>: ユーザーが各ミニペストリーは通常サイズの1/3のカロリーであると提示。アシスタントは以前のカロリー計算を調整すると応答。</li>
                <li><span class="badge blue">TURN 5</span>: ユーザーがミニブルーベリーマフィンの情報を提示。アシスタントはミニブルーベリーマフィンのカロリーを計算。</li>
                <li><span class="badge blue">TURN 6</span>: ユーザーがレギュラーサイズのブルーベリーマフィンのカロリーを提示。アシスタントはこれに基づいてミニブルーベリーマフィンのカロリーを再計算し、「45,000カロリー」と回答。</li>
            </ul>
        </div>
    </div>

    <div class="content-box">
        <p class="subsection-title"><i class="fas fa-percentage"></i> 評価方法</p>
        <p>パフォーマンスは<span class="keyword">BLEUメトリック [58]</span> で評価しました。これは翻訳タスクの標準的なメトリックであり、元のWMT 2019コンペティションでも使用されていました。</p>
    </div>

    <h4 class="section-title"><i class="fas fa-cookie-bite"></i> Type A: Chocolate Croissant TURN 3 calorie count for Andrew's mini cinnamon rollsz</h4>
    <div class="content-box">
        <p>この小見出しは、図11の会話例の一部を指していると考えられます。図11のTURN 3では、ユーザーが「A regular-sized cinnamon roll has about 600 calories. (レギュラーサイズのシナモンロールは約600カロリーです。)」という情報を追加で提供しています。これを受けて、アシスタントはアンドリューのミニシナモンロールのカロリー数を計算し直そうとしています。</p>
        <p>図中では、Type Aはチョコレートクロワッサンとしてリストアップされていますが、TURN 3の会話の流れはシナモンロールに関するものです。この小見出しが具体的にどの計算ステップを指すかは文脈から判断する必要がありますが、図11のコンテキストでは、アシスタントがミニシナモンロールのカロリーを更新する部分を指している可能性が高いです。</p>
        <p>具体的には、</p>
        <ul class="unstyled-list">
            <li><strong>Type A: Chocolate Croissant</strong>
                <ul class="unstyled-list" style="margin-left:20px;">
                    <li>Calories per serving: 250 calories / pastry (1食あたり250カロリー)</li>
                    <li>Servings: 1 (1食分)</li>
                </ul>
            </li>
        </ul>
        <p>とありますが、TURN 3のユーザー入力はミニシナモンロールに関するもので、アシスタントの応答は「With this new information, we can calculate the calorie count for Andrew's mini cinnamon rolls. (この新しい情報で、アンドリューのミニシナモンロールのカロリーを計算できます。)」となっています。その後、Type E: Mini Cinnamon Rollsの項目で以下のように計算しています。</p>
        <ul class="unstyled-list">
            <li><strong>Type E: Mini Cinnamon Rolls</strong>
                <ul class="unstyled-list" style="margin-left:20px;">
                    <li>Calories per normal-sized serving: 600 (通常サイズの1食あたり600カロリー)</li>
                    <li>Calories per mini serving: approximately 200 calories / mini roll (ミニ1個あたり約200カロリー)</li>
                    <li>Total pieces: 200 (200個)</li>
                    <li>Total Calories for Type E: <span class="formula">\(200 \times 200 = 40,000\)</span> calories (ミニシナモンロールの総カロリーは40,000カロリー)</li>
                </ul>
            </li>
        </ul>
        <p>この小見出し自体は、図のキャプションや本文中で直接的に解説されているわけではなく、図中の特定の時点の計算状況をハイライトしているものと思われます。</p>
    </div>

    <h4 class="section-title"><i class="fas fa-apple-alt"></i> Type D: Apple Pastry Square Wedging with Flakes topping. ### Type A: Chocolate Croissant \* Calories per normal-sized serving: 450</h4>
    <div class="content-box">
        <p>この小見出しも、図11の会話例の一部を指していると考えられます。これは2つのペストリータイプに関する情報を含んでいます。</p>
        <p><strong>Type D: Apple Pastry Square Wedging with Flakes topping.</strong></p>
        <p>図11のTURN 4の[Assistant]の応答内で言及されています。</p>
        <ul class="unstyled-list">
            <li>We assume that type d pastry has three quarters of what a full piece contains. (タイプDのペストリーは、フルサイズの3/4の量だと仮定します。)</li>
            <li>Average per serving: <span class="formula">\(2/3 + 250 / (4+1) = 125\)</span> calories/piece (1個あたり平均125カロリー). ※この数式の妥当性は図からは不明です。文脈上、以前の計算や仮定に基づいている可能性があります。</li>
        </ul>

        <p><strong>Type A: Chocolate Croissant \* Calories per normal-sized serving: 450</strong></p>
        <p>これは図11のTURN 4の[Assistant]の応答内で、Type Aのチョコレートクロワッサンのカロリー情報が更新または再確認されている部分を指します。</p>
        <ul class="unstyled-list">
            <li>Normal serving size: 250 calories (通常サイズは250カロリー。これはTURN 3までの情報と一致)</li>
            <li>Mini serving size (1/3 of normal): 80-100 calories (a range due to variability in ingredients and sizes) (ミニサイズ(通常の1/3)は80-100カロリー。材料やサイズのばらつきによる範囲)</li>
            <li>However for these calculations we will assume an estimate that is near average. (しかし、これらの計算では平均に近い推定値を使用します。)</li>
        </ul>
        <p>小見出しの「Calories per normal-sized serving: 450」という記述は、図11のTURN 4のType Aの記述「Normal serving size: 250 calories」とは異なります。これは、小見出しが図中の特定の部分を指しつつも、その時点での別の仮定や、あるいは論文全体を通してType Aのカロリーが450であるという一般的な情報を示している可能性があります。図11の会話シミュレーションは特定の状況下でのやり取りであり、一般的なペストリー情報とは異なる値が使われることもあります。</p>
        <p>この小見出しは、図11の特定の時点（TURN 4）でのアシスタントによるカロリー計算の調整プロセスを示しており、特にType DとType Aの情報更新に焦点を当てています。</p>
        <div class="note-box">
            <p class="note-title"><i class="fas fa-exclamation-triangle"></i> 注意点</p>
            <p>図11はあくまで「シミュレーションの一例」であり、LLMが会話中に誤った仮定をしたり、情報を混同したりする様子を示しています。そのため、図中のカロリー計算やペストリーの定義が必ずしも現実の栄養情報や問題設定の「正解」を反映しているわけではありません。この小見出しは、そのようなLLMの振る舞いの一端を切り取ったものと解釈できます。</p>
        </div>
    </div>
</div>
<div class="section-card" id="Appendix_J_Example_Simulated_Conversation">
    <h2 class="section-title"><i class="fas fa-comments"></i> Appendix J Example Simulated Conversation</h2>
    <div class="content-box">
        <p>このセクションでは、論文で提唱されている<span class="keyword">「会話における迷子現象 (Lost in Conversation Phenomenon)」</span>を、具体的なシミュレーション会話例を通じて解説します。特に、ユーザーの指示が複数ターンに渡って少しずつ与えられる場合（<span class="highlight">不完全に特定された指示</span>）、LLMがどのように情報を処理し、時に誤った結論に至るかを示します。</p>
        <p>この現象を理解することは、LLMとのより効果的なコミュニケーション方法を考える上で非常に重要です。</p>
    </div>

    <h3 class="subsection-title"><i class="fas fa-cogs"></i> シミュレーションのセットアップ <span class="badge yellow">実験条件</span></h3>
    <div class="info-grid">
        <div class="info-card">
            <div class="icon-item"><i class="fas fa-brain"></i></div>
            <strong>タスク <i class="fas fa-tasks"></i></strong><br/>
            Mathタスク (算術問題の解決)
        </div>
        <div class="info-card">
            <div class="icon-item"><i class="fas fa-stream"></i></div>
            <strong>指示形式 <i class="fas fa-align-left"></i></strong><br/>
            6シャードの指示 (情報を6回に分割して提供)
        </div>
        <div class="info-card">
            <div class="icon-item"><i class="fas fa-robot"></i></div>
            <strong>アシスタントLLM <i class="fas fa-microchip"></i></strong><br/>
            Llama3.1-8B-Instruct
        </div>
    </div>
    <div class="note-box">
        <p><i class="fas fa-lightbulb"></i> <span class="note-title">ポイント</span><br/>
        ここでのポイントは、情報が一度に全て与えられるのではなく、<span class="keyword">分割されて段階的に提示される</span>という点です。これは実際の人間同士の会話や、ユーザーがAIに複雑な要求を伝える状況を模しています。</p>
    </div>

    <img alt="Figure 11: Example simulated multi-turn conversation for the Math task." src="Figure11.png" style="width: 100%; max-width: 800px; margin: 20px auto; display: block; border: 1px solid #ccc; border-radius: 8px;"/>
    <p style="text-align: center; font-style: italic; color: var(--color-gray);">図11: Mathタスクにおけるシミュレーションされたマルチターン会話の例</p>

    <h3 class="subsection-title"><i class="fas fa-list-ol"></i> 会話の進行と観察される特性 <span class="badge blue">詳細解説</span></h3>
    <p>この会話例は、論文で指摘されている以下の3つの重要な特性を示しています。</p>

    <div class="process-step">
        <div class="step-number">1</div>
        <div class="step-content">
            <h4 class="keyword"><i class="fas fa-feather-alt"></i> LLMによる早期の仮定 (Turn 1)</h4>
            <p>最初のターンで、ユーザーは「アンドリューのペストリーの総カロリー数を計算してください」という大まかな指示を出します。これに対し、LLMは関連性のない4種類のペストリー（チョコレートクロワッサン、ラズベリーミルフィーユ、ヘーゼルナッツティラミス、アップルペストリー）を<span class="highlight">仮定して記述</span>します。これは、情報が不十分な段階でLLMが自ら情報を補完しようとする傾向を示しています。</p>
            <div class="bubble-box">
                <p><strong><i class="fas fa-user"></i> ユーザー (Turn 1):</strong> calculate the total calorie count of Andrew's pastries</p>
                <p><strong><i class="fas fa-robot"></i> LLM (Turn 1):</strong> Andrew's pastries. ... Assumptions: * Andrew has 4 different types of pastries. ... Type A: Chocolate Croissant ... Type B: Raspberry Mille-Feuille ... Type C: Hazelnut Tiramisu Pastry Strip ... Type D: Apple Pastry Square ...</p>
                <p><span class="badge red">問題点</span> <i class="fas fa-exclamation-triangle"></i> これらのペストリーはユーザーが言及したものではなく、LLMが勝手に作り出したものです。</p>
            </div>
        </div>
    </div>

    <div class="arrow-connector"></div>

    <div class="process-step">
        <div class="step-number">2</div>
        <div class="step-content">
            <h4 class="keyword"><i class="fas fa-edit"></i> 不必要な情報更新 (Turn 4)</h4>
            <p>会話が進む中で、ユーザーは新たな情報を提供します (Turn 2, 3)。Turn 4でユーザーが「各ミニペストリーは通常サイズの約1/3のカロリーです」と伝えると、LLMはユーザー提供の情報を正しく解釈するものの、<span class="highlight">自身が初期に立てた仮定に対しても不必要に情報を更新</span>しようとします。例えば、Type A (Chocolate Croissant) のカロリー計算を更新しようとしますが、このペストリー自体がユーザーの指示とは無関係です。</p>
            <div class="bubble-box">
                <p><strong><i class="fas fa-user"></i> ユーザー (Turn 4):</strong> Each mini pastry has about one-third the calories of its normal-sized version.</p>
                <p><strong><i class="fas fa-robot"></i> LLM (Turn 4):</strong> With this new information, we can make some adjustments to our previous calorie counts. ### Type A: Chocolate Croissant * Normal serving size: 250 calories * Mini serving size (1/3 of normal): 80-100 calories ...</p>
                <p><span class="badge orange">観察</span> <i class="fas fa-search"></i> LLMは新しい情報を既存の（ただし誤った）枠組みに組み込もうとしています。</p>
            </div>
        </div>
    </div>

    <div class="arrow-connector"></div>

    <div class="process-step">
        <div class="step-number">3</div>
        <div class="step-content">
            <h4 class="keyword"><i class="fas fa-route"></i> 不必要な複雑化と初期指示の忘却 (最終ターン)</h4>
            <p>上記のような不必要な仮定と更新が繰り返されることで、会話は<span class="highlight">不必要に複雑化</span>します。その結果、LLMは最終的に、最初の指示が「総カロリー数を計算する」ことであったことを忘れ、計算の半分（ミニブルーベリーマフィンのみ）しか返しません。</p>
            <div class="bubble-box">
                <p><strong><i class="fas fa-robot"></i> LLM (Turn 6 - 最終応答):</strong> ... ### Type F: Mini Blueberry Muffins ... Total Calories for Type F: 300 * 150 = 45,000 calories</p>
                <p><strong>抽出された回答:</strong> 45,000 (スコア = 0)</p>
                <p><strong>正解:</strong> 85,000 カロリー</p>
                <p><span class="badge red">致命的エラー</span> <i class="fas fa-times-circle"></i> ミニシナモンロールのカロリー（40,000カロリー）が計算に含まれておらず、タスクを完全に達成できていません。</p>
            </div>
        </div>
    </div>

    <div class="glass-card">
        <h3 class="subsection-title" style="color: var(--color-dark); border-left-color: var(--color-dark);"><i class="fas fa-shoe-prints"></i> 会話における迷子現象 (Lost in Conversation Phenomenon)</h3>
        <p>この一連の会話は、<span class="keyword">「会話における迷子現象」</span>を明確に示しています。具体的には以下の通りです。</p>
        <ul class="unstyled-list">
            <li><i class="fas fa-map-signs" style="color: var(--color-secondary);"></i> ユーザーの指示が不完全に特定されている初期段階 (Turn 1-4) で、LLMは<span class="highlight">仮定</span>を立てます。</li>
            <li><i class="fas fa-draw-polygon" style="color: var(--color-secondary);"></i> これらの仮定は、会話の本筋から逸脱し、LLMを混乱させます。</li>
            <li><i class="fas fa-question-circle" style="color: var(--color-secondary);"></i> 結果として、LLMは<span class="highlight">不正確または不完全な回答</span>を生成してしまいます。</li>
        </ul>
        <div class="note-box">
            <p><i class="fas fa-exclamation-triangle"></i> <span class="note-title">重要な示唆</span><br/>
            このシミュレーション例は、LLMがマルチターンの会話で文脈を維持し、初期の目的を記憶し続けることの難しさを浮き彫りにしています。特に、<span class="keyword">不確実な情報に基づいて早期に結論を急ぐ</span>傾向が、最終的なパフォーマンス低下に繋がっていることが分かります。</p>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-chart-line"></i> まとめと考察 <span class="badge green">結論</span></h3>
    <div class="content-box">
        <p>このAppendix Jの会話例は、LLMがマルチターンで情報を段階的に受け取る際に直面する課題を具体的に示しています。主なポイントは以下の通りです。</p>
        <div class="feature-card-grid">
            <div class="feature-item">
                <div class="icon-item"><i class="fas fa-lightbulb"></i></div>
                <strong>早期の仮定</strong><br/>
                情報が不足していると、LLMは独自の仮定を導入する。
            </div>
            <div class="feature-item">
                <div class="icon-item"><i class="fas fa-sync-alt"></i></div>
                <strong>不必要な更新</strong><br/>
                新しい情報を、誤った既存の仮定に適用しようとする。
            </div>
            <div class="feature-item">
                <div class="icon-item"><i class="fas fa-unlink"></i></div>
                <strong>目的の忘却</strong><br/>
                会話が複雑化すると、初期の目的を見失うことがある。
            </div>
        </div>
        <p>これらの挙動が積み重なることで、「会話における迷子現象」が発生し、LLMのパフォーマンスが著しく低下する可能性があります。この現象の理解は、LLMの評価方法や、より堅牢な対話システムの開発において不可欠です。</p>
    </div>
</div>
<div class="section-card" id="Appendix_K_Gradual_Sharding_Implementation">
    <h2 class="section-title"><i class="fas fa-layer-group"></i> Appendix K Gradual Sharding Implementation</h2>

    <div class="glass-card">
        <p>このセクションでは、論文で実施された「<span class="keyword">段階的シャーディング実験 (Gradual Sharding Experiment)</span>」の実装に関する詳細について解説します。この実験は、LLMが情報をどのように処理し、特に情報の提示の仕方がパフォーマンスにどう影響するかを理解する上で非常に重要です。</p>
        <div class="note-box">
            <p class="note-title"><i class="fas fa-bullseye"></i> 実験の主な目的</p>
            <p>この実験の核心的な目的は、ユーザーがLLMに与える<span class="highlight">指示の「粒度」（情報の細かさや分割の度合い）が、LLMのパフォーマンス（応答の品質や正しさ）の低下にどのような影響を及ぼすか</span>を評価することです。言い換えれば、「情報はまとめて一度に与えた方が良いのか、それとも少しずつ段階的に与えた方が良いのか？」という問いに答えようとしています。</p>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-flask"></i> 「段階的シャーディング実験」とは？</h3>
    <div class="definition-box">
        <p class="definition-title"><i class="fas fa-book-open"></i> 用語解説：段階的シャーディング実験</p>
        <p>「<span class="keyword">段階的シャーディング実験 (Gradual Sharding Experiment)</span>」とは、元々1つのまとまった指示（instruction）を、複数の小さな情報の断片（これを「<span class="keyword">シャード (shard)</span>」と呼びます）に分割し、そのシャードの数を意図的に変化させながらLLMに提示する実験手法です。具体的には、シャード数を1（全ての情報を1つのシャードにまとめた状態）から、論文では最大8まで段階的に増やしていきます。これにより、LLMが受け取る情報の「粒度」を変えたときに、その応答の質（パフォーマンス）がどのように変動するかを観察・分析します。</p>
    </div>
    <div class="bubble-box">
        <p>🤔 <span style="font-family: 'Yomogi', cursive; font-weight: bold; color: var(--color-primary);">なぜこのような実験が重要なのでしょうか？</span></p>
        <p>実際の人間とAIの対話では、ユーザーは必ずしも最初から全ての情報を完璧に、かつ一度に伝えるわけではありません。多くの場合、段階的に情報を提供したり、会話の途中で新しい情報を追加したり、あるいは以前の発言を修正したりします。この「段階的シャーディング実験」は、そうしたより現実的なコミュニケーションの状況下で、LLMがどれだけ効果的に情報を理解し、タスクを遂行できるかを評価するために不可欠です。</p>
    </div>

    <h3 class="subsection-title"><i class="fas fa-cogs"></i> 実験プロセスの詳細 🛠️</h3>
    <p>この「段階的シャーディング実験」は、以下のステップで慎重に進められました。</p>

    <div class="pipeline">
        <div class="pipeline-step">
            <div class="step-number">1</div>
            <div class="step-content">
                <h4><i class="fas fa-filter"></i> 📜 元となる指示の選定</h4>
                <p>実験の出発点として、まず元となるデータセットから特定の条件を満たす「シャーディングされた指示」を選び出しました。</p>
                <ul>
                    <li>選定基準: <span class="highlight">正確に8つのシャード（情報の断片）で構成されている既存の指示</span>。これは、後のステップでシャード数を多様化させるための基準点となります。</li>
                    <li>選定された指示の総数: <span class="keyword" style="font-size: 1.1em;">合計31個</span></li>
                    <li>対象となったタスクの分野 (3分野):
                        <ul class="unstyled-list feature-card-grid">
                            <li class="feature-item glass-card"><i class="fas fa-code fa-2x" style="color: var(--color-accent1);"></i> Code (プログラミング問題の作成)</li>
                            <li class="feature-item glass-card"><i class="fas fa-calculator fa-2x" style="color: var(--color-accent2);"></i> Math (数学の文章問題)</li>
                            <li class="feature-item glass-card"><i class="fas fa-file-alt fa-2x" style="color: var(--color-accent3);"></i> Data-to-Text (構造化データからのテキスト記述生成)</li>
                        </ul>
                    </li>
                </ul>
                <div class="note-box">
                    <p class="note-title"><i class="fas fa-sticky-note"></i> 📝 補足：指示数について</p>
                    <p>論文のAppendix Kの原文には「leading to a total of eight instructions across three tasks」という記述がありますが、これは後の「Applying this method to the 31 instructions yields a total of 248 instructions」という記述や、論文本文のセクション6.3にある「we selected 31 instructions from our original experiment」という記述と照らし合わせると、31個の指示が正しいと考えられます。そのため、この解説では31個の指示が選定されたものとして進めます。</p>
                </div>
            </div>
        </div>

        <div class="pipeline-step">
            <div class="step-number">2</div>
            <div class="step-content">
                <h4><i class="fas fa-magic"></i> ✨ 指示バリアントの生成 (LLMの活用)</h4>
                <p>次に、ステップ1で選ばれた各「8シャードの指示」を元にして、シャード数が異なる複数のバリアント指示を生成しました。この複雑な書き換え作業には、高性能なLLMである<span class="keyword">GPT-4o</span>が活用されました。</p>
                <div class="info-grid">
                    <div class="info-card">
                        <h5><i class="fas fa-robot"></i> GPT-4oへのタスク指示</h5>
                        <p>GPT-4oには、元の8シャードの指示を、よりシャード数が少ない<span class="highlight">2シャードから7シャードまでの指示に「マージ（統合）」する</span>よう指示が出されました。これにより、元の各8シャード指示に対して、シャード数が2, 3, 4, 5, 6, 7の計6種類の新しい指示バリアントが作られることになります。</p>
                    </div>
                    <div class="info-card">
                        <h5><i class="fas fa-pencil-ruler"></i> 言い換えの際のルール</h5>
                        <ul class="unstyled-list">
                            <li><span class="badge" style="background-color: var(--color-accent1); color: white;"><i class="fas fa-check"></i> 許可</span>: 個々のシャードが人間にとって自然で流暢な表現になるように、軽微な言い換えを行うこと。</li>
                            <li><span class="badge" style="background-color: var(--color-secondary); color: white;"><i class="fas fa-bullhorn"></i> 推奨</span>: 元の指示で使われている言葉遣いやニュアンスをできるだけ維持し、意味内容を変えないこと。</li>
                        </ul>
                    </div>
                </div>
                <p style="text-align: center; margin-top: 15px;"><strong><i class="fas fa-sitemap"></i> 指示バリアント生成プロセスのイメージ図</strong></p>
                <div style="border: 2px dashed var(--color-primary); border-radius: 12px; padding: 20px; margin: 20px auto; background: rgba(74, 111, 165, 0.05); text-align: center;">
                    <div style="margin-bottom: 15px;">
                        <span class="badge blue">元の8シャード指示</span>
                    </div>
                    <i class="fas fa-arrow-down fa-2x" style="color: var(--color-primary); margin-bottom: 5px;"></i>
                    <div style="font-family: 'Yomogi', cursive; font-size: 1.2em; margin-bottom: 15px;">
                        <i class="fas fa-robot" style="color: var(--color-accent2);"></i> GPT-4oによるマージ処理 <i class="fas fa-tools" style="color: var(--color-accent2);"></i>
                    </div>
                     <i class="fas fa-arrow-down fa-2x" style="color: var(--color-primary); margin-bottom: 5px;"></i>
                    <div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(100px, 1fr));">
                        <div class="feature-item glass-card" style="border-left: 5px solid var(--color-accent1);">7シャード指示</div>
                        <div class="feature-item glass-card" style="border-left: 5px solid var(--color-accent1);">6シャード指示</div>
                        <div class="feature-item glass-card" style="border-left: 5px solid var(--color-accent1);">5シャード指示</div>
                        <div class="feature-item glass-card" style="border-left: 5px solid var(--color-accent2);">4シャード指示</div>
                        <div class="feature-item glass-card" style="border-left: 5px solid var(--color-accent2);">3シャード指示</div>
                        <div class="feature-item glass-card" style="border-left: 5px solid var(--color-accent2);">2シャード指示</div>
                    </div>
                </div>
            </div>
        </div>

        <div class="pipeline-step">
            <div class="step-number">3</div>
            <div class="step-content">
                <h4><i class="fas fa-list-ol"></i> 🧪 実験用指示セットの構築</h4>
                <p>上記のプロセスを通じて、元の各指示に対して以下のような指示セットがペアとして用意されました。</p>
                <div class="info-grid">
                    <div class="info-card" style="background-color: rgba(255, 248, 225, 0.7);">
                        <h5><i class="fas fa-compress-arrows-alt" style="color: var(--color-secondary);"></i> (1) 連結指示 (concat instruction)</h5>
                        <p>これは、元の8つのシャードを全て連結して1つの長い指示にしたものです。つまり、<span class="keyword">1シャードの指示</span>に相当します。これにより、全ての情報が一度に提示される「シングルターン」の状況をシミュレートします。</p>
                    </div>
                    <div class="info-card" style="background-color: rgba(232, 245, 233, 0.7);">
                        <h5><i class="fas fa-stream" style="color: var(--color-accent1);"></i> (2) シャーディングされた指示 (sharded instructions)</h5>
                        <p>ステップ2でGPT-4oによって生成された、シャード数が<span class="keyword">2から8までの7種類の指示バリアント</span>です。</p>
                        <ul class="tag-list" style="justify-content: center;">
                            <li class="tag">2シャード</li>
                            <li class="tag">3シャード</li>
                            <li class="tag">4シャード</li>
                            <li class="tag">5シャード</li>
                            <li class="tag">6シャード</li>
                            <li class="tag">7シャード</li>
                            <li class="tag">8シャード (元々の指示)</li>
                        </ul>
                    </div>
                </div>

                <p style="margin-top: 20px;">この方法を最初に選定した<span class="keyword" style="font-size: 1.1em;">31個</span>の指示それぞれに適用しました。その結果...</p>
                <div class="formula" style="background: linear-gradient(135deg, var(--color-primary), var(--color-accent2)); color: white; padding: 20px; border-radius: 12px; box-shadow: 0 4px 15px rgba(0,0,0,0.2);">
                    <p style="font-size: 1.2em; margin: 0;">元の指示1つあたり: 1 (連結指示) + 7 (シャード数2～8の指示) = <span style="font-size: 1.5em; font-weight: bold;">8種類</span>の指示</p>
                    <p style="font-size: 1.2em; margin: 5px 0 0;">全指示数: 31 (元の指示数) × 8 (種類) = <span style="font-size: 1.8em; font-weight: bold;">248個</span>の実験用指示</p>
                </div>

                <div class="note-box" style="margin-top: 20px;">
                    <p class="note-title"><i class="fas fa-balance-scale"></i> 重要なポイント：均等性と同一性</p>
                    <p>このプロセスにより、以下の2つの重要な条件が満たされた実験セットが構築されました。</p>
                    <ul>
                        <li><span class="highlight">シャード数ごとの指示数が均等</span>: 1シャードから8シャードまでの各シャード数に対して、同数の指示（この場合は31個ずつ）が存在します。</li>
                        <li><span class="highlight">基盤となる問題は同一</span>: シャード数が異なっても、元になっている問題（タスク）自体は同じです。これにより、純粋に「情報の提示の仕方（シャード数）」の違いがパフォーマンスにどう影響するかを比較できます。</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="pipeline-step">
            <div class="step-number">4</div>
            <div class="step-content">
                <h4><i class="fas fa-play-circle"></i> 💻 シミュレーションの実行</h4>
                <p>構築された248個の指示セットを用いて、LLMのパフォーマンス評価シミュレーションが実施されました。</p>
                <ul>
                    <li>シミュレーション回数: 各指示と各モデルの組み合わせに対して、<span class="keyword">10回の対話シミュレーション</span>を実施。</li>
                    <li>対象LLMモデル (2種類):
                        <ul class="unstyled-list feature-card-grid">
                            <li class="feature-item glass-card"><i class="fas fa-brain fa-2x" style="color: var(--color-primary);"></i> GPT-4o</li>
                            <li class="feature-item glass-card"><i class="fas fa-microchip fa-2x" style="color: var(--color-secondary);"></i> GPT-4o-mini</li>
                        </ul>
                    </li>
                </ul>
            </div>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-chart-line"></i> 📊 実験結果の参照先</h3>
    <div class="bubble-box" style="border-color: var(--color-accent1);">
        <p>この「段階的シャーディング実験」から得られた具体的な知見や結果については、論文本文の<span class="keyword">セクション6.3 (Section 6.3)</span> で詳細に記述されています。</p>
        <p style="text-align: center; margin-top: 15px;">
            <a class="button" href="#Section_6.3" style="background-color: var(--color-accent1); color: white; padding: 10px 15px; border-radius: 8px; text-decoration: none; font-family: 'Yomogi', cursive;">
                <i class="fas fa-external-link-alt"></i> セクション6.3へジャンプ (イメージ)
            </a>
        </p>
        <p class="reference">※ このリンクは概念的なもので、実際の論文のセクション6.3へ誘導するものではありません。</p>
    </div>

    <div class="content-box" style="margin-top: 30px; border-top: 2px dashed var(--color-primary); padding-top: 20px;">
        <h4><i class="fas fa-lightbulb"></i> まとめると...</h4>
        <p>「Appendix K Gradual Sharding Implementation」では、LLMのパフォーマンスに対する指示の粒度の影響を調べるために、非常に緻密な実験計画が立てられ、実行されたことが分かります。</p>
        <ol class="process-step-list">
            <li class="process-step"><div class="step-number" style="background-color: var(--color-secondary);">①</div><div class="step-content">基準となる8シャードの指示を選定。</div></li>
            <li class="process-step"><div class="step-number" style="background-color: var(--color-secondary);">②</div><div class="step-content">GPT-4oを用いて、シャード数を2から7に変化させた指示バリアントを生成。</div></li>
            <li class="process-step"><div class="step-number" style="background-color: var(--color-secondary);">③</div><div class="step-content">1シャード（全情報連結）から8シャードまで、各シャード数で均等な数の指示セットを構築。</div></li>
            <li class="process-step"><div class="step-number" style="background-color: var(--color-secondary);">④</div><div class="step-content">複数のLLMモデル（GPT-4o, GPT-4o-mini）でシミュレーションを実行。</div></li>
        </ol>
        <p>この実験設計により、情報の提示方法がLLMの応答品質に与える影響を、より客観的かつ系統的に評価することが可能になります。このAppendix Kは、論文の主張を裏付けるための重要な実験的基盤を提供していると言えるでしょう。</p>
    </div>

</div>
<div class="section-card" id="Appendix_L_Temperature_Experiment_Implementation">
    <h2 class="section-title"><i class="fas fa-thermometer-half"></i> Appendix L Temperature Experiment Implementation</h2>

    <div class="bubble-box" style="border-color: var(--color-accent1);">
        <p style="font-family: 'Yomogi', cursive; font-size: 16px; color: var(--color-accent1);">
            <i class="fas fa-bullhorn"></i> このセクションのポイント！
        </p>
        <p>この実験の主な目的は、LLM（大規模言語モデル）の応答生成時の<strong>「温度 (temperature)」</strong>という設定が、モデルの<strong><span class="keyword">適性 (aptitude)</span></strong> と <strong><span class="keyword">信頼性 (reliability)</span></strong> にどのような影響を与えるのかを調べることです。特に、1回のやりとりで完結する<strong>シングルターン</strong>設定と、複数回のやりとりを行う<strong>マルチターン</strong>設定の両方で評価しています。🔬</p>
        <p>簡単に言うと、「LLMの創造性やランダム性を調整する『温度』を変えると、タスクをこなす上手さや、結果の安定性がどう変わるのかな？」という疑問に答えようとしています。</p>
    </div>

    <div class="definition-box">
        <div class="definition-title"><i class="fas fa-book-open"></i> ちょっと用語解説 📌</div>
        <ul class="unstyled-list">
            <li><p><span class="keyword">温度 (Temperature)</span>: LLMがテキストを生成する際の「ランダム性」や「創造性」をコントロールするパラメータです。値が低い (例: 0.0) と、より予測可能で一貫性のあるテキストを生成しやすく、値が高い (例: 1.0) と、より多様で、時には斬新なテキストを生成しやすくなります。</p></li>
            <li><p><span class="keyword">適性 (Aptitude)</span>: モデルが特定のタスクをどれだけ上手く実行できるか、その根本的な能力の高さを示します。</p></li>
            <li><p><span class="keyword">信頼性 (Reliability)</span>: モデルの出力がどれだけ安定しているか、つまり、同じ入力や条件に対して、結果の品質が大きくばらつかずに一貫しているかを示します。</p></li>
            <li><p><span class="keyword">シングルターン (Single-turn)</span>: ユーザーとLLMが一往復のやり取りでタスクを完了するような状況です。</p></li>
            <li><p><span class="keyword">マルチターン (Multi-turn)</span>: ユーザーとLLMが複数回のやり取りを重ねてタスクを進めていく状況です。</p></li>
        </ul>
    </div>

    <h3 class="subsection-title"><i class="fas fa-cogs"></i> 実験の具体的なセットアップ</h3>
    <p>この温度実験は、以下のステップと設定で実施されました。</p>

    <div class="pipeline">
        <div class="pipeline-step" style="border-color: var(--color-secondary);">
            <p><span class="badge orange">ステップ1</span> <strong>タスクと指示の選定</strong> ✏️</p>
            <p>実験に使用する指示は、4つの異なるタスクから選ばれました。</p>
            <div class="feature-card-grid" style="grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));">
                <div class="feature-item" style="background-color: rgba(255, 126, 95, 0.1);">
                    <i class="fas fa-code" style="font-size: 20px; color: var(--color-secondary);"></i>
                    <p><strong>Code (コード生成)</strong></p>
                    <p>10個の指示</p>
                </div>
                <div class="feature-item" style="background-color: rgba(255, 126, 95, 0.1);">
                    <i class="fas fa-database" style="font-size: 20px; color: var(--color-secondary);"></i>
                    <p><strong>Database (データベース操作)</strong></p>
                    <p>10個の指示</p>
                </div>
                <div class="feature-item" style="background-color: rgba(255, 126, 95, 0.1);">
                    <i class="fas fa-bolt" style="font-size: 20px; color: var(--color-secondary);"></i>
                    <p><strong>Actions (アクション実行)</strong></p>
                    <p>10個の指示</p>
                </div>
                <div class="feature-item" style="background-color: rgba(255, 126, 95, 0.1);">
                    <i class="fas fa-calculator" style="font-size: 20px; color: var(--color-secondary);"></i>
                    <p><strong>Math (数学問題)</strong></p>
                    <p>10個の指示</p>
                </div>
            </div>
            <p style="text-align: center; margin-top: 10px;">➡️ 合計で <strong class="highlight">40個</strong> の指示が使われました。</p>
        </div>

        <div class="pipeline-step" style="border-color: var(--color-accent1);">
            <p><span class="badge green">ステップ2</span> <strong>使用モデルの選定</strong> 🤖</p>
            <p>実験には、以下の2つのLLMが選ばれました。</p>
            <ul style="font-family: 'Yomogi', cursive; list-style-type: '🤖 '; padding-left: 20px;">
                <li>GPT-4o</li>
                <li>GPT-4o-mini</li>
            </ul>
        </div>

        <div class="pipeline-step" style="border-color: var(--color-accent2);">
            <p><span class="badge purple">ステップ3</span> <strong>会話設定と温度パラメータ</strong> 🗣️🔥</p>
            <p>各指示と各モデルの組み合わせに対して、3つの異なる<span class="keyword">会話設定 (conversation settings)</span>でシミュレーションが行われました。そして、それぞれの会話設定で、温度パラメータを3つの値 (<strong class="highlight">0.0, 0.5, 1.0</strong>) に変化させました。</p>

            <div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));">
                <div class="info-card">
                    <p style="font-family: 'Yomogi', cursive; font-size:16px; color: var(--color-primary);"><i class="fas fa-comments"></i> <strong>Full と Concat 設定</strong> (シングルターン)</p>
                    <p>これらの設定では、アシスタント（LLM自身）の温度のみ変更可能です。そのため、温度の組み合わせは以下の<strong class="highlight">3通り</strong>です。</p>
                    <ul class="unstyled-list" style="padding-left: 10px;">
                        <li><i class="fas fa-fire" style="color: #FF7043;"></i> アシスタント温度: <code class="highlight">0.0</code></li>
                        <li><i class="fas fa-fire" style="color: #FFA726;"></i> アシスタント温度: <code class="highlight">0.5</code></li>
                        <li><i class="fas fa-fire" style="color: #FFCA28;"></i> アシスタント温度: <code class="highlight">1.0</code></li>
                    </ul>
                </div>
                <div class="info-card">
                    <p style="font-family: 'Yomogi', cursive; font-size:16px; color: var(--color-secondary);"><i class="fas fa-exchange-alt"></i> <strong>Sharded 設定</strong> (マルチターン)</p>
                    <p>この設定では、アシスタントの温度 (Assistant Temperature: AT) とユーザーシミュレータの温度 (User Temperature: UT) の両方を変更できます。そのため、温度の組み合わせは 3 (AT) × 3 (UT) = <strong class="highlight">9通り</strong>になります。</p>
                    <div class="table-wrapper" style="margin-top:10px;">
                        <table>
                            <thead>
                                <tr>
                                    <th>ユーザー温度 (UT)</th>
                                    <th>アシスタント温度 (AT)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td rowspan="3" style="text-align:center; vertical-align: middle;"><code class="highlight">0.0</code></td>
                                    <td><code class="highlight">0.0</code></td>
                                </tr>
                                <tr><td><code class="highlight">0.5</code></td></tr>
                                <tr><td><code class="highlight">1.0</code></td></tr>
                                <tr>
                                    <td rowspan="3" style="text-align:center; vertical-align: middle;"><code class="highlight">0.5</code></td>
                                    <td><code class="highlight">0.0</code></td>
                                </tr>
                                <tr><td><code class="highlight">0.5</code></td></tr>
                                <tr><td><code class="highlight">1.0</code></td></tr>
                                <tr>
                                    <td rowspan="3" style="text-align:center; vertical-align: middle;"><code class="highlight">1.0</code></td>
                                    <td><code class="highlight">0.0</code></td>
                                </tr>
                                <tr><td><code class="highlight">0.5</code></td></tr>
                                <tr><td><code class="highlight">1.0</code></td></tr>
                            </tbody>
                        </table>
                    </div>
                    <p style="font-size: 12px; text-align: center; color: var(--color-gray);">図: Sharded設定での温度の組み合わせ</p>
                </div>
            </div>
        </div>

        <div class="pipeline-step" style="border-color: var(--color-primary);">
            <p><span class="badge blue">ステップ4</span> <strong>シミュレーション回数の増加</strong> 🔄</p>
            <p>この温度実験では、各条件（指示、モデル、会話設定、温度の組み合わせ）ごとにシミュレーションを<strong class="highlight">20回</strong>実施しました。これは、論文の主実験で行われた10回よりも多い回数です。</p>
            <div class="note-box" style="background-color: rgba(74, 111, 165, 0.05);">
                <div class="note-title" style="color: var(--color-primary);"><i class="fas fa-question-circle"></i> なぜシミュレーション回数を増やしたの？</div>
                <p>主な理由は、モデルの<span class="keyword">適性 (aptitude)</span> と <span class="keyword">信頼性 (reliability)</span> の「ばらつき」や「変動」をより精密に測定するためです。シミュレーション回数を増やすことで、統計的な信頼性が向上し、特にパーセンタイル（例えば、上位10%のスコアなど）に基づいた評価指標の推定精度が向上します。</p>
            </div>
            <div class="note-box" style="background-color: rgba(92, 184, 92, 0.1);">
                <div class="note-title" style="color: var(--color-accent1);"><i class="fas fa-coins"></i> 計算コストは大丈夫？</div>
                <p>この追加のシミュレーション回数は、計算コストの観点からはそれほど大きな負担ではありませんでした。なぜなら、この温度実験では、主実験と比較して使用するモデルの数 (<strong class="highlight">2モデル</strong> vs 15モデル) や指示の数 (<strong class="highlight">40指示</strong> vs 600指示) が限定的だったためです。</p>
            </div>
        </div>
    </div>

    <div class="framework-box" style="margin-top: 30px; border-color: var(--color-accent3);">
        <div class="framework-title" style="color: var(--color-accent3); border-bottom-color: var(--color-accent3);"><i class="fas fa-chart-line"></i> 実験結果の行方</div>
        <p>これらの温度実験から得られた知見や結果については、論文の本文 <strong class="highlight">Section 7.2</strong> で詳しく説明されています。そちらもぜひチェックしてみてくださいね！🔍</p>
    </div>

</div>
<div class="section-card" id="Appendix_M_Recap_&amp;_Snowball_Experiment_Implementation">
    <h2 class="section-title"><i class="fas fa-cogs"></i> Appendix M Recap &amp; Snowball Experiment Implementation</h2>

    <div class="glass-card" style="margin-bottom: 25px;">
        <h3 class="subsection-title" style="margin-top:0; border-left-color: var(--color-accent1); color: var(--color-accent1);"><i class="fas fa-bullseye"></i> このセクションの目的と概要</h3>
        <p>このセクションでは、論文で提案されている2つの特別な会話シミュレーション戦略、<span class="keyword">RECAP</span>（リキャップ）と<span class="keyword">SNOWBALL</span>（スノーボール）について、それらが具体的にどのように実装され、どのような実験設定で評価されたのかを解説します。これらの戦略は、LLMが複数ターンにわたる会話の中で情報をどのように扱い、記憶し、活用するかをより深く理解するために考案されました。</p>
        <div class="info-grid" style="grid-template-columns: 1fr 1fr; margin-top:15px;">
            <div class="info-card">
                <h4><i class="fas fa-lightbulb" style="color: var(--color-primary);"></i> RECAP 戦略とは？</h4>
                <p>RECAP戦略は、会話の<strong>最後に</strong>、それまでユーザーが発言した<span class="highlight">全ての情報をまとめて提示</span>し、LLMに最終的な応答を生成させるアプローチです。これにより、LLMが全ての情報を一度に受け取った場合に、どのように応答を改善できるかを評価します。</p>
            </div>
            <div class="info-card">
                <h4><i class="fas fa-雪だるま" style="color: var(--color-secondary);"></i> SNOWBALL 戦略とは？</h4>
                <p>SNOWBALL戦略は、会話の<strong>各ターン</strong>で、新しい情報を提供する際に、<span class="highlight">それまでに提示された全ての過去の情報を繰り返し提示</span>する方法です。情報が雪だるま式に蓄積されていく様子から名付けられました。これにより、LLMが情報を継続的に記憶し、新しい情報と統合する能力を評価します。</p>
            </div>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-recycle"></i> RECAP実験の実装方法</h3>
    <div class="content-box">
        <p><span class="badge orange">ポイント</span> RECAP実験のシミュレーションは、既存の<span class="keyword">SHARDED</span>会話のログデータを活用して行われます。これは、RECAP戦略がSHARDED戦略と非常に似ており、主な違いは<span class="highlight">会話の最後に過去の全ユーザー発話をまとめた特別な「要約ターン」が追加される</span>点のみだからです。</p>

        <div class="framework-box" style="margin-top: 15px;">
            <div class="framework-title"><i class="fas fa-shoe-prints"></i> RECAPシミュレーションの手順</div>
            <div class="process-step">
                <div class="step-number" style="background-color: var(--color-secondary);">1</div>
                <div class="step-content">
                    <strong>SHARDEDシミュレーションの実行:</strong> まず、ベースとなるSHARDEDシミュレーションを実行します。このシミュレーションでは、ユーザーからの指示（シャード）が1ターンずつ段階的にLLMに提示されます。
                    <div style="text-align: center; margin: 10px 0; padding: 10px; background-color: rgba(74, 111, 165, 0.05); border-radius: 8px;">
                        <span class="badge blue">ターン1: ユーザー発話 A</span> <i class="fas fa-long-arrow-alt-right" style="color: var(--color-primary); margin: 0 5px;"></i>
                        <span class="badge blue">ターン2: ユーザー発話 B</span> <i class="fas fa-long-arrow-alt-right" style="color: var(--color-primary); margin: 0 5px;"></i>
                        <span class="badge" style="background-color: #ddd; color: #333;">...</span> <i class="fas fa-long-arrow-alt-right" style="color: var(--color-primary); margin: 0 5px;"></i>
                        <span class="badge blue">最終ターン: ユーザー発話 X</span>
                    </div>
                </div>
            </div>
            <div class="process-step">
                <div class="step-number" style="background-color: var(--color-secondary);">2</div>
                <div class="step-content">
                    <strong>「要約ターン」の追加:</strong> 実行されたSHARDEDシミュレーションのログの最後に、<span class="highlight">「recap（要約）」ターン</span>を人工的に追加します。このターンでは、それまでの全てのユーザー発話 (A, B, ..., X) が一つにまとめられます。
                    <div class="bubble-box" style="margin-top:10px; border-color: var(--color-accent1); background-color: #f0fff0;">
                        <p style="font-family: 'Yomogi', cursive;">💬 <strong>ユーザーシミュレータ (要約ターン):</strong><br/>
                        「これまでの会話内容をまとめると、以下のようになりますね：<br/>
                          - [ユーザー発話 A の内容]<br/>
                          - [ユーザー発話 B の内容]<br/>
                          ... <br/>
                          - [ユーザー発話 X の内容]」</p>
                    </div>
                </div>
            </div>
            <div class="process-step">
                <div class="step-number" style="background-color: var(--color-secondary);">3</div>
                <div class="step-content">
                    <strong>追加シミュレーションの実行:</strong> この追加された「recap」ターンをLLMに提示し、LLMが応答を生成するまで、<span class="highlight">もう1ターンだけシミュレーションを続行</span>します。
                </div>
            </div>
        </div>
        <div class="note-box" style="margin-top: 20px;">
            <div class="note-title"><i class="fas fa-balance-scale"></i> 実装の利点</div>
            <p>この実装方法の大きな利点は、RECAPアプローチの有効性を、ベースとなった<span class="keyword">SHARDED</span>シミュレーションの結果と<span class="highlight">直接比較できる</span>点です。つまり、同じ会話の初期段階を共有し、最後の要約情報提示がパフォーマンスにどのような影響を与えるかを明確に評価できます。</p>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-雪だるま"></i> SNOWBALL実験の実装方法</h3>
    <div class="content-box">
        <p>SNOWBALL実験では、<span class="highlight">各ターンで過去の全てのユーザー発話が繰り返し提示される</span>ため、SHARDEDのログを再利用することはできません。代わりに、<span class="keyword">会話全体を最初からシミュレート</span>する必要があります。</p>

        <div class="definition-box" style="margin-top:15px;">
            <div class="definition-title"><i class="fas fa-comment-alt"></i> SNOWBALLにおけるプロンプト形式</div>
            <p>各ターンでユーザーシミュレータがLLMに送信するプロンプトは、以下のような特別な形式を取ります。過去のユーザー発話が箇条書きで連結され、その後に現在のターンの新しい発話が続きます。</p>
            <div class="bubble-box" style="border-color: var(--color-accent2); background-color: #f5f0ff; margin-top:10px;">
                <p style="font-family: 'Yomogi', cursive; font-size:14px;">「<span style="font-weight:bold; color:var(--color-secondary);">Just to reiterate:</span> (再確認ですが：)<br/>
                  - <span style="color:var(--color-gray); font-style:italic;">[past utterance 1]</span> (過去の発話1)<br/>
                  - <span style="color:var(--color-gray); font-style:italic;">[past utterance 2]</span> (過去の発話2)<br/>
                <br/>
                <span style="font-weight:bold; color:var(--color-secondary);">Also,</span> (そして、)<br/>
                <span style="color:var(--color-gray); font-style:italic;">[current utterance]</span> (現在の発話)」</p>
            </div>
            <p style="margin-top: 10px;">この形式により、LLMは常に過去の全コンテキストを明示的に参照しながら、新しい情報に対応することになります。</p>
        </div>

        <h4 class="subsection-title" style="font-size:16px; margin-top:25px; color: var(--color-dark); border-left-color: var(--color-dark);"><i class="fas fa-stream"></i> SNOWBALLシミュレーションのターン進行例</h4>
        <p>具体的にSNOWBALLシミュレーションがどのように進行するかを見てみましょう：</p>
        <div class="pipeline" style="margin-top: 15px;">
            <div class="pipeline-step" style="background-color: #e3f2fd;">
                <strong><i class="fas fa-hourglass-start"></i> ターン1:</strong><br/>
                <p style="font-family: 'Yomogi', cursive;">ユーザーシミュレータ: 「[発話A]」</p>
            </div>
            <div class="pipeline-step" style="background-color: #e3f2fd;">
                <strong><i class="fas fa-hourglass-half"></i> ターン2:</strong><br/>
                <p style="font-family: 'Yomogi', cursive;">ユーザーシミュレータ: 「再確認ですが：<br/>
                  - [発話A]<br/><br/>
                そして、<br/>
                [発話B]」</p>
            </div>
            <div class="pipeline-step" style="background-color: #e3f2fd;">
                <strong><i class="fas fa-hourglass-end"></i> ターン3:</strong><br/>
                <p style="font-family: 'Yomogi', cursive;">ユーザーシミュレータ: 「再確認ですが：<br/>
                  - [発話A]<br/>
                  - [発話B]<br/><br/>
                そして、<br/>
                [発話C]」</p>
            </div>
            <div class="pipeline-step" style="border-bottom: none; background-color: #e3f2fd;">
                <p style="text-align:center; font-family: 'Yomogi', cursive; font-weight:bold;">... このように、過去の発話が雪だるま式に増えながら会話が進行します ...</p>
            </div>
        </div>

        <div class="note-box" style="margin-top: 25px; background-color: rgba(255, 126, 95, 0.05); border-left-color: var(--color-secondary);">
            <div class="note-title" style="color: var(--color-secondary);"><i class="fas fa-exclamation-triangle"></i> 非常に重要な注意点：蓄積される情報の内容</div>
            <p>RECAP戦略とSNOWBALL戦略の両方で、LLMに提示される情報について、極めて重要な点があります。それは、<span class="highlight">蓄積・提示されるのは、元の「シャード（shard）」自体ではなく、ユーザーシミュレータによって「言語化された発話（verbalized utterance）」である</span>ということです。</p>
            <div class="two-column" style="margin-top: 15px; align-items: stretch;">
                <div class="column">
                    <div class="feature-item" style="background-color: white; border: 1px dashed var(--color-gray); padding:15px; height:100%;">
                        <i class="fas fa-file-invoice fa-2x" style="color: var(--color-gray); margin-bottom:10px;"></i>
                        <h5 style="margin:0 0 5px 0;">元のシャード (Original Shard)</h5>
                        <p style="font-size: 0.9em;">これは、元の指示を分割した、<span class="keyword">構造化された情報単位</span>です。例えば、「関数の入力パラメータは整数型のリストである」といった形式的な記述です。</p>
                    </div>
                </div>
                <div class="column">
                    <div class="feature-item" style="background-color: white; border: 1px dashed var(--color-accent1); padding:15px; height:100%;">
                        <i class="fas fa-comments fa-2x" style="color: var(--color-accent1); margin-bottom:10px;"></i>
                        <h5 style="margin:0 0 5px 0;">言語化された発話 (Verbalized Utterance)</h5>
                        <p style="font-size: 0.9em;">こちらは、ユーザーシミュレータがシャードの内容を基に生成した、より<span class="keyword">自然な会話形式の文</span>です。例えば、「あ、そうそう、その関数に入れるのは整数のリストにしてほしいんだ」といった、実際の人間が話しそうな表現になります。</p>
                    </div>
                </div>
            </div>
            <p style="margin-top: 15px;">この違いは、LLMがより現実の人間との対話に近い形で情報を処理する状況をシミュレートするために重要です。LLMは単なる情報の断片ではなく、<span class="highlight">文脈化された、より自然な発話の流れ</span>の中で情報を理解し、応答することが求められます。</p>
        </div>
    </div>

    <h3 class="subsection-title"><i class="fas fa-flask"></i> 実験設定と報告される指標</h3>
    <div class="content-box">
        <p>RECAPおよびSNOWBALLのシミュレーションは、以下の共通の実験設定に基づいて行われました。</p>
        <div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));">
            <div class="info-card">
                <h4><i class="fas fa-tasks" style="color:var(--color-primary);"></i> 対象タスク <span class="badge yellow">4種類</span></h4>
                <p>シミュレーションは、以下の4つの異なるタスクで行われました。</p>
                <ul class="unstyled-list" style="margin-top:10px; padding-left:10px; list-style-type: '✏️ ';">
                    <li style="margin-bottom:5px;"><span class="keyword">Code</span> (プログラミング課題)</li>
                    <li style="margin-bottom:5px; list-style-type: '📊 ';"><span class="keyword">Database</span> (データベースクエリ生成)</li>
                    <li style="margin-bottom:5px; list-style-type: '📐 ';"><span class="keyword">Math</span> (算術問題)</li>
                    <li style="margin-bottom:5px; list-style-type: '🤖 ';"><span class="keyword">Actions</span> (API呼び出し)</li>
                </ul>
            </div>
            <div class="info-card">
                <h4><i class="fas fa-redo" style="color:var(--color-secondary);"></i> シミュレーション回数 <span class="badge yellow">N=10</span></h4>
                <p>各タスクの全ての<span class="keyword">sharded instructions</span>（分割された指示）に対して、RECAPとSNOWBALLの各設定で<span class="highlight">10回ずつ</span>シミュレーションが実行されました。複数回実行することで、LLMの応答のばらつきを考慮し、より信頼性の高い結果を得ることができます。</p>
            </div>
            <div class="info-card">
                <h4><i class="fas fa-chart-line" style="color:var(--color-accent1);"></i> 報告されるパフォーマンス指標</h4>
                <p>実験結果として報告されるのは、<span class="highlight">タスク全体の平均パフォーマンスの平均値</span>です。具体的には、各タスクで得られたパフォーマンス（例：正解率など）をまず平均し、その後に4つのタスク間での平均を取ります。</p>
                <div class="formula" style="margin-top:10px; background-color: #f9f9f9; border: 1px solid #eee;">
                    パフォーマンス指標 = \( \frac{1}{4} \sum_{\text{task} \in \{\text{Code, DB, Math, Actions}\}} (\text{タスクごとの平均パフォーマンス}) \)
                </div>
            </div>
        </div>

        <div class="note-box" style="margin-top: 25px;">
            <div class="note-title"><i class="fas fa-table"></i> 結果の提示箇所</div>
            <p>これらの実験結果は、論文中の<span class="keyword">Table 2</span>にまとめられています。この表を参照することで、RECAPおよびSNOWBALL戦略が、ベースラインとなるFULLやSHARDED戦略と比較して、LLMのパフォーマンスにどのような影響を与えたかを確認できます。</p>
        </div>
    </div>
</div>
<div class="section-card" id="Appendix_N_On_obtaining_deterministic_outputs_from_LLMs">
    <h2 class="section-title"><i class="fas fa-cogs"></i>Appendix N LLMから決定的出力を得る方法について</h2>

    <div class="content-box">
        <p><span class="badge yellow">📝 主な目的</span> このセクションでは、大規模言語モデル（LLM）の出力の<strong>決定的出力 (deterministic outputs)</strong>、つまり同じ入力に対して常に同じ結果を得ようとする試みと、それがなぜ現実には難しいのかについて深掘りして解説します。</p>
        <p><span class="badge blue">💡 論旨</span> 論文の実験結果が示すように、LLMの生成時のランダム性を制御するパラメータである<span class="keyword">temperatureを0</span>に設定したとしても、依然として高い<span class="highlight">信頼性の低さ</span>が見られます。これは、トークンごとや対話のターンごとに生じる微妙な<span class="keyword">非決定性 (non-determinism)</span>が積み重なり、特に複数ターンの対話において複合的な影響を及ぼすためです。</p>
    </div>

    <div class="arrow-connector"></div>

    <div class="glass-card">
        <h3 class="subsection-title"><i class="fas fa-question-circle"></i>Temperature = 0 なのに、なぜ非決定的になるのか？</h3>

        <div class="info-grid">
            <div class="info-card">
                <div class="feature-item">
                    <i class="fas fa-cogs fa-2x" style="color: var(--color-primary);"></i>
                    <p class="note-title" style="color: var(--color-primary); margin-bottom: 5px;">理論上の期待: Greedy Decoding</p>
                </div>
                <p>理論上、<span class="keyword">temperature (T) = 0</span> と設定すると、モデルは<span class="keyword">greedy decoding（貪欲デコーディング）</span>という戦略を取ります。これは、各生成ステップにおいて、モデルが予測する次のトークンの<span class="highlight">語彙分布（vocabulary distribution）の中で最も確率の高いトークン</span>、つまり<span class="keyword">argmax</span>を常に選択することを意味します。</p>
                <p style="text-align: center; font-family: 'Kaisei Decol', serif;">
                    選択されるトークン = <span class="math-inline">\( \underset{token \in V}{\text{argmax}} P(token | \text{context}) \)</span>
                </p>
                <div style="text-align: center; margin-top: 10px;">
                    <i class="fas fa-lightbulb fa-2x" style="color: var(--color-accent1);"></i>
                     <p style="font-size: 12px; color: var(--color-gray); font-family: 'Yomogi', cursive;">「一番ありえそうな言葉を選ぶ！」</p>
                </div>
            </div>

            <div class="info-card">
                <div class="feature-item">
                     <i class="fas fa-laptop-code fa-2x" style="color: var(--color-secondary);"></i>
                    <p class="note-title" style="color: var(--color-secondary); margin-bottom: 5px;">実際の挙動: 浮動小数点演算の限界</p>
                </div>
                <p>しかし、論文では、この理想的な挙動が現実には妨げられると指摘しています。その主な原因は、<span class="highlight">コンピュータのハードウェアにおける浮動小数点演算の制約</span>です。</p>
                <p>浮動小数点演算では、実数を完全な精度で表現できず、ごくわずかな誤差が生じることがあります。これにより、計算の途中で<span class="highlight">わずかに異なる中間値</span>が生成される可能性があります。</p>
                <div style="text-align: center; margin-top: 10px;">
                     <i class="fas fa-calculator fa-2x" style="color: var(--color-accent3);"></i>
                     <p style="font-size: 12px; color: var(--color-gray); font-family: 'Yomogi', cursive;">0.30000000000000001 vs 0.29999999999999998 のような微妙な差</p>
                </div>
            </div>
        </div>

        <div class="content-box" style="text-align: center; margin-top: 20px; padding:15px; background-color: rgba(255,255,255,0.5); border-radius:8px;">
            <p><i class="fas fa-water" style="color: var(--color-accent2);"></i> この本当に小さな計算上の差異が、<span class="keyword">波及効果 (ripple effect)</span> を引き起こします。</p>
            <div style="display: flex; justify-content: center; align-items: center; margin-top: 15px; flex-wrap: wrap;">
                <div style="text-align: center; margin: 5px 10px;">
                    <i class="fas fa-circle" style="color: var(--color-accent3); font-size: 0.5em;"></i>
                    <p style="font-size: 12px; color: var(--color-dark); margin-top:2px;">微小な中間値の差</p>
                </div>
                <i class="fas fa-long-arrow-alt-right fa-lg" style="color: var(--color-gray); margin: 5px 10px;"></i>
                <div style="text-align: center; margin: 5px 10px;">
                    <i class="fas fa-project-diagram" style="color: var(--color-accent2); font-size: 1.2em;"></i>
                    <p style="font-size: 12px; color: var(--color-dark); margin-top:2px;">より大きな値の変化</p>
                </div>
                <i class="fas fa-long-arrow-alt-right fa-lg" style="color: var(--color-gray); margin: 5px 10px;"></i>
                <div style="text-align: center; margin: 5px 10px;">
                    <i class="fas fa-random" style="color: var(--color-secondary); font-size: 1.2em;"></i>
                    <p style="font-size: 12px; color: var(--color-dark); margin-top:2px;">異なるトークンの選択</p>
                </div>
                 <i class="fas fa-long-arrow-alt-right fa-lg" style="color: var(--color-gray); margin: 5px 10px;"></i>
                <div style="text-align: center; margin: 5px 10px;">
                    <i class="fas fa-question" style="color: var(--color-primary); font-size: 1.2em;"></i>
                    <p style="font-size: 12px; color: var(--color-dark); margin-top:2px; font-weight:bold;">出力の非決定性</p>
                </div>
            </div>
            <p style="margin-top:10px; font-style:italic; font-size:13px; font-family: 'Yomogi', cursive;">結果として、理論上は決定的であるはずのgreedy decodingでも、実際には異なるトークンが選ばれ、出力が変わってしまうことがあるのです。</p>
        </div>
    </div>

    <div class="arrow-connector"></div>

    <h3 class="subsection-title"><i class="fas fa-building"></i>モデル提供者の認識と対応</h3>
    <p>主要なLLM提供者も、この非決定性の問題を認識しており、それについて言及したり、対策を提案したりしています。</p>
    <div class="info-grid" style="grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));">
        <div class="info-card">
            <div class="feature-item">
                <i class="fas fa-comments fa-2x" style="color: #E67E22;"></i>
                <p class="note-title" style="color: #E67E22; margin-bottom: 5px;">Anthropic</p>
            </div>
            <p>Anthropic社は、出力の一貫性を確認するために、<span class="highlight">複数回サンプリングを行い、結果を相互検証する</span>ことを推奨しています。<sup>4</sup></p>
            <div style="text-align: center; margin-top: 10px;">
                <i class="fas fa-redo-alt fa-2x" style="color: #E67E22;"></i>
                <p style="font-size: 12px; color: var(--color-gray); font-family: 'Yomogi', cursive;">「何度か試して、だいたい同じ答えが出るか見てみよう！」</p>
            </div>
        </div>
        <div class="info-card">
            <div class="feature-item">
                <i class="fab fa-google fa-2x" style="color: #3498DB;"></i>
                <p class="note-title" style="color: #3498DB; margin-bottom: 5px;">Google</p>
            </div>
            <p>Google社は、自社のモデル出力は「<span class="highlight">ほとんど決定的 (mostly deterministic)</span>」であると述べています。<sup>5</sup> これは、完全には決定的ではないことを示唆しています。</p>
            <div style="text-align: center; margin-top: 10px;">
                <i class="fas fa-check-circle fa-2x" style="color: #3498DB;"></i>
                <p style="font-size: 12px; color: var(--color-gray); font-family: 'Yomogi', cursive;">「だいたいは同じ答えになるはず...たぶん！」</p>
            </div>
        </div>
        <div class="info-card">
            <div class="feature-item">
                <i class="fas fa-microchip fa-2x" style="color: #9B59B6;"></i>
                <p class="note-title" style="color: #9B59B6; margin-bottom: 5px;">OpenAI</p>
            </div>
            <p>OpenAI社は、非決定性をさらに低減するための方法として、<span class="highlight">seed（シード）パラメータを設定する</span>ことを推奨しています。<sup>6</sup> Seed値を固定すると、乱数生成の系列が同じになり、結果が再現しやすくなります。</p>
            <div style="text-align: center; margin-top: 10px;">
                <i class="fas fa-cogs fa-2x" style="color: #9B59B6;"></i>
                <p style="font-size: 12px; color: var(--color-gray); font-family: 'Yomogi', cursive;">「この『魔法の数字』を同じにすれば、同じ結果が出やすいよ！」</p>
            </div>
        </div>
    </div>
    <p style="font-size: 12px; text-align: right; color: var(--color-gray); margin-top:5px; font-family: 'Kaisei Decol', serif;">
        参考文献: <sup>4</sup> Anthropicのドキュメント, <sup>5</sup> Googleのドキュメント, <sup>6</sup> OpenAIのドキュメントより
    </p>

    <div class="arrow-connector"></div>

    <div class="challenge-box">
        <p class="challenge-title"><i class="fas fa-exclamation-triangle"></i>複数ターン対話におけるさらなる注意点</p>
        <p>論文の著者らは、特に<span class="keyword">複数ターンの対話 (multi-turn conversations)</span> においては、LLMの応答が各ターンでわずかに分岐していくことで、その影響が積み重なり、<span class="highlight">信頼性がますます低下する</span>可能性があると警告しています。</p>
        <div style="display: flex; align-items: stretch; justify-content: space-around; margin-top: 20px; padding: 15px; background-color: rgba(255, 255, 255, 0.7); border-radius: 8px; flex-wrap: wrap;">
            <div style="text-align: center; margin:10px; width:100px;">
                <i class="fas fa-comment-dots fa-2x" style="color: var(--color-accent1);"></i>
                <p style="font-size: 13px; color: var(--color-dark); font-family: 'Yomogi', cursive;">ターン1: 最初の発言</p>
            </div>
            <div style="display: flex; align-items: center; margin:10px;"> <i class="fas fa-arrow-right fa-lg" style="color: var(--color-secondary);"></i> </div>
            <div style="text-align: center; margin:10px; width:100px;">
                <i class="fas fa-comment-medical fa-2x" style="color: var(--color-accent1); opacity:0.8;"></i>
                <p style="font-size: 13px; color: var(--color-dark); font-family: 'Yomogi', cursive;">ターン2: 少しズレた応答</p>
                <p style="font-size:10px; color:var(--color-gray);">(微小な非決定性)</p>
            </div>
            <div style="display: flex; align-items: center; margin:10px;"> <i class="fas fa-arrow-right fa-lg" style="color: var(--color-secondary);"></i> </div>
            <div style="text-align: center; margin:10px; width:100px;">
                <i class="fas fa-comment-slash fa-2x" style="color: var(--color-accent1); opacity:0.5;"></i>
                <p style="font-size: 13px; color: var(--color-dark); font-family: 'Yomogi', cursive;">ターンN: 大きくズレる可能性</p>
                <p style="font-size:10px; color:var(--color-gray);">(非決定性の蓄積)</p>
            </div>
        </div>
        <p style="margin-top:15px; text-align:center; font-style:italic; font-family: 'Kaisei Decol', serif;">💬 一度会話の مسیرがわずかにズレると、その後のターンでそのズレが拡大し、意図しない方向に会話が進んでしまうことがあります。これは、LLMとの長い対話における大きな課題の一つです。</p>
    </div>
</div>
<div class="section-card" id="Appendix_O_Prompts">
    <h2 class="section-title"><i class="fas fa-puzzle-piece"></i>Appendix O Prompts</h2>
    <div class="content-box">
        <p>このセクションでは、論文の研究で用いられた様々な「プロンプト」について、その具体的な内容を詳しく見ていきます。プロンプトとは、簡単に言うと<span class="keyword">大規模言語モデル（LLM）への指示文</span>のことです。</p>
        <p>ここに示すプロンプトは、主に以下の2つの目的で使用されました：</p>
        <ul class="unstyled-list">
            <li><i class="fas fa-cogs icon-item"></i> <strong>シャーディングプロセス：</strong> 複雑な指示をより小さな情報単位（シャード）に分割・整理するためのプロンプト群です。</li>
            <li><i class="fas fa-comments icon-item"></i> <strong>実験における会話シミュレーション：</strong> ユーザーとLLMアシスタント間の対話を模擬的に生成し、LLMの応答や振る舞いを分析するためのプロンプト群です。</li>
        </ul>
        <p>これらのプロンプトは、LLMがどのように情報を処理し、タスクを実行し、対話を進めるかを制御し、その性能を評価するための基盤となります。いわば、<span class="highlight">実験の設計図の一部</span>と言えるでしょう ✏️📝。</p>
    </div>

    <h3 class="section-title"><i class="fas fa-sitemap"></i>O.1 Sharding</h3>
    <div class="content-box">
        <p>「シャーディング（Sharding）」とは、元々一つだった完全な指示を、複数の小さな情報のかけら（シャード）に分割する処理のことです。このセクションでは、シャーディングプロセスでLLMに与えるプロンプトの具体的な例を、<span class="keyword">数学の問題解決タスク</span>を例にとって紹介します。</p>
        <p>プロンプト中に出てくる二重角括弧 <code class="highlight">[[例: INSTRUCTION]]</code> で囲まれた部分は「<span class="keyword">プレースホルダ</span>」と呼ばれ、実際の処理時には具体的なデータ（例えば、ユーザーの質問文など）に置き換えられます。</p>
        <p>他のタスク（例：プログラミング、データベース検索など）でも、基本的なプロンプトの骨格は似ていますが、それぞれのタスクで安定した品質の出力を得るために、異なる模範例（exemplars）やルールが用いられています。より詳細な、各タスク固有のプロンプトについては、論文のGitHubリポジトリ 🔗 で確認できますので、興味のある方はそちらも参照してください。</p>
    </div>

    <h4 class="section-title"><i class="fas fa-cut"></i>Segmentation</h4>
    <div class="content-box">
        <div class="bubble-box">
            <p><i class="fas fa-bullseye"></i> <strong>目的：</strong> 与えられた完全に記述された指示文を、それぞれが<span class="keyword">単一の情報を表す小さな単位（セグメント）</span>に分解します。</p>
        </div>
        <p><strong>出力形式：</strong></p>
        <p>セグメントのリストを、以下のJSON形式で出力しなければなりません：</p>
        <pre><code class="language-json">
[
  {"segment": "[指示文からの正確な抜粋]"},
  {"segment": "[指示文からの正確な抜粋]"},
  ...
]
        </code></pre>
        <div class="framework-box">
            <p class="framework-title"><i class="fas fa-ruler-combined"></i> ルール：</p>
            <ul class="unstyled-list">
                <li><i class="fas fa-object-ungroup icon-item"></i> <span class="keyword">[Non-overlapping (非重複)]</span> 各セグメントは互いに重複せず、指示文全体をカバーする必要があります。ただし、元の指示文の非本質的な部分（区切り文字、ヘッダーなど）については、任意で隙間を残しても構いません。</li>
                <li><i class="fas fa-compress-arrows-alt icon-item"></i> <span class="keyword">[Minimalistic (最小限)]</span> セグメント内の情報は、可能な限り小さく分割すべきです。もし複合的な表現（例：「X そして Y」）があれば、それは2つのセグメントに分けるべきです。各セグメントは、情報の「単位」を表すものでなければなりません。</li>
            </ul>
        </div>
        <div class="note-box">
            <p class="note-title"><i class="fas fa-clipboard-list"></i> 具体例：</p>
            <p><strong>入力クエリ (Example Query):</strong></p>
            <p><code>What are the names and locations of the stadiums that had concerts that occurred in both 2014 and 2015?</code>
            <br/>(訳：2014年と2015年の両方でコンサートが開催されたスタジアムの名前と場所は何ですか？)</p>
            <p><strong>出力 (Output):</strong></p>
            <pre><code class="language-json">
{
  "segments": [
    {"segment": "names and locations"},
    {"segment": "stadiums"},
    {"segment": "concerts"},
    {"segment": "in both 2014"},
    {"segment": "and 2015"}
  ]
}
            </code></pre>
        </div>
        <p>このタスクを、以下の完全に指定された指示文に対して実行してください：</p>
        <p><code class="highlight">[[INSTRUCTION]]</code></p>
    </div>

    <h4 class="section-title"><i class="fas fa-retweet"></i>Rephrasing</h4>
    <div class="content-box">
        <div class="bubble-box">
            <p><i class="fas fa-bullseye"></i> <strong>目的：</strong></p>
            <ol>
                <li>完全に指定された指示から得られたセグメント群の中から、<span class="keyword">複数ステップにわたる問い合わせの最初のシャード（初期シャード）</span>となるものを1つ選びます。</li>
                <li>その後、各セグメントを<span class="keyword">より自然な会話形式の表現に言い換え</span>ます。これらの言い換えられたシャードは、会話の次のターンでシステムに提供されます。</li>
            </ol>
        </div>
        <p><strong>出力形式：</strong></p>
        <p>出力は、以下の形式のJSONオブジェクトである必要があります：</p>
        <pre><code class="language-json">
{
  "initial_segment": "[指示文からの正確な抜粋]",
  "initial_shard": "初期セグメントの会話的な言い換え",
  "shards": [
    {
      "segment": "[指示文からの正確な抜粋]",
      "shard": "残りの指示内容を考慮したセグメントの会話的な言い換え"
    },
    ...
  ]
}
        </code></pre>
        <div class="framework-box">
            <p class="framework-title"><i class="fas fa-ruler-combined"></i> ルール：</p>
            <ul class="unstyled-list">
                <li><i class="fas fa-exchange-alt icon-item"></i> <span class="keyword">[Transform each segment (各セグメントを変換)]</span> 各セグメントが、初期シャードとして、あるいは残りのシャード群の中に含まれるようにしてください。どのセグメントも漏らしてはいけません。</li>
                <li><i class="fas fa-comment-dots icon-item"></i> <span class="keyword">[Short initial shard (短い初期シャード)]</span> 初期シャードは、完全な文章ではなく、短くしてください。ユーザーがGoogleのような検索エンジンを使う際のキーワード入力に似た形が望ましいです。</li>
                <li><i class="fas fa-sort-amount-down icon-item"></i> <span class="keyword">[Order of shards (シャードの順序)]</span> シャードは、初期シャードに対する重要度の高いものから低いものへと順序付けてください。入力として与えられたセグメントの元の順序を維持する必要はありません。</li>
            </ul>
        </div>
        <div class="note-box">
            <p class="note-title"><i class="fas fa-clipboard-list"></i> 具体例：</p>
            <p><strong>フルクエリ (Full Query):</strong></p>
            <p><code>What are the names and locations of the stadiums that had concerts that occurred in both 2014 and 2015?</code>
            <br/>(訳：2014年と2015年の両方でコンサートが開催されたスタジアムの名前と場所は何ですか？)</p>
            <p><strong>セグメント (Segments):</strong></p>
            <pre><code class="language-json">
[
  {"segment": "names and locations"},
  {"segment": "stadiums"},
  {"segment": "concerts"},
  {"segment": "in both 2014"},
  {"segment": "and 2015"}
]
            </code></pre>
            <p><strong>出力 (Output):</strong></p>
            <pre><code class="language-json">
{
  "initial_segment": "stadiums",
  "initial_shard": "popular stadiums",
  "shards": [
    {"segment": "concerts", "shard": "the stadiums should have concerts during a period"},
    {"segment": "in both 2014", "shard": "the concerts should have occurred in 2014 in the stadiums"},
    {"segment": "and 2015", "shard": "the concerts should have also occurred in 2015 in the same stadiums"},
    {"segment": "names and locations", "shard": "for the stadiums, returned both the name and location"}
  ]
}
            </code></pre>
        </div>
        <p>このタスクを、以下の完全に指定された指示文とセグメントに対して実行してください：</p>
        <p><strong>完全に指定された指示文 (Fully Specified Instruction):</strong></p>
        <p><code class="highlight">[[QUESTION]]</code></p>
        <p><strong>セグメント (Segments):</strong></p>
        <p><code class="highlight">[[SEGMENTS]]</code></p>
    </div>

    <h4 class="section-title"><i class="fas fa-check-double"></i>Verification</h4>
    <div class="content-box">
        <div class="bubble-box">
            <p><i class="fas fa-bullseye"></i> <strong>目的：</strong> 問題を完全に指定する指示文と、それに対応するシャードのリストが与えられた際に、<span class="keyword">元の指示文に含まれる全ての情報がシャード群によって網羅されているか</span>を判断します。</p>
            <p>もし網羅されていない情報があれば、その<span class="keyword">欠けている情報単位</span>を指示文から特定して出力します。</p>
        </div>
        <p><strong>出力形式：</strong></p>
        <p>出力は、上記の例で示されているようにJSON形式でなければなりません。</p>

        <div class="info-grid">
            <div class="info-card glass-card">
                <p class="note-title"><i class="fas fa-clipboard-list"></i> 具体例 1 (情報が網羅されている場合):</p>
                <p><strong>指示文 (Instruction):</strong></p>
                <p><code>What are the names and locations of the stadiums that had concerts that occurred in both 2014 and 2015?</code>
                <br/>(訳：2014年と2015年の両方でコンサートが開催されたスタジアムの名前と場所は何ですか？)</p>
                <p><strong>シャード群 (Shards):</strong></p>
                <pre><code class="language-json">
{
  "initial_segment": "stadiums",
  "initial_shard": "I'm looking for active stadiums",
  "shards": [
    {"segment": "concerts", "shard": "the stadiums should have concerts during a period"},
    {"segment": "in both 2014 and 2015", "shard": "the concerts should have occurred in both 2014 and \(2 \odot 1 5 ^ { " } \) "},
    {"segment": "names and locations", "shard": "for the stadiums, returned both the name and location"}
  ]
}
                </code></pre>
                <p><strong>出力 (Output):</strong></p>
                <pre><code class="language-json">
{"converage": "complete"}
                </code></pre>
                <p class="reference">(訳注：`converage` は `coverage` の誤字と思われますが、原文通り記載しています。また、数式 \(2 \odot 1 5 ^ { " } \) は原文のママです。これは "2015" を意図している可能性があります。)</p>
            </div>
            <div class="info-card glass-card">
                <p class="note-title"><i class="fas fa-clipboard-list"></i> 具体例 2 (情報が欠けている場合):</p>
                <p><strong>指示文 (Instruction):</strong></p>
                <p><code>Which Asian countries have a population that is larger than any country in Africa?</code>
                <br/>(訳：アフリカのどの国よりも人口が多いアジアの国はどれですか？)</p>
                <p><strong>シャード群 (Shards):</strong></p>
                <pre><code class="language-json">
{
  "initial_shard": "I'm interested in learning about countries in Asia",
  "shards": [
    {"shard": "consider the population size of these Asian countries"},
    {"shard": "the population should be compared in size"},
    {"shard": "specifically, compare to the population of African countries"}
  ]
}
                </code></pre>
                <p><strong>出力 (Output):</strong></p>
                <pre><code class="language-json">
{
  "coverage": "incomplete",
  "missing_segment": "the shards do not specify that the population of the Asian countries should be *larger* than the population of any African countries"
}
                </code></pre>
                <p class="reference">(訳：シャード群は、アジア諸国の人口がアフリカ諸国のどの国の人口よりも「大きい」という点を明示していません。)</p>
            </div>
        </div>
        <p>このタスクを、以下の完全に指定された指示文とシャード群に対して実行してください：</p>
        <p><strong>指示文 (Instruction):</strong> <code class="highlight">[[QUERY]]</code></p>
        <p><strong>シャード群 (Shards):</strong> <code class="highlight">[[SHARDS]]</code></p>
    </div>

    <h3 class="section-title"><i class="fas fa-flask"></i>O.2 Experiments</h3>
    <div class="content-box">
        <p>この論文の実験では、会話をシミュレートするために、特定のプロンプトを用いた複数の大規模言語モデル（LLM）呼び出しが行われました。ここでは、そのプロンプトの一部をリストアップします。</p>
        <p>これらのプロンプトが実験プロセス全体の中でどのように組み込まれているか、その詳細については、GitHubリポジトリ 🔗 を参照してください。ここでは、主要なプロンプトの役割と内容に焦点を当てて説明します。</p>
    </div>

    <h3 class="section-title"><i class="fas fa-user-astronaut"></i>User simulator</h3>
    <div class="content-box">
        <div class="bubble-box">
            <p><i class="fas fa-robot"></i> <strong>役割：</strong> あなたは、ChatGPTのような対話型LLMシステムのユーザーをシミュレートします。</p>
            <p>この<span class="keyword">シミュレートされたユーザー</span>は、本質的に怠惰であり、短い形式で応答し、システムには最小限の情報しか提供しません。積極的な行動（例：先回りして情報を提供するなど）はとるべきではありません。</p>
        </div>
        <p><strong>現在の状況：</strong></p>
        <ul class="unstyled-list">
            <li><i class="far fa-comments icon-item"></i> <strong>これまでの会話 (Here's the conversation so far):</strong> <code class="highlight">[[CONVERSATION_SO_FAR]]</code></li>
            <li><i class="fas fa-eye icon-item"></i> <strong>既に開示されたシャード (Here are the shards that have already been revealed):</strong> <code class="highlight">[[SHARDS_REVEALED]]</code></li>
            <li><i class="fas fa-eye-slash icon-item"></i> <strong>まだ開示されていない全てのシャード (Here are all the shards that have not been revealed yet):</strong> <code class="highlight">[[SHARDS_NOT_REVEALED]]</code></li>
        </ul>
        <p>これまでの会話に対して応答を生成しなければなりません。以下にルールを示します：</p>
        <div class="framework-box">
            <p class="framework-title"><i class="fas fa-gavel"></i> ルール：</p>
            <ul class="unstyled-list">
                <li><i class="fas fa-hand-holding-medical icon-item"></i> <span class="keyword">[Providing a shard (シャードの提供)]</span> システムが問題解決に近づくのに役立つ場合、応答の中でシャードの内容をシステムに開示することができます。開示すべきシャードは、最も「基本的」で、かつ現在最も関連性の高いものを選択すべきです。</li>
                <li><i class="fas fa-dice-one icon-item"></i> <span class="keyword">[One Shard at a Time (一度に1シャード)]</span> 一度に開示するシャードは最大1つだけにしてください。</li>
                <li><i class="fas fa-info-circle icon-item"></i> <span class="keyword">[Reveal Entire Shard (シャード全体の開示)]</span> シャードを開示する場合、そのシャード内の<span class="highlight">全ての情報</span>を必ず含めるようにしてください。例えば、シャードが「あなたの症状は朝に頭痛がすることです」である場合、応答は単に「ええ、頭痛があります」ではいけません。「ええ、主に朝に頭痛があります」と言うべきです。</li>
                <li><i class="fas fa-question-circle icon-item"></i> <span class="keyword">[Irrelevant Clarifications (無関係な明確化要求)]</span> システムがシャードと無関係な質問をしたり、一般的な質問（「ヒントをくれますか？」など）をしてきた場合、シャードを提供しない応答をすべきです（「分かりません」「それは本当に重要ですか？」など）。シャードで利用可能な情報以上の情報はいかなるものも開示すべきではありません。</li>
                <li><i class="fas fa-ban icon-item"></i> <span class="keyword">[No Repeated Shards (繰り返されるシャードの禁止)]</span> 同じシャードを複数回開示してはいけません。既に開示されたシャードを注意深く確認し、その<code class="highlight">shard_id</code>がリストにない場合にのみシャードを開示してください。</li>
                <li><i class="fas fa-random icon-item"></i> <span class="keyword">[Rephrase Shards (シャードの言い換え)]</span> シャードを開示する場合、それを会話的な方法で言い換えるべきです。シャードをそのままコピーしてはいけません。</li>
                <li><i class="fas fa-comment-slash icon-item"></i> <span class="keyword">[Do Not Ask Questions (質問禁止)]</span> あなたの応答は常に平叙文であるべきで、疑問文であってはなりません。</li>
                <li><i class="fas fa-feather-alt icon-item"></i> <span class="keyword">[Brevity of Response (応答の簡潔さ)]</span> 簡潔であることを優先すべきです。あなたの回答には、タイプミス、不適切な文法、大文字・小文字の誤りなどがあっても構いません。あなたは急いでいるAIと話している実在の人物をシミュレートしています。</li>
                <li><i class="fas fa-code icon-item"></i> <span class="keyword">[Format (フォーマット)]</span> あなたの応答は、以下のキーを持つJSONオブジェクトとしてフォーマットされなければなりません：
                    <ul>
                        <li><code class="highlight">response</code>: これまでの会話への応答。</li>
                        <li><code class="highlight">shard_id</code>: あなたがシステムに開示しているシャードのID。shard_idは整数、またはシャードを開示しなかった場合は-1になります。</li>
                    </ul>
                </li>
            </ul>
        </div>
        <div class="note-box">
            <p class="note-title"><i class="fas fa-lightbulb"></i> 具体例：</p>
            <p>シャードを開示しない場合:</p>
            <pre><code class="language-json">
{"response": "I don't know", "shard_id": -1}
            </code></pre>
            <p>シャードを開示する場合:</p>
            <pre><code class="language-json">
{"response": "yeah I want it to [...]", "shard_id": 1}
            </code></pre>
        </div>
    </div>

    <h3 class="section-title"><i class="fas fa-tags"></i>Response strategy categorization</h3>
    <div class="content-box">
        <div class="bubble-box">
            <p><i class="fas fa-search"></i> <strong>役割：</strong> あなたは、ユーザーとアシスタント間の複数ターンにわたる会話をレビューし、会話の最後のターンが与えられます。</p>
        </div>
        <p><strong>問題の完全な仕様：</strong></p>
        <ul class="unstyled-list">
            <li><i class="fas fa-map-pin icon-item"></i> <strong>システムが解決しようとしている問題の完全な仕様 (Here is the full specification of the problem the system is attempting to solve):</strong> <code class="highlight">[[INITIAL_SHARD]]</code></li>
            <li><i class="fas fa-list-alt icon-item"></i> <strong>仕様 (Specification):</strong> <code class="highlight">[[SHARDS]]</code></li>
        </ul>
        <p>アシスタントの応答を、以下の応答タイプに従って分類しなければなりません：</p>
        <div class="info-grid">
            <div class="info-card glass-card">
                <p><span class="badge orange">answer_attempt</span>: 応答には、ユーザーの質問に対する完全な回答試行（テンプレート化されたものや仮説的なものではない）が含まれており、そのまま抽出できます。詳細については、タスク固有の回答の説明を参照してください。</p>
            </div>
            <div class="info-card glass-card">
                <p><span class="badge blue">clarification</span>: 応答は短く（100語未満）、ユーザーのクエリのある側面について直接問い合わせる単一の質問をユーザーに対して含んでいます。明確化のターンは長くあってはならず（「discussion」を参照）、曖昧な質問を含んではならず（「discussion」を参照）、複数の質問を含んではなりません（「interrogation」を参照）。</p>
            </div>
            <div class="info-card glass-card">
                <p><span class="badge purple">interrogation</span>: 応答には、ユーザーに向けられた複数の質問が含まれており、時にはリストや箇条書きで整理されています。</p>
            </div>
            <div class="info-card glass-card">
                <p><span class="badge yellow">discussion</span>: 応答は、最終的な回答を提供したり、特定の明確化の質問をしたり、回答を拒否したりすることなく、質問について詳細に議論します。応答には、曖昧な質問（例：「他に何かお手伝いできることはありますか？」）が含まれる場合と含まれない場合があります。</p>
            </div>
            <div class="info-card glass-card">
                <p><span class="badge green">hedge</span>: 応答には、仮説（if）や分岐（ケース1、ケース2）に基づく複数の回答候補と、それに対応する説明が含まれています。</p>
            </div>
            <div class="info-card glass-card">
                <p><span class="badge red">refuse</span>: 応答には、フォローアップの質問や要求なしに、ユーザーの質問への明示的または暗黙的な回答拒否が含まれています。</p>
            </div>
            <div class="info-card glass-card">
                <p><span class="badge gray">missing</span>: 応答は空/空白です。</p>
            </div>
        </div>
        <p><strong>出力形式：</strong></p>
        <p>回答を以下のJSON形式で出力しなければなりません：</p>
        <pre><code class="language-json">
{"response_type": "refuse|missing|answer_attempt|hedge|clarification|interrogation|discussion"}
        </code></pre>
        <div class="framework-box">
            <p class="framework-title"><i class="fas fa-gavel"></i> ルール：</p>
            <ul class="unstyled-list">
                <li><i class="fas fa-lightbulb icon-item"></i> アシスタントが回答がどのように見えるかのヒントを与えることは、最終的な回答ではありません。<code class="highlight">answer_attempt</code> は、ユーザーが策定した問題に対する完全に最終的な回答を得て、この段階で会話が終了できる場合にのみ選択すべきです。</li>
                <li><i class="fas fa-tasks icon-item"></i> <span class="keyword">[Task Specific Answer (タスク固有の回答)]</span> <code class="highlight">[[ANSWER_DESCRIPTION]]</code></li>
            </ul>
        </div>
        <p><strong>会話の最後のターン (Conversation's last turn):</strong> <code class="highlight">[[CONVERSATION_SO_FAR]]</code></p>
    </div>

    <h3 class="section-title"><i class="fas fa-highlighter"></i>Answer Extraction</h3>
    <div class="content-box">
        <div class="bubble-box">
            <p><i class="fas fa-search-plus"></i> <strong>役割：</strong> あなたは、ユーザーとアシスタント間の複数ターンにわたる会話をレビューし、会話の最後のターンが与えられます。</p>
            <p>アシスタントからの最終応答には、最終的な回答が含まれています。あなたの目標は、<span class="keyword">その回答が何であるかをそのまま抽出する</span>ことです。</p>
        </div>
        <p><strong>抽出ルール：</strong></p>
        <ul class="unstyled-list">
            <li><i class="fas fa-text-width icon-item"></i> 回答が短い場合（10語未満）、その回答を<code class="highlight">answer</code>フィールドにそのままコピーすべきです。</li>
            <li><i class="fas fa-ellipsis-h icon-item"></i> 回答が長い場合、省略記号（...）を用いて回答を作成し、回答の正確な開始と終了を示すべきです（例：<code class="highlight">def funny_function(n): [...] return funny_output</code>）。省略記号の前には<span class="keyword">最低でも4語または1行全体</span>、省略記号の後にも<span class="keyword">最低でも4語または1行全体</span>を含めるべきです。これにより、回答を正確に特定できるようにします。</li>
        </ul>
        <div class="framework-box">
            <p class="framework-title"><i class="fas fa-gavel"></i> ルール：</p>
            <ul class="unstyled-list">
                <li><i class="fas fa-cut icon-item"></i> <span class="keyword">[Exact Answer Only (正確な回答のみ)]</span> 正確な回答のみを抽出し、それ以外のもの（コードブロックのバッククォート<code class="highlight">
    </code></li></ul></div>
</div></div></pre></div></div></div></div></div></body>
</html>
